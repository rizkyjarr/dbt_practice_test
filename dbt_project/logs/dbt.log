[0m02:01:58.167482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc44a050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc9a0690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc4481d0>]}


============================== 02:01:58.169998 | f30404dd-70bc-499f-b040-8dec280d234b ==============================
[0m02:01:58.169998 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:01:58.171483 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:01:58.194779 [info ] [MainThread]: dbt version: 1.9.0
[0m02:01:58.196604 [info ] [MainThread]: python version: 3.11.2
[0m02:01:58.199261 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:01:58.200610 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:01:58.202280 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:01:58.204031 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:01:58.205188 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:01:58.303120 [info ] [MainThread]: Configuration:
[0m02:01:58.304294 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m02:01:58.305538 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:01:58.306951 [info ] [MainThread]: Required dependencies:
[0m02:01:58.308008 [debug] [MainThread]: Executing "git --help"
[0m02:01:58.323742 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:01:58.324603 [debug] [MainThread]: STDERR: "b''"
[0m02:01:58.325333 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:01:58.326344 [info ] [MainThread]: Connection test skipped since no profile was found
[0m02:01:58.327995 [info ] [MainThread]: [31m1 check failed:[0m
[0m02:01:58.329152 [info ] [MainThread]: dbt looked for a profiles.yml file in /usr/app/dbt_project/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m02:01:58.331588 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.21399155, "process_in_blocks": "776", "process_kernel_time": 0.060459, "process_mem_max_rss": "90472", "process_out_blocks": "0", "process_user_time": 0.977432}
[0m02:01:58.332640 [debug] [MainThread]: Command `dbt debug` failed at 02:01:58.332515 after 0.22 seconds
[0m02:01:58.333781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc429c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cfd6d210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cfd6d150>]}
[0m02:01:58.334968 [debug] [MainThread]: Flushing usage events
[0m02:01:59.648058 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:03:01.751208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3dce910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c42af7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3dcd990>]}


============================== 02:03:01.755328 | 7f50ea83-094b-4ed3-971d-39636c6fa73a ==============================
[0m02:03:01.755328 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:03:01.756721 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:03:01.767470 [info ] [MainThread]: dbt version: 1.9.0
[0m02:03:01.768348 [info ] [MainThread]: python version: 3.11.2
[0m02:03:01.769784 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:03:01.770739 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:03:02.302614 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:03:02.303759 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:03:02.304871 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:03:02.305801 [info ] [MainThread]: adapter type: bigquery
[0m02:03:02.307297 [info ] [MainThread]: adapter version: 1.9.0
[0m02:03:02.402199 [info ] [MainThread]: Configuration:
[0m02:03:02.403292 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:03:02.404241 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:03:02.405112 [info ] [MainThread]: Required dependencies:
[0m02:03:02.406134 [debug] [MainThread]: Executing "git --help"
[0m02:03:02.408326 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:03:02.409631 [debug] [MainThread]: STDERR: "b''"
[0m02:03:02.410439 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:03:02.411349 [info ] [MainThread]: Connection:
[0m02:03:02.412438 [info ] [MainThread]:   method: service-account
[0m02:03:02.413312 [info ] [MainThread]:   database: purwadika
[0m02:03:02.414164 [info ] [MainThread]:   execution_project: purwadika
[0m02:03:02.415144 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:03:02.416415 [info ] [MainThread]:   location: None
[0m02:03:02.417588 [info ] [MainThread]:   priority: None
[0m02:03:02.418533 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:03:02.419663 [info ] [MainThread]:   impersonate_service_account: None
[0m02:03:02.420829 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:03:02.422152 [info ] [MainThread]:   job_retries: 1
[0m02:03:02.423846 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:03:02.424872 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:03:02.426031 [info ] [MainThread]:   timeout_seconds: None
[0m02:03:02.427484 [info ] [MainThread]:   client_id: None
[0m02:03:02.428781 [info ] [MainThread]:   token_uri: None
[0m02:03:02.430586 [info ] [MainThread]:   dataproc_region: None
[0m02:03:02.431899 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:03:02.432880 [info ] [MainThread]:   gcs_bucket: None
[0m02:03:02.434031 [info ] [MainThread]:   dataproc_batch: None
[0m02:03:02.435123 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:03:02.502738 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:03:02.503622 [debug] [MainThread]: On debug: select 1 as id
[0m02:03:02.504454 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:02.531994 [debug] [MainThread]: BigQuery adapter: Got an error when attempting to create a bigquery " "client: '[Errno 21] Is a directory: '/root/.dbt/credentials.json''
[0m02:03:02.533124 [debug] [MainThread]: BigQuery adapter: Unhandled error while running:
select 1 as id
[0m02:03:02.534054 [debug] [MainThread]: BigQuery adapter: Database Error
  [Errno 21] Is a directory: '/root/.dbt/credentials.json'
[0m02:03:02.534785 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m02:03:02.535672 [info ] [MainThread]: [31m1 check failed:[0m
[0m02:03:02.536718 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >'NoneType' object has no attribute 'close'

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m02:03:02.538374 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.8450967, "process_in_blocks": "696", "process_kernel_time": 0.1747, "process_mem_max_rss": "207440", "process_out_blocks": "24", "process_user_time": 2.733544}
[0m02:03:02.539326 [debug] [MainThread]: Command `dbt debug` failed at 02:03:02.539222 after 0.85 seconds
[0m02:03:02.540230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3e04450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5896576250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c4aaf290>]}
[0m02:03:02.541443 [debug] [MainThread]: Flushing usage events
[0m02:03:03.693784 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:04:31.038959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596e53810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596f60e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596e87090>]}


============================== 02:04:31.043418 | 81d713c9-fbc7-4523-921b-5a295ad22e3d ==============================
[0m02:04:31.043418 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:04:31.044686 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:04:31.051027 [info ] [MainThread]: dbt version: 1.9.0
[0m02:04:31.051864 [info ] [MainThread]: python version: 3.11.2
[0m02:04:31.054054 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:04:31.055178 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:04:31.556857 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:04:31.558394 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:04:31.559756 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:04:31.561102 [info ] [MainThread]: adapter type: bigquery
[0m02:04:31.562446 [info ] [MainThread]: adapter version: 1.9.0
[0m02:04:31.641979 [info ] [MainThread]: Configuration:
[0m02:04:31.644292 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:04:31.645262 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:04:31.646400 [info ] [MainThread]: Required dependencies:
[0m02:04:31.647547 [debug] [MainThread]: Executing "git --help"
[0m02:04:31.649460 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:04:31.650135 [debug] [MainThread]: STDERR: "b''"
[0m02:04:31.650881 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:04:31.651960 [info ] [MainThread]: Connection:
[0m02:04:31.653391 [info ] [MainThread]:   method: service-account
[0m02:04:31.654439 [info ] [MainThread]:   database: purwadika
[0m02:04:31.655544 [info ] [MainThread]:   execution_project: purwadika
[0m02:04:31.656705 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:04:31.659063 [info ] [MainThread]:   location: None
[0m02:04:31.660554 [info ] [MainThread]:   priority: None
[0m02:04:31.661527 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:04:31.662408 [info ] [MainThread]:   impersonate_service_account: None
[0m02:04:31.663369 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:04:31.664496 [info ] [MainThread]:   job_retries: 1
[0m02:04:31.665590 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:04:31.666913 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:04:31.667968 [info ] [MainThread]:   timeout_seconds: None
[0m02:04:31.668867 [info ] [MainThread]:   client_id: None
[0m02:04:31.669906 [info ] [MainThread]:   token_uri: None
[0m02:04:31.670765 [info ] [MainThread]:   dataproc_region: None
[0m02:04:31.671720 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:04:31.672753 [info ] [MainThread]:   gcs_bucket: None
[0m02:04:31.673635 [info ] [MainThread]:   dataproc_batch: None
[0m02:04:31.674714 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:04:31.729175 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:04:31.730186 [debug] [MainThread]: On debug: select 1 as id
[0m02:04:31.731072 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:04:32.794278 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:87d88a11-3360-405e-8b46-a8ca6bbbbf3c&page=queryresults
[0m02:04:33.636786 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:04:33.638193 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:04:33.639993 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.6463816, "process_in_blocks": "1728", "process_kernel_time": 0.200069, "process_mem_max_rss": "212840", "process_out_blocks": "1952", "process_user_time": 2.727258}
[0m02:04:33.641273 [debug] [MainThread]: Command `dbt debug` succeeded at 02:04:33.641161 after 2.65 seconds
[0m02:04:33.642154 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:04:33.643123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596ccfed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd59a8ed810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd59a5f4b90>]}
[0m02:04:33.644089 [debug] [MainThread]: Flushing usage events
[0m02:04:35.179263 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:13:23.075436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d3efc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d3eed10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d4f9c90>]}


============================== 02:13:23.078000 | c09a6ece-1481-4071-b0cc-401b4b306eb2 ==============================
[0m02:13:23.078000 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:13:23.079859 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:13:23.657306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df58ee90>]}
[0m02:13:23.701756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df668f10>]}
[0m02:13:23.703096 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:13:23.769821 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:13:23.772243 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:13:23.773545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df304610>]}
[0m02:13:24.778057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df184190>]}
[0m02:13:24.848924 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:13:24.854999 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:13:24.878854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dd7f51d0>]}
[0m02:13:24.880016 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:13:24.881104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df174a90>]}
[0m02:13:24.883858 [info ] [MainThread]: 
[0m02:13:24.884947 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:13:24.885962 [info ] [MainThread]: 
[0m02:13:24.887547 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:13:24.892377 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:13:24.893723 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:13:25.533676 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_staging_layer)
[0m02:13:25.534636 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_staging_layer"
"
[0m02:13:25.544110 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_staging_layer`
  
[0m02:13:25.545018 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:13:26.420654 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ff549e3d-6554-4cfb-bd1b-ec70f66fdf2b&page=queryresults
[0m02:13:27.364350 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_staging_layer, now list_purwadika_rizky_dwh_hailing_source_staging_layer)
[0m02:13:27.365587 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:13:27.962897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df3d4a90>]}
[0m02:13:27.964146 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:13:27.968860 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:13:27.969238 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:13:27.969552 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:13:27.969869 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:13:27.970397 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_customer  [RUN]
[0m02:13:27.971371 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_driver  [RUN]
[0m02:13:27.972555 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_ride  [RUN]
[0m02:13:27.973745 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_vehicle  [RUN]
[0m02:13:27.974666 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_staging_layer, now model.hailing_project.stg_customer)
[0m02:13:27.975693 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:13:27.976480 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:13:27.977492 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:13:27.978532 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:13:27.979457 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:13:27.980371 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:13:27.981171 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:13:27.990440 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:13:27.993778 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:13:27.997289 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:13:28.002557 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:13:28.013883 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:13:28.020199 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:13:28.055805 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:13:28.077280 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:13:28.094918 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:13:28.095777 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:13:28.098535 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:13:28.102086 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:13:28.113235 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:13:28.114468 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:13:28.114968 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:13:28.116441 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:13:28.117278 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:13:28.118506 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:13:28.120172 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:13:28.168238 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:13:28.521749 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:646f9616-63cc-45b6-bf88-99d73b4ed749&page=queryresults
[0m02:13:28.523204 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:646f9616-63cc-45b6-bf88-99d73b4ed749&page=queryresults
[0m02:13:28.528143 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f54b5075-3bf2-4aba-9c4a-dd2e97f5d340&page=queryresults
[0m02:13:28.529736 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33a93330-c5ad-4749-9727-560eebeb7501&page=queryresults
[0m02:13:28.530267 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f54b5075-3bf2-4aba-9c4a-dd2e97f5d340&page=queryresults
[0m02:13:28.531426 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33a93330-c5ad-4749-9727-560eebeb7501&page=queryresults
[0m02:13:28.541292 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:13:28.542367 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:13:28.543449 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:13:28.545777 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df15de50>]}
[0m02:13:28.546575 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dcc6e4d0>]}
[0m02:13:28.547746 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dcb1f610>]}
[0m02:13:28.549150 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_vehicle  [[31mERROR[0m in 0.57s]
[0m02:13:28.551069 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_customer  [[31mERROR[0m in 0.57s]
[0m02:13:28.553330 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_driver  [[31mERROR[0m in 0.57s]
[0m02:13:28.554927 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:13:28.556276 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:13:28.557515 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:13:28.558931 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:13:28.561649 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:13:28.562905 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:13:28.565097 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4885aa9d-e541-4d05-bcc8-860385bcb7c1&page=queryresults
[0m02:13:28.566302 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4885aa9d-e541-4d05-bcc8-860385bcb7c1&page=queryresults
[0m02:13:28.570401 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:13:28.571656 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dd7053d0>]}
[0m02:13:28.572987 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_ride  [[31mERROR[0m in 0.60s]
[0m02:13:28.574379 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:13:28.575882 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:13:28.578237 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:13:28.581305 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:13:28.581993 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:13:28.582844 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:13:28.583559 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:13:28.584355 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:13:28.585086 [info ] [MainThread]: 
[0m02:13:28.586045 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.70 seconds (3.70s).
[0m02:13:28.587818 [debug] [MainThread]: Command end result
[0m02:13:28.623846 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:13:28.628422 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:13:28.637064 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:13:28.637811 [info ] [MainThread]: 
[0m02:13:28.638883 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:13:28.640157 [info ] [MainThread]: 
[0m02:13:28.642484 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:13:28.644360 [info ] [MainThread]: 
[0m02:13:28.645843 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:13:28.646854 [info ] [MainThread]: 
[0m02:13:28.647998 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:13:28.649370 [info ] [MainThread]: 
[0m02:13:28.651287 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:13:28.652467 [info ] [MainThread]: 
[0m02:13:28.653536 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:13:28.655363 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.626566, "process_in_blocks": "2952", "process_kernel_time": 0.239406, "process_mem_max_rss": "227664", "process_out_blocks": "120", "process_user_time": 3.980132}
[0m02:13:28.656716 [debug] [MainThread]: Command `dbt run` failed at 02:13:28.656571 after 5.63 seconds
[0m02:13:28.657757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d26fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d26f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff410d3c910>]}
[0m02:13:28.659269 [debug] [MainThread]: Flushing usage events
[0m02:13:29.808444 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:45.087750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0a810>]}


============================== 02:18:45.090624 | 4a4e9f48-a67f-4b7f-8886-913783f5298a ==============================
[0m02:18:45.090624 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:45.091889 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:18:45.170120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a4e9f48-a67f-4b7f-8886-913783f5298a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165dd4a150>]}
[0m02:18:45.236071 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19432564, "process_in_blocks": "16", "process_kernel_time": 0.09933, "process_mem_max_rss": "90056", "process_out_blocks": "0", "process_user_time": 0.913843}
[0m02:18:45.237553 [debug] [MainThread]: Command `dbt clean` succeeded at 02:18:45.237391 after 0.20 seconds
[0m02:18:45.238719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de5fc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de5fc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1661600c10>]}
[0m02:18:45.239771 [debug] [MainThread]: Flushing usage events
[0m02:18:46.409339 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:47.583171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa9834b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa988b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa9c2de50>]}


============================== 02:18:47.586327 | bdee2df0-a205-4d95-a78f-035433b48340 ==============================
[0m02:18:47.586327 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:47.587616 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:18:47.673552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bdee2df0-a205-4d95-a78f-035433b48340', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa96e7590>]}
[0m02:18:47.687732 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:18:47.690576 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:18:47.692333 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15736815, "process_in_blocks": "224", "process_kernel_time": 0.099129, "process_mem_max_rss": "90016", "process_out_blocks": "0", "process_user_time": 1.001206}
[0m02:18:47.693464 [debug] [MainThread]: Command `dbt deps` succeeded at 02:18:47.693309 after 0.16 seconds
[0m02:18:47.694459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad028c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad185350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad1850d0>]}
[0m02:18:47.695615 [debug] [MainThread]: Flushing usage events
[0m02:18:48.762707 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:52.308476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38623fb090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38624289d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3862429210>]}


============================== 02:18:52.311249 | 995e2a61-4840-4443-befc-8244674169b3 ==============================
[0m02:18:52.311249 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:52.312645 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:18:52.907063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38623fded0>]}
[0m02:18:52.955932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383885ef10>]}
[0m02:18:52.957296 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:18:53.026383 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:18:53.028816 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:18:53.029763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38386fdcd0>]}
[0m02:18:54.032005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38381e0890>]}
[0m02:18:54.103335 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:18:54.109105 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:18:54.126461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38381fe650>]}
[0m02:18:54.127461 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:18:54.128376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3838301450>]}
[0m02:18:54.130972 [info ] [MainThread]: 
[0m02:18:54.132065 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:18:54.133306 [info ] [MainThread]: 
[0m02:18:54.134660 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:18:54.139423 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:18:54.140644 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:18:54.790776 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer)
[0m02:18:54.791786 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer"
"
[0m02:18:54.799925 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`
  
[0m02:18:54.800625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:18:55.669445 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:285fe163-a733-42d8-bdca-8b8d38f7b5b4&page=queryresults
[0m02:18:56.649128 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer)
[0m02:18:56.650897 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:18:57.247028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38385a43d0>]}
[0m02:18:57.247999 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:18:57.253541 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:18:57.253984 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:18:57.254370 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:18:57.254750 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:18:57.255599 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_customer  [RUN]
[0m02:18:57.256713 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_driver  [RUN]
[0m02:18:57.258216 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_ride  [RUN]
[0m02:18:57.259397 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_vehicle  [RUN]
[0m02:18:57.260814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer, now model.hailing_project.stg_customer)
[0m02:18:57.261950 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:18:57.263136 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:18:57.264714 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:18:57.266058 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:18:57.268773 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:18:57.271434 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:18:57.273046 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:18:57.284746 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:18:57.289441 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:18:57.294893 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:18:57.299210 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:18:57.310739 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:18:57.317324 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:18:57.376507 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:18:57.382602 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:18:57.390017 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:18:57.390640 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:18:57.393482 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:18:57.397157 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:18:57.408477 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:18:57.410030 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:18:57.410566 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:18:57.411426 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:18:57.413100 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:18:57.413703 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:18:57.438615 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:18:57.441446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:18:57.764466 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6107e896-4330-4e03-92fd-74ee8ca3a5bf&page=queryresults
[0m02:18:57.767348 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6107e896-4330-4e03-92fd-74ee8ca3a5bf&page=queryresults
[0m02:18:57.768242 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c7171be9-3886-4586-806c-f92482b5aba9&page=queryresults
[0m02:18:57.771344 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c7171be9-3886-4586-806c-f92482b5aba9&page=queryresults
[0m02:18:57.774681 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:18:57.777527 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:18:57.779421 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2c108a5b-ad82-48ce-aaae-e21c5ac369d1&page=queryresults
[0m02:18:57.779887 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831dde650>]}
[0m02:18:57.780818 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831ca1250>]}
[0m02:18:57.781873 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2c108a5b-ad82-48ce-aaae-e21c5ac369d1&page=queryresults
[0m02:18:57.783172 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_driver  [[31mERROR[0m in 0.52s]
[0m02:18:57.784548 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_vehicle  [[31mERROR[0m in 0.52s]
[0m02:18:57.788188 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:18:57.789031 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:18:57.790559 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:18:57.792189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831c256d0>]}
[0m02:18:57.793376 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:18:57.795166 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_customer  [[31mERROR[0m in 0.53s]
[0m02:18:57.796610 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:18:57.797827 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:18:57.800033 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:18:57.840670 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:703422ab-858d-4051-99c6-58851df2b19d&page=queryresults
[0m02:18:57.842184 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:703422ab-858d-4051-99c6-58851df2b19d&page=queryresults
[0m02:18:57.846614 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:18:57.847909 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831c30c10>]}
[0m02:18:57.849065 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_ride  [[31mERROR[0m in 0.58s]
[0m02:18:57.850382 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:18:57.851855 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:18:57.854570 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:18:57.857707 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:18:57.858629 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:18:57.859634 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:18:57.860714 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:18:57.861703 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:18:57.862721 [info ] [MainThread]: 
[0m02:18:57.863614 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.73 seconds (3.73s).
[0m02:18:57.865233 [debug] [MainThread]: Command end result
[0m02:18:57.896602 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:18:57.900681 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:18:57.908344 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:18:57.909181 [info ] [MainThread]: 
[0m02:18:57.910394 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:18:57.911592 [info ] [MainThread]: 
[0m02:18:57.912736 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:18:57.913900 [info ] [MainThread]: 
[0m02:18:57.915756 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:18:57.917607 [info ] [MainThread]: 
[0m02:18:57.919166 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:18:57.920601 [info ] [MainThread]: 
[0m02:18:57.922638 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:18:57.924235 [info ] [MainThread]: 
[0m02:18:57.926002 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:18:57.929051 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.6718855, "process_in_blocks": "0", "process_kernel_time": 0.240604, "process_mem_max_rss": "228632", "process_out_blocks": "0", "process_user_time": 4.130384}
[0m02:18:57.930771 [debug] [MainThread]: Command `dbt run` failed at 02:18:57.930469 after 5.67 seconds
[0m02:18:57.932291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38627f2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865ee57d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865d70850>]}
[0m02:18:57.933518 [debug] [MainThread]: Flushing usage events
[0m02:18:58.973754 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:43.036703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f4546e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f459b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f493e110>]}


============================== 02:19:43.039152 | 7f508b4b-59f7-4147-8cd6-0d08a45c1978 ==============================
[0m02:19:43.039152 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:43.040884 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:19:43.124750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f508b4b-59f7-4147-8cd6-0d08a45c1978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f493e4d0>]}
[0m02:19:43.174142 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18960154, "process_in_blocks": "0", "process_kernel_time": 0.080068, "process_mem_max_rss": "90120", "process_out_blocks": "0", "process_user_time": 0.930793}
[0m02:19:43.175183 [debug] [MainThread]: Command `dbt clean` succeeded at 02:19:43.175049 after 0.19 seconds
[0m02:19:43.176197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f45a3050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f45a3150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f7d10c10>]}
[0m02:19:43.177249 [debug] [MainThread]: Flushing usage events
[0m02:19:44.249420 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:45.393126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d1af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d6b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d1ab10>]}


============================== 02:19:45.395761 | 50629c51-5b48-4916-bf16-b08f55f53855 ==============================
[0m02:19:45.395761 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:45.397063 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:19:45.475692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '50629c51-5b48-4916-bf16-b08f55f53855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9bc6d50>]}
[0m02:19:45.485546 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:19:45.488201 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:19:45.489894 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.14864384, "process_in_blocks": "0", "process_kernel_time": 0.059938, "process_mem_max_rss": "90020", "process_out_blocks": "0", "process_user_time": 1.018951}
[0m02:19:45.490991 [debug] [MainThread]: Command `dbt deps` succeeded at 02:19:45.490853 after 0.15 seconds
[0m02:19:45.491753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ecd508c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5eca10e150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d19910>]}
[0m02:19:45.492620 [debug] [MainThread]: Flushing usage events
[0m02:19:46.645759 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:47.798072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3a57b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e02510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e023d0>]}


============================== 02:19:47.800876 | 36b4bddf-c76d-46a3-ba6c-257ff399de47 ==============================
[0m02:19:47.800876 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:47.802377 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:19:48.399327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5d91d50>]}
[0m02:19:48.443383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced5c7c850>]}
[0m02:19:48.444634 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:19:48.514047 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:19:48.516226 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:19:48.517453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5b93790>]}
[0m02:19:49.503689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea57e90d0>]}
[0m02:19:49.568227 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:19:49.574022 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:19:49.589989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5887290>]}
[0m02:19:49.591258 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:19:49.592417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5a61790>]}
[0m02:19:49.594991 [info ] [MainThread]: 
[0m02:19:49.596181 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:19:49.597270 [info ] [MainThread]: 
[0m02:19:49.598509 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:19:49.603426 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:19:49.604465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:19:50.214126 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:19:50.215642 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer"
"
[0m02:19:50.229867 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`
  
[0m02:19:50.231396 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:19:51.075076 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:eff2262a-9599-4bac-8e25-f6defc77ceb5&page=queryresults
[0m02:19:52.051860 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:19:52.052882 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:19:52.647637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5884410>]}
[0m02:19:52.649546 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:19:52.654428 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:19:52.654897 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:19:52.655325 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:19:52.655779 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:19:52.656379 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [RUN]
[0m02:19:52.657696 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [RUN]
[0m02:19:52.659094 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [RUN]
[0m02:19:52.660466 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [RUN]
[0m02:19:52.661523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now model.hailing_project.stg_customer)
[0m02:19:52.662659 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:19:52.663775 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:19:52.665131 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:19:52.666395 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:19:52.667350 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:19:52.668200 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:19:52.669164 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:19:52.678200 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:19:52.681497 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:19:52.685727 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:19:52.689378 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:19:52.702546 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:19:52.709417 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:19:52.742979 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:19:52.743343 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:19:52.782538 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:19:52.785044 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:19:52.785581 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:19:52.788713 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:19:52.801166 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:19:52.802363 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:19:52.803163 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:19:52.804698 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:19:52.805201 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:19:52.807701 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:19:52.809056 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:19:52.835926 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:19:53.069577 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:efbadefb-97fe-4c22-a6c8-b73c0fb171d7&page=queryresults
[0m02:19:53.070866 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:efbadefb-97fe-4c22-a6c8-b73c0fb171d7&page=queryresults
[0m02:19:53.076360 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:19:53.079108 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f3e5450>]}
[0m02:19:53.080368 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [[31mERROR[0m in 0.42s]
[0m02:19:53.081709 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:19:53.083138 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:19:53.160594 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:70c69ada-06e4-4a82-a967-4279d5e053f4&page=queryresults
[0m02:19:53.161707 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:70c69ada-06e4-4a82-a967-4279d5e053f4&page=queryresults
[0m02:19:53.165304 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:19:53.166187 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f140950>]}
[0m02:19:53.167406 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [[31mERROR[0m in 0.50s]
[0m02:19:53.168375 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:19:53.169604 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:19:53.189273 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dbf52f61-28b6-4b38-9bd0-87e904709498&page=queryresults
[0m02:19:53.190659 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dbf52f61-28b6-4b38-9bd0-87e904709498&page=queryresults
[0m02:19:53.194317 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:19:53.195547 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f132d90>]}
[0m02:19:53.196796 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [[31mERROR[0m in 0.53s]
[0m02:19:53.198030 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:19:53.199262 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:19:53.206344 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9d6d5eab-a475-46fa-9d54-3c7d7e00878d&page=queryresults
[0m02:19:53.207441 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9d6d5eab-a475-46fa-9d54-3c7d7e00878d&page=queryresults
[0m02:19:53.210872 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:19:53.212108 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f3f4390>]}
[0m02:19:53.213401 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [[31mERROR[0m in 0.55s]
[0m02:19:53.214467 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:19:53.215679 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:19:53.217446 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:19:53.221052 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:19:53.221827 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:19:53.222608 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:19:53.223536 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:19:53.224323 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:19:53.225250 [info ] [MainThread]: 
[0m02:19:53.226377 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.63 seconds (3.63s).
[0m02:19:53.228128 [debug] [MainThread]: Command end result
[0m02:19:53.264122 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:19:53.269292 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:19:53.278390 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:19:53.279099 [info ] [MainThread]: 
[0m02:19:53.280452 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:19:53.281929 [info ] [MainThread]: 
[0m02:19:53.283440 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:19:53.284486 [info ] [MainThread]: 
[0m02:19:53.285700 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:19:53.286808 [info ] [MainThread]: 
[0m02:19:53.288665 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:19:53.290195 [info ] [MainThread]: 
[0m02:19:53.292798 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:19:53.296067 [info ] [MainThread]: 
[0m02:19:53.298499 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:19:53.301766 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.559815, "process_in_blocks": "0", "process_kernel_time": 0.159599, "process_mem_max_rss": "227496", "process_out_blocks": "0", "process_user_time": 4.199452}
[0m02:19:53.304129 [debug] [MainThread]: Command `dbt run` failed at 02:19:53.303881 after 5.56 seconds
[0m02:19:53.309675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e028d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced5b8aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3a3f190>]}
[0m02:19:53.312580 [debug] [MainThread]: Flushing usage events
[0m02:19:54.432570 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:22:59.298886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de2c90>]}


============================== 02:22:59.301439 | 598de295-1704-4dee-b3ae-d4343be14bee ==============================
[0m02:22:59.301439 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:22:59.304163 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:22:59.897242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc559f64b50>]}
[0m02:22:59.941040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58505a210>]}
[0m02:22:59.942289 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:23:00.011330 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:23:00.078598 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m02:23:00.079893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc583be4390>]}
[0m02:23:01.075126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558fa2d10>]}
[0m02:23:01.141482 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:23:01.148081 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:23:01.161756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc543122a50>]}
[0m02:23:01.162979 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:23:01.164993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558dea390>]}
[0m02:23:01.168040 [info ] [MainThread]: 
[0m02:23:01.169154 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:23:01.170684 [info ] [MainThread]: 
[0m02:23:01.172194 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:23:01.176700 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:23:01.177769 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:23:02.337608 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:23:02.338814 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:23:02.888646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558e3d850>]}
[0m02:23:02.893292 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:23:02.898715 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:23:02.899162 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:23:02.899561 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:23:02.899911 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:23:02.900627 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [RUN]
[0m02:23:02.902948 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [RUN]
[0m02:23:02.905319 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [RUN]
[0m02:23:02.907001 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [RUN]
[0m02:23:02.908807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now model.hailing_project.stg_customer)
[0m02:23:02.910166 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:23:02.911458 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:23:02.912759 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:23:02.914024 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:23:02.914986 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:23:02.915994 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:23:02.916878 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:23:02.926278 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:23:02.929758 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:23:02.933442 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:23:02.937378 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:23:02.943149 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:23:02.944703 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:23:02.951044 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:23:02.951686 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:23:03.023351 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:23:03.026136 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:23:03.026779 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:23:03.029786 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:23:03.038455 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:23:03.039788 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:23:03.040237 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:23:03.041026 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:23:03.041683 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:23:03.042414 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:23:03.043246 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:23:03.044854 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:23:03.359713 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79e5f65c-7115-4456-8243-3c91fd64924f&page=queryresults
[0m02:23:03.361730 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79e5f65c-7115-4456-8243-3c91fd64924f&page=queryresults
[0m02:23:03.362561 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86310e65-be7e-4ea7-b55f-428455560bc9&page=queryresults
[0m02:23:03.365437 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86310e65-be7e-4ea7-b55f-428455560bc9&page=queryresults
[0m02:23:03.369647 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:23:03.370817 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:23:03.372341 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc507709590>]}
[0m02:23:03.373028 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5431e9b10>]}
[0m02:23:03.374161 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [[31mERROR[0m in 0.46s]
[0m02:23:03.375896 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [[31mERROR[0m in 0.46s]
[0m02:23:03.377233 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:23:03.378654 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:23:03.380169 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:23:03.381903 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:23:03.413141 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a793c2ef-2f5d-41b2-a0a1-9a8012d35841&page=queryresults
[0m02:23:03.414247 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a793c2ef-2f5d-41b2-a0a1-9a8012d35841&page=queryresults
[0m02:23:03.417566 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:23:03.418427 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc507728cd0>]}
[0m02:23:03.419705 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [[31mERROR[0m in 0.51s]
[0m02:23:03.420942 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:23:03.422227 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:23:03.431591 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4f7e0877-0170-42bf-8f06-39971f85f0b7&page=queryresults
[0m02:23:03.433212 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4f7e0877-0170-42bf-8f06-39971f85f0b7&page=queryresults
[0m02:23:03.436933 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:23:03.438133 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5432431d0>]}
[0m02:23:03.439279 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [[31mERROR[0m in 0.53s]
[0m02:23:03.440640 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:23:03.442280 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:23:03.444426 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:23:03.447601 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:23:03.448553 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:23:03.449372 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:23:03.450095 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:23:03.450805 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:23:03.451757 [info ] [MainThread]: 
[0m02:23:03.452678 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 2.28 seconds (2.28s).
[0m02:23:03.454381 [debug] [MainThread]: Command end result
[0m02:23:03.485186 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:23:03.490386 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:23:03.497818 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:23:03.498665 [info ] [MainThread]: 
[0m02:23:03.499917 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:23:03.500952 [info ] [MainThread]: 
[0m02:23:03.502062 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:23:03.503073 [info ] [MainThread]: 
[0m02:23:03.504059 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:23:03.505185 [info ] [MainThread]: 
[0m02:23:03.506282 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:23:03.507134 [info ] [MainThread]: 
[0m02:23:03.508120 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:23:03.509039 [info ] [MainThread]: 
[0m02:23:03.510102 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:23:03.511788 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.2606525, "process_in_blocks": "0", "process_kernel_time": 0.212551, "process_mem_max_rss": "224192", "process_out_blocks": "0", "process_user_time": 4.078972}
[0m02:23:03.512753 [debug] [MainThread]: Command `dbt run` failed at 02:23:03.512647 after 4.26 seconds
[0m02:23:03.513724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582e5d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582e5f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58675d150>]}
[0m02:23:03.514650 [debug] [MainThread]: Flushing usage events
[0m02:23:05.016646 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:10.061335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bafa2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bb4503d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7baff71d0>]}


============================== 02:27:10.063905 | 31c668d0-44a8-423d-9cba-07485a1d97cc ==============================
[0m02:27:10.063905 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:10.065631 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:27:10.142962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '31c668d0-44a8-423d-9cba-07485a1d97cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bae36950>]}
[0m02:27:10.196558 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18368678, "process_in_blocks": "0", "process_kernel_time": 0.081932, "process_mem_max_rss": "90140", "process_out_blocks": "0", "process_user_time": 0.92174}
[0m02:27:10.197709 [debug] [MainThread]: Command `dbt clean` succeeded at 02:27:10.197592 after 0.19 seconds
[0m02:27:10.198861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bb39a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7be8f1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bafa1850>]}
[0m02:27:10.199813 [debug] [MainThread]: Flushing usage events
[0m02:27:11.381765 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:12.492552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb382950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb3c0790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb77de10>]}


============================== 02:27:12.495880 | 105f7905-72f4-4f26-b25a-0023adc54469 ==============================
[0m02:27:12.495880 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:12.497159 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt deps', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:27:12.581002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '105f7905-72f4-4f26-b25a-0023adc54469', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb3d5950>]}
[0m02:27:12.591820 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:27:12.594827 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:27:12.596546 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15206721, "process_in_blocks": "0", "process_kernel_time": 0.079586, "process_mem_max_rss": "90212", "process_out_blocks": "0", "process_user_time": 0.974936}
[0m02:27:12.597503 [debug] [MainThread]: Command `dbt deps` succeeded at 02:27:12.597373 after 0.15 seconds
[0m02:27:12.598341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb77e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fec6ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fecfd5d0>]}
[0m02:27:12.599115 [debug] [MainThread]: Flushing usage events
[0m02:27:13.667226 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:18.126541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9375bbed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9379b2610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9379b24d0>]}


============================== 02:27:18.129205 | ed0e3112-f793-4b76-89d4-df3e53df2e2c ==============================
[0m02:27:18.129205 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:18.130468 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:27:18.714561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9097b8450>]}
[0m02:27:18.757460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff939868890>]}
[0m02:27:18.758844 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:27:18.827246 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:27:18.829601 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:27:18.830408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff937615d10>]}
[0m02:27:19.666752 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:27:19.668956 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5943345, "process_in_blocks": "16", "process_kernel_time": 0.234997, "process_mem_max_rss": "211636", "process_out_blocks": "0", "process_user_time": 3.412571}
[0m02:27:19.670237 [debug] [MainThread]: Command `dbt run` failed at 02:27:19.670097 after 1.60 seconds
[0m02:27:19.671146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9375ea510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff937a70410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90967fe50>]}
[0m02:27:19.672119 [debug] [MainThread]: Flushing usage events
[0m02:27:20.698749 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:19.756932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4fd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e02a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e022d0>]}


============================== 02:29:19.759598 | cfa47e46-00f7-47de-9070-f6658cefd0e9 ==============================
[0m02:29:19.759598 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:19.763323 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:29:19.842269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cfa47e46-00f7-47de-9070-f6658cefd0e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876cc7150>]}
[0m02:29:19.857803 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.14823915, "process_in_blocks": "0", "process_kernel_time": 0.118135, "process_mem_max_rss": "90124", "process_out_blocks": "0", "process_user_time": 0.905702}
[0m02:29:19.858795 [debug] [MainThread]: Command `dbt clean` succeeded at 02:29:19.858683 after 0.15 seconds
[0m02:29:19.859609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4f8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876f11b10>]}
[0m02:29:19.860396 [debug] [MainThread]: Flushing usage events
[0m02:29:21.008618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:36.098313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb763a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb7a7090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb762b10>]}


============================== 02:29:36.100834 | ae7e7a25-d2f8-4c6c-97f2-7663699b82f7 ==============================
[0m02:29:36.100834 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:36.102185 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m02:29:36.182096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ae7e7a25-d2f8-4c6c-97f2-7663699b82f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb7dbdd0>]}
[0m02:29:36.192091 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:29:36.195892 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:29:36.197299 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1474884, "process_in_blocks": "0", "process_kernel_time": 0.089347, "process_mem_max_rss": "89884", "process_out_blocks": "0", "process_user_time": 0.93318}
[0m02:29:36.198655 [debug] [MainThread]: Command `dbt deps` succeeded at 02:29:36.198507 after 0.15 seconds
[0m02:29:36.199593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfef5cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dff0e1390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dff0e1110>]}
[0m02:29:36.200359 [debug] [MainThread]: Flushing usage events
[0m02:29:37.248158 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:42.747893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17872e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1793e7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff178afe550>]}


============================== 02:29:42.750836 | f2242523-1c80-44d8-8022-7848c9aa47cc ==============================
[0m02:29:42.750836 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:42.752017 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt compile', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:29:43.366137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff14a90e2d0>]}
[0m02:29:43.412740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff14a950f10>]}
[0m02:29:43.413928 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:29:43.485356 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:29:43.487673 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:29:43.488700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17858c590>]}
[0m02:29:44.327713 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:29:44.329316 [debug] [MainThread]: Resource report: {"command_name": "compile", "command_success": false, "command_wall_clock_time": 1.6324943, "process_in_blocks": "0", "process_kernel_time": 0.18059, "process_mem_max_rss": "212028", "process_out_blocks": "0", "process_user_time": 3.551614}
[0m02:29:44.330421 [debug] [MainThread]: Command `dbt compile` failed at 02:29:44.330251 after 1.63 seconds
[0m02:29:44.331210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17857be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17857bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17c07d0d0>]}
[0m02:29:44.332149 [debug] [MainThread]: Flushing usage events
[0m02:29:45.589524 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:53.502418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca52fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca85a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca86f50>]}


============================== 02:29:53.505798 | 41cb02dc-0cc4-4c1b-965c-9dc620114dec ==============================
[0m02:29:53.505798 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:53.507274 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:29:54.116437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca53490>]}
[0m02:29:54.168556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ed06250>]}
[0m02:29:54.169894 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:29:54.238174 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:29:54.240432 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:29:54.241225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180ebe17d0>]}
[0m02:29:55.066343 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:29:55.068222 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.617304, "process_in_blocks": "0", "process_kernel_time": 0.131437, "process_mem_max_rss": "211732", "process_out_blocks": "0", "process_user_time": 3.548801}
[0m02:29:55.069459 [debug] [MainThread]: Command `dbt run` failed at 02:29:55.069352 after 1.62 seconds
[0m02:29:55.070305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca98910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180eaa7810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1840409210>]}
[0m02:29:55.071221 [debug] [MainThread]: Flushing usage events
[0m02:29:56.099082 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:30:20.664628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46baa52b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b9343350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b8a49f10>]}


============================== 02:30:20.667132 | 4630e5b5-e768-46ab-8517-fec3768dbd26 ==============================
[0m02:30:20.667132 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:30:20.668783 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:30:21.213151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a7f5fd0>]}
[0m02:30:21.262779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46ba8c6250>]}
[0m02:30:21.263928 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:30:21.327974 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:30:21.330285 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:30:21.332570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a997c50>]}
[0m02:30:22.115540 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:30:22.117385 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5054442, "process_in_blocks": "0", "process_kernel_time": 0.180737, "process_mem_max_rss": "213952", "process_out_blocks": "0", "process_user_time": 3.383815}
[0m02:30:22.118554 [debug] [MainThread]: Command `dbt run` failed at 02:30:22.118408 after 1.51 seconds
[0m02:30:22.119529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b86cb810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b86cb750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a6a8d90>]}
[0m02:30:22.120437 [debug] [MainThread]: Flushing usage events
[0m02:30:23.406765 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:46.577975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03cbec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e04afbc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e040be110>]}


============================== 03:48:46.581100 | 4b6e4011-c2d3-4c10-ba46-fe102571ed89 ==============================
[0m03:48:46.581100 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:46.583063 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:48:46.673982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b6e4011-c2d3-4c10-ba46-fe102571ed89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d16210>]}
[0m03:48:46.691460 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.17322543, "process_in_blocks": "0", "process_kernel_time": 0.071361, "process_mem_max_rss": "90076", "process_out_blocks": "0", "process_user_time": 0.937895}
[0m03:48:46.692203 [debug] [MainThread]: Command `dbt clean` succeeded at 03:48:46.692116 after 0.17 seconds
[0m03:48:46.692904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d15010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d14210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e074b8b90>]}
[0m03:48:46.693683 [debug] [MainThread]: Flushing usage events
[0m03:48:47.999145 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:49.140859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f516cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f4c3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f4c2650>]}


============================== 03:48:49.143352 | 1f903d85-65ef-48f7-8c9a-aed9097531ac ==============================
[0m03:48:49.143352 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:49.144652 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:48:49.228319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1f903d85-65ef-48f7-8c9a-aed9097531ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f402090>]}
[0m03:48:49.239323 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:48:49.241814 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:48:49.243604 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1564101, "process_in_blocks": "0", "process_kernel_time": 0.120278, "process_mem_max_rss": "90156", "process_out_blocks": "0", "process_user_time": 0.962226}
[0m03:48:49.244668 [debug] [MainThread]: Command `dbt deps` succeeded at 03:48:49.244540 after 0.16 seconds
[0m03:48:49.245366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f516cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f8be8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b92cb8c10>]}
[0m03:48:49.246184 [debug] [MainThread]: Flushing usage events
[0m03:48:50.258690 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:52.041857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74036e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74036a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74087950>]}


============================== 03:48:52.044630 | d45ae16e-a5ef-414b-92c4-b8dabf098e93 ==============================
[0m03:48:52.044630 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:52.045738 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:48:52.628930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb463df5d0>]}
[0m03:48:52.674213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb46297490>]}
[0m03:48:52.675430 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:48:52.750946 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:48:52.753801 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:48:52.754901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb4cc71590>]}
[0m03:48:53.740104 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:48:53.751432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb460d4f10>]}
[0m03:48:53.818544 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:48:53.824729 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:48:53.841886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb44626610>]}
[0m03:48:53.843072 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:48:53.844252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb46382550>]}
[0m03:48:53.847146 [info ] [MainThread]: 
[0m03:48:53.848265 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:48:53.849418 [info ] [MainThread]: 
[0m03:48:53.851660 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:48:53.856931 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:48:53.858131 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:54.461050 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:48:54.462308 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:48:54.658101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb45f3ad10>]}
[0m03:48:54.659578 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:48:54.664912 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:48:54.665303 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:48:54.665665 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:48:54.666059 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:48:54.666709 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:48:54.667970 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:48:54.669068 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:48:54.670214 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:48:54.671678 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:48:54.676645 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:48:54.674594 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:48:54.675816 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:48:54.673185 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:48:54.685826 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:48:54.686787 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:48:54.688038 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:48:54.689235 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:48:54.694104 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:48:54.697849 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:48:54.702073 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:48:54.714652 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:48:54.721008 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:48:54.742940 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:48:54.769683 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:48:54.832074 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:48:54.832728 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:48:54.833474 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:48:54.836786 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:48:54.847600 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
),
SELECT *
FROM source
    );
  
[0m03:48:54.848840 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:48:54.849350 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:48:54.850869 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
),

SELECT *
FROM source
    );
  
[0m03:48:54.851760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:48:54.852316 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:48:54.854713 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:48:54.880104 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:48:55.333011 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:867609ef-42fc-4e69-bce0-062e7c18a7a4&page=queryresults
[0m03:48:55.334001 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:867609ef-42fc-4e69-bce0-062e7c18a7a4&page=queryresults
[0m03:48:55.340453 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:48:55.342403 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb444266d0>]}
[0m03:48:55.343664 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_vehicle  [[31mERROR[0m in 0.67s]
[0m03:48:55.345422 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:48:55.346745 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m03:48:55.383661 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ca4ee090-40bb-4a20-bdb7-770e5b76ea45&page=queryresults
[0m03:48:55.384765 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ca4ee090-40bb-4a20-bdb7-770e5b76ea45&page=queryresults
[0m03:48:55.388337 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m03:48:55.389174 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb446b5f50>]}
[0m03:48:55.390177 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_ride .. [[31mERROR[0m in 0.71s]
[0m03:48:55.391380 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:48:55.392421 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m03:48:56.472613 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:26f5a9d0-22b5-4fc2-b25e-72b5439fe2c8&page=queryresults
[0m03:48:56.710713 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c86efc61-8407-4610-87cc-2fd6b7c7c6f7&page=queryresults
[0m03:48:56.802393 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c86efc61-8407-4610-87cc-2fd6b7c7c6f7&page=queryresults
[0m03:48:56.806713 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:48:56.807969 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb44417d50>]}
[0m03:48:56.809454 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 2.14s]
[0m03:48:56.811066 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:48:56.812800 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:48:58.223982 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb4441b490>]}
[0m03:48:58.225257 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mCREATE TABLE (70.0 rows, 4.8 KiB processed)[0m in 3.55s]
[0m03:48:58.226780 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:48:58.229292 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:48:58.232549 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:48:58.233494 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:48:58.234578 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:48:58.235380 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:48:58.237180 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:48:58.238281 [info ] [MainThread]: 
[0m03:48:58.239667 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.39 seconds (4.39s).
[0m03:48:58.241893 [debug] [MainThread]: Command end result
[0m03:48:58.276224 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:48:58.280265 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:48:58.288287 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:48:58.289101 [info ] [MainThread]: 
[0m03:48:58.290190 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m03:48:58.291264 [info ] [MainThread]: 
[0m03:48:58.292355 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:48:58.293521 [info ] [MainThread]: 
[0m03:48:58.294788 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m03:48:58.295737 [info ] [MainThread]: 
[0m03:48:58.297045 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:48:58.297984 [info ] [MainThread]: 
[0m03:48:58.299187 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m03:48:58.300716 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.308942, "process_in_blocks": "0", "process_kernel_time": 0.217576, "process_mem_max_rss": "227536", "process_out_blocks": "0", "process_user_time": 4.11417}
[0m03:48:58.302115 [debug] [MainThread]: Command `dbt run` failed at 03:48:58.301996 after 6.31 seconds
[0m03:48:58.302959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb740b14d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb740b3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb779ed210>]}
[0m03:48:58.303931 [debug] [MainThread]: Flushing usage events
[0m03:48:59.325197 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:41.729427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a610>]}


============================== 03:50:41.731891 | 529f87d7-6afb-4e1e-8bac-84c3ff408093 ==============================
[0m03:50:41.731891 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:41.734506 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:50:41.815197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '529f87d7-6afb-4e1e-8bac-84c3ff408093', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5670c90a50>]}
[0m03:50:41.874857 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19473526, "process_in_blocks": "0", "process_kernel_time": 0.06868, "process_mem_max_rss": "90052", "process_out_blocks": "0", "process_user_time": 0.93209}
[0m03:50:41.875697 [debug] [MainThread]: Command `dbt clean` succeeded at 03:50:41.875599 after 0.20 seconds
[0m03:50:41.876484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56707d1810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56707cfa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56706c2a10>]}
[0m03:50:41.877255 [debug] [MainThread]: Flushing usage events
[0m03:50:42.997065 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:44.109329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb372e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb76a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb853750>]}


============================== 03:50:44.112663 | 850e8d11-8c97-4829-ae46-7eb0c2df9421 ==============================
[0m03:50:44.112663 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:44.114330 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:50:44.197698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '850e8d11-8c97-4829-ae46-7eb0c2df9421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb209650>]}
[0m03:50:44.211517 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.15543059, "process_in_blocks": "0", "process_kernel_time": 0.068863, "process_mem_max_rss": "89856", "process_out_blocks": "0", "process_user_time": 0.98377}
[0m03:50:44.212608 [debug] [MainThread]: Command `dbt clean` succeeded at 03:50:44.212482 after 0.16 seconds
[0m03:50:44.213587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb3ce2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb3cc410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfeb3cc50>]}
[0m03:50:44.214622 [debug] [MainThread]: Flushing usage events
[0m03:50:45.280840 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:46.480062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e7db010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377ebd6110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e80c490>]}


============================== 03:50:46.482657 | de1a6b8e-6207-4037-a5a6-884431cd32f9 ==============================
[0m03:50:46.482657 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:46.483781 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m03:50:46.570851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de1a6b8e-6207-4037-a5a6-884431cd32f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e82e290>]}
[0m03:50:46.582813 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:50:46.585585 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:50:46.587296 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15657125, "process_in_blocks": "0", "process_kernel_time": 0.100615, "process_mem_max_rss": "90328", "process_out_blocks": "0", "process_user_time": 1.026273}
[0m03:50:46.589094 [debug] [MainThread]: Command `dbt deps` succeeded at 03:50:46.588626 after 0.16 seconds
[0m03:50:46.590465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e84d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e84f990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3781fd0b90>]}
[0m03:50:46.591425 [debug] [MainThread]: Flushing usage events
[0m03:50:47.650574 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:51:37.432385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decb4ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ded033910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decb97dd0>]}


============================== 03:51:37.434767 | b7190cd3-1d5e-4235-9367-57ccdda45d7e ==============================
[0m03:51:37.434767 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:51:37.435957 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m03:51:38.032673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbee72f10>]}
[0m03:51:38.104604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7deedf8850>]}
[0m03:51:38.105818 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:51:38.179653 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:51:38.181631 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:51:38.183040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc5d7ca90>]}
[0m03:51:39.129366 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:51:39.140710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd124990>]}
[0m03:51:39.203809 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:51:39.209147 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:51:39.223960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd0c3910>]}
[0m03:51:39.225159 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:51:39.226267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbea7c550>]}
[0m03:51:39.229243 [info ] [MainThread]: 
[0m03:51:39.230500 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:51:39.231429 [info ] [MainThread]: 
[0m03:51:39.232873 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:51:39.237955 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:51:39.239048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:51:39.782113 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:51:39.783168 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:51:40.017044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbeae8e90>]}
[0m03:51:40.018928 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:51:40.024765 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:51:40.025121 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:51:40.025509 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:51:40.025865 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:51:40.026365 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:51:40.027623 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:51:40.028738 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:51:40.029993 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:51:40.031309 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:51:40.032596 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:51:40.034403 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:51:40.035875 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:51:40.037337 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:51:40.038363 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:51:40.039320 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:51:40.040346 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:51:40.047996 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:51:40.051314 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:51:40.055683 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:51:40.060410 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:51:40.070428 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:51:40.077158 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:51:40.103838 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:51:40.115046 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:51:40.152124 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:51:40.153432 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:51:40.156050 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:51:40.160344 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:51:40.196248 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
),
SELECT *
FROM source
    );
  
[0m03:51:40.197601 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:51:40.198241 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

WITH cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:51:40.200194 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:51:40.200599 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
    );
  
[0m03:51:40.225450 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:51:40.420935 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:51:40.427200 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:51:40.690507 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:1f357af3-36f2-458e-8d19-0edfbf4cc3da&page=queryresults
[0m03:51:40.691849 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:1f357af3-36f2-458e-8d19-0edfbf4cc3da&page=queryresults
[0m03:51:40.696871 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:51:40.699082 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbc750090>]}
[0m03:51:40.700058 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_vehicle  [[31mERROR[0m in 0.66s]
[0m03:51:40.701238 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:51:40.702358 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m03:51:40.716636 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:519f6a0e-86f0-41b2-8158-7c9575306572&page=queryresults
[0m03:51:40.718019 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:519f6a0e-86f0-41b2-8158-7c9575306572&page=queryresults
[0m03:51:40.721398 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:51:40.722416 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbc750ad0>]}
[0m03:51:40.723425 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.69s]
[0m03:51:40.724598 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:51:40.725682 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:51:40.772889 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc8dac86-73ac-48c6-85af-c1e36756a363&page=queryresults
[0m03:51:40.774108 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc8dac86-73ac-48c6-85af-c1e36756a363&page=queryresults
[0m03:51:40.777571 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:51:40.778659 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd1c6a90>]}
[0m03:51:40.779741 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.75s]
[0m03:51:40.780860 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:51:40.782030 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:51:40.906121 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31ba37c3-4d51-4737-87eb-4a5a8bede1c8&page=queryresults
[0m03:51:42.967413 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd0e6090>]}
[0m03:51:42.968893 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mCREATE TABLE (70.0 rows, 6.2 KiB processed)[0m in 2.93s]
[0m03:51:42.970393 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:51:42.973070 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:51:42.976480 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:51:42.977315 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:51:42.978132 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:51:42.978812 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:51:42.979523 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:51:42.980342 [info ] [MainThread]: 
[0m03:51:42.981362 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.75 seconds (3.75s).
[0m03:51:42.983605 [debug] [MainThread]: Command end result
[0m03:51:43.019384 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:51:43.025356 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:51:43.035800 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:51:43.036967 [info ] [MainThread]: 
[0m03:51:43.038677 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m03:51:43.039925 [info ] [MainThread]: 
[0m03:51:43.041192 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:51:43.042449 [info ] [MainThread]: 
[0m03:51:43.044025 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:51:43.045395 [info ] [MainThread]: 
[0m03:51:43.046603 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:51:43.047640 [info ] [MainThread]: 
[0m03:51:43.048597 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m03:51:43.050753 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.6623764, "process_in_blocks": "0", "process_kernel_time": 0.279745, "process_mem_max_rss": "226472", "process_out_blocks": "0", "process_user_time": 4.006348}
[0m03:51:43.052336 [debug] [MainThread]: Command `dbt run` failed at 03:51:43.052165 after 5.66 seconds
[0m03:51:43.053376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decf42990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7df04fd010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decba36d0>]}
[0m03:51:43.054444 [debug] [MainThread]: Flushing usage events
[0m03:51:44.297123 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:52:34.409055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a4ef10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14e4a150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a4ebd0>]}


============================== 03:52:34.411673 | de1a501b-b97a-415c-8de0-788dc80242eb ==============================
[0m03:52:34.411673 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:52:34.412727 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:52:34.975291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acbd50>]}
[0m03:52:35.019882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d16cc6290>]}
[0m03:52:35.021404 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:52:35.084190 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:52:35.209905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m03:52:35.211040 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_vehicle.sql
[0m03:52:35.211817 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m03:52:35.449778 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:52:35.463221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce6eb2e90>]}
[0m03:52:35.534400 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:52:35.539796 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:52:35.554360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4ef4050>]}
[0m03:52:35.555556 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:52:35.556727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce6c35390>]}
[0m03:52:35.560001 [info ] [MainThread]: 
[0m03:52:35.561074 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:52:35.561965 [info ] [MainThread]: 
[0m03:52:35.563230 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:52:35.568495 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:52:35.569612 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:52:36.059137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:52:36.059990 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:52:36.292422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a668d0>]}
[0m03:52:36.293387 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:52:36.298922 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:52:36.299280 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:52:36.299817 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:52:36.300199 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:52:36.301256 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:52:36.302525 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:52:36.303743 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:52:36.304819 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:52:36.305904 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:52:36.307093 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:52:36.308099 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:52:36.308953 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:52:36.309717 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:52:36.310523 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:52:36.311449 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:52:36.312287 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:52:36.320882 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:52:36.324058 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:52:36.328077 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:52:36.332522 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:52:36.337689 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:52:36.338229 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:52:36.349609 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:52:36.349973 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:52:36.404600 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:52:36.428087 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:52:36.429149 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:52:36.432434 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:52:36.463644 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:52:36.487628 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
    );
  
[0m03:52:36.488093 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:52:36.490382 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:52:36.727963 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:52:36.731604 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:52:36.736612 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:52:36.737835 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:52:36.991392 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:3b14d6d9-cf1f-4053-89f3-bd4f4a87e22c&page=queryresults
[0m03:52:36.993419 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:3b14d6d9-cf1f-4053-89f3-bd4f4a87e22c&page=queryresults
[0m03:52:36.999488 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:52:37.002115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f6bf50>]}
[0m03:52:37.003624 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.70s]
[0m03:52:37.005887 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:52:37.008203 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:52:37.083185 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:0c115b79-c3a8-42f3-b535-5e101cf409a9&page=queryresults
[0m03:52:37.085011 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:0c115b79-c3a8-42f3-b535-5e101cf409a9&page=queryresults
[0m03:52:37.091496 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:52:37.092561 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f680d0>]}
[0m03:52:37.093857 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.79s]
[0m03:52:37.094960 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:52:37.096111 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:52:37.235539 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e74471db-864e-4bd5-b7ed-e966e126058a&page=queryresults
[0m03:52:38.120191 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1dc6c1d3-a482-46ee-af62-ac21695f3093&page=queryresults
[0m03:52:38.917728 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4eebd50>]}
[0m03:52:38.918881 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mCREATE TABLE (70.0 rows, 3.8 KiB processed)[0m in 2.61s]
[0m03:52:38.920028 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:52:39.679385 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f5f290>]}
[0m03:52:39.680362 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.37s]
[0m03:52:39.681451 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:52:39.683459 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:52:39.686098 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:52:39.686767 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:52:39.687347 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:52:39.688064 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:52:39.688677 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:52:39.689405 [info ] [MainThread]: 
[0m03:52:39.690190 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.13 seconds (4.13s).
[0m03:52:39.691872 [debug] [MainThread]: Command end result
[0m03:52:39.724313 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:52:39.728477 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:52:39.737091 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:52:39.737790 [info ] [MainThread]: 
[0m03:52:39.738825 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:52:39.739745 [info ] [MainThread]: 
[0m03:52:39.740820 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:52:39.741979 [info ] [MainThread]: 
[0m03:52:39.743012 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:52:39.743991 [info ] [MainThread]: 
[0m03:52:39.744993 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:52:39.746473 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.3955393, "process_in_blocks": "0", "process_kernel_time": 0.179213, "process_mem_max_rss": "228640", "process_out_blocks": "0", "process_user_time": 3.494667}
[0m03:52:39.747372 [debug] [MainThread]: Command `dbt run` failed at 03:52:39.747265 after 5.40 seconds
[0m03:52:39.748166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14e4a290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acbf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acba50>]}
[0m03:52:39.749218 [debug] [MainThread]: Flushing usage events
[0m03:52:40.816296 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:54:09.824353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac2cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4efd8c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac2610>]}


============================== 03:54:09.826791 | dca53bf5-95ca-495c-a2d5-f385a35a5fe7 ==============================
[0m03:54:09.826791 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:54:09.828128 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:54:10.392039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac9d90>]}
[0m03:54:10.444749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d50d3a190>]}
[0m03:54:10.446382 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:54:10.515417 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:54:10.668063 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:54:10.669476 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_driver.sql
[0m03:54:10.932783 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:54:10.945126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d24d8fa90>]}
[0m03:54:11.016954 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:11.022375 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:11.037186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d130fe950>]}
[0m03:54:11.038504 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:54:11.040006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d24a611d0>]}
[0m03:54:11.042707 [info ] [MainThread]: 
[0m03:54:11.043862 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:54:11.044906 [info ] [MainThread]: 
[0m03:54:11.046330 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:54:11.051326 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:54:11.052237 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:54:11.620969 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:54:11.621871 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:54:11.853218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d2485e910>]}
[0m03:54:11.854570 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:54:11.858863 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:54:11.859202 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:54:11.859759 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:54:11.860114 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:54:11.860800 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:54:11.862351 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:54:11.863397 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:54:11.864522 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:54:11.865737 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:54:11.867042 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:54:11.868162 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:54:11.869546 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:54:11.870647 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:54:11.871533 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:54:11.872319 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:54:11.873149 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:54:11.881753 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:54:11.885135 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:54:11.888635 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:54:11.892817 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:54:11.898729 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:54:11.899191 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:54:11.910645 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:54:11.921005 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:54:11.943261 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:54:11.943612 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:54:11.968643 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:54:11.973685 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:54:12.050539 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:54:12.051715 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:54:12.258156 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:54:12.265814 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:54:12.282459 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:54:12.285197 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:54:12.292256 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:54:12.293721 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:54:12.497365 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc35f3a9-4a3c-4aa0-9e92-a8e815d27132&page=queryresults
[0m03:54:12.498647 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc35f3a9-4a3c-4aa0-9e92-a8e815d27132&page=queryresults
[0m03:54:12.503409 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:54:12.505335 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d131ddf10>]}
[0m03:54:12.506641 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.64s]
[0m03:54:12.507699 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:54:12.508665 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:54:12.642837 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:81548928-2f7a-48f0-a02d-c57c47f1e53f&page=queryresults
[0m03:54:12.644081 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:81548928-2f7a-48f0-a02d-c57c47f1e53f&page=queryresults
[0m03:54:12.647977 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:54:12.650207 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d1319d850>]}
[0m03:54:12.653167 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.78s]
[0m03:54:12.654899 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:54:12.656314 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:54:12.860424 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a9427830-3516-49dd-9eb5-a2219a516405&page=queryresults
[0m03:54:13.771075 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e4333740-597d-4c81-a3c3-1f327fd88867&page=queryresults
[0m03:54:14.462404 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d131e4d90>]}
[0m03:54:14.463748 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.59s]
[0m03:54:14.464971 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:54:15.705479 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d0bf5ed50>]}
[0m03:54:15.706518 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.84s]
[0m03:54:15.708446 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:54:15.710841 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:54:15.714265 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:54:15.715176 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:54:15.716248 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:54:15.717148 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:54:15.718336 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:54:15.719294 [info ] [MainThread]: 
[0m03:54:15.720339 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.67 seconds (4.67s).
[0m03:54:15.722362 [debug] [MainThread]: Command end result
[0m03:54:15.756474 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:15.762363 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:15.772373 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:54:15.773330 [info ] [MainThread]: 
[0m03:54:15.774326 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:54:15.775362 [info ] [MainThread]: 
[0m03:54:15.776403 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:54:15.778073 [info ] [MainThread]: 
[0m03:54:15.779409 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:54:15.780443 [info ] [MainThread]: 
[0m03:54:15.781604 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:54:15.783321 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.004255, "process_in_blocks": "0", "process_kernel_time": 0.274545, "process_mem_max_rss": "226336", "process_out_blocks": "0", "process_user_time": 3.42674}
[0m03:54:15.784707 [debug] [MainThread]: Command `dbt run` failed at 03:54:15.784406 after 6.01 seconds
[0m03:54:15.785493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eebe650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eb41850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eb43c50>]}
[0m03:54:15.786593 [debug] [MainThread]: Flushing usage events
[0m03:54:16.902471 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:09.159775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4cbfcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a506a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c726d0>]}


============================== 03:55:09.162354 | b8cac8fb-cd27-41d4-8ccc-b907ce13dd9d ==============================
[0m03:55:09.162354 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:09.163683 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:09.242657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b8cac8fb-cd27-41d4-8ccc-b907ce13dd9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4ccd810>]}
[0m03:55:09.294947 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18828923, "process_in_blocks": "0", "process_kernel_time": 0.039608, "process_mem_max_rss": "89936", "process_out_blocks": "0", "process_user_time": 0.960514}
[0m03:55:09.296131 [debug] [MainThread]: Command `dbt clean` succeeded at 03:55:09.296013 after 0.19 seconds
[0m03:55:09.297179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c72ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c72190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a843cc10>]}
[0m03:55:09.298057 [debug] [MainThread]: Flushing usage events
[0m03:55:10.369621 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:24.770918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383cfe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383cf110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383ce650>]}


============================== 03:55:24.774277 | 0c7ae357-769b-49ef-8725-7187896870d1 ==============================
[0m03:55:24.774277 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:24.775891 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:24.863354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c7ae357-769b-49ef-8725-7187896870d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc38302f10>]}
[0m03:55:24.872599 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:55:24.875455 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:55:24.876872 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15382788, "process_in_blocks": "0", "process_kernel_time": 0.090793, "process_mem_max_rss": "90180", "process_out_blocks": "0", "process_user_time": 0.978553}
[0m03:55:24.877995 [debug] [MainThread]: Command `dbt deps` succeeded at 03:55:24.877857 after 0.16 seconds
[0m03:55:24.878921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3841f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc38884310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3bc24b90>]}
[0m03:55:24.879873 [debug] [MainThread]: Flushing usage events
[0m03:55:26.050892 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:28.807178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777b2078d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a54f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a8f8190>]}


============================== 03:55:28.810814 | 2963f7c2-f555-493c-bdd6-ed99d18b3bd1 ==============================
[0m03:55:28.810814 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:28.812027 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:29.417786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7753134b50>]}
[0m03:55:29.464029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775080f5d0>]}
[0m03:55:29.465558 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:55:29.538658 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:55:29.541544 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:55:29.542274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775086c750>]}
[0m03:55:30.548355 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:55:30.559047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7750557c10>]}
[0m03:55:30.623650 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:55:30.629340 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:55:30.644547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7750407650>]}
[0m03:55:30.645711 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:55:30.646988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775012b390>]}
[0m03:55:30.649699 [info ] [MainThread]: 
[0m03:55:30.650862 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:55:30.651836 [info ] [MainThread]: 
[0m03:55:30.653009 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:55:30.657771 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:55:30.658952 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:55:31.214619 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:55:31.215562 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:55:31.431486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77505cb690>]}
[0m03:55:31.432650 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:55:31.438165 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:55:31.438546 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:55:31.439004 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:55:31.439377 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:55:31.440151 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:55:31.441542 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:55:31.442821 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:55:31.443938 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:55:31.445307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:55:31.446572 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:55:31.448002 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:55:31.449149 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:55:31.450139 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:55:31.450927 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:55:31.451735 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:55:31.452862 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:55:31.461263 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:55:31.465636 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:55:31.469369 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:55:31.472947 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:55:31.486675 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:55:31.498362 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:55:31.522128 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:55:31.522470 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:55:31.538896 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:55:31.541798 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:55:31.567226 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:55:31.575318 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:55:31.669405 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

WITH cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:55:31.670530 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:55:31.918699 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:55:31.921156 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:55:31.922692 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:55:31.928621 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:55:31.931728 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:55:31.934284 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:55:32.182142 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:099f2d54-5d14-4ae4-9ffb-989e83538f9f&page=queryresults
[0m03:55:32.183346 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:099f2d54-5d14-4ae4-9ffb-989e83538f9f&page=queryresults
[0m03:55:32.187968 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:55:32.190308 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7702f8f150>]}
[0m03:55:32.191747 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.74s]
[0m03:55:32.193153 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:55:32.194571 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:55:32.199419 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8ef050e-ecc6-4976-bae6-17bd99d1396c&page=queryresults
[0m03:55:32.283921 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:9b6c3bff-c7bc-4c12-86a7-385f561c0395&page=queryresults
[0m03:55:32.285117 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:9b6c3bff-c7bc-4c12-86a7-385f561c0395&page=queryresults
[0m03:55:32.289236 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:55:32.290314 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f774a90fe90>]}
[0m03:55:32.291582 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.84s]
[0m03:55:32.292890 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:55:32.294284 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:55:32.472294 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5b3e4fc1-d0ad-4058-84bf-60127e0576f9&page=queryresults
[0m03:55:34.019349 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f774a9ef2d0>]}
[0m03:55:34.020819 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.57s]
[0m03:55:34.022224 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:55:34.274515 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7702fe1090>]}
[0m03:55:34.276259 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 2.83s]
[0m03:55:34.278487 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:55:34.281322 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:55:34.285203 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:55:34.285984 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:55:34.286849 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:55:34.287649 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:55:34.288407 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:55:34.289540 [info ] [MainThread]: 
[0m03:55:34.290431 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.64 seconds (3.64s).
[0m03:55:34.292046 [debug] [MainThread]: Command end result
[0m03:55:34.326600 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:55:34.330260 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:55:34.337377 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:55:34.338364 [info ] [MainThread]: 
[0m03:55:34.339345 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:55:34.340285 [info ] [MainThread]: 
[0m03:55:34.341190 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:55:34.342011 [info ] [MainThread]: 
[0m03:55:34.343022 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:55:34.343830 [info ] [MainThread]: 
[0m03:55:34.344871 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:55:34.346684 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.5879216, "process_in_blocks": "0", "process_kernel_time": 0.23382, "process_mem_max_rss": "229560", "process_out_blocks": "0", "process_user_time": 4.188439}
[0m03:55:34.347840 [debug] [MainThread]: Command `dbt run` failed at 03:55:34.347695 after 5.59 seconds
[0m03:55:34.348837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a57b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777deb5190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a925f50>]}
[0m03:55:34.349649 [debug] [MainThread]: Flushing usage events
[0m03:55:35.369581 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:01.842205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18996e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ebbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18eb0a50>]}


============================== 03:57:01.845022 | faa07538-7d5c-40c2-b3fa-ba941cc648ea ==============================
[0m03:57:01.845022 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:01.846405 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:57:01.925705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'faa07538-7d5c-40c2-b3fa-ba941cc648ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18828290>]}
[0m03:57:01.984078 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19159567, "process_in_blocks": "0", "process_kernel_time": 0.110106, "process_mem_max_rss": "90232", "process_out_blocks": "0", "process_user_time": 0.990958}
[0m03:57:01.985043 [debug] [MainThread]: Command `dbt clean` succeeded at 03:57:01.984933 after 0.19 seconds
[0m03:57:01.985741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ef010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ee250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee1c190c10>]}
[0m03:57:01.986387 [debug] [MainThread]: Flushing usage events
[0m03:57:03.102048 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:04.236538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e1db990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e22efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd60a89ed0>]}


============================== 03:57:04.239085 | 12044cc6-e7bf-4a2b-9974-6fa04b8997a3 ==============================
[0m03:57:04.239085 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:04.240329 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:57:04.321313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '12044cc6-e7bf-4a2b-9974-6fa04b8997a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e0e3dd0>]}
[0m03:57:04.330902 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:57:04.333293 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:57:04.334731 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.14978145, "process_in_blocks": "0", "process_kernel_time": 0.050052, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 1.02107}
[0m03:57:04.335828 [debug] [MainThread]: Command `dbt deps` succeeded at 03:57:04.335688 after 0.15 seconds
[0m03:57:04.336779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e22f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e26a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd61a34b90>]}
[0m03:57:04.337703 [debug] [MainThread]: Flushing usage events
[0m03:57:05.361502 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:10.069705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db55d7890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db597e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db5586e50>]}


============================== 03:57:10.072220 | 69de4a25-c58b-4675-beab-b2b8eff3ef12 ==============================
[0m03:57:10.072220 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:10.074696 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:57:10.640124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8cd99ad0>]}
[0m03:57:10.688109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db77d8dd0>]}
[0m03:57:10.689656 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:57:10.758220 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:57:10.761682 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:57:10.762700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d877cf610>]}
[0m03:57:11.751320 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:57:11.764502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d877c16d0>]}
[0m03:57:11.835931 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:57:11.842835 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:57:11.860727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87396ad0>]}
[0m03:57:11.861885 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:57:11.863283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87369a10>]}
[0m03:57:11.867070 [info ] [MainThread]: 
[0m03:57:11.868330 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:57:11.869453 [info ] [MainThread]: 
[0m03:57:11.870892 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:57:11.876006 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:57:11.877128 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:12.483653 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:57:12.485001 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:12.697190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8746b290>]}
[0m03:57:12.701160 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:57:12.706561 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:57:12.706888 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:57:12.707224 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:57:12.707525 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:57:12.708027 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:57:12.708940 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:57:12.709867 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:57:12.710807 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:57:12.711929 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:57:12.712899 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:57:12.713772 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:57:12.714622 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:57:12.715332 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:57:12.716134 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:57:12.716881 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:57:12.717629 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:57:12.724464 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:57:12.728563 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:57:12.732520 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:57:12.736321 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:57:12.748694 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:57:12.749993 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:57:12.794869 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:57:12.795275 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:57:12.797594 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:57:12.797998 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:57:12.822461 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:57:12.827901 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:57:12.927185 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:57:12.928316 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:57:13.157076 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:57:13.161516 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:57:13.162911 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:57:13.168305 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:57:13.169715 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:57:13.173739 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:57:13.347744 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9c82e0b7-2856-4508-9a62-6e88dec4c098&page=queryresults
[0m03:57:13.452667 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:22fa7bdc-468c-48cd-8f1c-d452a15eeef1&page=queryresults
[0m03:57:13.509953 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2034e47d-b241-441c-96b7-b0377fa7389e&page=queryresults
[0m03:57:13.798102 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d09d99b6-dd3d-4f3b-b11a-6e5e01b7e7d3&page=queryresults
[0m03:57:15.216883 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d45f12190>]}
[0m03:57:15.218074 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.50s]
[0m03:57:15.219463 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:57:15.227541 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8599fc50>]}
[0m03:57:15.228867 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mCREATE TABLE (70.0 rows, 4.8 KiB processed)[0m in 2.52s]
[0m03:57:15.230098 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:57:15.310368 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d85957850>]}
[0m03:57:15.311608 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (70.0 rows, 9.4 KiB processed)[0m in 2.60s]
[0m03:57:15.312911 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:57:15.334356 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d859c6cd0>]}
[0m03:57:15.335323 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 2.62s]
[0m03:57:15.336578 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:57:15.339497 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:57:15.342938 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:57:15.343644 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:57:15.344402 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:57:15.345062 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:57:15.346048 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:57:15.346926 [info ] [MainThread]: 
[0m03:57:15.347830 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.48 seconds (3.48s).
[0m03:57:15.349520 [debug] [MainThread]: Command end result
[0m03:57:15.382035 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:57:15.386515 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:57:15.395721 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:57:15.396571 [info ] [MainThread]: 
[0m03:57:15.397619 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:57:15.398638 [info ] [MainThread]: 
[0m03:57:15.399671 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m03:57:15.401547 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3793664, "process_in_blocks": "0", "process_kernel_time": 0.191403, "process_mem_max_rss": "226976", "process_out_blocks": "0", "process_user_time": 4.200798}
[0m03:57:15.402517 [debug] [MainThread]: Command `dbt run` succeeded at 03:57:15.402401 after 5.38 seconds
[0m03:57:15.403554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db8d50b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87841410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db597e150>]}
[0m03:57:15.404425 [debug] [MainThread]: Flushing usage events
[0m03:57:16.432072 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:14:24.057157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e3050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e2ed0>]}


============================== 07:14:24.062167 | 9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f ==============================
[0m07:14:24.062167 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:14:24.063873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:14:24.739792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b247eb10>]}
[0m07:14:24.789404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e256e0d0>]}
[0m07:14:24.790645 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:14:24.876192 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:14:25.046511 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:14:25.047417 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:14:25.053276 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:14:25.080426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e111e0d0>]}
[0m07:14:25.204505 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:14:25.213125 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:14:25.236328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b233e390>]}
[0m07:14:25.237722 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m07:14:25.238754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e2662310>]}
[0m07:14:25.243057 [info ] [MainThread]: 
[0m07:14:25.244300 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:14:25.245371 [info ] [MainThread]: 
[0m07:14:25.246653 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:14:25.251061 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:14:25.252149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:14:25.932829 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:14:25.934527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:14:26.181470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e08c53d0>]}
[0m07:14:26.183857 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:14:26.191654 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:14:26.192053 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:14:26.192475 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:14:26.192840 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:14:26.193442 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:14:26.196094 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:14:26.197379 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:14:26.198742 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:14:26.199964 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:14:26.203516 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:14:26.204699 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:14:26.206016 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:14:26.206896 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:14:26.209575 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:14:26.210992 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:14:26.212091 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:14:26.222007 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:14:26.226201 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:14:26.232466 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:14:26.237762 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:14:26.253551 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:14:26.255208 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:14:26.266408 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:14:26.289452 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:14:26.329708 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:14:26.331299 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:14:26.334154 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:14:26.337479 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:14:26.663888 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:14:26.666159 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:14:26.667965 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:14:26.669058 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:14:26.686209 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:14:26.692104 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:14:26.692943 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:14:26.695761 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:14:27.289022 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0bb9971d-ed97-4412-8de7-1cd4eb96858a&page=queryresults
[0m07:14:27.534418 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:30b64f7e-61b1-4cc3-88a0-49449c954f94&page=queryresults
[0m07:14:27.539028 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f5e5bea-79f6-44ed-b2be-3149264083f8&page=queryresults
[0m07:14:28.140278 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7df0087e-63ef-46b7-9232-2f978ab7357a&page=queryresults
[0m07:14:29.295070 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e08735d0>]}
[0m07:14:29.296256 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (70.0 rows, 9.5 KiB processed)[0m in 3.09s]
[0m07:14:29.297908 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:14:29.474888 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e10afa90>]}
[0m07:14:29.476368 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 3.27s]
[0m07:14:29.477631 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:14:29.667286 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b2142dd0>]}
[0m07:14:29.669166 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.46s]
[0m07:14:29.671011 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:14:30.129711 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e9b90>]}
[0m07:14:30.130940 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (70.0 rows, 9.4 KiB processed)[0m in 3.93s]
[0m07:14:30.133340 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:14:30.135664 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:14:30.138650 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:14:30.139566 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:14:30.140512 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:14:30.141337 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:14:30.142170 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:14:30.143229 [info ] [MainThread]: 
[0m07:14:30.144330 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.90 seconds (4.90s).
[0m07:14:30.146268 [debug] [MainThread]: Command end result
[0m07:14:30.181117 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:14:30.186507 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:14:30.194413 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:14:30.195439 [info ] [MainThread]: 
[0m07:14:30.196633 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:14:30.197755 [info ] [MainThread]: 
[0m07:14:30.198773 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:14:30.200481 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.2747736, "process_in_blocks": "0", "process_kernel_time": 0.386009, "process_mem_max_rss": "222724", "process_out_blocks": "0", "process_user_time": 3.741319}
[0m07:14:30.201630 [debug] [MainThread]: Command `dbt run` succeeded at 07:14:30.201452 after 6.28 seconds
[0m07:14:30.202788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e035f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e035f690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e3adcb90>]}
[0m07:14:30.203700 [debug] [MainThread]: Flushing usage events
[0m07:14:31.324369 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:30:49.092343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243071950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243073710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243072a10>]}


============================== 07:30:49.094968 | 9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91 ==============================
[0m07:30:49.094968 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:30:49.096823 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:30:49.662161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243185d50>]}
[0m07:30:49.707859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2452f4e50>]}
[0m07:30:49.709238 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:30:49.773126 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:30:49.898481 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 4 files changed.
[0m07:30:49.899480 [debug] [MainThread]: Partial parsing: added file: hailing_project://macros/check_if_incremental.sql
[0m07:30:49.900583 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_ride.sql
[0m07:30:49.901425 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_driver.sql
[0m07:30:49.902315 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_vehicle.sql
[0m07:30:49.903057 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m07:30:50.157347 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:30:50.169781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218f507d0>]}
[0m07:30:50.249233 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:30:50.255615 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:30:50.270170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218f04450>]}
[0m07:30:50.271348 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m07:30:50.272388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218d4e5d0>]}
[0m07:30:50.275228 [info ] [MainThread]: 
[0m07:30:50.276310 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:30:50.277605 [info ] [MainThread]: 
[0m07:30:50.279144 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:30:50.284100 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:30:50.285414 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:30:50.877964 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:30:50.879091 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:30:51.124803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218d4d4d0>]}
[0m07:30:51.126503 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:30:51.132518 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:30:51.132941 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:30:51.134089 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:30:51.134510 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:30:51.135150 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:30:51.136590 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:30:51.137744 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:30:51.138924 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:30:51.139939 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:30:51.141051 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:30:51.142063 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:30:51.142952 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:30:51.143863 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:30:51.144646 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:30:51.145421 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:30:51.146314 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:30:51.156291 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:30:51.160500 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:30:51.165748 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:30:51.169689 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:30:51.175006 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:30:51.175513 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:30:51.181812 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:30:51.192903 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:30:51.213840 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:30:51.216169 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:30:51.219998 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:30:51.223265 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:30:51.477753 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:30:51.486710 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:30:51.495854 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:30:51.501589 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:30:51.503763 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:30:51.511415 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:30:51.532187 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:30:51.538923 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:30:51.802681 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:090693f2-a77b-4dc8-a974-f80c6d37090c&page=queryresults
[0m07:30:51.866937 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1f396e0-69ee-46d7-be88-08796ccc7b23&page=queryresults
[0m07:30:52.912257 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:50043940-5a09-439b-8426-768bd85eb2cb&page=queryresults
[0m07:30:52.914930 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fd6c4e65-9a9f-4e70-89dd-ccfa76572ad6&page=queryresults
[0m07:30:53.702659 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218e9c590>]}
[0m07:30:53.703990 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 7.7 KiB processed)[0m in 2.56s]
[0m07:30:53.706127 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:30:53.754802 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218ddbb90>]}
[0m07:30:53.756838 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 9.5 KiB processed)[0m in 2.61s]
[0m07:30:53.758693 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:30:54.561517 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218dee910>]}
[0m07:30:54.564764 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 9.4 KiB processed)[0m in 3.42s]
[0m07:30:54.567154 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:30:54.798589 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218ddc590>]}
[0m07:30:54.799938 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 12.4 KiB processed)[0m in 3.66s]
[0m07:30:54.801464 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:30:54.804555 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:30:54.807896 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:30:54.808619 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:30:54.809528 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:30:54.810651 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:30:54.811606 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:30:54.812830 [info ] [MainThread]: 
[0m07:30:54.814584 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.53 seconds (4.53s).
[0m07:30:54.816849 [debug] [MainThread]: Command end result
[0m07:30:54.849859 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:30:54.854511 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:30:54.863605 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:30:54.864344 [info ] [MainThread]: 
[0m07:30:54.865567 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:30:54.866583 [info ] [MainThread]: 
[0m07:30:54.867577 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:30:54.869308 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.824409, "process_in_blocks": "0", "process_kernel_time": 0.194672, "process_mem_max_rss": "226324", "process_out_blocks": "0", "process_user_time": 3.463129}
[0m07:30:54.870348 [debug] [MainThread]: Command `dbt run` succeeded at 07:30:54.870241 after 5.83 seconds
[0m07:30:54.871225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f10d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f1250>]}
[0m07:30:54.872311 [debug] [MainThread]: Flushing usage events
[0m07:30:55.990910 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:42:35.533356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fad10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fa310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fac90>]}


============================== 07:42:35.536888 | 3b0b4895-c001-42c0-9901-b182671f7801 ==============================
[0m07:42:35.536888 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:42:35.538473 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:42:36.138255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2e81450>]}
[0m07:42:36.197358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda027ae2d0>]}
[0m07:42:36.198620 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:42:36.276413 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:42:36.427590 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:42:36.428428 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:42:36.433150 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:42:36.457172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2807790>]}
[0m07:42:36.590853 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:42:36.597347 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:42:36.615077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d25779d0>]}
[0m07:42:36.616421 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m07:42:36.617623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda01d2aa50>]}
[0m07:42:36.620269 [info ] [MainThread]: 
[0m07:42:36.621304 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:42:36.622260 [info ] [MainThread]: 
[0m07:42:36.623673 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:42:36.629307 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:42:36.630232 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:42:37.168645 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:42:37.169482 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:42:37.359274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d29c77d0>]}
[0m07:42:37.360592 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:42:37.366038 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:42:37.366422 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:42:37.366910 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:42:37.367290 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:42:37.368112 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:42:37.369831 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:42:37.370910 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:42:37.372130 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:42:37.373291 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:42:37.374617 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:42:37.376171 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:42:37.377221 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:42:37.378030 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:42:37.379097 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:42:37.380111 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:42:37.381012 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:42:37.398034 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:42:37.401786 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:42:37.406678 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:42:37.411604 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:42:37.417003 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:42:37.417593 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:42:37.418344 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:42:37.436542 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:42:37.465613 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:42:37.468608 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:42:37.471307 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:42:37.475882 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:42:37.750408 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:42:37.752883 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:42:37.754469 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:42:37.760311 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:42:37.761455 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:42:37.763542 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:42:37.767001 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:42:37.775191 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:42:38.030298 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:48c61271-4f05-40fe-a346-89e53ea76384&page=queryresults
[0m07:42:38.038643 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7c53dd75-39f1-4742-9386-016641bb0607&page=queryresults
[0m07:42:39.110434 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8c792602-497d-4efe-aaf1-5997c496371b&page=queryresults
[0m07:42:39.111976 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4eb10280-dad4-41fb-9670-9016ab9bc08e&page=queryresults
[0m07:42:39.873799 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d28c1b50>]}
[0m07:42:39.874953 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (15.0 rows, 13.8 KiB processed)[0m in 2.50s]
[0m07:42:39.876635 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:42:39.910703 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2535450>]}
[0m07:42:39.912022 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (15.0 rows, 10.5 KiB processed)[0m in 2.54s]
[0m07:42:39.913738 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:42:40.607381 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda00a8fe50>]}
[0m07:42:40.609295 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (15.0 rows, 10.5 KiB processed)[0m in 3.23s]
[0m07:42:40.610912 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:42:40.629043 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda0052db10>]}
[0m07:42:40.631131 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (15.0 rows, 8.5 KiB processed)[0m in 3.25s]
[0m07:42:40.633420 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:42:40.636556 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:42:40.639742 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:42:40.640702 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:42:40.641409 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:42:40.642052 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:42:40.642883 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:42:40.644114 [info ] [MainThread]: 
[0m07:42:40.645495 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.02 seconds (4.02s).
[0m07:42:40.647562 [debug] [MainThread]: Command end result
[0m07:42:40.684982 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:42:40.689692 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:42:40.698032 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:42:40.698780 [info ] [MainThread]: 
[0m07:42:40.699834 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:42:40.700859 [info ] [MainThread]: 
[0m07:42:40.701995 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:42:40.703611 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.221707, "process_in_blocks": "0", "process_kernel_time": 0.271276, "process_mem_max_rss": "222804", "process_out_blocks": "0", "process_user_time": 3.345746}
[0m07:42:40.704672 [debug] [MainThread]: Command `dbt run` succeeded at 07:42:40.704554 after 5.22 seconds
[0m07:42:40.705678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda03e13e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda03d2cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda008f65d0>]}
[0m07:42:40.706704 [debug] [MainThread]: Flushing usage events
[0m07:42:41.823814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:18:12.432832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201ec90>]}


============================== 08:18:12.436866 | 873b1c9b-3fbb-4208-95d5-5d3038cd76f1 ==============================
[0m08:18:12.436866 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:18:12.438432 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:18:13.019581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7281f7fd0>]}
[0m08:18:13.068481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7542cc9d0>]}
[0m08:18:13.069551 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:18:13.133470 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:18:13.303393 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:18:13.304297 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:18:13.309036 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:18:13.334214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728340610>]}
[0m08:18:13.454205 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:18:13.459718 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:18:13.473409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc730bcc350>]}
[0m08:18:13.474285 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:18:13.475356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7283d30d0>]}
[0m08:18:13.478100 [info ] [MainThread]: 
[0m08:18:13.479228 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:18:13.480274 [info ] [MainThread]: 
[0m08:18:13.481633 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:18:13.486338 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:18:13.487277 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:18:14.120962 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:18:14.123822 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:18:14.328906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7298132d0>]}
[0m08:18:14.330246 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:18:14.335727 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:18:14.336095 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:18:14.336501 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:18:14.337017 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:18:14.337710 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:18:14.339459 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:18:14.340884 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:18:14.342085 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:18:14.343308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:18:14.344823 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:18:14.345920 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:18:14.346739 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:18:14.347521 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:18:14.348287 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:18:14.348945 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:18:14.349605 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:18:14.364590 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:18:14.368731 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:18:14.373105 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:18:14.376836 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:18:14.382847 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:18:14.383522 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:18:14.389653 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:18:14.400012 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:18:14.429197 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:18:14.429478 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:18:14.432490 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:18:14.435631 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:18:14.726733 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:18:14.728540 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:18:14.729286 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:18:14.730515 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:18:14.735505 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:18:14.736582 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:18:14.738965 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:18:14.739581 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:18:15.072113 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:49718984-e9aa-404c-99c2-2a8a9ee4778a&page=queryresults
[0m08:18:15.075968 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c27e9b31-331d-4ef1-a721-af21532687e2&page=queryresults
[0m08:18:15.078186 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a07a28b7-71de-49a1-880d-3110dd9b5c5f&page=queryresults
[0m08:18:15.078652 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b6fb1980-78c9-41e3-8fef-05578a1c4be1&page=queryresults
[0m08:18:16.682071 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728327bd0>]}
[0m08:18:16.682628 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc720185590>]}
[0m08:18:16.682909 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728236210>]}
[0m08:18:16.683860 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.33s]
[0m08:18:16.685961 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.34s]
[0m08:18:16.687373 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.34s]
[0m08:18:16.688659 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:18:16.690023 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:18:16.691368 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:18:16.925810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7284a0490>]}
[0m08:18:16.928615 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.58s]
[0m08:18:16.931276 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:18:16.933597 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:18:16.936740 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:18:16.937819 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:18:16.938708 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:18:16.939486 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:18:16.940531 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:18:16.941790 [info ] [MainThread]: 
[0m08:18:16.943806 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.46 seconds (3.46s).
[0m08:18:16.945513 [debug] [MainThread]: Command end result
[0m08:18:16.989803 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:18:16.997847 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:18:17.006172 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:18:17.007010 [info ] [MainThread]: 
[0m08:18:17.008111 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:18:17.009185 [info ] [MainThread]: 
[0m08:18:17.010118 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:18:17.011798 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.648351, "process_in_blocks": "0", "process_kernel_time": 0.190411, "process_mem_max_rss": "223264", "process_out_blocks": "0", "process_user_time": 3.397345}
[0m08:18:17.012890 [debug] [MainThread]: Command `dbt run` succeeded at 08:18:17.012744 after 4.65 seconds
[0m08:18:17.013849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc755874b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7559d1190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7559d1150>]}
[0m08:18:17.014724 [debug] [MainThread]: Flushing usage events
[0m08:18:18.388019 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:21:35.277834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa71026ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa71077610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa714229d0>]}


============================== 08:21:35.280368 | e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949 ==============================
[0m08:21:35.280368 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:21:35.282387 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:21:35.849786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa437f7d90>]}
[0m08:21:35.897980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa4394edd0>]}
[0m08:21:35.899081 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:21:35.965936 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:21:36.099694 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:21:36.101230 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:21:36.392563 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.hailing_project.stg_customer' (models/staging/stg_customer.sql) depends on a source named 'source.customer_data' which was not found
[0m08:21:36.394691 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1627843, "process_in_blocks": "0", "process_kernel_time": 0.201076, "process_mem_max_rss": "215860", "process_out_blocks": "0", "process_user_time": 2.996037}
[0m08:21:36.395751 [debug] [MainThread]: Command `dbt run` failed at 08:21:36.395644 after 1.16 seconds
[0m08:21:36.396832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa710857d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa714228d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa749a1210>]}
[0m08:21:36.397751 [debug] [MainThread]: Flushing usage events
[0m08:21:37.585841 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:21:58.696691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357390>]}


============================== 08:21:58.699223 | 3ac88093-f584-4fae-8042-6fc9b98c9baf ==============================
[0m08:21:58.699223 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:21:58.701425 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:21:59.258717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f952b4d0>]}
[0m08:21:59.304815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5295aa690>]}
[0m08:21:59.306289 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:21:59.373130 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:21:59.512444 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:21:59.513637 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:21:59.686979 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:21:59.699330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f921f790>]}
[0m08:21:59.771445 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:21:59.777832 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:21:59.792999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f8fc9550>]}
[0m08:21:59.794272 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:21:59.795320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527a60c10>]}
[0m08:21:59.798178 [info ] [MainThread]: 
[0m08:21:59.799314 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:21:59.800266 [info ] [MainThread]: 
[0m08:21:59.801528 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:21:59.806732 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:21:59.807705 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:00.404796 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:22:00.405806 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:22:00.625979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5271c8490>]}
[0m08:22:00.627142 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:22:00.631898 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:22:00.632440 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:22:00.632851 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:22:00.633224 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:22:00.633784 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:22:00.634833 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:22:00.635791 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:22:00.636717 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:22:00.637766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:22:00.638723 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:22:00.639631 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:22:00.640452 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:22:00.641237 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:22:00.641989 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:22:00.642641 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:22:00.643469 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:22:00.657714 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:22:00.661531 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:22:00.666182 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:22:00.670362 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:22:00.676069 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:22:00.676537 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:22:00.682740 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:22:00.683077 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:22:00.728513 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:22:00.731399 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:22:00.731912 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:00.735429 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:22:01.021917 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:22:01.031763 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:22:01.032304 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:22:01.040120 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:22:01.042016 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:22:01.044675 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:22:01.047051 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:22:01.055653 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:22:01.320422 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bf34a7f2-05d8-4b66-8f93-38355ae08d44&page=queryresults
[0m08:22:01.331037 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9c67940c-8b6f-440b-8c72-e95e28d6caeb&page=queryresults
[0m08:22:01.346206 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9fcd591b-0bb1-4f74-87e7-94b821539846&page=queryresults
[0m08:22:01.587215 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c36f477f-d378-4222-81ba-639f48b9ab5f&page=queryresults
[0m08:22:03.143042 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f86db890>]}
[0m08:22:03.143483 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f9060890>]}
[0m08:22:03.144057 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f9060fd0>]}
[0m08:22:03.144982 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.50s]
[0m08:22:03.146513 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m08:22:03.147929 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.50s]
[0m08:22:03.149289 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:22:03.150357 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:22:03.151275 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:22:03.396862 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f8696150>]}
[0m08:22:03.398466 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.76s]
[0m08:22:03.399879 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:22:03.402692 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:22:03.407263 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:03.408525 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:22:03.410677 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:22:03.411769 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:22:03.412743 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:22:03.414100 [info ] [MainThread]: 
[0m08:22:03.416519 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.61 seconds (3.61s).
[0m08:22:03.419113 [debug] [MainThread]: Command end result
[0m08:22:03.459681 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:03.464349 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:03.473447 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:22:03.474283 [info ] [MainThread]: 
[0m08:22:03.475524 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:22:03.476657 [info ] [MainThread]: 
[0m08:22:03.477740 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:22:03.479739 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8314342, "process_in_blocks": "0", "process_kernel_time": 0.144241, "process_mem_max_rss": "222996", "process_out_blocks": "0", "process_user_time": 3.451483}
[0m08:22:03.480925 [debug] [MainThread]: Command `dbt run` succeeded at 08:22:03.480799 after 4.83 seconds
[0m08:22:03.481928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52ab48c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52aca5350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52aca5210>]}
[0m08:22:03.482989 [debug] [MainThread]: Flushing usage events
[0m08:22:04.544138 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:22:17.701112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44daecbb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dae7b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dae7aa10>]}


============================== 08:22:17.703736 | b4a8c7b2-0f48-4de6-bf00-984e84d2b338 ==============================
[0m08:22:17.703736 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:22:17.707145 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:22:18.292096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b4a8c7b2-0f48-4de6-bf00-984e84d2b338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b1103810>]}
[0m08:22:18.337217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b4a8c7b2-0f48-4de6-bf00-984e84d2b338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b117cf10>]}
[0m08:22:18.338226 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:22:18.406073 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:22:18.534804 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m08:22:18.536253 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:22:18.536954 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:22:18.833272 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.hailing_project.stg_driver' (models/staging/stg_driver.sql) depends on a source named 'source.driver_data' which was not found
[0m08:22:18.835370 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1823285, "process_in_blocks": "0", "process_kernel_time": 0.141755, "process_mem_max_rss": "215568", "process_out_blocks": "0", "process_user_time": 3.057857}
[0m08:22:18.836458 [debug] [MainThread]: Command `dbt run` failed at 08:22:18.836343 after 1.18 seconds
[0m08:22:18.837279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dacf9690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dacfba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b0cd05d0>]}
[0m08:22:18.838174 [debug] [MainThread]: Flushing usage events
[0m08:22:19.859620 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:22:41.760571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38887f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388c6e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888c36d0>]}


============================== 08:22:41.764248 | 971611f3-095f-4bdc-adff-384ed1f3b5dd ==============================
[0m08:22:41.764248 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:22:41.766273 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:22:42.405008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888df610>]}
[0m08:22:42.454837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38ab04a10>]}
[0m08:22:42.456489 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:22:42.528347 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:22:42.672747 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:22:42.673793 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:22:43.007607 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:22:43.020459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35aa23810>]}
[0m08:22:43.100224 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:43.105650 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:43.121002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a86ff50>]}
[0m08:22:43.122311 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:22:43.123673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a6d4390>]}
[0m08:22:43.126684 [info ] [MainThread]: 
[0m08:22:43.127817 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:22:43.128843 [info ] [MainThread]: 
[0m08:22:43.130513 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:22:43.136209 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:22:43.137209 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:43.637140 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:22:43.638417 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:22:43.886919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a673d50>]}
[0m08:22:43.888157 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:22:43.894076 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:22:43.894455 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:22:43.894891 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:22:43.895213 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:22:43.895744 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:22:43.896819 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:22:43.897984 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:22:43.899057 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:22:43.900200 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:22:43.901220 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:22:43.902148 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:22:43.903061 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:22:43.903774 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:22:43.904853 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:22:43.905711 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:22:43.906540 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:22:43.916133 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:22:43.920501 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:22:43.925880 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:22:43.930128 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:22:43.936002 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:22:43.936673 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:22:43.942979 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:22:43.953090 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:22:43.987034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:43.987499 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:22:43.989835 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:22:43.992680 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:22:44.286333 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:22:44.288181 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:22:44.292592 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:22:44.293746 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:22:44.296363 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:22:44.303643 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:22:44.305470 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:22:44.307945 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:22:44.560086 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:898bc365-4a1b-4083-b8c1-dfc45cf4a1f1&page=queryresults
[0m08:22:44.565353 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:077de461-4221-4a1c-af9d-237cbc305ec8&page=queryresults
[0m08:22:44.731529 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:077de461-4221-4a1c-af9d-237cbc305ec8&page=queryresults
[0m08:22:44.747043 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m08:22:44.749992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd358405ed0>]}
[0m08:22:44.751242 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.85s]
[0m08:22:44.752903 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:22:44.754518 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m08:22:44.836801 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8a6a3c55-e78c-4954-9742-fd78f2485047&page=queryresults
[0m08:22:45.653035 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce572007-8886-46ca-9dbb-0cc80cf42a36&page=queryresults
[0m08:22:46.396178 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a5a1d10>]}
[0m08:22:46.398178 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.49s]
[0m08:22:46.399788 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:22:46.895988 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35842f9d0>]}
[0m08:22:46.897519 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.99s]
[0m08:22:46.899179 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:22:47.464938 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a5a1850>]}
[0m08:22:47.466621 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.56s]
[0m08:22:47.468175 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:22:47.470574 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:22:47.473975 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:47.474902 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:22:47.475720 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:22:47.476571 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:22:47.477315 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:22:47.478392 [info ] [MainThread]: 
[0m08:22:47.479390 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m08:22:47.482287 [debug] [MainThread]: Command end result
[0m08:22:47.516280 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:47.520396 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:47.528804 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:22:47.529804 [info ] [MainThread]: 
[0m08:22:47.531162 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:22:47.532243 [info ] [MainThread]: 
[0m08:22:47.533362 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m08:22:47.534328 [info ] [MainThread]: 
[0m08:22:47.535393 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m08:22:47.537137 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.833213, "process_in_blocks": "448", "process_kernel_time": 0.207239, "process_mem_max_rss": "228060", "process_out_blocks": "0", "process_user_time": 3.621758}
[0m08:22:47.538493 [debug] [MainThread]: Command `dbt run` failed at 08:22:47.538312 after 5.83 seconds
[0m08:22:47.539590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888b5790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34a6ba050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888b4790>]}
[0m08:22:47.540485 [debug] [MainThread]: Flushing usage events
[0m08:22:48.770993 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:23:10.006409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d483bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d8d84d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d42f050>]}


============================== 08:23:10.009479 | e8c378eb-1201-41dc-995a-5ef9097b55f0 ==============================
[0m08:23:10.009479 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:23:10.010632 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:23:10.703903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df546e10>]}
[0m08:23:10.757024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e4e14f10>]}
[0m08:23:10.758564 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:23:10.834599 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:23:10.985412 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:23:10.986755 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:23:11.270486 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:23:11.286192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df502290>]}
[0m08:23:11.362266 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:23:11.368632 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:23:11.383211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df19ea10>]}
[0m08:23:11.384297 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:23:11.386028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df1a4610>]}
[0m08:23:11.389244 [info ] [MainThread]: 
[0m08:23:11.390372 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:23:11.391547 [info ] [MainThread]: 
[0m08:23:11.393473 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:23:11.398866 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:23:11.400111 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:11.874677 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:23:11.875625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:23:12.104283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df7d4b90>]}
[0m08:23:12.105692 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:23:12.112297 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:23:12.112845 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:23:12.113454 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:23:12.114011 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:23:12.114755 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:23:12.116068 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:23:12.117779 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:23:12.119291 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:23:12.121170 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:23:12.122695 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:23:12.124071 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:23:12.125413 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:23:12.126641 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:23:12.127832 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:23:12.129124 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:23:12.130232 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:23:12.144780 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:23:12.150053 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:23:12.157498 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:23:12.161654 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:23:12.167988 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:23:12.168905 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:23:12.174713 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:23:12.175104 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:23:12.211682 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:23:12.211969 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:23:12.214865 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:23:12.218302 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:23:12.538360 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:23:12.539920 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:23:12.540565 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:23:12.537091 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:23:12.545917 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:23:12.546812 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:23:12.548862 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:23:12.551573 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:23:12.794914 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6988f829-1759-42d0-bb8d-9fadc9750f5c&page=queryresults
[0m08:23:12.795537 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4e4cccf0-ba08-4fe6-b244-40d31183711b&page=queryresults
[0m08:23:12.812820 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a3a3a744-253c-4f7b-b4c1-e911e23fb65b&page=queryresults
[0m08:23:12.840339 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27a1e004-58ca-4360-83e5-3d73608b0a5d&page=queryresults
[0m08:23:14.364948 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df323a50>]}
[0m08:23:14.366262 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.24s]
[0m08:23:14.368496 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:23:14.564064 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc75b890>]}
[0m08:23:14.568138 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc764ed0>]}
[0m08:23:14.569354 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.44s]
[0m08:23:14.572283 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m08:23:14.574182 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:23:14.575777 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:23:14.609671 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc74c590>]}
[0m08:23:14.610826 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.49s]
[0m08:23:14.622350 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:23:14.628976 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:23:14.632897 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:23:14.639967 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:23:14.641615 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:23:14.642475 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:23:14.643922 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:23:14.645390 [info ] [MainThread]: 
[0m08:23:14.646648 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m08:23:14.648508 [debug] [MainThread]: Command end result
[0m08:23:14.699662 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:23:14.705466 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:23:14.713966 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:23:14.714931 [info ] [MainThread]: 
[0m08:23:14.716212 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:23:14.717633 [info ] [MainThread]: 
[0m08:23:14.718841 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:23:14.720861 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.779687, "process_in_blocks": "0", "process_kernel_time": 0.161282, "process_mem_max_rss": "224496", "process_out_blocks": "0", "process_user_time": 3.769968}
[0m08:23:14.721979 [debug] [MainThread]: Command `dbt run` succeeded at 08:23:14.721862 after 4.78 seconds
[0m08:23:14.723011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d2abdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4810ce8a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4810d787d0>]}
[0m08:23:14.724382 [debug] [MainThread]: Flushing usage events
[0m08:23:15.791846 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:27:30.959413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316be3950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c33f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c2b7d0>]}


============================== 08:27:30.962303 | bea2439a-3348-4f55-a283-4c04192d726c ==============================
[0m08:27:30.962303 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:27:30.963575 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:27:31.561458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ed06a950>]}
[0m08:27:31.610933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3318e96150>]}
[0m08:27:31.612449 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:27:31.682920 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:27:31.822084 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 4 files added, 1 files changed.
[0m08:27:31.823302 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_ride_staging.sql
[0m08:27:31.824261 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_vehicle_staging.sql
[0m08:27:31.825284 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_customer_staging.sql
[0m08:27:31.826110 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_driver_staging.sql
[0m08:27:31.826988 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:27:31.827802 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_customer.sql
[0m08:27:31.828532 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_driver.sql
[0m08:27:31.829297 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_ride.sql
[0m08:27:31.830335 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_vehicle.sql
[0m08:27:32.183624 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:27:32.197759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec9e8610>]}
[0m08:27:32.277301 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:27:32.283668 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:27:32.298710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec7f7290>]}
[0m08:27:32.299996 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:27:32.301759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33172d65d0>]}
[0m08:27:32.304783 [info ] [MainThread]: 
[0m08:27:32.306121 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:27:32.307523 [info ] [MainThread]: 
[0m08:27:32.309641 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:27:32.314422 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:27:32.316149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:27:32.905040 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:27:32.906245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:27:33.111609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ecf7c210>]}
[0m08:27:33.113027 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:27:33.120084 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.120622 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.121101 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.121634 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.123495 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [RUN]
[0m08:27:33.125415 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [RUN]
[0m08:27:33.127184 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [RUN]
[0m08:27:33.129172 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [RUN]
[0m08:27:33.131370 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_customer_staging)
[0m08:27:33.133550 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_driver_staging'
[0m08:27:33.136521 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_ride_staging'
[0m08:27:33.138106 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_vehicle_staging'
[0m08:27:33.139550 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.140992 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.142840 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.144255 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.154140 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_customer_staging"
[0m08:27:33.159558 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_driver_staging"
[0m08:27:33.165776 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_ride_staging"
[0m08:27:33.170662 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:27:33.176842 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.183716 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.211126 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.216911 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.273959 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:27:33.274959 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_customer_staging"
[0m08:27:33.277939 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_driver_staging"
[0m08:27:33.282491 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_ride_staging"
[0m08:27:33.287572 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_customer_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_customer_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:27:33.288961 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:27:33.289427 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_vehicle_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_vehicle_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    );
  
[0m08:27:33.290744 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_ride_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_ride_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    );
  
[0m08:27:33.291570 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:27:33.292389 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_driver_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_driver_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:27:33.294527 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:27:33.318625 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:27:33.706692 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7fc33d6e-81d0-4263-95bf-1c8956f8c172&page=queryresults
[0m08:27:33.716220 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31085e80-a3cf-4850-9b4a-0e89417e82c9&page=queryresults
[0m08:27:33.722078 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bc8394a4-3750-4e31-b3a2-1d3aeabb0b44&page=queryresults
[0m08:27:33.726232 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9066ce79-d874-4f6f-a75a-2e05455cc4ce&page=queryresults
[0m08:27:35.593557 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ecfab0d0>]}
[0m08:27:35.595426 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec45b050>]}
[0m08:27:35.597305 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.46s]
[0m08:27:35.598170 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec283350>]}
[0m08:27:35.599250 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.46s]
[0m08:27:35.600598 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_customer_staging
[0m08:27:35.602178 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.46s]
[0m08:27:35.603419 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:35.605232 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_driver_staging
[0m08:27:35.617693 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec7f5f50>]}
[0m08:27:35.618692 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.48s]
[0m08:27:35.619871 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_ride_staging
[0m08:27:35.622893 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:27:35.625989 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:27:35.626936 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_customer_staging' was properly closed.
[0m08:27:35.627933 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_driver_staging' was properly closed.
[0m08:27:35.628818 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_ride_staging' was properly closed.
[0m08:27:35.629777 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_vehicle_staging' was properly closed.
[0m08:27:35.630671 [info ] [MainThread]: 
[0m08:27:35.631722 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.32 seconds (3.32s).
[0m08:27:35.633318 [debug] [MainThread]: Command end result
[0m08:27:35.668417 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:27:35.673451 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:27:35.682040 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:27:35.682934 [info ] [MainThread]: 
[0m08:27:35.684269 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:27:35.686117 [info ] [MainThread]: 
[0m08:27:35.687174 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:27:35.688857 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7852182, "process_in_blocks": "0", "process_kernel_time": 0.270995, "process_mem_max_rss": "224704", "process_out_blocks": "0", "process_user_time": 3.663454}
[0m08:27:35.690050 [debug] [MainThread]: Command `dbt run` succeeded at 08:27:35.689879 after 4.79 seconds
[0m08:27:35.691191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c2b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316fddf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f331a508b10>]}
[0m08:27:35.692269 [debug] [MainThread]: Flushing usage events
[0m08:27:36.829557 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:39:38.577262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88def3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88def3510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88dea2d90>]}


============================== 08:39:38.580813 | 5b5196af-75b8-4e53-bbcd-ea4035cf723e ==============================
[0m08:39:38.580813 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:39:38.582552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:39:39.188386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8647dc2d0>]}
[0m08:39:39.233777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff890158b10>]}
[0m08:39:39.235247 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:39:39.307329 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:39:39.446764 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:39:39.448612 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:39:39.801061 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:39:39.812341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88ec64490>]}
[0m08:39:39.884185 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:39:39.891044 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:39:39.905683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8641aed50>]}
[0m08:39:39.906796 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:39:39.908433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85fcf7d90>]}
[0m08:39:39.911366 [info ] [MainThread]: 
[0m08:39:39.912489 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:39:39.913568 [info ] [MainThread]: 
[0m08:39:39.914949 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:39:39.920109 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:39:39.921037 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:39:40.503687 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:39:40.504818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:39:40.773147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88f098750>]}
[0m08:39:40.774127 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:39:40.779144 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.779498 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.779838 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.780118 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.780634 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [RUN]
[0m08:39:40.781653 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [RUN]
[0m08:39:40.782763 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [RUN]
[0m08:39:40.783878 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [RUN]
[0m08:39:40.784902 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_customer_staging)
[0m08:39:40.785951 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_driver_staging'
[0m08:39:40.786883 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_ride_staging'
[0m08:39:40.788751 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_vehicle_staging'
[0m08:39:40.789745 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.790628 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.791483 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.792417 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.800291 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_customer_staging"
[0m08:39:40.804776 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_driver_staging"
[0m08:39:40.809609 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_ride_staging"
[0m08:39:40.813770 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:39:40.820314 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.821615 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.827934 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.848484 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.905256 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_customer_staging"
[0m08:39:40.905858 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:39:40.910465 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_ride_staging"
[0m08:39:40.915140 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_driver_staging"
[0m08:39:40.921371 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_customer_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_customer_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:39:40.923021 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_driver_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_driver_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:39:40.923574 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_ride_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_ride_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m08:39:40.924351 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:39:40.925255 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_vehicle_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_vehicle_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m08:39:40.925913 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:39:40.927023 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:39:40.929315 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:39:41.431996 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1363d983-f250-470b-82bc-904e80a950b5&page=queryresults
[0m08:39:41.439151 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9940b5b3-c090-43f4-a64b-faa6760986a4&page=queryresults
[0m08:39:41.448901 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:54c66f7a-af0b-476e-87a8-66e5049e5903&page=queryresults
[0m08:39:41.467382 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a16d22a3-38b6-46f5-b56a-2a38549df091&page=queryresults
[0m08:39:43.178411 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88e599f90>]}
[0m08:39:43.178990 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85c138210>]}
[0m08:39:43.179664 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85c11a9d0>]}
[0m08:39:43.180781 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m08:39:43.182279 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.39s]
[0m08:39:43.183893 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m08:39:43.187346 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_customer_staging
[0m08:39:43.188234 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85fa78990>]}
[0m08:39:43.189308 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_ride_staging
[0m08:39:43.191172 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_driver_staging
[0m08:39:43.193714 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.40s]
[0m08:39:43.197053 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:43.199905 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:39:43.204144 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:39:43.205339 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_customer_staging' was properly closed.
[0m08:39:43.206770 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_driver_staging' was properly closed.
[0m08:39:43.207741 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_ride_staging' was properly closed.
[0m08:39:43.208462 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_vehicle_staging' was properly closed.
[0m08:39:43.209673 [info ] [MainThread]: 
[0m08:39:43.210887 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.29 seconds (3.29s).
[0m08:39:43.212824 [debug] [MainThread]: Command end result
[0m08:39:43.250261 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:39:43.255282 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:39:43.264495 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:39:43.265487 [info ] [MainThread]: 
[0m08:39:43.266789 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:39:43.267931 [info ] [MainThread]: 
[0m08:39:43.269090 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:39:43.270753 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.754618, "process_in_blocks": "0", "process_kernel_time": 0.178834, "process_mem_max_rss": "224996", "process_out_blocks": "0", "process_user_time": 3.646234}
[0m08:39:43.271813 [debug] [MainThread]: Command `dbt run` succeeded at 08:39:43.271665 after 4.76 seconds
[0m08:39:43.272837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88e38b710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8917ba890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8917bbe10>]}
[0m08:39:43.273980 [debug] [MainThread]: Flushing usage events
[0m08:39:44.535912 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:41:44.508859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe0015f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc1db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc6ba90>]}


============================== 08:41:44.511995 | 9e13fda7-806a-4f8c-92f7-037962eb7068 ==============================
[0m08:41:44.511995 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:41:44.513392 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:41:45.091789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb81d5750>]}
[0m08:41:45.139722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe1e91f50>]}
[0m08:41:45.141190 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:41:45.208456 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:41:45.354277 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 4 files added, 0 files changed.
[0m08:41:45.355482 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_ride.sql
[0m08:41:45.356515 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m08:41:45.357617 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_driver.sql
[0m08:41:45.358502 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_vehicle.sql
[0m08:41:45.359555 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_driver_staging.sql
[0m08:41:45.360456 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_customer_staging.sql
[0m08:41:45.361405 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_ride_staging.sql
[0m08:41:45.362254 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_vehicle_staging.sql
[0m08:41:45.630494 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:41:45.642505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1e46b10>]}
[0m08:41:45.720003 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:41:45.726872 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:41:45.741856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1d9ebd0>]}
[0m08:41:45.742934 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:41:45.744183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1f1dd50>]}
[0m08:41:45.747599 [info ] [MainThread]: 
[0m08:41:45.748694 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:41:45.749705 [info ] [MainThread]: 
[0m08:41:45.750723 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:41:45.754864 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:41:45.755758 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:41:46.326346 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:41:46.327235 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:41:46.584013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1f1e310>]}
[0m08:41:46.585502 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:41:46.592811 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.593231 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.593562 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.593910 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.594450 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m08:41:46.596132 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m08:41:46.597253 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m08:41:46.598298 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m08:41:46.599467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m08:41:46.600500 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m08:41:46.601496 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m08:41:46.602530 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:41:46.603243 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.604029 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.604734 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.605536 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.614089 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:41:46.618498 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:41:46.622632 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:41:46.626572 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:41:46.631751 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.638684 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.660511 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.666438 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.716323 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:41:46.718476 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:41:46.722007 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:41:46.727807 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:41:46.736683 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:41:46.738298 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:41:46.739047 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m08:41:46.740751 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m08:41:46.741412 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:41:46.742243 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:41:46.746092 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:41:46.768762 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:41:47.228720 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cb0b32c7-6a70-428c-9c74-72a25cffcf1f&page=queryresults
[0m08:41:47.231334 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:486b0192-d722-449f-b154-09c4ef7334d7&page=queryresults
[0m08:41:47.234280 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:860fee08-ffe9-4668-8cbc-cf82af9cd63b&page=queryresults
[0m08:41:47.259504 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:05c35d65-43f5-47e1-a6c4-47b023f0b583&page=queryresults
[0m08:41:49.155470 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effa1f6c750>]}
[0m08:41:49.155836 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1fab690>]}
[0m08:41:49.156142 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe099ea90>]}
[0m08:41:49.157290 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.55s]
[0m08:41:49.158635 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.56s]
[0m08:41:49.160177 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.55s]
[0m08:41:49.161613 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:41:49.162813 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:41:49.164114 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:41:49.177392 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1a1ba90>]}
[0m08:41:49.178844 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.57s]
[0m08:41:49.180411 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:49.182571 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:41:49.185888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:41:49.186909 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m08:41:49.187942 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:41:49.188715 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:41:49.189306 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:41:49.190023 [info ] [MainThread]: 
[0m08:41:49.190945 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.44 seconds (3.44s).
[0m08:41:49.193114 [debug] [MainThread]: Command end result
[0m08:41:49.226359 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:41:49.230612 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:41:49.238958 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:41:49.239950 [info ] [MainThread]: 
[0m08:41:49.241156 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:41:49.242717 [info ] [MainThread]: 
[0m08:41:49.244169 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:41:49.245833 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.790658, "process_in_blocks": "0", "process_kernel_time": 0.242733, "process_mem_max_rss": "224756", "process_out_blocks": "0", "process_user_time": 3.499414}
[0m08:41:49.247003 [debug] [MainThread]: Command `dbt run` succeeded at 08:41:49.246894 after 4.79 seconds
[0m08:41:49.247855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc6b110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc9b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe3438c10>]}
[0m08:41:49.248612 [debug] [MainThread]: Flushing usage events
[0m08:41:50.360982 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:53.438048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb843090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bbd23790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb842d90>]}


============================== 08:55:53.440785 | 188f2d7a-2cad-4b2f-9d3b-318ce69a68c5 ==============================
[0m08:55:53.440785 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:53.443792 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:55:53.541592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '188f2d7a-2cad-4b2f-9d3b-318ce69a68c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb740590>]}
[0m08:55:53.616102 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.22455075, "process_in_blocks": "0", "process_kernel_time": 0.119231, "process_mem_max_rss": "89884", "process_out_blocks": "0", "process_user_time": 0.924043}
[0m08:55:53.616990 [debug] [MainThread]: Command `dbt clean` succeeded at 08:55:53.616891 after 0.23 seconds
[0m08:55:53.617840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bf305850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bf00cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bbc3a090>]}
[0m08:55:53.618611 [debug] [MainThread]: Flushing usage events
[0m08:55:54.719266 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:55.867510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eccfdb250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd016150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eccfdad10>]}


============================== 08:55:55.870876 | ab56964a-a0bb-4c5d-8da2-9de161090d50 ==============================
[0m08:55:55.870876 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:55.872480 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:55:55.955841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab56964a-a0bb-4c5d-8da2-9de161090d50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecced5d90>]}
[0m08:55:55.967959 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m08:55:55.970791 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m08:55:55.972410 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1555311, "process_in_blocks": "0", "process_kernel_time": 0.109292, "process_mem_max_rss": "90120", "process_out_blocks": "0", "process_user_time": 0.963762}
[0m08:55:55.973544 [debug] [MainThread]: Command `dbt deps` succeeded at 08:55:55.973423 after 0.16 seconds
[0m08:55:55.974805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd04f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd016150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed07f4b90>]}
[0m08:55:55.975714 [debug] [MainThread]: Flushing usage events
[0m08:55:57.027390 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:59.333091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec212f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec257910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec256f90>]}


============================== 08:55:59.336082 | 9be4d424-1a46-4f73-b13a-dc52af359668 ==============================
[0m08:55:59.336082 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:59.337134 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:55:59.954350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be4273d0>]}
[0m08:56:00.011637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ee486150>]}
[0m08:56:00.013063 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:00.111993 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:00.114820 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:56:00.116055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be40c890>]}
[0m08:56:00.959452 [error] [MainThread]: Encountered an error:
Compilation Error in model dim_customer (models/facts/dim_customer.sql)
  expected token ',', got 'partition_by'
    line 6
      partition_by={
[0m08:56:00.961679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6971128, "process_in_blocks": "0", "process_kernel_time": 0.173183, "process_mem_max_rss": "212028", "process_out_blocks": "0", "process_user_time": 3.545171}
[0m08:56:00.962928 [debug] [MainThread]: Command `dbt run` failed at 08:56:00.962774 after 1.70 seconds
[0m08:56:00.963870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec31dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be517a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec242b90>]}
[0m08:56:00.964920 [debug] [MainThread]: Flushing usage events
[0m08:56:02.218201 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:56:14.289954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0d97190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d2ba9ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0d96610>]}


============================== 08:56:14.293297 | 47699dbc-bf56-4bee-86af-c67e838e11b7 ==============================
[0m08:56:14.293297 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:56:14.294521 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:56:14.927525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a80db5d0>]}
[0m08:56:14.972869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d300c710>]}
[0m08:56:14.974099 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:15.043632 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:15.047056 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:56:15.048294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a9335c90>]}
[0m08:56:16.070617 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:56:16.083971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a321bd50>]}
[0m08:56:16.160529 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:56:16.166191 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:56:16.180220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2947010>]}
[0m08:56:16.181182 [info ] [MainThread]: Found 5 models, 4 sources, 488 macros
[0m08:56:16.182253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2b4c910>]}
[0m08:56:16.185224 [info ] [MainThread]: 
[0m08:56:16.186651 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:56:16.187777 [info ] [MainThread]: 
[0m08:56:16.189187 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:56:16.194044 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:16.194817 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:16.195635 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:16.196568 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:17.174266 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m08:56:17.175593 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m08:56:17.185112 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m08:56:17.185993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:18.033143 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:a4611c7b-5f04-4e83-a696-d54823fc335a&page=queryresults
[0m08:56:18.952582 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m08:56:18.953105 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:56:18.954022 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:18.955119 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:19.504221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2fb3650>]}
[0m08:56:19.505634 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:56:19.511265 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.511990 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.512357 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.512797 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.513537 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m08:56:19.514609 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m08:56:19.515507 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m08:56:19.516567 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m08:56:19.517726 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m08:56:19.519027 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_driver)
[0m08:56:19.520188 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m08:56:19.521117 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:56:19.521991 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.522896 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.523746 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.524590 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.535354 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:56:19.540152 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:56:19.545159 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:56:19.549713 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:56:19.564158 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.570611 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.589141 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.608163 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:19.609444 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:56:19.609835 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.612375 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:56:19.617880 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:56:19.911915 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:56:19.915510 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:56:19.916741 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:56:19.918280 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:56:19.929276 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:56:19.930726 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:56:19.934719 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:56:19.937538 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:56:20.261435 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d34d8f83-627d-4416-95ee-161fecb8b93d&page=queryresults
[0m08:56:20.261907 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b945e293-6643-4419-8c69-ba34c7d4dd22&page=queryresults
[0m08:56:20.264128 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:29ebc6f8-24cf-46ca-ad87-cb0162c9c32b&page=queryresults
[0m08:56:20.266154 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9bd397cb-b8f3-45da-a108-41ad7e513f76&page=queryresults
[0m08:56:21.808083 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a29acdd0>]}
[0m08:56:21.809431 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.29s]
[0m08:56:21.811020 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:56:21.812414 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m08:56:21.813620 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m08:56:21.814852 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_customer)
[0m08:56:21.815989 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m08:56:21.820607 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m08:56:21.831710 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m08:56:21.857714 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2937890>]}
[0m08:56:21.870866 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a16be7d0>]}
[0m08:56:21.872176 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m08:56:21.872998 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.34s]
[0m08:56:21.874492 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.35s]
[0m08:56:21.876872 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:21.877997 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:56:21.885955 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m08:56:21.887595 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:22.066828 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a1663c10>]}
[0m08:56:22.068223 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.55s]
[0m08:56:22.069559 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:56:22.145883 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27053855-795a-4b5e-a8d0-39f127d3302c&page=queryresults
[0m08:56:22.147182 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27053855-795a-4b5e-a8d0-39f127d3302c&page=queryresults
[0m08:56:22.152102 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m08:56:22.153159 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a03f1750>]}
[0m08:56:22.155106 [error] [Thread-1 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.34s]
[0m08:56:22.157201 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m08:56:22.158745 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m08:56:22.161659 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:56:22.165718 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:56:22.166637 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m08:56:22.167453 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:56:22.168136 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:56:22.168996 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:56:22.170079 [info ] [MainThread]: 
[0m08:56:22.171559 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.98 seconds (5.98s).
[0m08:56:22.174005 [debug] [MainThread]: Command end result
[0m08:56:22.211249 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:56:22.215917 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:56:22.225212 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:56:22.225981 [info ] [MainThread]: 
[0m08:56:22.226983 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:56:22.228025 [info ] [MainThread]: 
[0m08:56:22.229124 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m08:56:22.230038 [info ] [MainThread]: 
[0m08:56:22.231046 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m08:56:22.232740 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.001722, "process_in_blocks": "0", "process_kernel_time": 0.270523, "process_mem_max_rss": "227580", "process_out_blocks": "0", "process_user_time": 4.318353}
[0m08:56:22.233893 [debug] [MainThread]: Command `dbt run` failed at 08:56:22.233774 after 8.00 seconds
[0m08:56:22.234960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d1192250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d1192490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0e13650>]}
[0m08:56:22.235975 [debug] [MainThread]: Flushing usage events
[0m08:56:23.522471 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:02:51.542904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c3bd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058fde110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c3bad0>]}


============================== 09:02:51.545550 | 330823d6-ff0a-4567-87ad-72d7c9342a21 ==============================
[0m09:02:51.545550 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:02:51.546773 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:02:52.119321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058beac50>]}
[0m09:02:52.177202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f005ae5a250>]}
[0m09:02:52.178567 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:02:52.252413 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:02:52.400017 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m09:02:52.401572 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m09:02:52.402603 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m09:02:52.733720 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m09:02:52.745280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa17c10>]}
[0m09:02:52.819470 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:02:52.825069 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:02:52.840761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a9fea10>]}
[0m09:02:52.841995 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m09:02:52.843352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa0ce90>]}
[0m09:02:52.846181 [info ] [MainThread]: 
[0m09:02:52.847420 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:02:52.848474 [info ] [MainThread]: 
[0m09:02:52.849960 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:02:52.855113 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:02:52.856788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:53.499168 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m09:02:53.500207 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:02:53.728327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a9d5c50>]}
[0m09:02:53.729338 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:02:53.734358 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m09:02:53.734705 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.735116 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.735495 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.736050 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m09:02:53.737325 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m09:02:53.738564 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m09:02:53.739692 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m09:02:53.741038 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m09:02:53.742016 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m09:02:53.743448 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m09:02:53.744709 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m09:02:53.745860 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m09:02:53.747015 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.748515 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.749682 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.757780 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m09:02:53.764643 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m09:02:53.768179 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m09:02:53.772066 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m09:02:53.777580 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.778568 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.779070 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m09:02:53.779403 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.827489 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m09:02:53.828068 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m09:02:53.851716 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m09:02:53.858596 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m09:02:53.933183 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m09:02:53.934676 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:02:54.152322 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m09:02:54.153664 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m09:02:54.154833 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m09:02:54.159867 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m09:02:54.160491 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:02:54.161284 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m09:02:54.370648 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6923a34-c577-44dd-b997-85fd21cd509c&page=queryresults
[0m09:02:54.441687 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:293ccd08-85c5-4147-83ce-6594f1c73c86&page=queryresults
[0m09:02:54.481932 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:aa9af51f-d7d5-423b-804e-cd12e703d850&page=queryresults
[0m09:02:54.482568 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:59fc1ea1-e78f-42cd-bf0e-9d46f236fbb2&page=queryresults
[0m09:02:55.997230 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a799f90>]}
[0m09:02:55.998739 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m09:02:56.000818 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m09:02:56.001894 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.003167 [info ] [Thread-3 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m09:02:56.004397 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m09:02:56.005565 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.009769 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:02:56.016948 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.021384 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m09:02:56.254285 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:02:56.255329 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa03c10>]}
[0m09:02:56.258163 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.51s]
[0m09:02:56.260890 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m09:02:56.265466 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m09:02:56.308142 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00283a4350>]}
[0m09:02:56.309167 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.56s]
[0m09:02:56.310601 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m09:02:56.321177 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a7ea350>]}
[0m09:02:56.322610 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.58s]
[0m09:02:56.324235 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m09:02:56.536349 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d34e8e4e-03a9-4c73-8223-06ff0091a353&page=queryresults
[0m09:02:58.336631 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00283bc6d0>]}
[0m09:02:58.337669 [info ] [Thread-3 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.33s]
[0m09:02:58.339068 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:58.341586 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:02:58.344499 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:02:58.346593 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m09:02:58.347619 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m09:02:58.348772 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m09:02:58.349562 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m09:02:58.350458 [info ] [MainThread]: 
[0m09:02:58.351800 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.50 seconds (5.50s).
[0m09:02:58.354845 [debug] [MainThread]: Command end result
[0m09:02:58.389635 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:02:58.393696 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:02:58.402108 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:02:58.402813 [info ] [MainThread]: 
[0m09:02:58.403912 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:02:58.404872 [info ] [MainThread]: 
[0m09:02:58.405898 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m09:02:58.407909 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.9183664, "process_in_blocks": "0", "process_kernel_time": 0.252014, "process_mem_max_rss": "225460", "process_out_blocks": "0", "process_user_time": 3.659243}
[0m09:02:58.409070 [debug] [MainThread]: Command `dbt run` succeeded at 09:02:58.408936 after 6.92 seconds
[0m09:02:58.410072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c5d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c5fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f005c400b90>]}
[0m09:02:58.411296 [debug] [MainThread]: Flushing usage events
[0m09:02:59.905363 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:05:40.652242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d047210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d09f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d09f910>]}


============================== 09:05:40.655139 | 69f36ca5-b52f-4434-9df8-c01e6bfa18b1 ==============================
[0m09:05:40.655139 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:05:40.657692 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:05:41.221983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadf7d8090>]}
[0m09:05:41.272996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0f2a18d0>]}
[0m09:05:41.274088 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:05:41.341978 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:05:41.506980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:05:41.508246 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m09:05:41.843912 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m09:05:41.857778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadf1e1210>]}
[0m09:05:41.924061 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:05:41.929959 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:05:41.945913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadee1c650>]}
[0m09:05:41.947028 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m09:05:41.948225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadecb8d90>]}
[0m09:05:41.951359 [info ] [MainThread]: 
[0m09:05:41.952641 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:05:41.953677 [info ] [MainThread]: 
[0m09:05:41.954813 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:05:41.959141 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:05:41.959976 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:05:42.505924 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m09:05:42.508689 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:05:42.705898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadee4bd50>]}
[0m09:05:42.707070 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:05:42.711777 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m09:05:42.712149 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.712530 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.712974 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.713593 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m09:05:42.714723 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m09:05:42.715762 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m09:05:42.716752 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m09:05:42.717724 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m09:05:42.718797 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m09:05:42.719745 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m09:05:42.720696 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m09:05:42.721593 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m09:05:42.722431 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.723343 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.724209 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.733091 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m09:05:42.737167 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m09:05:42.742361 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m09:05:42.747988 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m09:05:42.757199 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.758157 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m09:05:42.759121 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.759747 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.808084 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:05:42.809762 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m09:05:42.812481 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m09:05:42.815776 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m09:05:43.112639 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m09:05:43.113519 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m09:05:43.115071 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m09:05:43.116180 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m09:05:43.122014 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m09:05:43.122620 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m09:05:43.125599 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:05:43.127344 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:05:43.421019 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dc41b09a-2c91-4117-94e1-03dc32416fb4&page=queryresults
[0m09:05:43.421995 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2ebf480d-6083-4b76-b06f-cc075be5146f&page=queryresults
[0m09:05:43.445782 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f0f01d8c-25fa-49c7-abcb-197fde24211b&page=queryresults
[0m09:05:43.792253 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2a8b8531-8b06-4a7c-90b5-eb8b68f29216&page=queryresults
[0m09:05:43.793595 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2a8b8531-8b06-4a7c-90b5-eb8b68f29216&page=queryresults
[0m09:05:43.797989 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m09:05:43.800027 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc2c6610>]}
[0m09:05:43.800929 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.08s]
[0m09:05:43.802058 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m09:05:43.802775 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.803259 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m09:05:43.803975 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m09:05:43.806136 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m09:05:43.806851 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.811173 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:05:43.817349 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.821184 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:05:44.027398 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:05:44.035178 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m09:05:44.295538 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1650f28a-0e0d-472d-9078-a9b6e4b6dc61&page=queryresults
[0m09:05:44.982314 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc1a4910>]}
[0m09:05:44.984122 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.26s]
[0m09:05:44.985539 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m09:05:45.233156 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac6ec44d0>]}
[0m09:05:45.235443 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.51s]
[0m09:05:45.237945 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m09:05:45.255788 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc2c0210>]}
[0m09:05:45.257290 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.54s]
[0m09:05:45.258591 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m09:05:46.947955 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc298f50>]}
[0m09:05:46.949453 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.14s]
[0m09:05:46.950578 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:46.952496 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:05:46.955351 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:05:46.955931 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m09:05:46.956816 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m09:05:46.957511 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m09:05:46.958173 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m09:05:46.959013 [info ] [MainThread]: 
[0m09:05:46.959783 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.00 seconds (5.00s).
[0m09:05:46.961654 [debug] [MainThread]: Command end result
[0m09:05:46.996389 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:05:47.001341 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:05:47.010074 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:05:47.010829 [info ] [MainThread]: 
[0m09:05:47.012168 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:05:47.013214 [info ] [MainThread]: 
[0m09:05:47.014350 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m09:05:47.015429 [info ] [MainThread]: 
[0m09:05:47.016467 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m09:05:47.018282 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.4130325, "process_in_blocks": "0", "process_kernel_time": 0.23354, "process_mem_max_rss": "228600", "process_out_blocks": "0", "process_user_time": 3.564031}
[0m09:05:47.019699 [debug] [MainThread]: Command `dbt run` failed at 09:05:47.019516 after 6.41 seconds
[0m09:05:47.020730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0cec76d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb10995290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb10995390>]}
[0m09:05:47.021595 [debug] [MainThread]: Flushing usage events
[0m09:05:48.408742 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:47:05.225716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28ee70d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f293fc950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f29cad5d0>]}


============================== 10:47:05.228612 | 70065145-3523-41bc-992e-7d6e2fb95346 ==============================
[0m10:47:05.228612 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:47:05.230662 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --models dim_customer', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:47:05.808886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb096f50>]}
[0m10:47:05.852676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb152550>]}
[0m10:47:05.854086 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:47:05.916922 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:47:06.076192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:47:06.077099 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m10:47:06.328828 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m10:47:06.341285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb10ae90>]}
[0m10:47:06.413539 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:06.418740 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:06.434100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb0b46d0>]}
[0m10:47:06.435339 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:47:06.436370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb08f350>]}
[0m10:47:06.438724 [info ] [MainThread]: 
[0m10:47:06.439927 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:47:06.441276 [info ] [MainThread]: 
[0m10:47:06.442827 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:47:06.444437 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:06.445411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:17.822829 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m10:47:17.823799 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3efac27490>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m10:47:17.825410 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:47:17.829274 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:47:17.830451 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m10:47:17.831838 [info ] [MainThread]: 
[0m10:47:17.832922 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 11.39 seconds (11.39s).
[0m10:47:17.834442 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3efac27490>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m10:47:17.836759 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.658774, "process_in_blocks": "0", "process_kernel_time": 0.222013, "process_mem_max_rss": "214436", "process_out_blocks": "0", "process_user_time": 3.037542}
[0m10:47:17.838187 [debug] [MainThread]: Command `dbt run` failed at 10:47:17.837949 after 12.66 seconds
[0m10:47:17.839805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28f676d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28f67550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efac01090>]}
[0m10:47:17.840947 [debug] [MainThread]: Flushing usage events
[0m10:47:19.128927 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:47:29.890639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0d8d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0db390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0d9e50>]}


============================== 10:47:29.893103 | aed52596-fa5c-42f7-9590-4cbae6145803 ==============================
[0m10:47:29.893103 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:47:29.894280 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:47:30.446491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd2a1150>]}
[0m10:47:30.492198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010d3657d0>]}
[0m10:47:30.493549 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:47:30.565273 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:47:30.718687 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:47:30.719554 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:47:30.724595 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m10:47:30.749674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd336150>]}
[0m10:47:30.865414 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:30.873196 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:30.890421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd47add0>]}
[0m10:47:30.891309 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:47:30.893053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd470150>]}
[0m10:47:30.896264 [info ] [MainThread]: 
[0m10:47:30.897417 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:47:30.898724 [info ] [MainThread]: 
[0m10:47:30.900159 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:47:30.904676 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:30.905776 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:30.906319 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:30.907107 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:31.889457 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:47:31.890522 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m10:47:31.900627 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m10:47:31.901549 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:32.742313 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:8f19e5ce-566a-4a7d-b456-cfa1f1e47693&page=queryresults
[0m10:47:33.686668 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source)
[0m10:47:33.687280 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:47:33.687978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:33.688826 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:34.341070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010c8f6e90>]}
[0m10:47:34.342752 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:47:34.381884 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:47:34.382382 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.382793 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.383101 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.383898 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m10:47:34.386038 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m10:47:34.387942 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m10:47:34.389955 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m10:47:34.391547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m10:47:34.392633 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m10:47:34.393747 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m10:47:34.395249 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m10:47:34.396334 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:47:34.397367 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.398488 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.399620 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.413776 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:47:34.419657 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:47:34.423768 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:47:34.428177 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:47:34.434463 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.435678 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.436226 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:47:34.447262 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.487731 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:47:34.489182 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:47:34.513163 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:47:34.515725 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:47:34.567791 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m10:47:34.592349 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:47:34.875333 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:47:34.876068 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:47:34.877706 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:47:34.883807 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:47:34.884528 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:47:34.886993 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:47:35.172063 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:13e00322-d17c-4cbe-b915-cdd8192c84c0&page=queryresults
[0m10:47:35.178874 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:11c1d713-f50b-42d6-b111-2ff54ccb4fbb&page=queryresults
[0m10:47:35.277297 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5a647779-f690-45dc-a73b-bc1b9fada9a4&page=queryresults
[0m10:47:35.530748 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:4c8fb234-d042-4ba4-a29f-6efbe0a2a0fe&page=queryresults
[0m10:47:35.531684 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:4c8fb234-d042-4ba4-a29f-6efbe0a2a0fe&page=queryresults
[0m10:47:35.536624 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:47:35.538460 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc2c1350>]}
[0m10:47:35.539431 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 1.15s]
[0m10:47:35.540637 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:47:35.541617 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.542159 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m10:47:35.543001 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m10:47:35.545726 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m10:47:35.546761 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.552090 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:47:35.558583 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.564042 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:47:35.829480 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:47:35.835495 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:47:36.117440 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d05ca8ae-accb-459a-94c2-588490c5f08b&page=queryresults
[0m10:47:36.856692 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd07cf10>]}
[0m10:47:36.858301 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.46s]
[0m10:47:36.859676 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:47:37.043756 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc38f510>]}
[0m10:47:37.045100 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.65s]
[0m10:47:37.046657 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:47:37.059635 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc417bd0>]}
[0m10:47:37.060893 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.66s]
[0m10:47:37.062248 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:47:37.944995 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc31cf10>]}
[0m10:47:37.946232 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.40s]
[0m10:47:37.947712 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:37.950505 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:47:37.954244 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:47:37.955193 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:47:37.956014 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:47:37.956828 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:47:37.957779 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:47:37.958864 [info ] [MainThread]: 
[0m10:47:37.959765 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.06 seconds (7.06s).
[0m10:47:37.961967 [debug] [MainThread]: Command end result
[0m10:47:37.998440 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:38.003288 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:38.010868 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:47:38.011659 [info ] [MainThread]: 
[0m10:47:38.012678 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:47:38.013896 [info ] [MainThread]: 
[0m10:47:38.014928 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:47:38.016006 [info ] [MainThread]: 
[0m10:47:38.017065 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m10:47:38.018943 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.172857, "process_in_blocks": "0", "process_kernel_time": 0.264918, "process_mem_max_rss": "222012", "process_out_blocks": "0", "process_user_time": 3.505078}
[0m10:47:38.019974 [debug] [MainThread]: Command `dbt run` failed at 10:47:38.019806 after 8.17 seconds
[0m10:47:38.021093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea59290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea59250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea58950>]}
[0m10:47:38.022004 [debug] [MainThread]: Flushing usage events
[0m10:47:39.351814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:38.348914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682575d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682ab2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682571d0>]}


============================== 10:52:38.351342 | 17fc23dc-a634-49a0-8b4c-e41baa1e2b8a ==============================
[0m10:52:38.351342 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:52:38.352826 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:38.432436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17fc23dc-a634-49a0-8b4c-e41baa1e2b8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6815fc90>]}
[0m10:52:38.503026 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.2023951, "process_in_blocks": "0", "process_kernel_time": 0.112961, "process_mem_max_rss": "89976", "process_out_blocks": "0", "process_user_time": 0.90369}
[0m10:52:38.504197 [debug] [MainThread]: Command `dbt clean` succeeded at 10:52:38.504075 after 0.20 seconds
[0m10:52:38.505002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6ba74b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6bbd1210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6bbd1150>]}
[0m10:52:38.505804 [debug] [MainThread]: Flushing usage events
[0m10:52:42.509533 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:43.744737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c806c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565cbda1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c84efd0>]}


============================== 10:52:43.748318 | 1c121a38-fa0e-401a-bf84-3f9485a1f1ce ==============================
[0m10:52:43.748318 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:52:43.749671 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:43.851136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c121a38-fa0e-401a-bf84-3f9485a1f1ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c6f9510>]}
[0m10:52:43.864771 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:52:43.867773 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:52:43.869966 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.18397304, "process_in_blocks": "0", "process_kernel_time": 0.111166, "process_mem_max_rss": "90236", "process_out_blocks": "0", "process_user_time": 1.081347}
[0m10:52:43.871359 [debug] [MainThread]: Command `dbt deps` succeeded at 10:52:43.871158 after 0.19 seconds
[0m10:52:43.872336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c67d450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c67f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c74aa10>]}
[0m10:52:43.873362 [debug] [MainThread]: Flushing usage events
[0m10:52:47.878066 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:53:07.696733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d955cabd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d96414610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d9561b410>]}


============================== 10:53:07.699204 | 47bb5eb9-06b2-4690-b05d-35c68e8e2196 ==============================
[0m10:53:07.699204 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:53:07.702056 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:53:08.253466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d677635d0>]}
[0m10:53:08.299888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d9784ced0>]}
[0m10:53:08.301660 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:53:08.370858 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:53:08.372926 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m10:53:08.374931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d67e93b50>]}
[0m10:53:09.371956 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m10:53:09.383773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d673785d0>]}
[0m10:53:09.450207 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:53:09.456044 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:53:09.471319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6711ebd0>]}
[0m10:53:09.472528 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:53:09.473825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d672ecd90>]}
[0m10:53:09.476804 [info ] [MainThread]: 
[0m10:53:09.477944 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:53:09.478929 [info ] [MainThread]: 
[0m10:53:09.480210 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:53:09.485253 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:53:09.485904 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:53:09.486780 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:09.487601 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:10.386444 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:53:10.387554 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m10:53:10.396096 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m10:53:10.397067 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:11.471603 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:55bcf902-10df-41de-8cc7-ca93e88efd24&page=queryresults
[0m10:53:12.348471 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:53:12.349105 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m10:53:12.350164 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:12.351336 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:12.931753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d67301b10>]}
[0m10:53:12.932660 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:53:12.938348 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:53:12.938922 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.939270 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:53:12.939618 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:53:12.940152 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m10:53:12.941465 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m10:53:12.942901 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m10:53:12.944061 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m10:53:12.945068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m10:53:12.945836 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m10:53:12.946885 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m10:53:12.948200 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m10:53:12.949027 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:53:12.949889 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.950723 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:53:12.951532 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:53:12.959698 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:53:12.965147 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:53:12.970622 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:53:12.976305 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:53:12.989110 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.990432 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:53:13.017386 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:53:13.028498 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:53:13.046872 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:53:13.057133 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:53:13.064165 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:53:13.067779 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:53:13.147882 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m10:53:13.148872 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:53:13.365141 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:53:13.366434 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:53:13.367792 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:53:13.373978 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:53:13.376038 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:53:13.379635 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:53:13.418202 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce26da19-9c35-42c5-8056-6834abd4339a&page=queryresults
[0m10:53:13.419318 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce26da19-9c35-42c5-8056-6834abd4339a&page=queryresults
[0m10:53:13.424529 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:53:13.426879 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65eb5590>]}
[0m10:53:13.428449 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.48s]
[0m10:53:13.429664 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:53:13.430940 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.431452 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m10:53:13.432424 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m10:53:13.435175 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m10:53:13.436277 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.441153 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:53:13.447412 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.452686 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:53:13.601966 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ecabaf8b-6d28-4398-b1b4-2b39571d7780&page=queryresults
[0m10:53:13.663075 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:528b00ba-53cb-426f-9c07-6cbd1426c40f&page=queryresults
[0m10:53:13.686981 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:53:13.693072 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:53:13.698507 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:edc7d4ea-af0c-450d-8f04-313b9cf6e6bb&page=queryresults
[0m10:53:13.922791 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a49f2bc7-c3a9-4cb0-abd9-20081e720dd5&page=queryresults
[0m10:53:15.169462 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65dfa290>]}
[0m10:53:15.171789 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.22s]
[0m10:53:15.174204 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:53:15.258051 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65da0950>]}
[0m10:53:15.259586 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m10:53:15.261503 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:53:15.403681 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65d1d790>]}
[0m10:53:15.404760 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.46s]
[0m10:53:15.406012 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:53:15.477536 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d64431c90>]}
[0m10:53:15.479227 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.04s]
[0m10:53:15.481202 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:15.484080 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:53:15.487689 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:53:15.488387 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:53:15.489117 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:53:15.490038 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:53:15.490682 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:53:15.491520 [info ] [MainThread]: 
[0m10:53:15.492565 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.01 seconds (6.01s).
[0m10:53:15.494432 [debug] [MainThread]: Command end result
[0m10:53:15.529215 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:53:15.533998 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:53:15.541987 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:53:15.542915 [info ] [MainThread]: 
[0m10:53:15.544038 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:53:15.545046 [info ] [MainThread]: 
[0m10:53:15.546174 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:53:15.547147 [info ] [MainThread]: 
[0m10:53:15.548413 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m10:53:15.549979 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.898837, "process_in_blocks": "0", "process_kernel_time": 0.119124, "process_mem_max_rss": "228720", "process_out_blocks": "0", "process_user_time": 4.308323}
[0m10:53:15.551121 [debug] [MainThread]: Command `dbt run` failed at 10:53:15.551007 after 7.90 seconds
[0m10:53:15.552392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f49350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f490d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f49210>]}
[0m10:53:15.553604 [debug] [MainThread]: Flushing usage events
[0m10:53:16.835917 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:56:36.132311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1ef6610>]}


============================== 10:56:36.135252 | 343c2afa-6065-4787-854b-1d60fb94f933 ==============================
[0m10:56:36.135252 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:56:36.136883 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:56:36.225961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '343c2afa-6065-4787-854b-1d60fb94f933', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1dc2bd0>]}
[0m10:56:36.292894 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.22640637, "process_in_blocks": "0", "process_kernel_time": 0.060813, "process_mem_max_rss": "90112", "process_out_blocks": "0", "process_user_time": 1.094648}
[0m10:56:36.294064 [debug] [MainThread]: Command `dbt clean` succeeded at 10:56:36.293919 after 0.23 seconds
[0m10:56:36.294837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3f410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a574cb90>]}
[0m10:56:36.295788 [debug] [MainThread]: Flushing usage events
[0m10:56:37.666836 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:56:39.006991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dd66a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3e15e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3ddb32d0>]}


============================== 10:56:39.010429 | 815e6183-476d-460e-8e95-5e318e25ca22 ==============================
[0m10:56:39.010429 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:56:39.012443 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:56:39.099022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '815e6183-476d-460e-8e95-5e318e25ca22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dbe3390>]}
[0m10:56:39.110292 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:56:39.113055 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:56:39.114874 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16012742, "process_in_blocks": "0", "process_kernel_time": 0.121413, "process_mem_max_rss": "90280", "process_out_blocks": "0", "process_user_time": 1.092723}
[0m10:56:39.116214 [debug] [MainThread]: Command `dbt deps` succeeded at 10:56:39.116067 after 0.16 seconds
[0m10:56:39.117329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dd65e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e41530b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e416b5250>]}
[0m10:56:39.118296 [debug] [MainThread]: Flushing usage events
[0m10:56:40.153294 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:02:00.047549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ee036d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880f1aa110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880edb1e50>]}


============================== 11:02:00.050164 | e8a77b28-d12e-46be-b714-e83cca3e5af3 ==============================
[0m11:02:00.050164 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:02:00.051707 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:02:00.650740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4f5f290>]}
[0m11:02:00.699282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8811009ed0>]}
[0m11:02:00.700711 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:02:00.771486 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:02:00.774396 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:02:00.775527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e521ab10>]}
[0m11:02:01.812567 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m11:02:01.823962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4c4e050>]}
[0m11:02:01.894366 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:02:01.901120 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:02:01.917186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e49aa790>]}
[0m11:02:01.918126 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:02:01.919315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4fd8550>]}
[0m11:02:01.922066 [info ] [MainThread]: 
[0m11:02:01.923180 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:02:01.924383 [info ] [MainThread]: 
[0m11:02:01.925751 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:02:01.931864 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:02:01.933483 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:02:01.934266 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:01.935251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:17.970612 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m11:02:17.971668 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12510>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:17.994033 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m11:02:17.995312 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12d10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:17.996782 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:02:17.999626 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:02:18.000517 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m11:02:18.001860 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m11:02:18.002718 [info ] [MainThread]: 
[0m11:02:18.004022 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 16.08 seconds (16.08s).
[0m11:02:18.005311 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12510>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:18.006975 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 18.019152, "process_in_blocks": "0", "process_kernel_time": 0.139877, "process_mem_max_rss": "218452", "process_out_blocks": "0", "process_user_time": 3.826657}
[0m11:02:18.008146 [debug] [MainThread]: Command `dbt run` failed at 11:02:18.008016 after 18.02 seconds
[0m11:02:18.009454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ec33a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ec31750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4b4ae50>]}
[0m11:02:18.010433 [debug] [MainThread]: Flushing usage events
[0m11:02:22.012970 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:05:22.851114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f293450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f292f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f292610>]}


============================== 11:05:22.853931 | 61ffee6b-2d10-4073-8f6b-890c3396aa61 ==============================
[0m11:05:22.853931 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:05:22.855687 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:05:22.864717 [info ] [MainThread]: dbt version: 1.9.0
[0m11:05:22.865689 [info ] [MainThread]: python version: 3.11.2
[0m11:05:22.867034 [info ] [MainThread]: python path: /usr/local/bin/python
[0m11:05:22.868130 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m11:05:23.438647 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m11:05:23.439783 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m11:05:23.440969 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m11:05:23.442227 [info ] [MainThread]: adapter type: bigquery
[0m11:05:23.443197 [info ] [MainThread]: adapter version: 1.9.0
[0m11:05:23.529769 [info ] [MainThread]: Configuration:
[0m11:05:23.530977 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:05:23.532248 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:05:23.533740 [info ] [MainThread]: Required dependencies:
[0m11:05:23.534889 [debug] [MainThread]: Executing "git --help"
[0m11:05:23.556307 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:05:23.557605 [debug] [MainThread]: STDERR: "b''"
[0m11:05:23.558535 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:05:23.559501 [info ] [MainThread]: Connection:
[0m11:05:23.560601 [info ] [MainThread]:   method: service-account
[0m11:05:23.561561 [info ] [MainThread]:   database: purwadika
[0m11:05:23.562445 [info ] [MainThread]:   execution_project: purwadika
[0m11:05:23.563618 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m11:05:23.564728 [info ] [MainThread]:   location: None
[0m11:05:23.565897 [info ] [MainThread]:   priority: None
[0m11:05:23.567202 [info ] [MainThread]:   maximum_bytes_billed: None
[0m11:05:23.568244 [info ] [MainThread]:   impersonate_service_account: None
[0m11:05:23.569213 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m11:05:23.570893 [info ] [MainThread]:   job_retries: 1
[0m11:05:23.572461 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m11:05:23.573736 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m11:05:23.574676 [info ] [MainThread]:   timeout_seconds: None
[0m11:05:23.575692 [info ] [MainThread]:   client_id: None
[0m11:05:23.576686 [info ] [MainThread]:   token_uri: None
[0m11:05:23.578282 [info ] [MainThread]:   dataproc_region: None
[0m11:05:23.579453 [info ] [MainThread]:   dataproc_cluster_name: None
[0m11:05:23.580522 [info ] [MainThread]:   gcs_bucket: None
[0m11:05:23.581577 [info ] [MainThread]:   dataproc_batch: None
[0m11:05:23.582855 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:05:23.640826 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m11:05:23.641831 [debug] [MainThread]: On debug: select 1 as id
[0m11:05:23.642730 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:05:24.460305 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f0762509-4051-45ae-997f-9681928cc276&page=queryresults
[0m11:05:25.208408 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:05:25.209796 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:05:25.211732 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.416877, "process_in_blocks": "0", "process_kernel_time": 0.178668, "process_mem_max_rss": "211840", "process_out_blocks": "0", "process_user_time": 2.799132}
[0m11:05:25.213225 [debug] [MainThread]: Command `dbt debug` succeeded at 11:05:25.213029 after 2.42 seconds
[0m11:05:25.214754 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m11:05:25.215781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f2df010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f2df8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb31503210>]}
[0m11:05:25.216958 [debug] [MainThread]: Flushing usage events
[0m11:05:30.425424 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:05:34.071442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6033d2f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6037ca110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6033d2c50>]}


============================== 11:05:34.074281 | 46d3eba4-928d-4033-bfca-d452898145e4 ==============================
[0m11:05:34.074281 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:05:34.075384 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:05:34.676214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d555b350>]}
[0m11:05:34.743263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60562d6d0>]}
[0m11:05:34.744618 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:05:34.816693 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:05:34.892881 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:05:34.894050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff603aba910>]}
[0m11:05:35.918442 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m11:05:35.931881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d52f23d0>]}
[0m11:05:36.006038 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:05:36.012005 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:05:36.028391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f836d0>]}
[0m11:05:36.029438 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:05:36.030755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d51e6810>]}
[0m11:05:36.033749 [info ] [MainThread]: 
[0m11:05:36.034940 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:05:36.036305 [info ] [MainThread]: 
[0m11:05:36.037869 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:05:36.043288 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:05:36.044276 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:05:36.045081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:05:36.046060 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:05:37.411332 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:05:37.412513 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m11:05:37.420573 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m11:05:37.421400 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:38.452477 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:b6be366f-1712-44de-82f8-3906d6bac1b2&page=queryresults
[0m11:05:39.638740 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source)
[0m11:05:39.639487 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:05:39.640697 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:39.641995 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:40.287210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f47990>]}
[0m11:05:40.288748 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:05:40.296401 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:05:40.297374 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.298037 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.298772 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.299870 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m11:05:40.301772 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:05:40.303407 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:05:40.304989 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:05:40.306409 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:05:40.307702 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m11:05:40.309240 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:05:40.310422 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:05:40.311479 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:05:40.312500 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.313399 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.314189 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.324907 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:05:40.331556 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:05:40.336841 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:05:40.341997 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:05:40.359449 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.360666 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:05:40.366628 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.377925 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.440805 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:05:40.447373 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:05:40.467845 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:05:40.475621 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:05:40.578089 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:05:40.579760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:05:40.832321 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:05:40.842349 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:05:40.861408 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:05:40.862738 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:05:40.868415 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:05:40.870179 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:05:40.962738 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca333fcf-3ee4-425c-aed5-397d6732d428&page=queryresults
[0m11:05:40.963808 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca333fcf-3ee4-425c-aed5-397d6732d428&page=queryresults
[0m11:05:40.969089 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:05:40.971603 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d420c790>]}
[0m11:05:40.973065 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.66s]
[0m11:05:40.975576 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:05:40.976946 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:40.977592 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:05:40.978523 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:05:40.981744 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:05:40.983278 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:40.990984 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:05:40.997556 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:41.001914 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:05:41.218352 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1132dcd3-cfdc-492b-ab44-c76d4f13ac12&page=queryresults
[0m11:05:41.222373 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7622e553-68e2-4e93-88c4-c0e70b4ed595&page=queryresults
[0m11:05:41.235992 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1de0a322-c038-4cd8-868b-8a98b0cc6910&page=queryresults
[0m11:05:41.639530 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:05:41.646522 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:05:41.899625 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d27816b5-e3b2-46fc-b5d0-a87a08a8e27a&page=queryresults
[0m11:05:43.074203 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d43d1310>]}
[0m11:05:43.075642 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.77s]
[0m11:05:43.077283 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:05:43.129154 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d43fe010>]}
[0m11:05:43.130337 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.82s]
[0m11:05:43.131493 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:05:43.369516 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f66150>]}
[0m11:05:43.370763 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 3.06s]
[0m11:05:43.372060 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:05:43.511571 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d44f24d0>]}
[0m11:05:43.512972 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.53s]
[0m11:05:43.514422 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:43.517059 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:05:43.519992 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:05:43.520852 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:05:43.521697 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:05:43.522483 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:05:43.523261 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:05:43.524372 [info ] [MainThread]: 
[0m11:05:43.525306 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.49 seconds (7.49s).
[0m11:05:43.527931 [debug] [MainThread]: Command end result
[0m11:05:43.564131 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:05:43.568963 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:05:43.577240 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:05:43.578018 [info ] [MainThread]: 
[0m11:05:43.579374 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:05:43.580443 [info ] [MainThread]: 
[0m11:05:43.581544 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:05:43.582646 [info ] [MainThread]: 
[0m11:05:43.583973 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:05:43.586203 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.566539, "process_in_blocks": "0", "process_kernel_time": 0.296034, "process_mem_max_rss": "227232", "process_out_blocks": "0", "process_user_time": 4.489856}
[0m11:05:43.587638 [debug] [MainThread]: Command `dbt run` failed at 11:05:43.587446 after 9.57 seconds
[0m11:05:43.588695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60342e810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60342c410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff606d21250>]}
[0m11:05:43.589646 [debug] [MainThread]: Flushing usage events
[0m11:05:44.881480 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:20.164168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29f7b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29f7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29ae610>]}


============================== 11:11:20.166778 | 352c0ca1-4001-4c01-8397-e327d13dd56a ==============================
[0m11:11:20.166778 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:20.168006 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:11:20.256342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '352c0ca1-4001-4c01-8397-e327d13dd56a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d28a86d0>]}
[0m11:11:20.323215 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.21705097, "process_in_blocks": "0", "process_kernel_time": 0.108743, "process_mem_max_rss": "90040", "process_out_blocks": "0", "process_user_time": 1.038006}
[0m11:11:20.324693 [debug] [MainThread]: Command `dbt clean` succeeded at 11:11:20.324463 after 0.22 seconds
[0m11:11:20.325986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6204b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6361210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6361150>]}
[0m11:11:20.327026 [debug] [MainThread]: Flushing usage events
[0m11:11:21.868659 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:23.209801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045262450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045778990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452b3b50>]}


============================== 11:11:23.212936 | 64c026e8-c291-4d03-8efd-bec7f523fa8d ==============================
[0m11:11:23.212936 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:23.214231 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:11:23.309690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '64c026e8-c291-4d03-8efd-bec7f523fa8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452610d0>]}
[0m11:11:23.322896 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:11:23.325257 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:11:23.327692 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.18529142, "process_in_blocks": "0", "process_kernel_time": 0.110625, "process_mem_max_rss": "90144", "process_out_blocks": "0", "process_user_time": 1.1666}
[0m11:11:23.329095 [debug] [MainThread]: Command `dbt deps` succeeded at 11:11:23.328846 after 0.19 seconds
[0m11:11:23.330160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045296650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452ee310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd048ab8b90>]}
[0m11:11:23.331476 [debug] [MainThread]: Flushing usage events
[0m11:11:24.397499 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:42.220268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3aff210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be5ca7650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b57810>]}


============================== 11:11:42.222861 | 951a46fd-64bb-4334-b063-fdffaa2d940c ==============================
[0m11:11:42.222861 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:42.224076 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:11:42.788686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5f83510>]}
[0m11:11:42.840116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5d66550>]}
[0m11:11:42.841411 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:11:42.908166 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:11:42.911147 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:11:42.912494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb6ed3e90>]}
[0m11:11:43.903632 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:11:43.915702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb58d9b50>]}
[0m11:11:43.987068 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:11:43.991622 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:11:44.006116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb56fafd0>]}
[0m11:11:44.007283 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:11:44.008917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb59b1f50>]}
[0m11:11:44.011723 [info ] [MainThread]: 
[0m11:11:44.012827 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:11:44.013752 [info ] [MainThread]: 
[0m11:11:44.015404 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:11:44.020107 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:11:44.020755 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:11:44.021466 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:11:44.022580 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:11:45.077803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:11:45.078467 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:11:45.079375 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:11:45.080256 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:11:45.606745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5e7fe10>]}
[0m11:11:45.607694 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:11:45.612544 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:11:45.613015 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.613496 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.613902 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.614544 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m11:11:45.616005 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:11:45.617378 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:11:45.618688 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:11:45.620434 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m11:11:45.621737 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m11:11:45.623315 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:11:45.624563 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:11:45.625680 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:11:45.626993 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.628245 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.629529 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.637783 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:11:45.643857 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:11:45.648064 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:11:45.652542 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:11:45.665391 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.665934 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:11:45.672126 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.709201 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:11:45.726323 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.729442 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:11:45.741602 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:11:45.746049 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:11:45.833003 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:11:45.834212 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:11:46.036427 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:11:46.037638 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:11:46.042761 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:11:46.046576 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:11:46.059044 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:11:46.065029 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:11:46.126871 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b5c24cd-c51b-4d72-b832-035d9b243967&page=queryresults
[0m11:11:46.127883 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b5c24cd-c51b-4d72-b832-035d9b243967&page=queryresults
[0m11:11:46.132732 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:11:46.134563 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb45ff490>]}
[0m11:11:46.135995 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.51s]
[0m11:11:46.137393 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:11:46.138452 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.138968 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:11:46.139848 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:11:46.142630 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:11:46.143737 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.149646 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:11:46.156025 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.159630 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:11:46.332943 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b96bca9f-1657-4cf3-a094-831b10087ded&page=queryresults
[0m11:11:46.336542 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:35953e6c-bc42-4ddd-b24d-18f83626225b&page=queryresults
[0m11:11:46.377864 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dfd5267b-1445-4f2b-848e-1bc7b4effcb3&page=queryresults
[0m11:11:46.401031 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:11:46.408214 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:11:46.729761 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1b452ab-4521-43c1-9361-c7ea548ab8ed&page=queryresults
[0m11:11:48.233971 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb44f92d0>]}
[0m11:11:48.234544 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb44f8b50>]}
[0m11:11:48.237558 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.61s]
[0m11:11:48.239409 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.61s]
[0m11:11:48.240963 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:11:48.242361 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:11:48.279723 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb58f72d0>]}
[0m11:11:48.281245 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.66s]
[0m11:11:48.282955 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:11:48.296531 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb46120d0>]}
[0m11:11:48.297992 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.15s]
[0m11:11:48.299640 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:48.302491 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:11:48.305778 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:11:48.306497 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:11:48.307274 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:11:48.308344 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:11:48.309371 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:11:48.310188 [info ] [MainThread]: 
[0m11:11:48.311066 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m11:11:48.313469 [debug] [MainThread]: Command end result
[0m11:11:48.348560 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:11:48.353288 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:11:48.362728 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:11:48.363757 [info ] [MainThread]: 
[0m11:11:48.364988 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:11:48.366078 [info ] [MainThread]: 
[0m11:11:48.367355 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:11:48.368556 [info ] [MainThread]: 
[0m11:11:48.369628 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:11:48.371639 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1992674, "process_in_blocks": "0", "process_kernel_time": 0.298109, "process_mem_max_rss": "227780", "process_out_blocks": "0", "process_user_time": 4.204377}
[0m11:11:48.372981 [debug] [MainThread]: Command `dbt run` failed at 11:11:48.372826 after 6.20 seconds
[0m11:11:48.374238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b324d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3efa550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b47810>]}
[0m11:11:48.375474 [debug] [MainThread]: Flushing usage events
[0m11:11:49.706061 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:12:25.320633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98aafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98aadd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98ab150>]}


============================== 11:12:25.323756 | 2b240de7-a472-4645-b8df-4bdf24c599ea ==============================
[0m11:12:25.323756 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:12:25.325092 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:12:25.887941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d0be1b10>]}
[0m11:12:25.938949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fbaf9ed0>]}
[0m11:12:25.940241 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:12:26.007729 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:12:26.175082 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:12:26.176573 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m11:12:26.436688 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:12:26.451352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cbba5810>]}
[0m11:12:26.525465 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:12:26.531183 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:12:26.545458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb6a19d0>]}
[0m11:12:26.546755 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:12:26.548077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb822890>]}
[0m11:12:26.550811 [info ] [MainThread]: 
[0m11:12:26.551901 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:12:26.553091 [info ] [MainThread]: 
[0m11:12:26.554544 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:12:26.559116 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:12:26.560109 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:12:34.211726 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:12:34.212503 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:12:34.470207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fa66f250>]}
[0m11:12:34.471056 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:12:34.475300 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:12:34.475679 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.475995 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.476297 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.476975 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:12:34.477920 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:12:34.478937 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:12:34.479946 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:12:34.480911 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:12:34.481748 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:12:34.482741 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:12:34.484178 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:12:34.485349 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:12:34.486270 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.487022 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.487777 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.495748 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:12:34.501918 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:12:34.506390 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:12:34.510269 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:12:34.515758 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.516234 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:12:34.516760 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.522763 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.565873 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:12:34.573741 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:12:34.592254 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:12:34.596978 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:12:34.670137 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:12:34.671361 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:34.984724 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:12:34.985119 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:12:34.986380 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:12:34.992659 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:12:34.993482 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:12:34.995019 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:12:35.051475 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:58485596-4c07-4919-aba5-39d3708490dd&page=queryresults
[0m11:12:35.052612 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:58485596-4c07-4919-aba5-39d3708490dd&page=queryresults
[0m11:12:35.057574 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:12:35.059448 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c83cd1d0>]}
[0m11:12:35.060747 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.58s]
[0m11:12:35.062111 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:12:35.063052 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.063739 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:12:35.064818 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:12:35.067871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:12:35.069988 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.074579 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:12:35.080069 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.083419 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:35.244916 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b662c5d1-b248-487d-a215-5163d58cad88&page=queryresults
[0m11:12:35.342687 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:12:35.352437 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:12:35.355985 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:344f6acf-49ac-4c9d-a26e-faecba5d993b&page=queryresults
[0m11:12:35.387883 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f22020a1-4bf8-4992-9c40-613b8b4400d3&page=queryresults
[0m11:12:35.629978 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:66395169-37e2-4ed0-bea4-b525be61dcec&page=queryresults
[0m11:12:36.815843 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb5a6650>]}
[0m11:12:36.817069 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.33s]
[0m11:12:36.818448 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:12:36.933345 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb5f5590>]}
[0m11:12:36.939146 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m11:12:36.941234 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:12:37.223626 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c841a410>]}
[0m11:12:37.225240 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.74s]
[0m11:12:37.226891 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:12:37.458452 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c848a750>]}
[0m11:12:37.459453 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.39s]
[0m11:12:37.460734 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:37.463097 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:12:37.466102 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:12:37.466934 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:12:37.467664 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:12:37.468464 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:12:37.469206 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:12:37.470360 [info ] [MainThread]: 
[0m11:12:37.471412 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 10.92 seconds (10.92s).
[0m11:12:37.473852 [debug] [MainThread]: Command end result
[0m11:12:37.512961 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:12:37.520492 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:12:37.529380 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:12:37.530390 [info ] [MainThread]: 
[0m11:12:37.531448 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:12:37.532708 [info ] [MainThread]: 
[0m11:12:37.534027 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:12:37.535102 [info ] [MainThread]: 
[0m11:12:37.536267 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:12:37.538520 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.267568, "process_in_blocks": "0", "process_kernel_time": 0.23348, "process_mem_max_rss": "227292", "process_out_blocks": "0", "process_user_time": 3.583422}
[0m11:12:37.540330 [debug] [MainThread]: Command `dbt run` failed at 11:12:37.540085 after 12.27 seconds
[0m11:12:37.541902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f9725510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f97275d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fd1f55d0>]}
[0m11:12:37.543415 [debug] [MainThread]: Flushing usage events
[0m11:12:39.269721 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:27.443642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5d5eb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a6159e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5d5e910>]}


============================== 11:20:27.446031 | 9b67a5a3-0d8d-411c-a510-77a5b190e2f0 ==============================
[0m11:20:27.446031 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:27.447464 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m11:20:27.525330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b67a5a3-0d8d-411c-a510-77a5b190e2f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5db3f90>]}
[0m11:20:27.584287 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18763956, "process_in_blocks": "0", "process_kernel_time": 0.078613, "process_mem_max_rss": "90040", "process_out_blocks": "0", "process_user_time": 0.943366}
[0m11:20:27.585554 [debug] [MainThread]: Command `dbt clean` succeeded at 11:20:27.585450 after 0.19 seconds
[0m11:20:27.586382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a615a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5e6db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a9590c10>]}
[0m11:20:27.587250 [debug] [MainThread]: Flushing usage events
[0m11:20:28.646025 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:29.854527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc06bef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc0a6a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc066b210>]}


============================== 11:20:29.857240 | e90511b4-1b19-43da-92b3-ff1550aa43eb ==============================
[0m11:20:29.857240 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:29.858571 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:20:29.953347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e90511b4-1b19-43da-92b3-ff1550aa43eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc06bfb50>]}
[0m11:20:29.965825 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:20:29.968839 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:20:29.971013 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1771441, "process_in_blocks": "0", "process_kernel_time": 0.079526, "process_mem_max_rss": "90148", "process_out_blocks": "0", "process_user_time": 1.063671}
[0m11:20:29.972289 [debug] [MainThread]: Command `dbt deps` succeeded at 11:20:29.972107 after 0.18 seconds
[0m11:20:29.973136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc3e64b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc059ae10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc0a6a190>]}
[0m11:20:29.974071 [debug] [MainThread]: Flushing usage events
[0m11:20:31.219106 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:33.980730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d229dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d622110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d621e90>]}


============================== 11:20:33.983266 | a771e0bb-ed61-46fe-a139-720c065cd1f3 ==============================
[0m11:20:33.983266 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:33.984569 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m11:20:34.566815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f37e1d0>]}
[0m11:20:34.614149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923f47e3d0>]}
[0m11:20:34.615591 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:20:34.685479 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:20:34.687614 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:20:34.688615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d08fa90>]}
[0m11:20:35.729350 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:20:35.740322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f077d90>]}
[0m11:20:35.817748 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:20:35.824563 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:20:35.841278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920ee024d0>]}
[0m11:20:35.842419 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:20:35.843517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920eff4fd0>]}
[0m11:20:35.846663 [info ] [MainThread]: 
[0m11:20:35.848101 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:20:35.849379 [info ] [MainThread]: 
[0m11:20:35.851115 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:20:35.858595 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:20:35.860301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:20:36.453988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:20:36.455136 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:20:36.695701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f3c9690>]}
[0m11:20:36.696687 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:20:36.702114 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:20:36.702501 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.702804 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.703113 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.703845 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:20:36.705257 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:20:36.707224 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:20:36.708730 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:20:36.709954 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:20:36.711035 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:20:36.712250 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:20:36.713205 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:20:36.714081 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:20:36.714867 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.715727 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.716642 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.725944 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:20:36.730154 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:20:36.734238 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:20:36.738111 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:20:36.747403 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.756381 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.779545 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:20:36.779929 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.851541 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:20:36.852982 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:20:36.855206 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:20:36.858156 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:20:36.872845 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m11:20:36.874934 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:20:36.875476 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:20:36.875985 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m11:20:36.876852 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:20:36.877592 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m11:20:36.880134 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:20:36.904900 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:20:37.369839 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6b52e01-2696-4ea6-9523-64de850e7ad8&page=queryresults
[0m11:20:37.388237 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6382486-ba08-46f2-8335-6610e6beb10c&page=queryresults
[0m11:20:37.421711 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b1777447-7bfc-4032-b9f5-ff862fe1a271&page=queryresults
[0m11:20:38.064083 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:00e7b0ef-594b-4484-b356-33d133c24926&page=queryresults
[0m11:20:38.065191 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:00e7b0ef-594b-4484-b356-33d133c24926&page=queryresults
[0m11:20:38.070635 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:20:38.072445 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c4c5f90>]}
[0m11:20:38.073881 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.36s]
[0m11:20:38.075365 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:20:38.076586 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.077162 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:20:38.078203 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:20:38.081383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:20:38.082594 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.087693 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:20:38.093370 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.098268 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:20:38.104465 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m11:20:38.105649 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:20:38.503930 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9fc61d43-09a8-4f16-bd7c-04550e44920f&page=queryresults
[0m11:20:39.102115 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c3f5450>]}
[0m11:20:39.104756 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m11:20:39.106413 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:20:39.340020 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c4d9a90>]}
[0m11:20:39.341390 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.63s]
[0m11:20:39.342718 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:20:39.360347 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920efcb2d0>]}
[0m11:20:39.361927 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.65s]
[0m11:20:39.363386 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:20:40.189894 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f0cc890>]}
[0m11:20:40.192303 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.11s]
[0m11:20:40.194044 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:40.196901 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:20:40.199773 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:20:40.200525 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:20:40.201387 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:20:40.202206 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:20:40.202856 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:20:40.203644 [info ] [MainThread]: 
[0m11:20:40.204832 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m11:20:40.207210 [debug] [MainThread]: Command end result
[0m11:20:40.238458 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:20:40.242663 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:20:40.251589 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:20:40.252487 [info ] [MainThread]: 
[0m11:20:40.253674 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:20:40.254787 [info ] [MainThread]: 
[0m11:20:40.255908 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:20:40.256898 [info ] [MainThread]: 
[0m11:20:40.257988 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:20:40.259969 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.3339143, "process_in_blocks": "0", "process_kernel_time": 0.209476, "process_mem_max_rss": "227272", "process_out_blocks": "0", "process_user_time": 4.279306}
[0m11:20:40.261109 [debug] [MainThread]: Command `dbt run` failed at 11:20:40.260953 after 6.34 seconds
[0m11:20:40.262139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d08f8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d22acd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9240b79110>]}
[0m11:20:40.263170 [debug] [MainThread]: Flushing usage events
[0m11:20:41.820755 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:29:56.540319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ea450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487e9d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ea610>]}


============================== 11:29:56.544016 | ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5 ==============================
[0m11:29:56.544016 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:29:56.545489 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:29:57.121455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1ac66c90>]}
[0m11:29:57.165259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4aa98750>]}
[0m11:29:57.166671 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:29:57.240947 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:29:57.313350 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:29:57.314733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d48ee2910>]}
[0m11:29:58.342206 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:29:58.355375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a60e890>]}
[0m11:29:58.440070 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:29:58.447031 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:29:58.468438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a3dbf10>]}
[0m11:29:58.469825 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:29:58.471833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a622d10>]}
[0m11:29:58.475310 [info ] [MainThread]: 
[0m11:29:58.476828 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:29:58.478305 [info ] [MainThread]: 
[0m11:29:58.480066 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:29:58.486059 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:29:58.487598 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:59.680488 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:29:59.681527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:29:59.923577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ff210>]}
[0m11:29:59.924538 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:29:59.929705 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:29:59.930226 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.930836 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.931245 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:29:59.931817 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:29:59.933046 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:29:59.934316 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:29:59.935803 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:29:59.937120 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:29:59.938440 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:29:59.939512 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:29:59.940606 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:29:59.941484 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:29:59.942579 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.943365 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.944245 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:29:59.952524 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:29:59.958464 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:29:59.962952 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:29:59.968267 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:29:59.974277 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.975295 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:29:59.981335 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.991581 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:30:00.021812 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:30:00.043121 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:30:00.053845 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:30:00.057226 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:30:00.131298 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:30:00.133422 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:00.332358 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:30:00.334040 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:30:00.338121 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:30:00.340543 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:30:00.360936 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:30:00.365280 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:30:00.647026 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d86aa73d-a630-4d34-9f1a-49826350d02e&page=queryresults
[0m11:30:00.649911 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f2fb1a3-ddeb-4695-8d7e-a6ed791adeea&page=queryresults
[0m11:30:00.663450 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6c1b27a-599d-49a8-a140-409e60da88a8&page=queryresults
[0m11:30:00.986754 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1467d589-0f46-4073-8c82-286e9a012290&page=queryresults
[0m11:30:00.988629 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1467d589-0f46-4073-8c82-286e9a012290&page=queryresults
[0m11:30:00.994584 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:30:00.997004 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a86d790>]}
[0m11:30:00.998075 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.06s]
[0m11:30:00.999252 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:30:01.000417 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.000933 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:30:01.002284 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:30:01.005060 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:30:01.006277 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.011150 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:30:01.018174 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.021974 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:01.257937 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:30:01.267681 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:30:01.538987 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f58b09c-7625-4f60-929b-7ad2f4b9bc2d&page=queryresults
[0m11:30:02.244034 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a85c8d0>]}
[0m11:30:02.244911 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a3c0a50>]}
[0m11:30:02.246158 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m11:30:02.247660 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m11:30:02.249052 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:30:02.250160 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:30:02.524172 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a439790>]}
[0m11:30:02.525662 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.58s]
[0m11:30:02.527230 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:30:03.094638 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d18280c50>]}
[0m11:30:03.096520 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.09s]
[0m11:30:03.098403 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:03.101199 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:30:03.104463 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:30:03.105364 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:30:03.106211 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:30:03.106894 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:30:03.108831 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:30:03.110057 [info ] [MainThread]: 
[0m11:30:03.111554 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.63 seconds (4.63s).
[0m11:30:03.113928 [debug] [MainThread]: Command end result
[0m11:30:03.147483 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:30:03.151863 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:30:03.160322 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:30:03.161196 [info ] [MainThread]: 
[0m11:30:03.162282 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:30:03.163459 [info ] [MainThread]: 
[0m11:30:03.164644 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:30:03.166103 [info ] [MainThread]: 
[0m11:30:03.167099 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:30:03.169012 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6820965, "process_in_blocks": "0", "process_kernel_time": 0.219308, "process_mem_max_rss": "226096", "process_out_blocks": "0", "process_user_time": 4.256585}
[0m11:30:03.170354 [debug] [MainThread]: Command `dbt run` failed at 11:30:03.170209 after 6.68 seconds
[0m11:30:03.171440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d48847cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4c19d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4c19d210>]}
[0m11:30:03.172615 [debug] [MainThread]: Flushing usage events
[0m11:30:04.723165 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:16.787903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708f0e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708fc8490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b136d0>]}


============================== 11:31:16.790503 | febe273f-97c8-4d1e-a3c5-1b5309a8ad37 ==============================
[0m11:31:16.790503 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:16.791783 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:31:16.872313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'febe273f-97c8-4d1e-a3c5-1b5309a8ad37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708a53350>]}
[0m11:31:16.943002 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20395628, "process_in_blocks": "0", "process_kernel_time": 0.100567, "process_mem_max_rss": "90060", "process_out_blocks": "0", "process_user_time": 1.00567}
[0m11:31:16.944342 [debug] [MainThread]: Command `dbt clean` succeeded at 11:31:16.944168 after 0.21 seconds
[0m11:31:16.945223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b674d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b67610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f570c308c10>]}
[0m11:31:16.946003 [debug] [MainThread]: Flushing usage events
[0m11:31:18.444590 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:19.597744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3e450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3ee10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3e610>]}


============================== 11:31:19.600594 | 1e4a9a36-06ea-4465-9085-f4fc67040004 ==============================
[0m11:31:19.600594 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:19.602123 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:31:19.693590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e4a9a36-06ea-4465-9085-f4fc67040004', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfbc5a50>]}
[0m11:31:19.702885 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:31:19.705661 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:31:19.707187 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1626803, "process_in_blocks": "0", "process_kernel_time": 0.1001, "process_mem_max_rss": "90184", "process_out_blocks": "0", "process_user_time": 1.001008}
[0m11:31:19.708434 [debug] [MainThread]: Command `dbt deps` succeeded at 11:31:19.708296 after 0.16 seconds
[0m11:31:19.709318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb909d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfa6cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfbc6e50>]}
[0m11:31:19.710130 [debug] [MainThread]: Flushing usage events
[0m11:31:20.735242 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:23.537188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d03edd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d08f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d523890>]}


============================== 11:31:23.540272 | 73b3fc82-725f-477e-919d-9ee5848fe7da ==============================
[0m11:31:23.540272 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:23.541492 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:31:24.129548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73f1d0a50>]}
[0m11:31:24.175174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76f2b63d0>]}
[0m11:31:24.176515 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:31:24.254757 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:31:24.258020 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:31:24.259904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73f946a90>]}
[0m11:31:25.274792 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:31:25.287905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee82050>]}
[0m11:31:25.360629 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:31:25.366480 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:31:25.383246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ec31590>]}
[0m11:31:25.384365 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:31:25.385720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee13150>]}
[0m11:31:25.388441 [info ] [MainThread]: 
[0m11:31:25.389516 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:31:25.390843 [info ] [MainThread]: 
[0m11:31:25.392273 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:31:25.397443 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:31:25.398444 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:25.953231 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:31:25.954095 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:31:26.191683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee2dd10>]}
[0m11:31:26.192718 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:31:26.198018 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:31:26.198456 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.198856 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.199185 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.199944 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:31:26.201527 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:31:26.202695 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:31:26.203808 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:31:26.204911 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:31:26.206116 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:31:26.207273 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:31:26.208412 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:31:26.209404 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:31:26.210246 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.211117 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.211959 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.221437 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:31:26.227588 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:31:26.231827 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:31:26.236500 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:31:26.250849 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.251438 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:31:26.263176 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.263537 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.300317 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:31:26.308005 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:31:26.330526 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:31:26.333010 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:31:26.421902 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:31:26.422856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:31:26.648026 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:31:26.650380 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:31:26.651645 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:31:26.661727 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:31:26.664696 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:31:26.667607 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:31:26.953683 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e627a688-b717-4be2-921a-c1d386c5f7a7&page=queryresults
[0m11:31:26.964758 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:626ad3a7-5ec2-4afb-8657-1e44348cc223&page=queryresults
[0m11:31:27.131845 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0c64b30a-05d3-4f76-812e-2f8ecb112c93&page=queryresults
[0m11:31:27.132814 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0c64b30a-05d3-4f76-812e-2f8ecb112c93&page=queryresults
[0m11:31:27.137643 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m11:31:27.139426 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c29f650>]}
[0m11:31:27.140429 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.93s]
[0m11:31:27.141491 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:31:27.142368 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.142826 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m11:31:27.143649 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:31:27.145609 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:31:27.146613 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.151116 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:31:27.157023 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.160343 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:31:27.392380 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:31:27.397854 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:31:27.533938 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b7a29872-a4b8-4bda-a7a9-c9488af202d0&page=queryresults
[0m11:31:27.535141 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b7a29872-a4b8-4bda-a7a9-c9488af202d0&page=queryresults
[0m11:31:27.539058 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:31:27.540285 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ef25490>]}
[0m11:31:27.541427 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.34s]
[0m11:31:27.542617 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:31:27.543817 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:31:27.708547 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6b2c0b6-363b-4479-86eb-a02749b1cef5&page=queryresults
[0m11:31:28.567941 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc726fb0f50>]}
[0m11:31:28.568638 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c21c650>]}
[0m11:31:28.569909 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.36s]
[0m11:31:28.571811 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.36s]
[0m11:31:28.572861 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:31:28.574116 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:31:29.254945 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c211bd0>]}
[0m11:31:29.256190 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.11s]
[0m11:31:29.257463 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:29.259692 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:31:29.262780 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:31:29.263611 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m11:31:29.264414 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:31:29.265257 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:31:29.266061 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:31:29.267086 [info ] [MainThread]: 
[0m11:31:29.268095 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 3.87 seconds (3.87s).
[0m11:31:29.270300 [debug] [MainThread]: Command end result
[0m11:31:29.306391 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:31:29.310744 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:31:29.318935 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:31:29.319616 [info ] [MainThread]: 
[0m11:31:29.320607 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m11:31:29.321777 [info ] [MainThread]: 
[0m11:31:29.322694 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m11:31:29.323548 [info ] [MainThread]: 
[0m11:31:29.324854 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:31:29.325662 [info ] [MainThread]: 
[0m11:31:29.326777 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 TOTAL=5
[0m11:31:29.328661 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.852827, "process_in_blocks": "0", "process_kernel_time": 0.211902, "process_mem_max_rss": "230036", "process_out_blocks": "0", "process_user_time": 4.227959}
[0m11:31:29.329755 [debug] [MainThread]: Command `dbt run` failed at 11:31:29.329625 after 5.85 seconds
[0m11:31:29.330616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bbad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bb790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bbf10>]}
[0m11:31:29.331708 [debug] [MainThread]: Flushing usage events
[0m11:31:30.889761 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:32:28.758726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53e83e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edbf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edb7d0>]}


============================== 11:32:28.761494 | d0b34ed4-d42a-48ef-a4ca-757c75494cba ==============================
[0m11:32:28.761494 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:32:28.763028 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:32:29.350576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f26056990>]}
[0m11:32:29.402656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f560f9e10>]}
[0m11:32:29.403761 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:32:29.467202 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:32:29.615293 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:32:29.616167 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m11:32:29.862117 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:32:29.874187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25cbf250>]}
[0m11:32:29.946424 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:32:29.952012 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:32:29.966328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25b97510>]}
[0m11:32:29.967645 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:32:29.969098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25caf590>]}
[0m11:32:29.972076 [info ] [MainThread]: 
[0m11:32:29.973231 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:32:29.974416 [info ] [MainThread]: 
[0m11:32:29.975815 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:32:29.980270 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:32:29.981222 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:32:30.873793 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:32:30.874816 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:32:31.101657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25e6b3d0>]}
[0m11:32:31.102801 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:32:31.108242 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:32:31.108711 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.109201 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.109542 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.110126 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:32:31.111513 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:32:31.112736 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:32:31.114865 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:32:31.116877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:32:31.118347 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:32:31.119413 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:32:31.121163 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:32:31.122299 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:32:31.123237 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.124011 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.125347 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.134551 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:32:31.140042 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:32:31.145315 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:32:31.149604 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:32:31.154068 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.155135 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.161077 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:32:31.161446 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.199080 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:32:31.199558 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:32:31.223711 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:32:31.231045 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:32:31.314574 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:32:31.315558 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:32:31.530156 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:32:31.532487 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:32:31.534156 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:32:31.539096 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:32:31.540457 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:32:31.542348 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:32:31.799093 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:812b7ba0-7fe3-4f01-9131-e8a5e39837dd&page=queryresults
[0m11:32:31.809849 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4db3d389-ceb3-4800-a15f-05cb5ade3d14&page=queryresults
[0m11:32:31.921972 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2fc360aa-15ad-48a2-85bc-2445f6641954&page=queryresults
[0m11:32:32.368277 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5ba88e81-5ff8-4b0f-8969-7402cf217734&page=queryresults
[0m11:32:32.372431 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5ba88e81-5ff8-4b0f-8969-7402cf217734&page=queryresults
[0m11:32:32.380728 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:32:32.382760 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f2423f150>]}
[0m11:32:32.384072 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.27s]
[0m11:32:32.385546 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:32:32.386873 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.387401 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:32:32.388192 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:32:32.390369 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:32:32.391516 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.396610 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:32:32.403395 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.407603 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:32:32.672519 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:32:32.680353 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:32:32.933038 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:03c381a0-3fc2-4abb-bbaf-c9ed0e0c4a46&page=queryresults
[0m11:32:33.365948 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25bcf210>]}
[0m11:32:33.369038 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.24s]
[0m11:32:33.370529 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:32:33.685075 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f2422bc50>]}
[0m11:32:33.686697 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.57s]
[0m11:32:33.688850 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:32:33.742697 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f241d53d0>]}
[0m11:32:33.746797 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.62s]
[0m11:32:33.749397 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:32:34.762458 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f241fbcd0>]}
[0m11:32:34.763796 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.37s]
[0m11:32:34.765047 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:34.767131 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:32:34.770250 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:32:34.770955 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:32:34.771590 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:32:34.772307 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:32:34.772946 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:32:34.774337 [info ] [MainThread]: 
[0m11:32:34.775570 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.80 seconds (4.80s).
[0m11:32:34.777497 [debug] [MainThread]: Command end result
[0m11:32:34.811082 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:32:34.815173 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:32:34.823165 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:32:34.824056 [info ] [MainThread]: 
[0m11:32:34.825051 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:32:34.826157 [info ] [MainThread]: 
[0m11:32:34.827215 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:32:34.828033 [info ] [MainThread]: 
[0m11:32:34.829288 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:32:34.831162 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1225686, "process_in_blocks": "0", "process_kernel_time": 0.285821, "process_mem_max_rss": "226000", "process_out_blocks": "0", "process_user_time": 3.511524}
[0m11:32:34.832401 [debug] [MainThread]: Command `dbt run` failed at 11:32:34.832272 after 6.12 seconds
[0m11:32:34.833284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f5427e210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f560e9190>]}
[0m11:32:34.834042 [debug] [MainThread]: Flushing usage events
[0m11:32:38.837431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:33:17.063249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfc9f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c0987990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfc9eb50>]}


============================== 11:33:17.066039 | 10575560-8b1f-4499-9aec-bb1a9e4d8e1c ==============================
[0m11:33:17.066039 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:33:17.067494 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:33:17.722606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791fb5d90>]}
[0m11:33:17.775893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c1f2a3d0>]}
[0m11:33:17.777070 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:33:17.865471 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:33:17.946309 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:33:17.947560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c0aa43d0>]}
[0m11:33:19.042025 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:33:19.056027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791d09510>]}
[0m11:33:19.133452 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:33:19.139021 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:33:19.153720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f879187c210>]}
[0m11:33:19.154698 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:33:19.158501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791aac990>]}
[0m11:33:19.161634 [info ] [MainThread]: 
[0m11:33:19.162818 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:33:19.164082 [info ] [MainThread]: 
[0m11:33:19.165427 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:33:19.170550 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:33:19.171478 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:20.213818 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:33:20.214859 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:20.471933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791b72690>]}
[0m11:33:20.472967 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:33:20.478036 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:33:20.478402 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.478782 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.479072 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.479575 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:33:20.480825 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:33:20.482278 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:33:20.483390 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:33:20.484538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:33:20.485603 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:33:20.486577 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:33:20.487584 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:33:20.488621 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:33:20.489506 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.490298 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.491311 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.499441 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:33:20.506367 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:33:20.511362 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:33:20.516952 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:33:20.523007 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.523646 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:33:20.524098 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.529979 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.570112 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:33:20.579419 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:33:20.605013 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:33:20.605248 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:33:20.680230 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:33:20.681345 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:33:20.919728 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:33:20.921154 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:33:20.923024 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:33:20.928663 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:33:20.929348 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:33:20.933097 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:33:21.204316 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f19c1f4e-abe1-4a59-aa7a-49c90325e418&page=queryresults
[0m11:33:21.208815 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a2e4a738-9fb5-4e70-8ab4-660b9511f8f4&page=queryresults
[0m11:33:21.209455 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:54bc30b8-c0e4-4c55-9b62-076cc18ddd51&page=queryresults
[0m11:33:21.455132 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8804f99-cdf1-4573-bfa3-3d7e985a1fcc&page=queryresults
[0m11:33:21.456440 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8804f99-cdf1-4573-bfa3-3d7e985a1fcc&page=queryresults
[0m11:33:21.461028 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:33:21.463527 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781f1c290>]}
[0m11:33:21.464948 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.98s]
[0m11:33:21.466103 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:33:21.467203 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.467813 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:33:21.468764 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:33:21.471720 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:33:21.472880 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.477840 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:33:21.485397 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.489400 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:33:21.742332 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:33:21.750118 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:33:22.001026 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:086fd329-0363-4989-b014-c834262650d3&page=queryresults
[0m11:33:22.762427 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781e5ce10>]}
[0m11:33:22.763846 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.27s]
[0m11:33:22.765328 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:33:23.005717 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781f35f50>]}
[0m11:33:23.007378 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.52s]
[0m11:33:23.008674 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:33:23.018617 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f879192fc90>]}
[0m11:33:23.019901 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.53s]
[0m11:33:23.021728 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:33:23.521383 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791af0a10>]}
[0m11:33:23.522532 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.05s]
[0m11:33:23.523719 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:23.525823 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:33:23.528833 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:33:23.529574 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:33:23.530432 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:33:23.531397 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:33:23.532075 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:33:23.532881 [info ] [MainThread]: 
[0m11:33:23.534070 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.37 seconds (4.37s).
[0m11:33:23.535951 [debug] [MainThread]: Command end result
[0m11:33:23.570109 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:33:23.574183 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:33:23.581754 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:33:23.582822 [info ] [MainThread]: 
[0m11:33:23.584013 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:33:23.585231 [info ] [MainThread]: 
[0m11:33:23.586496 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:33:23.587460 [info ] [MainThread]: 
[0m11:33:23.588465 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:33:23.590500 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.589186, "process_in_blocks": "0", "process_kernel_time": 0.188083, "process_mem_max_rss": "230292", "process_out_blocks": "0", "process_user_time": 4.484314}
[0m11:33:23.592600 [debug] [MainThread]: Command `dbt run` failed at 11:33:23.592435 after 6.59 seconds
[0m11:33:23.593608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfcd1250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c3791850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfcefd50>]}
[0m11:33:23.594555 [debug] [MainThread]: Flushing usage events
[0m11:33:24.907413 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:01:23.041808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2caf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2cb110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2cb1d0>]}


============================== 12:01:23.044429 | 2ba89753-9768-4f8a-b7f2-6b094f0fe7b7 ==============================
[0m12:01:23.044429 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:01:23.047094 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:01:23.680012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180f61add0>]}
[0m12:01:23.733319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183e544b90>]}
[0m12:01:23.734714 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:01:23.806481 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:01:23.877494 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:01:23.879576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e4b61d0>]}
[0m12:01:25.118524 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:01:25.132728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e108ad0>]}
[0m12:01:25.217637 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:01:25.225075 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:01:25.245321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de88150>]}
[0m12:01:25.246613 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:01:25.248027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180dea6e10>]}
[0m12:01:25.250992 [info ] [MainThread]: 
[0m12:01:25.252512 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:01:25.253530 [info ] [MainThread]: 
[0m12:01:25.255032 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:01:25.260178 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:01:25.261626 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:01:25.900015 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:01:25.903003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:01:26.170599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e59eb50>]}
[0m12:01:26.172041 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:01:26.178845 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:01:26.179249 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.179681 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.180075 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.180842 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:01:26.182127 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:01:26.183529 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:01:26.184622 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:01:26.186030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:01:26.187461 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:01:26.188740 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:01:26.189763 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:01:26.190717 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:01:26.191588 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.192329 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.193016 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.200604 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:01:26.206393 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:01:26.210531 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:01:26.215356 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:01:26.222096 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.223400 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:01:26.229143 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.239452 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.282538 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:01:26.292039 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:01:26.311097 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:01:26.314172 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:01:26.367791 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:01:26.393723 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:01:26.636590 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:01:26.645750 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:01:26.647494 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:01:26.654944 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:01:26.667413 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:01:26.675209 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:01:27.003611 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fd0297e6-69fc-4cae-b438-e94d1a05b14b&page=queryresults
[0m12:01:27.201704 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79769e63-e351-4cae-994b-7c78c08b6e0e&page=queryresults
[0m12:01:27.218517 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:162be8a4-aaf8-4df4-9526-5d502be3b88c&page=queryresults
[0m12:01:27.310780 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db1111d1-93e1-44e8-b511-5a1989193ce3&page=queryresults
[0m12:01:27.311802 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db1111d1-93e1-44e8-b511-5a1989193ce3&page=queryresults
[0m12:01:27.316815 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:01:27.319057 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e08a610>]}
[0m12:01:27.320309 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.13s]
[0m12:01:27.321488 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:01:27.322630 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.323145 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:01:27.324294 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:01:27.326713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:01:27.327614 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.333135 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:01:27.344289 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.348855 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:01:27.615966 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:01:27.622104 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:01:27.919878 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ee21e364-b539-45b7-b799-5c4d9e7d44e3&page=queryresults
[0m12:01:28.917833 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e0bccd0>]}
[0m12:01:28.919708 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.73s]
[0m12:01:28.921311 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:01:29.114175 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de82750>]}
[0m12:01:29.115991 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.92s]
[0m12:01:29.119290 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:01:29.119987 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de88d10>]}
[0m12:01:29.121583 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.93s]
[0m12:01:29.122565 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:01:29.532469 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180c56a390>]}
[0m12:01:29.533427 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.21s]
[0m12:01:29.534626 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:29.536609 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:01:29.539546 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:01:29.540232 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:01:29.540783 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:01:29.541380 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:01:29.542334 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:01:29.543443 [info ] [MainThread]: 
[0m12:01:29.544933 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m12:01:29.547106 [debug] [MainThread]: Command end result
[0m12:01:29.581528 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:01:29.585508 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:01:29.593859 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:01:29.594594 [info ] [MainThread]: 
[0m12:01:29.595587 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:01:29.596569 [info ] [MainThread]: 
[0m12:01:29.597515 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:01:29.598491 [info ] [MainThread]: 
[0m12:01:29.599484 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:01:29.601208 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6118755, "process_in_blocks": "0", "process_kernel_time": 0.223851, "process_mem_max_rss": "226992", "process_out_blocks": "0", "process_user_time": 4.466847}
[0m12:01:29.602333 [debug] [MainThread]: Command `dbt run` failed at 12:01:29.602155 after 6.61 seconds
[0m12:01:29.603455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c6c6710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c31b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183fc44a50>]}
[0m12:01:29.605309 [debug] [MainThread]: Flushing usage events
[0m12:01:31.039522 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:05:38.304484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da673810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dab4b990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da6735d0>]}


============================== 12:05:38.307713 | f9c893d6-2bde-4050-a55e-1e02c4b8110f ==============================
[0m12:05:38.307713 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:05:38.309552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:05:38.892751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9c893d6-2bde-4050-a55e-1e02c4b8110f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b088b690>]}
[0m12:05:38.938640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9c893d6-2bde-4050-a55e-1e02c4b8110f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dc8cdf10>]}
[0m12:05:38.940110 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:05:39.013672 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:05:39.168197 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:05:39.169719 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:05:39.374120 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:05:39.376534 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1221713, "process_in_blocks": "0", "process_kernel_time": 0.229939, "process_mem_max_rss": "214568", "process_out_blocks": "0", "process_user_time": 2.869246}
[0m12:05:39.377851 [debug] [MainThread]: Command `dbt run` failed at 12:05:39.377708 after 1.12 seconds
[0m12:05:39.378768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da4d1710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da4d0690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b0840190>]}
[0m12:05:39.379824 [debug] [MainThread]: Flushing usage events
[0m12:05:40.687083 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:06:54.076428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de3150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de2890>]}


============================== 12:06:54.078947 | a3ead25e-b070-4466-9b8a-0b6f3629b4eb ==============================
[0m12:06:54.078947 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:06:54.081273 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:06:54.168819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3ead25e-b070-4466-9b8a-0b6f3629b4eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc41da3d0>]}
[0m12:06:54.229774 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.1988981, "process_in_blocks": "0", "process_kernel_time": 0.097518, "process_mem_max_rss": "90112", "process_out_blocks": "0", "process_user_time": 0.955679}
[0m12:06:54.230916 [debug] [MainThread]: Command `dbt clean` succeeded at 12:06:54.230744 after 0.20 seconds
[0m12:06:54.231757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3d1bf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3e15c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc75d4c10>]}
[0m12:06:54.232854 [debug] [MainThread]: Flushing usage events
[0m12:06:55.275371 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:06:56.473248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fcaf490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6ae10>]}


============================== 12:06:56.476038 | 355a9074-6bed-498a-bab7-e6e35b153367 ==============================
[0m12:06:56.476038 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:06:56.477140 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:06:56.564639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '355a9074-6bed-498a-bab7-e6e35b153367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fafd090>]}
[0m12:06:56.575520 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:06:56.578000 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:06:56.579474 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16740432, "process_in_blocks": "0", "process_kernel_time": 0.100529, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 1.025405}
[0m12:06:56.580816 [debug] [MainThread]: Command `dbt deps` succeeded at 12:06:56.580648 after 0.17 seconds
[0m12:06:56.581819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc9ce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6b010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1223434b90>]}
[0m12:06:56.582708 [debug] [MainThread]: Flushing usage events
[0m12:06:57.645667 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:07:00.830664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83737ff210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373cdf790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373cdf6d0>]}


============================== 12:07:00.833489 | be01370c-820b-4130-93b4-4aa76e8fbb28 ==============================
[0m12:07:00.833489 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:07:00.834617 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:07:01.418288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83459a6e10>]}
[0m12:07:01.470950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8375a51ed0>]}
[0m12:07:01.472459 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:07:01.558442 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:07:01.561315 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:07:01.562420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8346fe6ed0>]}
[0m12:07:02.471392 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:07:02.472929 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6912909, "process_in_blocks": "0", "process_kernel_time": 0.180507, "process_mem_max_rss": "212280", "process_out_blocks": "0", "process_user_time": 3.610142}
[0m12:07:02.474009 [debug] [MainThread]: Command `dbt run` failed at 12:07:02.473886 after 1.69 seconds
[0m12:07:02.474781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373663450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373663910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8345f49410>]}
[0m12:07:02.475586 [debug] [MainThread]: Flushing usage events
[0m12:07:03.520886 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:18.671457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d36a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d36890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d368d0>]}


============================== 12:08:18.674089 | 3ce10335-4778-4cac-9a10-29aae94e2109 ==============================
[0m12:08:18.674089 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:18.675315 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:08:18.761271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3ce10335-4778-4cac-9a10-29aae94e2109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8c73510>]}
[0m12:08:18.789072 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.1728333, "process_in_blocks": "0", "process_kernel_time": 0.08973, "process_mem_max_rss": "90128", "process_out_blocks": "0", "process_user_time": 1.016945}
[0m12:08:18.790539 [debug] [MainThread]: Command `dbt clean` succeeded at 12:08:18.790425 after 0.17 seconds
[0m12:08:18.791706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d69290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d69b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56ec685110>]}
[0m12:08:18.793608 [debug] [MainThread]: Flushing usage events
[0m12:08:20.093374 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:21.263507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef476f050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef47c2fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef4b6a0d0>]}


============================== 12:08:21.266440 | d910b610-cd9a-4cdc-8642-8e8bab061d93 ==============================
[0m12:08:21.266440 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:21.267776 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:08:21.355016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd910b610-cd9a-4cdc-8642-8e8bab061d93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef466c350>]}
[0m12:08:21.366077 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:08:21.368873 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:08:21.370410 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16112548, "process_in_blocks": "0", "process_kernel_time": 0.050841, "process_mem_max_rss": "90184", "process_out_blocks": "0", "process_user_time": 1.057495}
[0m12:08:21.371464 [debug] [MainThread]: Command `dbt deps` succeeded at 12:08:21.371321 after 0.16 seconds
[0m12:08:21.372222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef47c3110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef471b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef7fc8b90>]}
[0m12:08:21.373043 [debug] [MainThread]: Flushing usage events
[0m12:08:22.411523 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:26.840281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba1e2090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba2377d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba237550>]}


============================== 12:08:26.842899 | ca4c587d-64de-4d11-9d71-104282f79f41 ==============================
[0m12:08:26.842899 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:26.844168 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:08:27.440523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089058b4d0>]}
[0m12:08:27.489054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08bc492310>]}
[0m12:08:27.490483 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:08:27.566023 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:08:27.568812 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:08:27.569792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba239c90>]}
[0m12:08:28.466267 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:08:28.468284 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6833, "process_in_blocks": "0", "process_kernel_time": 0.178624, "process_mem_max_rss": "212036", "process_out_blocks": "0", "process_user_time": 3.572497}
[0m12:08:28.470348 [debug] [MainThread]: Command `dbt run` failed at 12:08:28.470195 after 1.69 seconds
[0m12:08:28.471674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba23b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0890253a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba23b9d0>]}
[0m12:08:28.472719 [debug] [MainThread]: Flushing usage events
[0m12:08:29.525590 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:10:05.913438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b92bec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b9307590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b979f750>]}


============================== 12:10:05.916133 | 68d81414-eb80-436b-8f13-72f9f9356c39 ==============================
[0m12:10:05.916133 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:10:05.920392 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:10:06.493126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b5430d0>]}
[0m12:10:06.543156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bb51a1d0>]}
[0m12:10:06.545057 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:10:06.611318 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:10:06.613544 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:10:06.614389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b268c90>]}
[0m12:10:07.615662 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:10:07.627172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b177f90>]}
[0m12:10:07.696145 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:10:07.701545 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:10:07.716025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38aec4d10>]}
[0m12:10:07.717143 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:10:07.718269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38aee3710>]}
[0m12:10:07.720782 [info ] [MainThread]: 
[0m12:10:07.722121 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:10:07.723205 [info ] [MainThread]: 
[0m12:10:07.724862 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:10:07.731481 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:10:07.732627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:08.346235 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:10:08.347658 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:10:08.610951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b0ba0d0>]}
[0m12:10:08.612421 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:10:08.619143 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:10:08.619599 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.620004 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.620504 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.621248 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:10:08.622600 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:10:08.624011 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:10:08.625412 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:10:08.626773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:10:08.627862 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:10:08.628841 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:10:08.629920 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:10:08.630809 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:10:08.631794 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.632768 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.633627 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.642909 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:10:08.650212 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:10:08.654891 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:10:08.659401 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:10:08.673388 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.673943 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:10:08.685425 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.714156 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.717154 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:10:08.736582 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:10:08.748058 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:10:08.751051 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:10:08.836389 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:10:08.837254 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:09.051461 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:10:09.052854 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:10:09.058874 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:10:09.061367 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:10:09.077703 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:10:09.082892 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:10:09.440854 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a77580ae-74d7-4082-945e-1557dcd44eb3&page=queryresults
[0m12:10:09.444775 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5de3a9cf-f8f8-4fd6-927c-73b22a522df2&page=queryresults
[0m12:10:09.445230 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f11cbfee-0399-46d4-91a6-108a550c3f25&page=queryresults
[0m12:10:09.660010 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6e52364-52f9-4897-a96e-199f121bf859&page=queryresults
[0m12:10:09.661133 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6e52364-52f9-4897-a96e-199f121bf859&page=queryresults
[0m12:10:09.665395 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:10:09.667377 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3885b8350>]}
[0m12:10:09.668387 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.04s]
[0m12:10:09.670203 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:10:09.671349 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.671869 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:10:09.672662 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:10:09.675555 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:10:09.676387 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.681006 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:10:09.686430 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.690206 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:09.951947 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:10:09.959043 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:10:10.237203 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86441706-7148-489f-9571-02540b89f3e9&page=queryresults
[0m12:10:11.054244 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3882d1110>]}
[0m12:10:11.055069 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b05e790>]}
[0m12:10:11.056035 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.43s]
[0m12:10:11.057364 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.43s]
[0m12:10:11.058794 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:10:11.059985 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:10:11.074131 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388517dd0>]}
[0m12:10:11.075411 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m12:10:11.076808 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:10:12.113754 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388499850>]}
[0m12:10:12.115368 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.44s]
[0m12:10:12.116850 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:12.120018 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:10:12.123544 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:10:12.124481 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:10:12.125629 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:10:12.126520 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:10:12.127419 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:10:12.128389 [info ] [MainThread]: 
[0m12:10:12.129362 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.40 seconds (4.40s).
[0m12:10:12.131340 [debug] [MainThread]: Command end result
[0m12:10:12.173739 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:10:12.178852 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:10:12.188667 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:10:12.189541 [info ] [MainThread]: 
[0m12:10:12.190646 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:10:12.191954 [info ] [MainThread]: 
[0m12:10:12.193119 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:10:12.194426 [info ] [MainThread]: 
[0m12:10:12.195568 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:10:12.197869 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.334941, "process_in_blocks": "0", "process_kernel_time": 0.357176, "process_mem_max_rss": "227504", "process_out_blocks": "0", "process_user_time": 4.010581}
[0m12:10:12.199660 [debug] [MainThread]: Command `dbt run` failed at 12:10:12.199414 after 6.34 seconds
[0m12:10:12.200837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b99a1f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bcc0d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bcc0c910>]}
[0m12:10:12.202260 [debug] [MainThread]: Flushing usage events
[0m12:10:13.536417 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:35.168713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4887bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48c70190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb488cfb50>]}


============================== 12:11:35.171253 | 47c6053b-faf4-41c5-a733-a1dd39b8a577 ==============================
[0m12:11:35.171253 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:35.176483 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:11:35.256286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47c6053b-faf4-41c5-a733-a1dd39b8a577', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb488d2210>]}
[0m12:11:35.314893 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19363533, "process_in_blocks": "0", "process_kernel_time": 0.08905, "process_mem_max_rss": "90032", "process_out_blocks": "0", "process_user_time": 0.959763}
[0m12:11:35.315982 [debug] [MainThread]: Command `dbt clean` succeeded at 12:11:35.315862 after 0.19 seconds
[0m12:11:35.316715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48c72950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48766950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4c044c10>]}
[0m12:11:35.317586 [debug] [MainThread]: Flushing usage events
[0m12:11:36.402937 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:37.603564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc71b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dcbd0490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc71bdd0>]}


============================== 12:11:37.606573 | 684b4dc2-2ab3-424a-8bde-28c45ccc22ee ==============================
[0m12:11:37.606573 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:37.608495 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:11:37.691974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '684b4dc2-2ab3-424a-8bde-28c45ccc22ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc65ae10>]}
[0m12:11:37.702257 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:11:37.704740 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:11:37.706480 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15209816, "process_in_blocks": "0", "process_kernel_time": 0.111289, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 0.991485}
[0m12:11:37.707620 [debug] [MainThread]: Command `dbt deps` succeeded at 12:11:37.707487 after 0.15 seconds
[0m12:11:37.708400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc76edd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dff10c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dcb163d0>]}
[0m12:11:37.709156 [debug] [MainThread]: Flushing usage events
[0m12:11:38.942306 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:41.650625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed506d7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed513b7990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed506d6fd0>]}


============================== 12:11:41.653819 | 073d100a-dfe2-4ee1-9503-299194de87b3 ==============================
[0m12:11:41.653819 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:41.655146 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:11:42.258854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed228a73d0>]}
[0m12:11:42.309621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed52930bd0>]}
[0m12:11:42.310934 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:11:42.381136 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:11:42.385700 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:11:42.386707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed50bb7790>]}
[0m12:11:43.508970 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:11:43.519654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed22609690>]}
[0m12:11:43.598261 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:11:43.605464 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:11:43.621321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222da6d0>]}
[0m12:11:43.622368 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:11:43.623326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222fe110>]}
[0m12:11:43.626204 [info ] [MainThread]: 
[0m12:11:43.627503 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:11:43.628455 [info ] [MainThread]: 
[0m12:11:43.629659 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:11:43.633839 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:11:43.635054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:11:44.154201 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:11:44.155576 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:11:44.401719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed22512cd0>]}
[0m12:11:44.402882 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:11:44.410050 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:11:44.410402 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.410831 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.411275 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.411854 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:11:44.413065 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:11:44.414307 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:11:44.415469 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:11:44.416435 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:11:44.417560 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:11:44.418619 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:11:44.419483 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:11:44.420249 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:11:44.421223 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.422172 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.423786 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.432352 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:11:44.438179 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:11:44.442372 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:11:44.446291 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:11:44.458565 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.459090 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:11:44.465786 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.475922 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.519929 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:11:44.532109 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:11:44.541641 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:11:44.545307 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:11:44.628486 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:11:44.629488 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:11:44.848938 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:11:44.850431 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:11:44.851554 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:11:44.862853 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:11:44.865903 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:11:44.869830 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:11:45.016089 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:53a73ffb-79b6-48c9-8489-6a88a8382c0e&page=queryresults
[0m12:11:45.102723 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:197f5a52-0a08-4a33-8bb6-39402abe47cd&page=queryresults
[0m12:11:45.108728 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:313f6ff8-f2da-45f7-a325-eb66ba5c750c&page=queryresults
[0m12:11:45.123873 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7d479716-f885-4c5f-952d-34846b43049f&page=queryresults
[0m12:11:46.672117 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed201d7550>]}
[0m12:11:46.672494 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed2232c9d0>]}
[0m12:11:46.673577 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m12:11:46.675150 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m12:11:46.676771 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:11:46.677936 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:11:46.678940 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.681084 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:11:46.682336 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:11:46.683373 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.688350 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:11:46.693224 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed2017a0d0>]}
[0m12:11:46.695192 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.27s]
[0m12:11:46.696817 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:11:46.700049 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.705266 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:11:46.897861 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222af610>]}
[0m12:11:46.899345 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.48s]
[0m12:11:46.900838 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:11:46.941289 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:11:46.948468 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:11:47.298041 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6c829dee-2bf7-409f-aa18-1248149b1271&page=queryresults
[0m12:11:48.873005 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed124749d0>]}
[0m12:11:48.874508 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.19s]
[0m12:11:48.875890 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:48.878734 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:11:48.882337 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:11:48.883237 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:11:48.884050 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:11:48.884835 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:11:48.885837 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:11:48.886720 [info ] [MainThread]: 
[0m12:11:48.887577 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.26 seconds (5.26s).
[0m12:11:48.889466 [debug] [MainThread]: Command end result
[0m12:11:48.926176 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:11:48.930205 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:11:48.938203 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:11:48.938973 [info ] [MainThread]: 
[0m12:11:48.940020 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:11:48.941212 [info ] [MainThread]: 
[0m12:11:48.942310 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:11:48.943887 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.3556, "process_in_blocks": "0", "process_kernel_time": 0.329294, "process_mem_max_rss": "229256", "process_out_blocks": "0", "process_user_time": 4.270848}
[0m12:11:48.945162 [debug] [MainThread]: Command `dbt run` succeeded at 12:11:48.945016 after 7.36 seconds
[0m12:11:48.946035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed50ace090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed53ea0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed54024910>]}
[0m12:11:48.946878 [debug] [MainThread]: Flushing usage events
[0m12:11:50.262714 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:19.473043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c32bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c87d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c30950>]}


============================== 12:14:19.475646 | 9bc05b03-72be-4f12-bad1-482f86995b7b ==============================
[0m12:14:19.475646 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:19.478172 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m12:14:19.565999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9bc05b03-72be-4f12-bad1-482f86995b7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6ac0c90>]}
[0m12:14:19.625509 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20065594, "process_in_blocks": "0", "process_kernel_time": 0.0879, "process_mem_max_rss": "90048", "process_out_blocks": "0", "process_user_time": 0.947373}
[0m12:14:19.626680 [debug] [MainThread]: Command `dbt clean` succeeded at 12:14:19.626575 after 0.20 seconds
[0m12:14:19.627353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c8db90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c8c950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbfa428c90>]}
[0m12:14:19.628047 [debug] [MainThread]: Flushing usage events
[0m12:14:20.943576 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:22.121699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303976990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303e57790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303976890>]}


============================== 12:14:22.124290 | d9546f3a-3557-4e9d-a57c-42d8ecafd4cb ==============================
[0m12:14:22.124290 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:22.125415 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:14:22.211035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9546f3a-3557-4e9d-a57c-42d8ecafd4cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa304667290>]}
[0m12:14:22.221264 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:14:22.223764 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:14:22.226094 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15758468, "process_in_blocks": "0", "process_kernel_time": 0.079564, "process_mem_max_rss": "90244", "process_out_blocks": "0", "process_user_time": 1.024392}
[0m12:14:22.227380 [debug] [MainThread]: Command `dbt deps` succeeded at 12:14:22.227240 after 0.16 seconds
[0m12:14:22.228215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3039cf150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3072c5110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3072c5390>]}
[0m12:14:22.229115 [debug] [MainThread]: Flushing usage events
[0m12:14:23.276970 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:26.250444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2541131dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f254161b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2541132fd0>]}


============================== 12:14:26.253042 | 04c831b9-45ce-431c-b173-055c55d37ab0 ==============================
[0m12:14:26.253042 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:26.254557 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:14:26.839004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2513557590>]}
[0m12:14:26.888323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25433b9f50>]}
[0m12:14:26.890098 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:14:26.956775 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:14:26.958759 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:14:26.959673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25132986d0>]}
[0m12:14:28.038029 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:14:28.049247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512fa3c50>]}
[0m12:14:28.122172 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:14:28.129770 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:14:28.144730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512cd9550>]}
[0m12:14:28.145949 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:14:28.147221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d9ab10>]}
[0m12:14:28.150270 [info ] [MainThread]: 
[0m12:14:28.151515 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:14:28.152554 [info ] [MainThread]: 
[0m12:14:28.154108 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:14:28.159369 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:14:28.160494 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:14:28.634639 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:14:28.642530 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:14:28.866016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d99c90>]}
[0m12:14:28.867438 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:14:28.873152 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:14:28.873632 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.873976 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.874345 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.875011 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:14:28.876268 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:14:28.877460 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:14:28.878555 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:14:28.879884 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:14:28.881012 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:14:28.882001 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:14:28.882858 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:14:28.883917 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:14:28.884945 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.885731 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.886833 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.897534 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:14:28.901822 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:14:28.906517 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:14:28.912908 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:14:28.928453 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.929203 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:14:28.951625 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.957849 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.978371 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:14:28.979788 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:14:28.983259 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:14:28.987543 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:14:29.283489 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:14:29.285377 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:14:29.286867 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:14:29.288281 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:14:29.305352 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:14:29.307366 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:14:29.308202 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:14:29.308895 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:14:29.572549 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bf07f2b2-99ea-4d53-89cd-6901a3997f16&page=queryresults
[0m12:14:29.575205 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:513296c1-c5c5-46cf-812d-6bc9c80f7d67&page=queryresults
[0m12:14:29.575962 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:83d3ae75-aa55-4a3c-a3ed-eec7fe88ccae&page=queryresults
[0m12:14:29.587219 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31dd3710-8939-4d31-925f-55686ab54e26&page=queryresults
[0m12:14:31.092116 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f251037f690>]}
[0m12:14:31.092999 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2510388990>]}
[0m12:14:31.093884 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512e89350>]}
[0m12:14:31.096518 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.20s]
[0m12:14:31.098289 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.21s]
[0m12:14:31.100123 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.21s]
[0m12:14:31.101913 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:14:31.103510 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:14:31.105221 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:14:31.106477 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.109959 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:14:31.111271 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:14:31.112564 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.117440 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:14:31.123234 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.127103 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:14:31.158249 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f251038b550>]}
[0m12:14:31.159826 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.28s]
[0m12:14:31.161157 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:14:31.331237 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:14:31.339277 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:14:31.588307 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca60e0b1-0e1d-4b54-b1d4-1d7d56ea477c&page=queryresults
[0m12:14:33.191816 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d4e390>]}
[0m12:14:33.193413 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.08s]
[0m12:14:33.195094 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:33.197792 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:14:33.201545 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:14:33.202508 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:14:33.203175 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:14:33.203946 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:14:33.204876 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:14:33.205791 [info ] [MainThread]: 
[0m12:14:33.206684 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.05 seconds (5.05s).
[0m12:14:33.208978 [debug] [MainThread]: Command end result
[0m12:14:33.247311 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:14:33.252699 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:14:33.263204 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:14:33.264377 [info ] [MainThread]: 
[0m12:14:33.265811 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:14:33.267101 [info ] [MainThread]: 
[0m12:14:33.268162 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:14:33.269810 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.077331, "process_in_blocks": "0", "process_kernel_time": 0.182434, "process_mem_max_rss": "227056", "process_out_blocks": "0", "process_user_time": 4.317616}
[0m12:14:33.270949 [debug] [MainThread]: Command `dbt run` succeeded at 12:14:33.270824 after 7.08 seconds
[0m12:14:33.271860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f254181df50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2544ab1110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2544ab0910>]}
[0m12:14:33.272989 [debug] [MainThread]: Flushing usage events
[0m12:14:34.815361 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:28.535967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb7597ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d26410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb7592b710>]}


============================== 12:22:28.538465 | 00707613-d893-44b3-8421-9ece7ed0ae42 ==============================
[0m12:22:28.538465 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:28.540221 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:22:28.623364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '00707613-d893-44b3-8421-9ece7ed0ae42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75ddc550>]}
[0m12:22:28.687460 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20204052, "process_in_blocks": "0", "process_kernel_time": 0.079582, "process_mem_max_rss": "90048", "process_out_blocks": "0", "process_user_time": 0.97489}
[0m12:22:28.688389 [debug] [MainThread]: Command `dbt clean` succeeded at 12:22:28.688259 after 0.20 seconds
[0m12:22:28.689175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d268d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d264d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75817d10>]}
[0m12:22:28.689874 [debug] [MainThread]: Flushing usage events
[0m12:22:30.188452 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:31.357624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2bffb150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c3f2110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c4ac290>]}


============================== 12:22:31.360329 | 4e26e73a-e023-46db-864a-94a0378ce498 ==============================
[0m12:22:31.360329 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:31.361514 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:22:31.448064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4e26e73a-e023-46db-864a-94a0378ce498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c055350>]}
[0m12:22:31.461030 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:22:31.463759 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:22:31.465446 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16211414, "process_in_blocks": "0", "process_kernel_time": 0.079951, "process_mem_max_rss": "90168", "process_out_blocks": "0", "process_user_time": 1.039364}
[0m12:22:31.466440 [debug] [MainThread]: Command `dbt deps` succeeded at 12:22:31.466299 after 0.16 seconds
[0m12:22:31.467225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c4ac350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c3f2110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2f7c4b90>]}
[0m12:22:31.468047 [debug] [MainThread]: Flushing usage events
[0m12:22:32.711996 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:37.279476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e1133090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e152a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e1183690>]}


============================== 12:22:37.282021 | e8e934d5-ebb0-4544-b08e-ea96d9089c6e ==============================
[0m12:22:37.282021 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:37.285912 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:22:37.925687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b32b3b90>]}
[0m12:22:37.974327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e338ddd0>]}
[0m12:22:37.975900 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:22:38.048025 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:22:38.051182 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:22:38.052136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b3a051d0>]}
[0m12:22:38.912227 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m12:22:38.913720 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6879505, "process_in_blocks": "0", "process_kernel_time": 0.2304, "process_mem_max_rss": "211984", "process_out_blocks": "0", "process_user_time": 3.49608}
[0m12:22:38.914912 [debug] [MainThread]: Command `dbt run` failed at 12:22:38.914760 after 1.69 seconds
[0m12:22:38.916136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e116a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e4a81290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b385d410>]}
[0m12:22:38.917693 [debug] [MainThread]: Flushing usage events
[0m12:22:40.225349 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:24:50.347572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a02b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a02a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a01e90>]}


============================== 12:24:50.351031 | 5e7a04af-ab2c-429a-b9a2-5fd6defde211 ==============================
[0m12:24:50.351031 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:24:50.353079 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m12:24:50.361777 [info ] [MainThread]: dbt version: 1.9.0
[0m12:24:50.363262 [info ] [MainThread]: python version: 3.11.2
[0m12:24:50.364666 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:24:50.366517 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:24:50.907611 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:24:50.908813 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:24:50.909750 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:24:50.990226 [info ] [MainThread]: Configuration:
[0m12:24:50.991664 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m12:24:50.992923 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:24:50.993884 [info ] [MainThread]: Required dependencies:
[0m12:24:50.994803 [debug] [MainThread]: Executing "git --help"
[0m12:24:50.998514 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:24:50.999350 [debug] [MainThread]: STDERR: "b''"
[0m12:24:51.000211 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:24:51.001056 [info ] [MainThread]: Connection test skipped since no profile was found
[0m12:24:51.002568 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:24:51.003524 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "hailing_project", target "dev" invalid: Runtime Error
    Must specify schema


[0m12:24:51.005126 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.70546657, "process_in_blocks": "0", "process_kernel_time": 0.192204, "process_mem_max_rss": "206772", "process_out_blocks": "0", "process_user_time": 2.569475}
[0m12:24:51.006267 [debug] [MainThread]: Command `dbt debug` failed at 12:24:51.006128 after 0.71 seconds
[0m12:24:51.007996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a57310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b36c36a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b3736b150>]}
[0m12:24:51.009173 [debug] [MainThread]: Flushing usage events
[0m12:24:52.114373 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:02.227394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caea7290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cb38b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cb38b6d0>]}


============================== 12:25:02.230811 | 42bce0e9-25c5-4560-a6d4-37ab17094f2a ==============================
[0m12:25:02.230811 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:25:02.232172 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:25:02.239302 [info ] [MainThread]: dbt version: 1.9.0
[0m12:25:02.240291 [info ] [MainThread]: python version: 3.11.2
[0m12:25:02.241268 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:25:02.242526 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:25:02.773632 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:25:02.774683 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:25:02.775972 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:25:02.777199 [info ] [MainThread]: adapter type: bigquery
[0m12:25:02.778140 [info ] [MainThread]: adapter version: 1.9.0
[0m12:25:02.859356 [info ] [MainThread]: Configuration:
[0m12:25:02.860768 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:25:02.861994 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:25:02.863064 [info ] [MainThread]: Required dependencies:
[0m12:25:02.863977 [debug] [MainThread]: Executing "git --help"
[0m12:25:02.866047 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:25:02.866783 [debug] [MainThread]: STDERR: "b''"
[0m12:25:02.867742 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:25:02.868702 [info ] [MainThread]: Connection:
[0m12:25:02.870019 [info ] [MainThread]:   method: service-account
[0m12:25:02.871601 [info ] [MainThread]:   database: purwadika
[0m12:25:02.872664 [info ] [MainThread]:   execution_project: purwadika
[0m12:25:02.873606 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m12:25:02.874874 [info ] [MainThread]:   location: None
[0m12:25:02.876224 [info ] [MainThread]:   priority: None
[0m12:25:02.877343 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:25:02.878250 [info ] [MainThread]:   impersonate_service_account: None
[0m12:25:02.879179 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:25:02.880040 [info ] [MainThread]:   job_retries: 1
[0m12:25:02.881541 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:25:02.882636 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:25:02.883719 [info ] [MainThread]:   timeout_seconds: None
[0m12:25:02.884683 [info ] [MainThread]:   client_id: None
[0m12:25:02.885697 [info ] [MainThread]:   token_uri: None
[0m12:25:02.887209 [info ] [MainThread]:   dataproc_region: None
[0m12:25:02.888398 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:25:02.889561 [info ] [MainThread]:   gcs_bucket: None
[0m12:25:02.890798 [info ] [MainThread]:   dataproc_batch: None
[0m12:25:02.892004 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:25:02.945830 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:25:02.946883 [debug] [MainThread]: On debug: select 1 as id
[0m12:25:02.947681 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:25:03.617215 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:fc931634-228d-4b58-82f4-4600c2cb892c&page=queryresults
[0m12:25:04.366891 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:25:04.368622 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:25:04.370913 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1982403, "process_in_blocks": "0", "process_kernel_time": 0.190733, "process_mem_max_rss": "212356", "process_out_blocks": "0", "process_user_time": 2.680304}
[0m12:25:04.371960 [debug] [MainThread]: Command `dbt debug` succeeded at 12:25:04.371855 after 2.20 seconds
[0m12:25:04.372729 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:25:04.373547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caf1f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caf1f290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0ce69cc10>]}
[0m12:25:04.374454 [debug] [MainThread]: Flushing usage events
[0m12:25:05.434130 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:27:08.731101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76bd0>]}


============================== 12:27:08.735636 | 2d6f5382-0d24-42c2-a797-dd2a7bdc0c10 ==============================
[0m12:27:08.735636 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:27:08.738532 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:27:08.747167 [info ] [MainThread]: dbt version: 1.9.0
[0m12:27:08.749696 [info ] [MainThread]: python version: 3.11.2
[0m12:27:08.751053 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:27:08.752173 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:27:09.244898 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:27:09.248064 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:27:09.249293 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:27:09.250749 [info ] [MainThread]: adapter type: bigquery
[0m12:27:09.253528 [info ] [MainThread]: adapter version: 1.9.0
[0m12:27:09.335546 [info ] [MainThread]: Configuration:
[0m12:27:09.336904 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:27:09.338304 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:27:09.339333 [info ] [MainThread]: Required dependencies:
[0m12:27:09.340379 [debug] [MainThread]: Executing "git --help"
[0m12:27:09.342518 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:27:09.343447 [debug] [MainThread]: STDERR: "b''"
[0m12:27:09.344307 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:27:09.345287 [info ] [MainThread]: Connection:
[0m12:27:09.346476 [info ] [MainThread]:   method: service-account
[0m12:27:09.347409 [info ] [MainThread]:   database: purwadika
[0m12:27:09.348385 [info ] [MainThread]:   execution_project: purwadika
[0m12:27:09.349459 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m12:27:09.350324 [info ] [MainThread]:   location: None
[0m12:27:09.351261 [info ] [MainThread]:   priority: None
[0m12:27:09.352361 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:27:09.353185 [info ] [MainThread]:   impersonate_service_account: None
[0m12:27:09.354030 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:27:09.354903 [info ] [MainThread]:   job_retries: 1
[0m12:27:09.355721 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:27:09.356701 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:27:09.357587 [info ] [MainThread]:   timeout_seconds: None
[0m12:27:09.358371 [info ] [MainThread]:   client_id: None
[0m12:27:09.359542 [info ] [MainThread]:   token_uri: None
[0m12:27:09.360405 [info ] [MainThread]:   dataproc_region: None
[0m12:27:09.361317 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:27:09.362109 [info ] [MainThread]:   gcs_bucket: None
[0m12:27:09.362929 [info ] [MainThread]:   dataproc_batch: None
[0m12:27:09.363861 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:27:09.419090 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:27:09.420242 [debug] [MainThread]: On debug: select 1 as id
[0m12:27:09.421033 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:27:10.103520 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:d560c700-4198-4148-a916-ecc982868603&page=queryresults
[0m12:27:10.827252 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:27:10.829173 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:27:10.831613 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.150948, "process_in_blocks": "0", "process_kernel_time": 0.142167, "process_mem_max_rss": "214748", "process_out_blocks": "0", "process_user_time": 2.741803}
[0m12:27:10.832989 [debug] [MainThread]: Command `dbt debug` succeeded at 12:27:10.832802 after 2.15 seconds
[0m12:27:10.834598 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:27:10.836028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cdb661850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ca9cc64d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7f72310>]}
[0m12:27:10.837288 [debug] [MainThread]: Flushing usage events
[0m12:27:11.950725 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:04.068492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19879f6f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987f10c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19879f6e90>]}


============================== 12:35:04.071731 | f84d009d-3405-42d6-90ea-73e2a8b99d79 ==============================
[0m12:35:04.071731 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:04.074743 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:35:04.675180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987a3e3d0>]}
[0m12:35:04.728646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1989ca9fd0>]}
[0m12:35:04.729926 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:04.797959 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:35:04.799988 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:35:04.801138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959cdef10>]}
[0m12:35:05.827022 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:35:05.837875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959d61750>]}
[0m12:35:05.907689 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:05.913855 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:05.932847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19595ef490>]}
[0m12:35:05.933946 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:35:05.935229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959615d10>]}
[0m12:35:05.937988 [info ] [MainThread]: 
[0m12:35:05.939417 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:35:05.940607 [info ] [MainThread]: 
[0m12:35:05.942773 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:35:05.947710 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:35:05.948888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:35:06.619118 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_staging)
[0m12:35:06.621289 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_staging"
"
[0m12:35:06.629410 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_staging`
  
[0m12:35:06.630746 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:07.669352 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f94c82ed-3ee3-4d95-a86f-b35b0b08b108&page=queryresults
[0m12:35:08.621745 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_staging)
[0m12:35:08.622808 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:09.185113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959be1750>]}
[0m12:35:09.186288 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:09.191852 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:35:09.192202 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.192633 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.193007 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.193538 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m12:35:09.194694 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m12:35:09.195909 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m12:35:09.196976 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m12:35:09.198094 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m12:35:09.199187 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:35:09.200130 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:35:09.201399 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:35:09.202741 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:35:09.204027 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.205064 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.206099 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.215127 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:35:09.219018 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:09.223146 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:09.227159 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:09.244137 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.244637 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:35:09.250834 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.277877 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.326644 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:35:09.329615 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:09.324564 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:09.333413 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:09.348764 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m12:35:09.349395 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:35:09.350516 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:35:09.351654 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m12:35:09.352217 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:09.353753 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m12:35:09.354796 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:35:09.381099 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:35:09.713385 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:352fa713-7282-4532-91ac-48e7d7c9fd3c&page=queryresults
[0m12:35:09.714761 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:352fa713-7282-4532-91ac-48e7d7c9fd3c&page=queryresults
[0m12:35:09.719095 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m12:35:09.721633 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b826d0>]}
[0m12:35:09.723173 [error] [Thread-3 (]: 3 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[31mERROR[0m in 0.52s]
[0m12:35:09.725411 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.726776 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.728961 [info ] [Thread-3 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m12:35:09.727795 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_driver' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql.
[0m12:35:09.730813 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:35:09.733449 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.738642 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:09.740316 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:34e3ada8-b940-4fd9-9dd7-85c5c8805f47&page=queryresults
[0m12:35:09.741838 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:34e3ada8-b940-4fd9-9dd7-85c5c8805f47&page=queryresults
[0m12:35:09.746416 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33b2d751-c286-44fd-aac9-bb75cae310bb&page=queryresults
[0m12:35:09.747878 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m12:35:09.748603 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33b2d751-c286-44fd-aac9-bb75cae310bb&page=queryresults
[0m12:35:09.749252 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.750339 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b5eb90>]}
[0m12:35:09.754365 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m12:35:09.758314 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:09.759958 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.55s]
[0m12:35:09.761183 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f195962d7d0>]}
[0m12:35:09.763429 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.764696 [error] [Thread-4 (]: 4 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[31mERROR[0m in 0.56s]
[0m12:35:09.766007 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m12:35:09.767545 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.769903 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m12:35:09.770828 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_ride' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql.
[0m12:35:09.771806 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:35:10.055438 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:71d0a539-5076-4f7a-9818-e399bd338ee0&page=queryresults
[0m12:35:10.056663 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:71d0a539-5076-4f7a-9818-e399bd338ee0&page=queryresults
[0m12:35:10.060669 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m12:35:10.061991 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b63890>]}
[0m12:35:10.063334 [error] [Thread-3 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[31mERROR[0m in 0.33s]
[0m12:35:10.064640 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:10.065856 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql.
[0m12:35:10.122443 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e357a4e2-0d1c-4229-94b7-3606ac8b9cfb&page=queryresults
[0m12:35:10.123704 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e357a4e2-0d1c-4229-94b7-3606ac8b9cfb&page=queryresults
[0m12:35:10.127682 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:10.129198 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958a0edd0>]}
[0m12:35:10.131220 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.dim_customer  [[31mERROR[0m in 0.93s]
[0m12:35:10.132622 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:35:10.134163 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:35:10.136862 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:35:10.141750 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:35:10.142881 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:35:10.143817 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:35:10.144725 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:35:10.145687 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:35:10.146686 [info ] [MainThread]: 
[0m12:35:10.147711 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.20 seconds (4.20s).
[0m12:35:10.150147 [debug] [MainThread]: Command end result
[0m12:35:10.184708 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:10.189132 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:10.196887 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:35:10.197597 [info ] [MainThread]: 
[0m12:35:10.198781 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m12:35:10.199910 [info ] [MainThread]: 
[0m12:35:10.201024 [error] [MainThread]:   Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m12:35:10.202095 [info ] [MainThread]: 
[0m12:35:10.203354 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m12:35:10.204557 [info ] [MainThread]: 
[0m12:35:10.205835 [error] [MainThread]:   Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m12:35:10.207134 [info ] [MainThread]: 
[0m12:35:10.208569 [error] [MainThread]:   Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m12:35:10.209700 [info ] [MainThread]: 
[0m12:35:10.210951 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:10.212219 [info ] [MainThread]: 
[0m12:35:10.213799 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m12:35:10.216211 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1943884, "process_in_blocks": "0", "process_kernel_time": 0.218868, "process_mem_max_rss": "229740", "process_out_blocks": "0", "process_user_time": 4.188339}
[0m12:35:10.217388 [debug] [MainThread]: Command `dbt run` failed at 12:35:10.217250 after 6.20 seconds
[0m12:35:10.218490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987a779d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f198b3ad190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f195999aa10>]}
[0m12:35:10.219479 [debug] [MainThread]: Flushing usage events
[0m12:35:11.899031 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:24.781940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944bd7190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944c2b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944bd6cd0>]}


============================== 12:35:24.784962 | a7cf52e0-3a42-472a-a444-5c0691b23049 ==============================
[0m12:35:24.784962 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:24.786074 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:35:24.793244 [info ] [MainThread]: dbt version: 1.9.0
[0m12:35:24.794469 [info ] [MainThread]: python version: 3.11.2
[0m12:35:24.795776 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:35:24.797085 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:35:25.342777 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:35:25.343847 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:35:25.344761 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:35:25.345889 [info ] [MainThread]: adapter type: bigquery
[0m12:35:25.346786 [info ] [MainThread]: adapter version: 1.9.0
[0m12:35:25.425664 [info ] [MainThread]: Configuration:
[0m12:35:25.427205 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:35:25.428354 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:35:25.429525 [info ] [MainThread]: Required dependencies:
[0m12:35:25.430730 [debug] [MainThread]: Executing "git --help"
[0m12:35:25.432704 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:35:25.433991 [debug] [MainThread]: STDERR: "b''"
[0m12:35:25.434875 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:35:25.436078 [info ] [MainThread]: Connection:
[0m12:35:25.437308 [info ] [MainThread]:   method: service-account
[0m12:35:25.438423 [info ] [MainThread]:   database: purwadika
[0m12:35:25.439661 [info ] [MainThread]:   execution_project: purwadika
[0m12:35:25.440629 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m12:35:25.441662 [info ] [MainThread]:   location: None
[0m12:35:25.443336 [info ] [MainThread]:   priority: None
[0m12:35:25.444898 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:35:25.445953 [info ] [MainThread]:   impersonate_service_account: None
[0m12:35:25.446972 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:35:25.447964 [info ] [MainThread]:   job_retries: 1
[0m12:35:25.448949 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:35:25.450109 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:35:25.451116 [info ] [MainThread]:   timeout_seconds: None
[0m12:35:25.452085 [info ] [MainThread]:   client_id: None
[0m12:35:25.452895 [info ] [MainThread]:   token_uri: None
[0m12:35:25.453846 [info ] [MainThread]:   dataproc_region: None
[0m12:35:25.455107 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:35:25.456096 [info ] [MainThread]:   gcs_bucket: None
[0m12:35:25.457028 [info ] [MainThread]:   dataproc_batch: None
[0m12:35:25.458245 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:25.515866 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:35:25.516671 [debug] [MainThread]: On debug: select 1 as id
[0m12:35:25.517560 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:26.182606 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:5dd687be-1a3a-43e9-b75f-24f363e7c354&page=queryresults
[0m12:35:26.906317 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:35:26.910046 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:35:26.914259 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1825113, "process_in_blocks": "0", "process_kernel_time": 0.216603, "process_mem_max_rss": "212388", "process_out_blocks": "0", "process_user_time": 2.737082}
[0m12:35:26.918161 [debug] [MainThread]: Command `dbt debug` succeeded at 12:35:26.917918 after 2.19 seconds
[0m12:35:26.919472 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:35:26.921367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7916e47790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7948408c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7916d47110>]}
[0m12:35:26.922968 [debug] [MainThread]: Flushing usage events
[0m12:35:27.954886 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:35.128813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8427390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8472a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8472b90>]}


============================== 12:35:35.132311 | e44f0043-5b68-49aa-aa98-d702a4eff2e0 ==============================
[0m12:35:35.132311 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:35.133532 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:35:35.226883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e44f0043-5b68-49aa-aa98-d702a4eff2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a847d890>]}
[0m12:35:35.291775 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.21464151, "process_in_blocks": "0", "process_kernel_time": 0.08995, "process_mem_max_rss": "90152", "process_out_blocks": "0", "process_user_time": 1.029437}
[0m12:35:35.292995 [debug] [MainThread]: Command `dbt clean` succeeded at 12:35:35.292876 after 0.22 seconds
[0m12:35:35.293816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8427010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1abbf0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a9107310>]}
[0m12:35:35.294743 [debug] [MainThread]: Flushing usage events
[0m12:35:36.338119 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:37.536545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18b8ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18bdff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18b8ec10>]}


============================== 12:35:37.540987 | deaf3887-16cb-4d4f-b5f1-26be96e016fb ==============================
[0m12:35:37.540987 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:37.542517 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m12:35:37.673678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'deaf3887-16cb-4d4f-b5f1-26be96e016fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18bdfd90>]}
[0m12:35:37.692677 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:35:37.696532 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:35:37.698928 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.24335356, "process_in_blocks": "0", "process_kernel_time": 0.160146, "process_mem_max_rss": "90096", "process_out_blocks": "0", "process_user_time": 1.030945}
[0m12:35:37.700486 [debug] [MainThread]: Command `dbt deps` succeeded at 12:35:37.700283 after 0.25 seconds
[0m12:35:37.701784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18be1850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18be31d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1c3bcc10>]}
[0m12:35:37.702952 [debug] [MainThread]: Flushing usage events
[0m12:35:38.771242 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:42.196966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c203190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c5fa2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c5f9f10>]}


============================== 12:35:42.200034 | 03123977-0378-4c9c-a69f-0bf3ad79167a ==============================
[0m12:35:42.200034 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:42.201396 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:35:42.829783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e3c47d0>]}
[0m12:35:42.876135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e504f10>]}
[0m12:35:42.877503 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:42.950039 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:35:42.952711 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:35:42.953606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e983b50>]}
[0m12:35:44.040659 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:35:44.054036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e387410>]}
[0m12:35:44.130108 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:44.135162 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:44.150344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1ddf2510>]}
[0m12:35:44.151657 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:35:44.153365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e256490>]}
[0m12:35:44.157258 [info ] [MainThread]: 
[0m12:35:44.158604 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:35:44.159848 [info ] [MainThread]: 
[0m12:35:44.161462 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:35:44.167067 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:35:44.168288 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:35:44.953393 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:35:44.955842 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:45.228815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1df8d310>]}
[0m12:35:45.230372 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:45.237270 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:35:45.237620 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.238032 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.238414 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.239222 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:35:45.240468 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:35:45.242137 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:35:45.243358 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:35:45.244818 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:35:45.246008 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:35:45.247466 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:35:45.248547 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:35:45.249537 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:35:45.250610 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.251461 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.252484 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.263383 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:35:45.268115 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:45.273416 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:45.277587 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:45.290847 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.291334 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:35:45.303153 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.330171 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:35:45.330556 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.334013 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:45.337165 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:35:45.340848 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:35:45.672109 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:35:45.675954 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:45.679573 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:45.681724 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:45.689368 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:35:45.689959 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:35:45.692577 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:35:45.694630 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:35:45.924486 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6f216068-b27c-4e17-b374-12982d4a3c97&page=queryresults
[0m12:35:45.925606 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6f216068-b27c-4e17-b374-12982d4a3c97&page=queryresults
[0m12:35:45.931143 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:45.933100 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c43f2d0>]}
[0m12:35:45.934971 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.69s]
[0m12:35:45.936375 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:35:45.937684 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.938230 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:35:45.939219 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:35:45.941332 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:35:45.942200 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.946801 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:45.953178 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.957034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:46.035462 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6be76204-0106-45db-8e0b-351a846328bd&page=queryresults
[0m12:35:46.048460 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0fe0823f-427e-4ddd-8dfb-5ceb41d603c3&page=queryresults
[0m12:35:46.096361 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:697a74cf-f6ef-4511-9189-64f1aad1ac9d&page=queryresults
[0m12:35:46.306248 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:46.313577 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:35:46.603670 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cd5bcbee-bd2d-416b-b912-17de78c692ba&page=queryresults
[0m12:35:47.750441 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c3ada50>]}
[0m12:35:47.751006 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c3b1710>]}
[0m12:35:47.752082 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:35:47.753540 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:35:47.754817 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:35:47.756088 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:35:47.760978 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c481d50>]}
[0m12:35:47.762665 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.51s]
[0m12:35:47.764203 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:35:48.204856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c481690>]}
[0m12:35:48.205864 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.26s]
[0m12:35:48.207254 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:48.209746 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:35:48.213135 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:35:48.214094 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:35:48.215136 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:35:48.216503 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:35:48.217501 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:35:48.218750 [info ] [MainThread]: 
[0m12:35:48.219867 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.06 seconds (4.06s).
[0m12:35:48.222086 [debug] [MainThread]: Command end result
[0m12:35:48.258089 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:48.262037 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:48.271323 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:35:48.272381 [info ] [MainThread]: 
[0m12:35:48.273544 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:35:48.274744 [info ] [MainThread]: 
[0m12:35:48.275702 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:48.276591 [info ] [MainThread]: 
[0m12:35:48.277614 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:35:48.279407 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1315765, "process_in_blocks": "0", "process_kernel_time": 0.241492, "process_mem_max_rss": "227800", "process_out_blocks": "0", "process_user_time": 4.296552}
[0m12:35:48.280698 [debug] [MainThread]: Command `dbt run` failed at 12:35:48.280532 after 6.13 seconds
[0m12:35:48.281712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c081290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c083690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4fb515d0>]}
[0m12:35:48.282635 [debug] [MainThread]: Flushing usage events
[0m12:35:49.612867 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:38:00.616728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe1b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fcc21790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe1b5d0>]}


============================== 12:38:00.620358 | 67a234b6-9058-4d4c-a33a-a03b021aace6 ==============================
[0m12:38:00.620358 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:38:00.622428 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:38:01.222524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47ce777fd0>]}
[0m12:38:01.272648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fe0a5d90>]}
[0m12:38:01.273822 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:38:01.340824 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:38:01.407525 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:38:01.410508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fcc20410>]}
[0m12:38:02.421856 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:38:02.432965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdbcda10>]}
[0m12:38:02.506942 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:38:02.512595 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:38:02.527154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cd9e1510>]}
[0m12:38:02.528071 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:38:02.529448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdc12250>]}
[0m12:38:02.532344 [info ] [MainThread]: 
[0m12:38:02.533594 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:38:02.534886 [info ] [MainThread]: 
[0m12:38:02.536327 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:38:02.541633 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:38:02.542823 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:38:03.132534 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:38:03.133388 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:38:03.395520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdbceb50>]}
[0m12:38:03.396511 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:38:03.401000 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:38:03.401334 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.401644 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.401965 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.402623 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:38:03.403748 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:38:03.405269 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:38:03.406422 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:38:03.407508 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:38:03.408504 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:38:03.409548 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:38:03.410879 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:38:03.412195 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:38:03.413284 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.414371 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.415550 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.424881 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:38:03.428970 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:38:03.433974 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:38:03.439798 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:38:03.446476 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.446995 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.447392 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:38:03.447732 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.496875 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:38:03.498401 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:38:03.501996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:38:03.505118 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:38:03.832636 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:38:03.833467 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:38:03.835501 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:38:03.836763 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:38:03.842273 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:38:03.842808 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:38:03.843320 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:38:03.845430 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:38:04.060908 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7672eb36-f05c-4022-a962-14265aff265c&page=queryresults
[0m12:38:04.062019 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7672eb36-f05c-4022-a962-14265aff265c&page=queryresults
[0m12:38:04.066939 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:38:04.068696 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdc27f90>]}
[0m12:38:04.070294 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.66s]
[0m12:38:04.072564 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:38:04.074814 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.075599 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:38:04.076716 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:38:04.079499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:38:04.081543 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.086519 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:38:04.089455 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:adfbbf34-4e18-442f-86f7-bb1b7d267442&page=queryresults
[0m12:38:04.095950 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.099569 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:38:04.126292 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:61f6272e-dcc3-46d5-b629-ba526e2feb0a&page=queryresults
[0m12:38:04.126836 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9f8a9487-0cd8-41c1-a734-e205ae14d043&page=queryresults
[0m12:38:04.369037 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:38:04.378019 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:38:04.638641 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1a38cf87-7f2a-442c-b83f-e02fcbdb63de&page=queryresults
[0m12:38:05.667709 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47bdf58790>]}
[0m12:38:05.669970 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47bdcc7c90>]}
[0m12:38:05.670698 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.26s]
[0m12:38:05.671922 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.26s]
[0m12:38:05.672969 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:38:05.674037 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:38:05.835757 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cda35850>]}
[0m12:38:05.837024 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.43s]
[0m12:38:05.838897 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:38:06.164209 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cc0e2610>]}
[0m12:38:06.165612 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.08s]
[0m12:38:06.166981 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:06.169280 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:38:06.172684 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:38:06.173700 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:38:06.174716 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:38:06.175989 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:38:06.177080 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:38:06.179000 [info ] [MainThread]: 
[0m12:38:06.180564 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 3.64 seconds (3.64s).
[0m12:38:06.183075 [debug] [MainThread]: Command end result
[0m12:38:06.223587 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:38:06.230096 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:38:06.239402 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:38:06.240794 [info ] [MainThread]: 
[0m12:38:06.241981 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:38:06.243320 [info ] [MainThread]: 
[0m12:38:06.244643 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:38:06.245911 [info ] [MainThread]: 
[0m12:38:06.247227 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:38:06.249252 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.686209, "process_in_blocks": "0", "process_kernel_time": 0.241691, "process_mem_max_rss": "228712", "process_out_blocks": "0", "process_user_time": 4.179252}
[0m12:38:06.250777 [debug] [MainThread]: Command `dbt run` failed at 12:38:06.250652 after 5.69 seconds
[0m12:38:06.251855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe74090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe75c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47ff799250>]}
[0m12:38:06.252941 [debug] [MainThread]: Flushing usage events
[0m12:38:07.684839 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:22.716955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06afffed50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b04e7690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b004bfd0>]}


============================== 12:40:22.719605 | e8364ab3-67c4-429a-99b4-7126fb79e266 ==============================
[0m12:40:22.719605 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:22.721157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:40:22.804962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8364ab3-67c4-429a-99b4-7126fb79e266', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b0059d10>]}
[0m12:40:22.869526 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20637281, "process_in_blocks": "0", "process_kernel_time": 0.122746, "process_mem_max_rss": "89996", "process_out_blocks": "0", "process_user_time": 0.971743}
[0m12:40:22.870857 [debug] [MainThread]: Command `dbt clean` succeeded at 12:40:22.870556 after 0.21 seconds
[0m12:40:22.871698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b0058ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b00319d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b3924b10>]}
[0m12:40:22.872543 [debug] [MainThread]: Flushing usage events
[0m12:40:26.876124 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:27.998908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e13ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e623690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e13e9d0>]}


============================== 12:40:28.001850 | 62e82b7e-ff14-41b3-9a12-987090e68aba ==============================
[0m12:40:28.001850 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:28.003047 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:40:28.087268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62e82b7e-ff14-41b3-9a12-987090e68aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e192f10>]}
[0m12:40:28.096846 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:40:28.099842 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:40:28.101655 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15786701, "process_in_blocks": "0", "process_kernel_time": 0.081048, "process_mem_max_rss": "90252", "process_out_blocks": "0", "process_user_time": 0.982718}
[0m12:40:28.102856 [debug] [MainThread]: Command `dbt deps` succeeded at 12:40:28.102729 after 0.16 seconds
[0m12:40:28.103739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e53a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e1b5010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e02bd10>]}
[0m12:40:28.104642 [debug] [MainThread]: Flushing usage events
[0m12:40:31.985681 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:34.752626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bab2af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18baf264d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bab2ac90>]}


============================== 12:40:34.755367 | 5b93f61f-8719-40db-b2f0-a7334df7040a ==============================
[0m12:40:34.755367 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:34.756644 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:40:35.371648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f189370b6d0>]}
[0m12:40:35.421232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bcddc8d0>]}
[0m12:40:35.422389 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:40:35.495821 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:40:35.499338 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:40:35.500407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f189370aad0>]}
[0m12:40:36.540615 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:40:36.553984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890a9b5d0>]}
[0m12:40:36.640200 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:40:36.647392 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:40:36.665754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890717790>]}
[0m12:40:36.666806 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:40:36.668410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890ad8950>]}
[0m12:40:36.671304 [info ] [MainThread]: 
[0m12:40:36.672464 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:40:36.673590 [info ] [MainThread]: 
[0m12:40:36.675612 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:40:36.681736 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:40:36.682846 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:40:37.251390 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:40:37.252299 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:40:37.501569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bba63f90>]}
[0m12:40:37.502605 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:40:37.508984 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.509420 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.509861 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.510338 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.511102 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:40:37.512541 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:40:37.514017 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:40:37.515758 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:40:37.517247 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:40:37.518580 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:40:37.519897 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:40:37.521430 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:40:37.522988 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.524365 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.525887 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.527215 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.538773 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:40:37.543207 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:40:37.548034 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:40:37.553786 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:40:37.569493 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.571031 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.603358 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.614444 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.624815 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:40:37.625394 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:40:37.628085 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:40:37.631753 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:40:37.951004 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:40:37.953262 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:40:37.954853 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:40:37.956501 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:40:37.971504 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:40:37.972425 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:40:37.976284 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:40:37.978296 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:40:38.217058 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:04fa07f2-9e8a-447c-bac9-6f52330976fb&page=queryresults
[0m12:40:38.255553 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8ecf0cfd-a580-48fa-b11e-40eb2ab7387b&page=queryresults
[0m12:40:38.261291 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3faf8c96-e29d-4593-a958-af0802db3e5b&page=queryresults
[0m12:40:38.344578 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:285274e9-d77a-4f26-8962-b07558cd260e&page=queryresults
[0m12:40:39.811462 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890628410>]}
[0m12:40:39.812599 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.29s]
[0m12:40:39.813860 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:40:39.867814 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18907f7510>]}
[0m12:40:39.869189 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.35s]
[0m12:40:39.870696 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:39.972164 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18907a7650>]}
[0m12:40:39.973479 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.46s]
[0m12:40:39.974926 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:40:40.011624 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890614810>]}
[0m12:40:40.013345 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.49s]
[0m12:40:40.014678 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:40:40.017324 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:40:40.020334 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:40:40.021199 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:40:40.021992 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:40:40.023670 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:40:40.024822 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:40:40.026228 [info ] [MainThread]: 
[0m12:40:40.027341 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.35 seconds (3.35s).
[0m12:40:40.029574 [debug] [MainThread]: Command end result
[0m12:40:40.064933 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:40:40.069320 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:40:40.079259 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:40:40.080168 [info ] [MainThread]: 
[0m12:40:40.081253 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:40:40.082343 [info ] [MainThread]: 
[0m12:40:40.083555 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:40:40.085552 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3841953, "process_in_blocks": "0", "process_kernel_time": 0.231955, "process_mem_max_rss": "226544", "process_out_blocks": "0", "process_user_time": 4.265955}
[0m12:40:40.086775 [debug] [MainThread]: Command `dbt run` succeeded at 12:40:40.086611 after 5.39 seconds
[0m12:40:40.087869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18be384b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890233690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18baf26910>]}
[0m12:40:40.089226 [debug] [MainThread]: Flushing usage events
[0m12:40:41.151013 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:03.946633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7954fa74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79553a6110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7954fa7110>]}


============================== 12:41:03.949221 | 95b15488-65bc-469d-83e6-67fee15d43e9 ==============================
[0m12:41:03.949221 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:41:03.950262 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:41:04.522735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792715a390>]}
[0m12:41:04.567364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792729ff10>]}
[0m12:41:04.568557 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:41:04.638132 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:41:04.771246 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:41:04.772161 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:41:05.019694 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:41:05.035177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926db5c50>]}
[0m12:41:05.106925 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:05.112412 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:05.127712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926c65c50>]}
[0m12:41:05.129069 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:41:05.130229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926e27f10>]}
[0m12:41:05.132924 [info ] [MainThread]: 
[0m12:41:05.134239 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:41:05.135447 [info ] [MainThread]: 
[0m12:41:05.136881 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:41:05.142071 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:41:05.143035 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:05.675811 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:41:05.677302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:05.889896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79554fcc50>]}
[0m12:41:05.891701 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:05.897709 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.898084 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.898405 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.898735 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.899419 [info ] [Thread-1 (]: 1 of 4 START sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:41:05.900791 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:41:05.902280 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:41:05.903657 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:41:05.905067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:41:05.906173 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:41:05.907271 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:41:05.908564 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:41:05.909571 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.910417 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.911391 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.916546 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.928405 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:05.935301 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:05.941944 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:05.946522 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:05.957399 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.958167 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.958737 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.975675 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.975385 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:06.008982 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:41:06.011314 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:41:06.013878 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:41:06.069309 [debug] [Thread-1 (]: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m12:41:06.095417 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792437f510>]}
[0m12:41:06.096711 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.19s]
[0m12:41:06.097896 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:41:06.099096 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql).
[0m12:41:06.318785 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:06.319505 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:06.324337 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:41:06.326238 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:41:06.592375 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:06.603481 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:41:06.626595 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fb186b7a-c146-4103-99fd-a540f000dc68&page=queryresults
[0m12:41:06.730600 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5c854dc4-e8f0-4b69-acd4-105569b8e022&page=queryresults
[0m12:41:06.857379 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a169fed4-a8bc-4c83-b82a-94ff1a63fd8f&page=queryresults
[0m12:41:08.161064 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926d19650>]}
[0m12:41:08.162903 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.25s]
[0m12:41:08.164836 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:08.243634 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926cf3b50>]}
[0m12:41:08.245632 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.34s]
[0m12:41:08.247603 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:41:08.368400 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79243c5f90>]}
[0m12:41:08.369534 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.46s]
[0m12:41:08.371239 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:41:08.374407 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:41:08.378606 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:41:08.379402 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:41:08.380190 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:41:08.380806 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:41:08.381481 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:41:08.382217 [info ] [MainThread]: 
[0m12:41:08.383081 [info ] [MainThread]: Finished running 3 incremental models, 1 view model in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m12:41:08.385579 [debug] [MainThread]: Command end result
[0m12:41:08.420532 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:08.425800 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:08.435161 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:41:08.436026 [info ] [MainThread]: 
[0m12:41:08.437231 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:41:08.438397 [info ] [MainThread]: 
[0m12:41:08.439610 [error] [MainThread]:   Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m12:41:08.440711 [info ] [MainThread]: 
[0m12:41:08.441861 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m12:41:08.443647 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.549744, "process_in_blocks": "16", "process_kernel_time": 0.243292, "process_mem_max_rss": "225336", "process_out_blocks": "0", "process_user_time": 3.466916}
[0m12:41:08.444751 [debug] [MainThread]: Command `dbt run` failed at 12:41:08.444567 after 4.55 seconds
[0m12:41:08.445886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7927158910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f790efb3450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f795721d710>]}
[0m12:41:08.446672 [debug] [MainThread]: Flushing usage events
[0m12:41:09.512271 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:26.454650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4eeafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4eeae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f435d0>]}


============================== 12:41:26.457455 | 819d282b-95c4-42a4-8aa3-4f78cafa4317 ==============================
[0m12:41:26.457455 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:41:26.458586 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:41:27.014207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a977e3a90>]}
[0m12:41:27.062840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac7164b10>]}
[0m12:41:27.064062 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:41:27.135174 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:41:27.278006 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:41:27.279276 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:41:27.537153 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:41:27.550252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac5cb0610>]}
[0m12:41:27.630504 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:27.636094 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:27.649680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96d02150>]}
[0m12:41:27.650781 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:41:27.651861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96b9c0d0>]}
[0m12:41:27.654530 [info ] [MainThread]: 
[0m12:41:27.655814 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:41:27.656833 [info ] [MainThread]: 
[0m12:41:27.658356 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:41:27.662693 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:41:27.663928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:28.169416 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:41:28.170332 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:28.385373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a971da490>]}
[0m12:41:28.386506 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:28.391210 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.391536 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.391981 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.392418 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.393016 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:41:28.394269 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:41:28.395312 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:41:28.396500 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:41:28.397615 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:41:28.398738 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:41:28.399736 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:41:28.400864 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:41:28.401741 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.402883 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.403713 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.404556 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.413910 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:28.418039 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:28.423070 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:28.427072 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:28.434206 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.434823 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.441705 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.442216 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.476357 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:41:28.476759 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:41:28.480058 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:28.482888 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:41:28.778709 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:28.781342 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:28.783555 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:28.784828 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:28.793103 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:41:28.793837 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:41:28.795181 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:41:28.798734 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:41:29.025528 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9acce181-9288-4590-b114-ae1db5f62339&page=queryresults
[0m12:41:29.029475 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:de479302-a0a6-482b-8751-94e0aee19e75&page=queryresults
[0m12:41:29.073980 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1cd8456-6637-4927-9730-ce0ea608069c&page=queryresults
[0m12:41:29.110758 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:76ae07ed-c020-4db6-a99d-47fc7d78a5a8&page=queryresults
[0m12:41:30.595164 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96e912d0>]}
[0m12:41:30.596844 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.19s]
[0m12:41:30.599156 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:30.890796 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a7ee39290>]}
[0m12:41:30.895371 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96c3f050>]}
[0m12:41:30.896135 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.49s]
[0m12:41:30.898220 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:41:30.900702 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:41:30.906534 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a942524d0>]}
[0m12:41:30.907710 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:41:30.910096 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.51s]
[0m12:41:30.912362 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:41:30.914979 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:41:30.918982 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:41:30.920023 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:41:30.922273 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:41:30.923799 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:41:30.925339 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:41:30.926698 [info ] [MainThread]: 
[0m12:41:30.927822 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.27 seconds (3.27s).
[0m12:41:30.930023 [debug] [MainThread]: Command end result
[0m12:41:30.966979 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:30.971968 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:30.980023 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:41:30.980776 [info ] [MainThread]: 
[0m12:41:30.981881 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:41:30.983115 [info ] [MainThread]: 
[0m12:41:30.984479 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:41:30.986027 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.583139, "process_in_blocks": "0", "process_kernel_time": 0.172975, "process_mem_max_rss": "224628", "process_out_blocks": "0", "process_user_time": 3.571426}
[0m12:41:30.986960 [debug] [MainThread]: Command `dbt run` succeeded at 12:41:30.986851 after 4.58 seconds
[0m12:41:30.987839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f67c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f67910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac8708b90>]}
[0m12:41:30.988843 [debug] [MainThread]: Flushing usage events
[0m12:41:32.116889 [debug] [MainThread]: An error was encountered while trying to flush usage events
