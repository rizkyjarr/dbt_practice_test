[0m02:01:58.167482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc44a050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc9a0690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc4481d0>]}


============================== 02:01:58.169998 | f30404dd-70bc-499f-b040-8dec280d234b ==============================
[0m02:01:58.169998 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:01:58.171483 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:01:58.194779 [info ] [MainThread]: dbt version: 1.9.0
[0m02:01:58.196604 [info ] [MainThread]: python version: 3.11.2
[0m02:01:58.199261 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:01:58.200610 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:01:58.202280 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:01:58.204031 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:01:58.205188 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:01:58.303120 [info ] [MainThread]: Configuration:
[0m02:01:58.304294 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m02:01:58.305538 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:01:58.306951 [info ] [MainThread]: Required dependencies:
[0m02:01:58.308008 [debug] [MainThread]: Executing "git --help"
[0m02:01:58.323742 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:01:58.324603 [debug] [MainThread]: STDERR: "b''"
[0m02:01:58.325333 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:01:58.326344 [info ] [MainThread]: Connection test skipped since no profile was found
[0m02:01:58.327995 [info ] [MainThread]: [31m1 check failed:[0m
[0m02:01:58.329152 [info ] [MainThread]: dbt looked for a profiles.yml file in /usr/app/dbt_project/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m02:01:58.331588 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.21399155, "process_in_blocks": "776", "process_kernel_time": 0.060459, "process_mem_max_rss": "90472", "process_out_blocks": "0", "process_user_time": 0.977432}
[0m02:01:58.332640 [debug] [MainThread]: Command `dbt debug` failed at 02:01:58.332515 after 0.22 seconds
[0m02:01:58.333781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cc429c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cfd6d210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52cfd6d150>]}
[0m02:01:58.334968 [debug] [MainThread]: Flushing usage events
[0m02:01:59.648058 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:03:01.751208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3dce910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c42af7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3dcd990>]}


============================== 02:03:01.755328 | 7f50ea83-094b-4ed3-971d-39636c6fa73a ==============================
[0m02:03:01.755328 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:03:01.756721 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:03:01.767470 [info ] [MainThread]: dbt version: 1.9.0
[0m02:03:01.768348 [info ] [MainThread]: python version: 3.11.2
[0m02:03:01.769784 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:03:01.770739 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:03:02.302614 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:03:02.303759 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:03:02.304871 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:03:02.305801 [info ] [MainThread]: adapter type: bigquery
[0m02:03:02.307297 [info ] [MainThread]: adapter version: 1.9.0
[0m02:03:02.402199 [info ] [MainThread]: Configuration:
[0m02:03:02.403292 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:03:02.404241 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:03:02.405112 [info ] [MainThread]: Required dependencies:
[0m02:03:02.406134 [debug] [MainThread]: Executing "git --help"
[0m02:03:02.408326 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:03:02.409631 [debug] [MainThread]: STDERR: "b''"
[0m02:03:02.410439 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:03:02.411349 [info ] [MainThread]: Connection:
[0m02:03:02.412438 [info ] [MainThread]:   method: service-account
[0m02:03:02.413312 [info ] [MainThread]:   database: purwadika
[0m02:03:02.414164 [info ] [MainThread]:   execution_project: purwadika
[0m02:03:02.415144 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:03:02.416415 [info ] [MainThread]:   location: None
[0m02:03:02.417588 [info ] [MainThread]:   priority: None
[0m02:03:02.418533 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:03:02.419663 [info ] [MainThread]:   impersonate_service_account: None
[0m02:03:02.420829 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:03:02.422152 [info ] [MainThread]:   job_retries: 1
[0m02:03:02.423846 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:03:02.424872 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:03:02.426031 [info ] [MainThread]:   timeout_seconds: None
[0m02:03:02.427484 [info ] [MainThread]:   client_id: None
[0m02:03:02.428781 [info ] [MainThread]:   token_uri: None
[0m02:03:02.430586 [info ] [MainThread]:   dataproc_region: None
[0m02:03:02.431899 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:03:02.432880 [info ] [MainThread]:   gcs_bucket: None
[0m02:03:02.434031 [info ] [MainThread]:   dataproc_batch: None
[0m02:03:02.435123 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:03:02.502738 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:03:02.503622 [debug] [MainThread]: On debug: select 1 as id
[0m02:03:02.504454 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:02.531994 [debug] [MainThread]: BigQuery adapter: Got an error when attempting to create a bigquery " "client: '[Errno 21] Is a directory: '/root/.dbt/credentials.json''
[0m02:03:02.533124 [debug] [MainThread]: BigQuery adapter: Unhandled error while running:
select 1 as id
[0m02:03:02.534054 [debug] [MainThread]: BigQuery adapter: Database Error
  [Errno 21] Is a directory: '/root/.dbt/credentials.json'
[0m02:03:02.534785 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m02:03:02.535672 [info ] [MainThread]: [31m1 check failed:[0m
[0m02:03:02.536718 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >'NoneType' object has no attribute 'close'

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m02:03:02.538374 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.8450967, "process_in_blocks": "696", "process_kernel_time": 0.1747, "process_mem_max_rss": "207440", "process_out_blocks": "24", "process_user_time": 2.733544}
[0m02:03:02.539326 [debug] [MainThread]: Command `dbt debug` failed at 02:03:02.539222 after 0.85 seconds
[0m02:03:02.540230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c3e04450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5896576250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58c4aaf290>]}
[0m02:03:02.541443 [debug] [MainThread]: Flushing usage events
[0m02:03:03.693784 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:04:31.038959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596e53810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596f60e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596e87090>]}


============================== 02:04:31.043418 | 81d713c9-fbc7-4523-921b-5a295ad22e3d ==============================
[0m02:04:31.043418 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:04:31.044686 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:04:31.051027 [info ] [MainThread]: dbt version: 1.9.0
[0m02:04:31.051864 [info ] [MainThread]: python version: 3.11.2
[0m02:04:31.054054 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:04:31.055178 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:04:31.556857 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:04:31.558394 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:04:31.559756 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:04:31.561102 [info ] [MainThread]: adapter type: bigquery
[0m02:04:31.562446 [info ] [MainThread]: adapter version: 1.9.0
[0m02:04:31.641979 [info ] [MainThread]: Configuration:
[0m02:04:31.644292 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:04:31.645262 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:04:31.646400 [info ] [MainThread]: Required dependencies:
[0m02:04:31.647547 [debug] [MainThread]: Executing "git --help"
[0m02:04:31.649460 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:04:31.650135 [debug] [MainThread]: STDERR: "b''"
[0m02:04:31.650881 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:04:31.651960 [info ] [MainThread]: Connection:
[0m02:04:31.653391 [info ] [MainThread]:   method: service-account
[0m02:04:31.654439 [info ] [MainThread]:   database: purwadika
[0m02:04:31.655544 [info ] [MainThread]:   execution_project: purwadika
[0m02:04:31.656705 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:04:31.659063 [info ] [MainThread]:   location: None
[0m02:04:31.660554 [info ] [MainThread]:   priority: None
[0m02:04:31.661527 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:04:31.662408 [info ] [MainThread]:   impersonate_service_account: None
[0m02:04:31.663369 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:04:31.664496 [info ] [MainThread]:   job_retries: 1
[0m02:04:31.665590 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:04:31.666913 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:04:31.667968 [info ] [MainThread]:   timeout_seconds: None
[0m02:04:31.668867 [info ] [MainThread]:   client_id: None
[0m02:04:31.669906 [info ] [MainThread]:   token_uri: None
[0m02:04:31.670765 [info ] [MainThread]:   dataproc_region: None
[0m02:04:31.671720 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:04:31.672753 [info ] [MainThread]:   gcs_bucket: None
[0m02:04:31.673635 [info ] [MainThread]:   dataproc_batch: None
[0m02:04:31.674714 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:04:31.729175 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:04:31.730186 [debug] [MainThread]: On debug: select 1 as id
[0m02:04:31.731072 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:04:32.794278 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:87d88a11-3360-405e-8b46-a8ca6bbbbf3c&page=queryresults
[0m02:04:33.636786 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:04:33.638193 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:04:33.639993 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.6463816, "process_in_blocks": "1728", "process_kernel_time": 0.200069, "process_mem_max_rss": "212840", "process_out_blocks": "1952", "process_user_time": 2.727258}
[0m02:04:33.641273 [debug] [MainThread]: Command `dbt debug` succeeded at 02:04:33.641161 after 2.65 seconds
[0m02:04:33.642154 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:04:33.643123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd596ccfed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd59a8ed810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd59a5f4b90>]}
[0m02:04:33.644089 [debug] [MainThread]: Flushing usage events
[0m02:04:35.179263 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:13:23.075436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d3efc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d3eed10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d4f9c90>]}


============================== 02:13:23.078000 | c09a6ece-1481-4071-b0cc-401b4b306eb2 ==============================
[0m02:13:23.078000 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:13:23.079859 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:13:23.657306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df58ee90>]}
[0m02:13:23.701756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df668f10>]}
[0m02:13:23.703096 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:13:23.769821 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:13:23.772243 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:13:23.773545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df304610>]}
[0m02:13:24.778057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df184190>]}
[0m02:13:24.848924 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:13:24.854999 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:13:24.878854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dd7f51d0>]}
[0m02:13:24.880016 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:13:24.881104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df174a90>]}
[0m02:13:24.883858 [info ] [MainThread]: 
[0m02:13:24.884947 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:13:24.885962 [info ] [MainThread]: 
[0m02:13:24.887547 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:13:24.892377 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:13:24.893723 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:13:25.533676 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_staging_layer)
[0m02:13:25.534636 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_staging_layer"
"
[0m02:13:25.544110 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_staging_layer`
  
[0m02:13:25.545018 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:13:26.420654 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ff549e3d-6554-4cfb-bd1b-ec70f66fdf2b&page=queryresults
[0m02:13:27.364350 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_staging_layer, now list_purwadika_rizky_dwh_hailing_source_staging_layer)
[0m02:13:27.365587 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:13:27.962897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df3d4a90>]}
[0m02:13:27.964146 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:13:27.968860 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:13:27.969238 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:13:27.969552 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:13:27.969869 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:13:27.970397 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_customer  [RUN]
[0m02:13:27.971371 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_driver  [RUN]
[0m02:13:27.972555 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_ride  [RUN]
[0m02:13:27.973745 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_staging_layer.stg_vehicle  [RUN]
[0m02:13:27.974666 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_staging_layer, now model.hailing_project.stg_customer)
[0m02:13:27.975693 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:13:27.976480 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:13:27.977492 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:13:27.978532 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:13:27.979457 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:13:27.980371 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:13:27.981171 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:13:27.990440 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:13:27.993778 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:13:27.997289 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:13:28.002557 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:13:28.013883 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:13:28.020199 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:13:28.055805 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:13:28.077280 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:13:28.094918 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:13:28.095777 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:13:28.098535 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:13:28.102086 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:13:28.113235 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:13:28.114468 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:13:28.114968 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:13:28.116441 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:13:28.117278 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:13:28.118506 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:13:28.120172 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:13:28.168238 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:13:28.521749 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:646f9616-63cc-45b6-bf88-99d73b4ed749&page=queryresults
[0m02:13:28.523204 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:646f9616-63cc-45b6-bf88-99d73b4ed749&page=queryresults
[0m02:13:28.528143 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f54b5075-3bf2-4aba-9c4a-dd2e97f5d340&page=queryresults
[0m02:13:28.529736 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33a93330-c5ad-4749-9727-560eebeb7501&page=queryresults
[0m02:13:28.530267 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f54b5075-3bf2-4aba-9c4a-dd2e97f5d340&page=queryresults
[0m02:13:28.531426 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33a93330-c5ad-4749-9727-560eebeb7501&page=queryresults
[0m02:13:28.541292 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:13:28.542367 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:13:28.543449 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:13:28.545777 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3df15de50>]}
[0m02:13:28.546575 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dcc6e4d0>]}
[0m02:13:28.547746 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dcb1f610>]}
[0m02:13:28.549150 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_vehicle  [[31mERROR[0m in 0.57s]
[0m02:13:28.551069 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_customer  [[31mERROR[0m in 0.57s]
[0m02:13:28.553330 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_driver  [[31mERROR[0m in 0.57s]
[0m02:13:28.554927 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:13:28.556276 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:13:28.557515 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:13:28.558931 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:13:28.561649 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:13:28.562905 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:13:28.565097 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4885aa9d-e541-4d05-bcc8-860385bcb7c1&page=queryresults
[0m02:13:28.566302 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4885aa9d-e541-4d05-bcc8-860385bcb7c1&page=queryresults
[0m02:13:28.570401 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:13:28.571656 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c09a6ece-1481-4071-b0cc-401b4b306eb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3dd7053d0>]}
[0m02:13:28.572987 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_staging_layer.stg_ride  [[31mERROR[0m in 0.60s]
[0m02:13:28.574379 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:13:28.575882 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:13:28.578237 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:13:28.581305 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:13:28.581993 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:13:28.582844 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:13:28.583559 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:13:28.584355 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:13:28.585086 [info ] [MainThread]: 
[0m02:13:28.586045 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.70 seconds (3.70s).
[0m02:13:28.587818 [debug] [MainThread]: Command end result
[0m02:13:28.623846 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:13:28.628422 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:13:28.637064 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:13:28.637811 [info ] [MainThread]: 
[0m02:13:28.638883 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:13:28.640157 [info ] [MainThread]: 
[0m02:13:28.642484 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:13:28.644360 [info ] [MainThread]: 
[0m02:13:28.645843 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:13:28.646854 [info ] [MainThread]: 
[0m02:13:28.647998 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:13:28.649370 [info ] [MainThread]: 
[0m02:13:28.651287 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:13:28.652467 [info ] [MainThread]: 
[0m02:13:28.653536 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:13:28.655363 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.626566, "process_in_blocks": "2952", "process_kernel_time": 0.239406, "process_mem_max_rss": "227664", "process_out_blocks": "120", "process_user_time": 3.980132}
[0m02:13:28.656716 [debug] [MainThread]: Command `dbt run` failed at 02:13:28.656571 after 5.63 seconds
[0m02:13:28.657757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d26fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff40d26f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff410d3c910>]}
[0m02:13:28.659269 [debug] [MainThread]: Flushing usage events
[0m02:13:29.808444 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:45.087750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de0a810>]}


============================== 02:18:45.090624 | 4a4e9f48-a67f-4b7f-8886-913783f5298a ==============================
[0m02:18:45.090624 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:45.091889 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:18:45.170120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a4e9f48-a67f-4b7f-8886-913783f5298a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165dd4a150>]}
[0m02:18:45.236071 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19432564, "process_in_blocks": "16", "process_kernel_time": 0.09933, "process_mem_max_rss": "90056", "process_out_blocks": "0", "process_user_time": 0.913843}
[0m02:18:45.237553 [debug] [MainThread]: Command `dbt clean` succeeded at 02:18:45.237391 after 0.20 seconds
[0m02:18:45.238719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de5fc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f165de5fc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1661600c10>]}
[0m02:18:45.239771 [debug] [MainThread]: Flushing usage events
[0m02:18:46.409339 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:47.583171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa9834b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa988b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa9c2de50>]}


============================== 02:18:47.586327 | bdee2df0-a205-4d95-a78f-035433b48340 ==============================
[0m02:18:47.586327 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:47.587616 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:18:47.673552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bdee2df0-a205-4d95-a78f-035433b48340', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fa96e7590>]}
[0m02:18:47.687732 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:18:47.690576 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:18:47.692333 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15736815, "process_in_blocks": "224", "process_kernel_time": 0.099129, "process_mem_max_rss": "90016", "process_out_blocks": "0", "process_user_time": 1.001206}
[0m02:18:47.693464 [debug] [MainThread]: Command `dbt deps` succeeded at 02:18:47.693309 after 0.16 seconds
[0m02:18:47.694459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad028c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad185350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fad1850d0>]}
[0m02:18:47.695615 [debug] [MainThread]: Flushing usage events
[0m02:18:48.762707 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:18:52.308476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38623fb090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38624289d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3862429210>]}


============================== 02:18:52.311249 | 995e2a61-4840-4443-befc-8244674169b3 ==============================
[0m02:18:52.311249 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:18:52.312645 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:18:52.907063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38623fded0>]}
[0m02:18:52.955932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f383885ef10>]}
[0m02:18:52.957296 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:18:53.026383 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:18:53.028816 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:18:53.029763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38386fdcd0>]}
[0m02:18:54.032005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38381e0890>]}
[0m02:18:54.103335 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:18:54.109105 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:18:54.126461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38381fe650>]}
[0m02:18:54.127461 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:18:54.128376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3838301450>]}
[0m02:18:54.130972 [info ] [MainThread]: 
[0m02:18:54.132065 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:18:54.133306 [info ] [MainThread]: 
[0m02:18:54.134660 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:18:54.139423 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:18:54.140644 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:18:54.790776 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer)
[0m02:18:54.791786 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer"
"
[0m02:18:54.799925 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`
  
[0m02:18:54.800625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:18:55.669445 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:285fe163-a733-42d8-bdca-8b8d38f7b5b4&page=queryresults
[0m02:18:56.649128 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer)
[0m02:18:56.650897 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:18:57.247028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38385a43d0>]}
[0m02:18:57.247999 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:18:57.253541 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:18:57.253984 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:18:57.254370 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:18:57.254750 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:18:57.255599 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_customer  [RUN]
[0m02:18:57.256713 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_driver  [RUN]
[0m02:18:57.258216 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_ride  [RUN]
[0m02:18:57.259397 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_vehicle  [RUN]
[0m02:18:57.260814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer, now model.hailing_project.stg_customer)
[0m02:18:57.261950 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:18:57.263136 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:18:57.264714 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:18:57.266058 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:18:57.268773 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:18:57.271434 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:18:57.273046 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:18:57.284746 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:18:57.289441 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:18:57.294893 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:18:57.299210 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:18:57.310739 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:18:57.317324 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:18:57.376507 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:18:57.382602 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:18:57.390017 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:18:57.390640 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:18:57.393482 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:18:57.397157 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:18:57.408477 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:18:57.410030 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:18:57.410566 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:18:57.411426 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:18:57.413100 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:18:57.413703 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:18:57.438615 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:18:57.441446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:18:57.764466 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6107e896-4330-4e03-92fd-74ee8ca3a5bf&page=queryresults
[0m02:18:57.767348 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6107e896-4330-4e03-92fd-74ee8ca3a5bf&page=queryresults
[0m02:18:57.768242 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c7171be9-3886-4586-806c-f92482b5aba9&page=queryresults
[0m02:18:57.771344 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c7171be9-3886-4586-806c-f92482b5aba9&page=queryresults
[0m02:18:57.774681 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:18:57.777527 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:18:57.779421 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2c108a5b-ad82-48ce-aaae-e21c5ac369d1&page=queryresults
[0m02:18:57.779887 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831dde650>]}
[0m02:18:57.780818 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831ca1250>]}
[0m02:18:57.781873 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2c108a5b-ad82-48ce-aaae-e21c5ac369d1&page=queryresults
[0m02:18:57.783172 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_driver  [[31mERROR[0m in 0.52s]
[0m02:18:57.784548 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_vehicle  [[31mERROR[0m in 0.52s]
[0m02:18:57.788188 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:18:57.789031 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:18:57.790559 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:18:57.792189 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831c256d0>]}
[0m02:18:57.793376 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:18:57.795166 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_customer  [[31mERROR[0m in 0.53s]
[0m02:18:57.796610 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:18:57.797827 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:18:57.800033 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:18:57.840670 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:703422ab-858d-4051-99c6-58851df2b19d&page=queryresults
[0m02:18:57.842184 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:703422ab-858d-4051-99c6-58851df2b19d&page=queryresults
[0m02:18:57.846614 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:18:57.847909 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '995e2a61-4840-4443-befc-8244674169b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3831c30c10>]}
[0m02:18:57.849065 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer.stg_ride  [[31mERROR[0m in 0.58s]
[0m02:18:57.850382 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:18:57.851855 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:18:57.854570 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:18:57.857707 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:18:57.858629 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:18:57.859634 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:18:57.860714 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:18:57.861703 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:18:57.862721 [info ] [MainThread]: 
[0m02:18:57.863614 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.73 seconds (3.73s).
[0m02:18:57.865233 [debug] [MainThread]: Command end result
[0m02:18:57.896602 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:18:57.900681 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:18:57.908344 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:18:57.909181 [info ] [MainThread]: 
[0m02:18:57.910394 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:18:57.911592 [info ] [MainThread]: 
[0m02:18:57.912736 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:18:57.913900 [info ] [MainThread]: 
[0m02:18:57.915756 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:18:57.917607 [info ] [MainThread]: 
[0m02:18:57.919166 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:18:57.920601 [info ] [MainThread]: 
[0m02:18:57.922638 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_source_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:18:57.924235 [info ] [MainThread]: 
[0m02:18:57.926002 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:18:57.929051 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.6718855, "process_in_blocks": "0", "process_kernel_time": 0.240604, "process_mem_max_rss": "228632", "process_out_blocks": "0", "process_user_time": 4.130384}
[0m02:18:57.930771 [debug] [MainThread]: Command `dbt run` failed at 02:18:57.930469 after 5.67 seconds
[0m02:18:57.932291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38627f2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865ee57d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3865d70850>]}
[0m02:18:57.933518 [debug] [MainThread]: Flushing usage events
[0m02:18:58.973754 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:43.036703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f4546e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f459b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f493e110>]}


============================== 02:19:43.039152 | 7f508b4b-59f7-4147-8cd6-0d08a45c1978 ==============================
[0m02:19:43.039152 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:43.040884 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:19:43.124750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f508b4b-59f7-4147-8cd6-0d08a45c1978', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f493e4d0>]}
[0m02:19:43.174142 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18960154, "process_in_blocks": "0", "process_kernel_time": 0.080068, "process_mem_max_rss": "90120", "process_out_blocks": "0", "process_user_time": 0.930793}
[0m02:19:43.175183 [debug] [MainThread]: Command `dbt clean` succeeded at 02:19:43.175049 after 0.19 seconds
[0m02:19:43.176197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f45a3050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f45a3150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f30f7d10c10>]}
[0m02:19:43.177249 [debug] [MainThread]: Flushing usage events
[0m02:19:44.249420 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:45.393126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d1af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d6b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d1ab10>]}


============================== 02:19:45.395761 | 50629c51-5b48-4916-bf16-b08f55f53855 ==============================
[0m02:19:45.395761 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:45.397063 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:19:45.475692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '50629c51-5b48-4916-bf16-b08f55f53855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9bc6d50>]}
[0m02:19:45.485546 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:19:45.488201 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:19:45.489894 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.14864384, "process_in_blocks": "0", "process_kernel_time": 0.059938, "process_mem_max_rss": "90020", "process_out_blocks": "0", "process_user_time": 1.018951}
[0m02:19:45.490991 [debug] [MainThread]: Command `dbt deps` succeeded at 02:19:45.490853 after 0.15 seconds
[0m02:19:45.491753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ecd508c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5eca10e150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ec9d19910>]}
[0m02:19:45.492620 [debug] [MainThread]: Flushing usage events
[0m02:19:46.645759 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:19:47.798072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3a57b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e02510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e023d0>]}


============================== 02:19:47.800876 | 36b4bddf-c76d-46a3-ba6c-257ff399de47 ==============================
[0m02:19:47.800876 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:19:47.802377 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:19:48.399327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5d91d50>]}
[0m02:19:48.443383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced5c7c850>]}
[0m02:19:48.444634 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:19:48.514047 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:19:48.516226 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:19:48.517453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5b93790>]}
[0m02:19:49.503689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea57e90d0>]}
[0m02:19:49.568227 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:19:49.574022 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:19:49.589989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5887290>]}
[0m02:19:49.591258 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:19:49.592417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5a61790>]}
[0m02:19:49.594991 [info ] [MainThread]: 
[0m02:19:49.596181 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:19:49.597270 [info ] [MainThread]: 
[0m02:19:49.598509 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:19:49.603426 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:19:49.604465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:19:50.214126 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:19:50.215642 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer"
"
[0m02:19:50.229867 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`
  
[0m02:19:50.231396 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:19:51.075076 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:eff2262a-9599-4bac-8e25-f6defc77ceb5&page=queryresults
[0m02:19:52.051860 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:19:52.052882 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:19:52.647637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcea5884410>]}
[0m02:19:52.649546 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:19:52.654428 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:19:52.654897 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:19:52.655325 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:19:52.655779 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:19:52.656379 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [RUN]
[0m02:19:52.657696 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [RUN]
[0m02:19:52.659094 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [RUN]
[0m02:19:52.660466 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [RUN]
[0m02:19:52.661523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now model.hailing_project.stg_customer)
[0m02:19:52.662659 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:19:52.663775 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:19:52.665131 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:19:52.666395 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:19:52.667350 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:19:52.668200 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:19:52.669164 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:19:52.678200 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:19:52.681497 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:19:52.685727 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:19:52.689378 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:19:52.702546 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:19:52.709417 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:19:52.742979 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:19:52.743343 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:19:52.782538 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:19:52.785044 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:19:52.785581 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:19:52.788713 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:19:52.801166 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:19:52.802363 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:19:52.803163 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:19:52.804698 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:19:52.805201 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:19:52.807701 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:19:52.809056 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:19:52.835926 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:19:53.069577 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:efbadefb-97fe-4c22-a6c8-b73c0fb171d7&page=queryresults
[0m02:19:53.070866 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:efbadefb-97fe-4c22-a6c8-b73c0fb171d7&page=queryresults
[0m02:19:53.076360 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:19:53.079108 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f3e5450>]}
[0m02:19:53.080368 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [[31mERROR[0m in 0.42s]
[0m02:19:53.081709 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:19:53.083138 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:19:53.160594 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:70c69ada-06e4-4a82-a967-4279d5e053f4&page=queryresults
[0m02:19:53.161707 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:70c69ada-06e4-4a82-a967-4279d5e053f4&page=queryresults
[0m02:19:53.165304 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:19:53.166187 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f140950>]}
[0m02:19:53.167406 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [[31mERROR[0m in 0.50s]
[0m02:19:53.168375 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:19:53.169604 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:19:53.189273 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dbf52f61-28b6-4b38-9bd0-87e904709498&page=queryresults
[0m02:19:53.190659 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dbf52f61-28b6-4b38-9bd0-87e904709498&page=queryresults
[0m02:19:53.194317 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:19:53.195547 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f132d90>]}
[0m02:19:53.196796 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [[31mERROR[0m in 0.53s]
[0m02:19:53.198030 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:19:53.199262 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:19:53.206344 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9d6d5eab-a475-46fa-9d54-3c7d7e00878d&page=queryresults
[0m02:19:53.207441 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9d6d5eab-a475-46fa-9d54-3c7d7e00878d&page=queryresults
[0m02:19:53.210872 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:19:53.212108 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36b4bddf-c76d-46a3-ba6c-257ff399de47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fce7f3f4390>]}
[0m02:19:53.213401 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [[31mERROR[0m in 0.55s]
[0m02:19:53.214467 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:19:53.215679 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:19:53.217446 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:19:53.221052 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:19:53.221827 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:19:53.222608 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:19:53.223536 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:19:53.224323 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:19:53.225250 [info ] [MainThread]: 
[0m02:19:53.226377 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.63 seconds (3.63s).
[0m02:19:53.228128 [debug] [MainThread]: Command end result
[0m02:19:53.264122 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:19:53.269292 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:19:53.278390 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:19:53.279099 [info ] [MainThread]: 
[0m02:19:53.280452 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:19:53.281929 [info ] [MainThread]: 
[0m02:19:53.283440 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:19:53.284486 [info ] [MainThread]: 
[0m02:19:53.285700 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:19:53.286808 [info ] [MainThread]: 
[0m02:19:53.288665 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:19:53.290195 [info ] [MainThread]: 
[0m02:19:53.292798 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:19:53.296067 [info ] [MainThread]: 
[0m02:19:53.298499 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:19:53.301766 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.559815, "process_in_blocks": "0", "process_kernel_time": 0.159599, "process_mem_max_rss": "227496", "process_out_blocks": "0", "process_user_time": 4.199452}
[0m02:19:53.304129 [debug] [MainThread]: Command `dbt run` failed at 02:19:53.303881 after 5.56 seconds
[0m02:19:53.309675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3e028d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced5b8aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fced3a3f190>]}
[0m02:19:53.312580 [debug] [MainThread]: Flushing usage events
[0m02:19:54.432570 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:22:59.298886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582de2c90>]}


============================== 02:22:59.301439 | 598de295-1704-4dee-b3ae-d4343be14bee ==============================
[0m02:22:59.301439 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:22:59.304163 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:22:59.897242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc559f64b50>]}
[0m02:22:59.941040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58505a210>]}
[0m02:22:59.942289 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:23:00.011330 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:23:00.078598 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m02:23:00.079893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc583be4390>]}
[0m02:23:01.075126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558fa2d10>]}
[0m02:23:01.141482 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:23:01.148081 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:23:01.161756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc543122a50>]}
[0m02:23:01.162979 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m02:23:01.164993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558dea390>]}
[0m02:23:01.168040 [info ] [MainThread]: 
[0m02:23:01.169154 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:23:01.170684 [info ] [MainThread]: 
[0m02:23:01.172194 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:23:01.176700 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:23:01.177769 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:23:02.337608 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer)
[0m02:23:02.338814 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:23:02.888646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc558e3d850>]}
[0m02:23:02.893292 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:23:02.898715 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m02:23:02.899162 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m02:23:02.899561 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m02:23:02.899911 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m02:23:02.900627 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [RUN]
[0m02:23:02.902948 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [RUN]
[0m02:23:02.905319 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [RUN]
[0m02:23:02.907001 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [RUN]
[0m02:23:02.908807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer, now model.hailing_project.stg_customer)
[0m02:23:02.910166 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m02:23:02.911458 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m02:23:02.912759 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m02:23:02.914024 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m02:23:02.914986 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m02:23:02.915994 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m02:23:02.916878 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m02:23:02.926278 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m02:23:02.929758 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m02:23:02.933442 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m02:23:02.937378 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m02:23:02.943149 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m02:23:02.944703 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m02:23:02.951044 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m02:23:02.951686 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m02:23:03.023351 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m02:23:03.026136 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m02:23:03.026779 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m02:23:03.029786 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m02:23:03.038455 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_vehicle`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
    );
  
[0m02:23:03.039788 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_customer`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:23:03.040237 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_driver`
      
    
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m02:23:03.041026 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:23:03.041683 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer`.`stg_ride`
      
    
    

    OPTIONS()
    as (
      

SELECT *
FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
    );
  
[0m02:23:03.042414 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:23:03.043246 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:23:03.044854 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:23:03.359713 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79e5f65c-7115-4456-8243-3c91fd64924f&page=queryresults
[0m02:23:03.361730 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79e5f65c-7115-4456-8243-3c91fd64924f&page=queryresults
[0m02:23:03.362561 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86310e65-be7e-4ea7-b55f-428455560bc9&page=queryresults
[0m02:23:03.365437 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86310e65-be7e-4ea7-b55f-428455560bc9&page=queryresults
[0m02:23:03.369647 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:23:03.370817 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:23:03.372341 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc507709590>]}
[0m02:23:03.373028 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5431e9b10>]}
[0m02:23:03.374161 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_vehicle  [[31mERROR[0m in 0.46s]
[0m02:23:03.375896 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_driver  [[31mERROR[0m in 0.46s]
[0m02:23:03.377233 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m02:23:03.378654 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m02:23:03.380169 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m02:23:03.381903 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m02:23:03.413141 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a793c2ef-2f5d-41b2-a0a1-9a8012d35841&page=queryresults
[0m02:23:03.414247 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a793c2ef-2f5d-41b2-a0a1-9a8012d35841&page=queryresults
[0m02:23:03.417566 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:23:03.418427 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc507728cd0>]}
[0m02:23:03.419705 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_customer  [[31mERROR[0m in 0.51s]
[0m02:23:03.420942 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m02:23:03.422227 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m02:23:03.431591 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4f7e0877-0170-42bf-8f06-39971f85f0b7&page=queryresults
[0m02:23:03.433212 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4f7e0877-0170-42bf-8f06-39971f85f0b7&page=queryresults
[0m02:23:03.436933 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:23:03.438133 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '598de295-1704-4dee-b3ae-d4343be14bee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5432431d0>]}
[0m02:23:03.439279 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer.stg_ride  [[31mERROR[0m in 0.53s]
[0m02:23:03.440640 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m02:23:03.442280 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m02:23:03.444426 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:23:03.447601 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:23:03.448553 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m02:23:03.449372 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m02:23:03.450095 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m02:23:03.450805 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m02:23:03.451757 [info ] [MainThread]: 
[0m02:23:03.452678 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 2.28 seconds (2.28s).
[0m02:23:03.454381 [debug] [MainThread]: Command end result
[0m02:23:03.485186 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:23:03.490386 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:23:03.497818 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:23:03.498665 [info ] [MainThread]: 
[0m02:23:03.499917 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m02:23:03.500952 [info ] [MainThread]: 
[0m02:23:03.502062 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m02:23:03.503073 [info ] [MainThread]: 
[0m02:23:03.504059 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m02:23:03.505185 [info ] [MainThread]: 
[0m02:23:03.506282 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m02:23:03.507134 [info ] [MainThread]: 
[0m02:23:03.508120 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging_layer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m02:23:03.509039 [info ] [MainThread]: 
[0m02:23:03.510102 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m02:23:03.511788 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.2606525, "process_in_blocks": "0", "process_kernel_time": 0.212551, "process_mem_max_rss": "224192", "process_out_blocks": "0", "process_user_time": 4.078972}
[0m02:23:03.512753 [debug] [MainThread]: Command `dbt run` failed at 02:23:03.512647 after 4.26 seconds
[0m02:23:03.513724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582e5d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc582e5f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc58675d150>]}
[0m02:23:03.514650 [debug] [MainThread]: Flushing usage events
[0m02:23:05.016646 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:10.061335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bafa2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bb4503d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7baff71d0>]}


============================== 02:27:10.063905 | 31c668d0-44a8-423d-9cba-07485a1d97cc ==============================
[0m02:27:10.063905 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:10.065631 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:27:10.142962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '31c668d0-44a8-423d-9cba-07485a1d97cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bae36950>]}
[0m02:27:10.196558 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18368678, "process_in_blocks": "0", "process_kernel_time": 0.081932, "process_mem_max_rss": "90140", "process_out_blocks": "0", "process_user_time": 0.92174}
[0m02:27:10.197709 [debug] [MainThread]: Command `dbt clean` succeeded at 02:27:10.197592 after 0.19 seconds
[0m02:27:10.198861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bb39a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7be8f1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7bafa1850>]}
[0m02:27:10.199813 [debug] [MainThread]: Flushing usage events
[0m02:27:11.381765 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:12.492552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb382950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb3c0790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb77de10>]}


============================== 02:27:12.495880 | 105f7905-72f4-4f26-b25a-0023adc54469 ==============================
[0m02:27:12.495880 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:12.497159 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt deps', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:27:12.581002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '105f7905-72f4-4f26-b25a-0023adc54469', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb3d5950>]}
[0m02:27:12.591820 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:27:12.594827 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:27:12.596546 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15206721, "process_in_blocks": "0", "process_kernel_time": 0.079586, "process_mem_max_rss": "90212", "process_out_blocks": "0", "process_user_time": 0.974936}
[0m02:27:12.597503 [debug] [MainThread]: Command `dbt deps` succeeded at 02:27:12.597373 after 0.15 seconds
[0m02:27:12.598341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fb77e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fec6ca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72fecfd5d0>]}
[0m02:27:12.599115 [debug] [MainThread]: Flushing usage events
[0m02:27:13.667226 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:27:18.126541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9375bbed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9379b2610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9379b24d0>]}


============================== 02:27:18.129205 | ed0e3112-f793-4b76-89d4-df3e53df2e2c ==============================
[0m02:27:18.129205 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:27:18.130468 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:27:18.714561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9097b8450>]}
[0m02:27:18.757460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff939868890>]}
[0m02:27:18.758844 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:27:18.827246 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:27:18.829601 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:27:18.830408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ed0e3112-f793-4b76-89d4-df3e53df2e2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff937615d10>]}
[0m02:27:19.666752 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:27:19.668956 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5943345, "process_in_blocks": "16", "process_kernel_time": 0.234997, "process_mem_max_rss": "211636", "process_out_blocks": "0", "process_user_time": 3.412571}
[0m02:27:19.670237 [debug] [MainThread]: Command `dbt run` failed at 02:27:19.670097 after 1.60 seconds
[0m02:27:19.671146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9375ea510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff937a70410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff90967fe50>]}
[0m02:27:19.672119 [debug] [MainThread]: Flushing usage events
[0m02:27:20.698749 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:19.756932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4fd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e02a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e022d0>]}


============================== 02:29:19.759598 | cfa47e46-00f7-47de-9070-f6658cefd0e9 ==============================
[0m02:29:19.759598 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:19.763323 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:29:19.842269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cfa47e46-00f7-47de-9070-f6658cefd0e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876cc7150>]}
[0m02:29:19.857803 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.14823915, "process_in_blocks": "0", "process_kernel_time": 0.118135, "process_mem_max_rss": "90124", "process_out_blocks": "0", "process_user_time": 0.905702}
[0m02:29:19.858795 [debug] [MainThread]: Command `dbt clean` succeeded at 02:29:19.858683 after 0.15 seconds
[0m02:29:19.859609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876e4f8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb876f11b10>]}
[0m02:29:19.860396 [debug] [MainThread]: Flushing usage events
[0m02:29:21.008618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:36.098313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb763a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb7a7090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb762b10>]}


============================== 02:29:36.100834 | ae7e7a25-d2f8-4c6c-97f2-7663699b82f7 ==============================
[0m02:29:36.100834 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:36.102185 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m02:29:36.182096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ae7e7a25-d2f8-4c6c-97f2-7663699b82f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfb7dbdd0>]}
[0m02:29:36.192091 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:29:36.195892 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:29:36.197299 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1474884, "process_in_blocks": "0", "process_kernel_time": 0.089347, "process_mem_max_rss": "89884", "process_out_blocks": "0", "process_user_time": 0.93318}
[0m02:29:36.198655 [debug] [MainThread]: Command `dbt deps` succeeded at 02:29:36.198507 after 0.15 seconds
[0m02:29:36.199593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dfef5cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dff0e1390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dff0e1110>]}
[0m02:29:36.200359 [debug] [MainThread]: Flushing usage events
[0m02:29:37.248158 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:42.747893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17872e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1793e7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff178afe550>]}


============================== 02:29:42.750836 | f2242523-1c80-44d8-8022-7848c9aa47cc ==============================
[0m02:29:42.750836 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:42.752017 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt compile', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:29:43.366137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff14a90e2d0>]}
[0m02:29:43.412740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff14a950f10>]}
[0m02:29:43.413928 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:29:43.485356 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:29:43.487673 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:29:43.488700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f2242523-1c80-44d8-8022-7848c9aa47cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17858c590>]}
[0m02:29:44.327713 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:29:44.329316 [debug] [MainThread]: Resource report: {"command_name": "compile", "command_success": false, "command_wall_clock_time": 1.6324943, "process_in_blocks": "0", "process_kernel_time": 0.18059, "process_mem_max_rss": "212028", "process_out_blocks": "0", "process_user_time": 3.551614}
[0m02:29:44.330421 [debug] [MainThread]: Command `dbt compile` failed at 02:29:44.330251 after 1.63 seconds
[0m02:29:44.331210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17857be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17857bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff17c07d0d0>]}
[0m02:29:44.332149 [debug] [MainThread]: Flushing usage events
[0m02:29:45.589524 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:29:53.502418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca52fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca85a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca86f50>]}


============================== 02:29:53.505798 | 41cb02dc-0cc4-4c1b-965c-9dc620114dec ==============================
[0m02:29:53.505798 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:29:53.507274 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:29:54.116437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca53490>]}
[0m02:29:54.168556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ed06250>]}
[0m02:29:54.169894 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:29:54.238174 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:29:54.240432 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:29:54.241225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '41cb02dc-0cc4-4c1b-965c-9dc620114dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180ebe17d0>]}
[0m02:29:55.066343 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:29:55.068222 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.617304, "process_in_blocks": "0", "process_kernel_time": 0.131437, "process_mem_max_rss": "211732", "process_out_blocks": "0", "process_user_time": 3.548801}
[0m02:29:55.069459 [debug] [MainThread]: Command `dbt run` failed at 02:29:55.069352 after 1.62 seconds
[0m02:29:55.070305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183ca98910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180eaa7810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1840409210>]}
[0m02:29:55.071221 [debug] [MainThread]: Flushing usage events
[0m02:29:56.099082 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:30:20.664628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46baa52b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b9343350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b8a49f10>]}


============================== 02:30:20.667132 | 4630e5b5-e768-46ab-8517-fec3768dbd26 ==============================
[0m02:30:20.667132 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:30:20.668783 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:30:21.213151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a7f5fd0>]}
[0m02:30:21.262779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46ba8c6250>]}
[0m02:30:21.263928 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:30:21.327974 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:30:21.330285 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:30:21.332570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4630e5b5-e768-46ab-8517-fec3768dbd26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a997c50>]}
[0m02:30:22.115540 [error] [MainThread]: Encountered an error:
Compilation Error in model stg_customer (models/staging/stg_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m02:30:22.117385 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5054442, "process_in_blocks": "0", "process_kernel_time": 0.180737, "process_mem_max_rss": "213952", "process_out_blocks": "0", "process_user_time": 3.383815}
[0m02:30:22.118554 [debug] [MainThread]: Command `dbt run` failed at 02:30:22.118408 after 1.51 seconds
[0m02:30:22.119529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b86cb810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46b86cb750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f468a6a8d90>]}
[0m02:30:22.120437 [debug] [MainThread]: Flushing usage events
[0m02:30:23.406765 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:46.577975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03cbec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e04afbc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e040be110>]}


============================== 03:48:46.581100 | 4b6e4011-c2d3-4c10-ba46-fe102571ed89 ==============================
[0m03:48:46.581100 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:46.583063 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:48:46.673982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b6e4011-c2d3-4c10-ba46-fe102571ed89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d16210>]}
[0m03:48:46.691460 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.17322543, "process_in_blocks": "0", "process_kernel_time": 0.071361, "process_mem_max_rss": "90076", "process_out_blocks": "0", "process_user_time": 0.937895}
[0m03:48:46.692203 [debug] [MainThread]: Command `dbt clean` succeeded at 03:48:46.692116 after 0.17 seconds
[0m03:48:46.692904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d15010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e03d14210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e074b8b90>]}
[0m03:48:46.693683 [debug] [MainThread]: Flushing usage events
[0m03:48:47.999145 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:49.140859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f516cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f4c3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f4c2650>]}


============================== 03:48:49.143352 | 1f903d85-65ef-48f7-8c9a-aed9097531ac ==============================
[0m03:48:49.143352 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:49.144652 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:48:49.228319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1f903d85-65ef-48f7-8c9a-aed9097531ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f402090>]}
[0m03:48:49.239323 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:48:49.241814 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:48:49.243604 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1564101, "process_in_blocks": "0", "process_kernel_time": 0.120278, "process_mem_max_rss": "90156", "process_out_blocks": "0", "process_user_time": 0.962226}
[0m03:48:49.244668 [debug] [MainThread]: Command `dbt deps` succeeded at 03:48:49.244540 after 0.16 seconds
[0m03:48:49.245366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f516cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b8f8be8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b92cb8c10>]}
[0m03:48:49.246184 [debug] [MainThread]: Flushing usage events
[0m03:48:50.258690 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:52.041857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74036e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74036a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb74087950>]}


============================== 03:48:52.044630 | d45ae16e-a5ef-414b-92c4-b8dabf098e93 ==============================
[0m03:48:52.044630 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:48:52.045738 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:48:52.628930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb463df5d0>]}
[0m03:48:52.674213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb46297490>]}
[0m03:48:52.675430 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:48:52.750946 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:48:52.753801 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:48:52.754901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb4cc71590>]}
[0m03:48:53.740104 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:48:53.751432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb460d4f10>]}
[0m03:48:53.818544 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:48:53.824729 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:48:53.841886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb44626610>]}
[0m03:48:53.843072 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:48:53.844252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb46382550>]}
[0m03:48:53.847146 [info ] [MainThread]: 
[0m03:48:53.848265 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:48:53.849418 [info ] [MainThread]: 
[0m03:48:53.851660 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:48:53.856931 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:48:53.858131 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:54.461050 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:48:54.462308 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:48:54.658101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb45f3ad10>]}
[0m03:48:54.659578 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:48:54.664912 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:48:54.665303 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:48:54.665665 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:48:54.666059 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:48:54.666709 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:48:54.667970 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:48:54.669068 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:48:54.670214 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:48:54.671678 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:48:54.676645 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:48:54.674594 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:48:54.675816 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:48:54.673185 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:48:54.685826 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:48:54.686787 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:48:54.688038 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:48:54.689235 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:48:54.694104 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:48:54.697849 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:48:54.702073 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:48:54.714652 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:48:54.721008 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:48:54.742940 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:48:54.769683 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:48:54.832074 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:48:54.832728 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:48:54.833474 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:48:54.836786 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:48:54.847600 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
),
SELECT *
FROM source
    );
  
[0m03:48:54.848840 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:48:54.849350 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        customer_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:48:54.850869 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
),

SELECT *
FROM source
    );
  
[0m03:48:54.851760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:48:54.852316 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:48:54.854713 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:48:54.880104 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:48:55.333011 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:867609ef-42fc-4e69-bce0-062e7c18a7a4&page=queryresults
[0m03:48:55.334001 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:867609ef-42fc-4e69-bce0-062e7c18a7a4&page=queryresults
[0m03:48:55.340453 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:48:55.342403 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb444266d0>]}
[0m03:48:55.343664 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_vehicle  [[31mERROR[0m in 0.67s]
[0m03:48:55.345422 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:48:55.346745 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m03:48:55.383661 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ca4ee090-40bb-4a20-bdb7-770e5b76ea45&page=queryresults
[0m03:48:55.384765 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:ca4ee090-40bb-4a20-bdb7-770e5b76ea45&page=queryresults
[0m03:48:55.388337 [debug] [Thread-3 (]: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m03:48:55.389174 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb446b5f50>]}
[0m03:48:55.390177 [error] [Thread-3 (]: 3 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_ride .. [[31mERROR[0m in 0.71s]
[0m03:48:55.391380 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:48:55.392421 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_ride' to be skipped because of status 'error'.  Reason: Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql.
[0m03:48:56.472613 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:26f5a9d0-22b5-4fc2-b25e-72b5439fe2c8&page=queryresults
[0m03:48:56.710713 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c86efc61-8407-4610-87cc-2fd6b7c7c6f7&page=queryresults
[0m03:48:56.802393 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c86efc61-8407-4610-87cc-2fd6b7c7c6f7&page=queryresults
[0m03:48:56.806713 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:48:56.807969 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb44417d50>]}
[0m03:48:56.809454 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 2.14s]
[0m03:48:56.811066 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:48:56.812800 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:48:58.223982 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd45ae16e-a5ef-414b-92c4-b8dabf098e93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb4441b490>]}
[0m03:48:58.225257 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mCREATE TABLE (70.0 rows, 4.8 KiB processed)[0m in 3.55s]
[0m03:48:58.226780 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:48:58.229292 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:48:58.232549 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:48:58.233494 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:48:58.234578 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:48:58.235380 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:48:58.237180 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:48:58.238281 [info ] [MainThread]: 
[0m03:48:58.239667 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.39 seconds (4.39s).
[0m03:48:58.241893 [debug] [MainThread]: Command end result
[0m03:48:58.276224 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:48:58.280265 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:48:58.288287 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:48:58.289101 [info ] [MainThread]: 
[0m03:48:58.290190 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m03:48:58.291264 [info ] [MainThread]: 
[0m03:48:58.292355 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:48:58.293521 [info ] [MainThread]: 
[0m03:48:58.294788 [error] [MainThread]:   Database Error in model stg_ride (models/staging/stg_ride.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_ride.sql
[0m03:48:58.295737 [info ] [MainThread]: 
[0m03:48:58.297045 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: customer_id; Did you mean cust_id? at [22:9]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:48:58.297984 [info ] [MainThread]: 
[0m03:48:58.299187 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m03:48:58.300716 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.308942, "process_in_blocks": "0", "process_kernel_time": 0.217576, "process_mem_max_rss": "227536", "process_out_blocks": "0", "process_user_time": 4.11417}
[0m03:48:58.302115 [debug] [MainThread]: Command `dbt run` failed at 03:48:58.301996 after 6.31 seconds
[0m03:48:58.302959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb740b14d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb740b3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb779ed210>]}
[0m03:48:58.303931 [debug] [MainThread]: Flushing usage events
[0m03:48:59.325197 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:41.729427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f567077a610>]}


============================== 03:50:41.731891 | 529f87d7-6afb-4e1e-8bac-84c3ff408093 ==============================
[0m03:50:41.731891 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:41.734506 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:50:41.815197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '529f87d7-6afb-4e1e-8bac-84c3ff408093', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5670c90a50>]}
[0m03:50:41.874857 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19473526, "process_in_blocks": "0", "process_kernel_time": 0.06868, "process_mem_max_rss": "90052", "process_out_blocks": "0", "process_user_time": 0.93209}
[0m03:50:41.875697 [debug] [MainThread]: Command `dbt clean` succeeded at 03:50:41.875599 after 0.20 seconds
[0m03:50:41.876484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56707d1810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56707cfa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56706c2a10>]}
[0m03:50:41.877255 [debug] [MainThread]: Flushing usage events
[0m03:50:42.997065 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:44.109329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb372e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb76a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb853750>]}


============================== 03:50:44.112663 | 850e8d11-8c97-4829-ae46-7eb0c2df9421 ==============================
[0m03:50:44.112663 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:44.114330 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:50:44.197698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '850e8d11-8c97-4829-ae46-7eb0c2df9421', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb209650>]}
[0m03:50:44.211517 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.15543059, "process_in_blocks": "0", "process_kernel_time": 0.068863, "process_mem_max_rss": "89856", "process_out_blocks": "0", "process_user_time": 0.98377}
[0m03:50:44.212608 [debug] [MainThread]: Command `dbt clean` succeeded at 03:50:44.212482 after 0.16 seconds
[0m03:50:44.213587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb3ce2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfb3cc410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcfeb3cc50>]}
[0m03:50:44.214622 [debug] [MainThread]: Flushing usage events
[0m03:50:45.280840 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:50:46.480062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e7db010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377ebd6110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e80c490>]}


============================== 03:50:46.482657 | de1a6b8e-6207-4037-a5a6-884431cd32f9 ==============================
[0m03:50:46.482657 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:50:46.483781 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m03:50:46.570851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de1a6b8e-6207-4037-a5a6-884431cd32f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e82e290>]}
[0m03:50:46.582813 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:50:46.585585 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:50:46.587296 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15657125, "process_in_blocks": "0", "process_kernel_time": 0.100615, "process_mem_max_rss": "90328", "process_out_blocks": "0", "process_user_time": 1.026273}
[0m03:50:46.589094 [debug] [MainThread]: Command `dbt deps` succeeded at 03:50:46.588626 after 0.16 seconds
[0m03:50:46.590465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e84d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f377e84f990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3781fd0b90>]}
[0m03:50:46.591425 [debug] [MainThread]: Flushing usage events
[0m03:50:47.650574 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:51:37.432385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decb4ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ded033910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decb97dd0>]}


============================== 03:51:37.434767 | b7190cd3-1d5e-4235-9367-57ccdda45d7e ==============================
[0m03:51:37.434767 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:51:37.435957 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m03:51:38.032673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbee72f10>]}
[0m03:51:38.104604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7deedf8850>]}
[0m03:51:38.105818 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:51:38.179653 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:51:38.181631 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:51:38.183040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dc5d7ca90>]}
[0m03:51:39.129366 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:51:39.140710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd124990>]}
[0m03:51:39.203809 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:51:39.209147 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:51:39.223960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd0c3910>]}
[0m03:51:39.225159 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:51:39.226267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbea7c550>]}
[0m03:51:39.229243 [info ] [MainThread]: 
[0m03:51:39.230500 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:51:39.231429 [info ] [MainThread]: 
[0m03:51:39.232873 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:51:39.237955 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:51:39.239048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:51:39.782113 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:51:39.783168 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:51:40.017044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbeae8e90>]}
[0m03:51:40.018928 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:51:40.024765 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:51:40.025121 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:51:40.025509 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:51:40.025865 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:51:40.026365 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:51:40.027623 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:51:40.028738 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:51:40.029993 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:51:40.031309 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:51:40.032596 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:51:40.034403 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:51:40.035875 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:51:40.037337 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:51:40.038363 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:51:40.039320 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:51:40.040346 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:51:40.047996 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:51:40.051314 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:51:40.055683 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:51:40.060410 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:51:40.070428 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:51:40.077158 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:51:40.103838 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:51:40.115046 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:51:40.152124 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:51:40.153432 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:51:40.156050 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:51:40.160344 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:51:40.196248 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
),
SELECT *
FROM source
    );
  
[0m03:51:40.197601 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:51:40.198241 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

WITH cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:51:40.200194 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:51:40.200599 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
    );
  
[0m03:51:40.225450 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:51:40.420935 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:51:40.427200 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:51:40.690507 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:1f357af3-36f2-458e-8d19-0edfbf4cc3da&page=queryresults
[0m03:51:40.691849 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:1f357af3-36f2-458e-8d19-0edfbf4cc3da&page=queryresults
[0m03:51:40.696871 [debug] [Thread-4 (]: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:51:40.699082 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbc750090>]}
[0m03:51:40.700058 [error] [Thread-4 (]: 4 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_vehicle  [[31mERROR[0m in 0.66s]
[0m03:51:40.701238 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:51:40.702358 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql.
[0m03:51:40.716636 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:519f6a0e-86f0-41b2-8158-7c9575306572&page=queryresults
[0m03:51:40.718019 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:519f6a0e-86f0-41b2-8158-7c9575306572&page=queryresults
[0m03:51:40.721398 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:51:40.722416 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbc750ad0>]}
[0m03:51:40.723425 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.69s]
[0m03:51:40.724598 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:51:40.725682 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:51:40.772889 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc8dac86-73ac-48c6-85af-c1e36756a363&page=queryresults
[0m03:51:40.774108 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc8dac86-73ac-48c6-85af-c1e36756a363&page=queryresults
[0m03:51:40.777571 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:51:40.778659 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd1c6a90>]}
[0m03:51:40.779741 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.75s]
[0m03:51:40.780860 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:51:40.782030 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:51:40.906121 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31ba37c3-4d51-4737-87eb-4a5a8bede1c8&page=queryresults
[0m03:51:42.967413 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7190cd3-1d5e-4235-9367-57ccdda45d7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7dbd0e6090>]}
[0m03:51:42.968893 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mCREATE TABLE (70.0 rows, 6.2 KiB processed)[0m in 2.93s]
[0m03:51:42.970393 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:51:42.973070 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:51:42.976480 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:51:42.977315 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:51:42.978132 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:51:42.978812 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:51:42.979523 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:51:42.980342 [info ] [MainThread]: 
[0m03:51:42.981362 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.75 seconds (3.75s).
[0m03:51:42.983605 [debug] [MainThread]: Command end result
[0m03:51:43.019384 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:51:43.025356 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:51:43.035800 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:51:43.036967 [info ] [MainThread]: 
[0m03:51:43.038677 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m03:51:43.039925 [info ] [MainThread]: 
[0m03:51:43.041192 [error] [MainThread]:   Database Error in model stg_vehicle (models/staging/stg_vehicle.sql)
  Syntax error: Trailing comma after the WITH clause before the main query is not allowed at [19:1]
  compiled code at target/run/hailing_project/models/staging/stg_vehicle.sql
[0m03:51:43.042449 [info ] [MainThread]: 
[0m03:51:43.044025 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:51:43.045395 [info ] [MainThread]: 
[0m03:51:43.046603 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:51:43.047640 [info ] [MainThread]: 
[0m03:51:43.048597 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m03:51:43.050753 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.6623764, "process_in_blocks": "0", "process_kernel_time": 0.279745, "process_mem_max_rss": "226472", "process_out_blocks": "0", "process_user_time": 4.006348}
[0m03:51:43.052336 [debug] [MainThread]: Command `dbt run` failed at 03:51:43.052165 after 5.66 seconds
[0m03:51:43.053376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decf42990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7df04fd010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7decba36d0>]}
[0m03:51:43.054444 [debug] [MainThread]: Flushing usage events
[0m03:51:44.297123 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:52:34.409055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a4ef10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14e4a150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a4ebd0>]}


============================== 03:52:34.411673 | de1a501b-b97a-415c-8de0-788dc80242eb ==============================
[0m03:52:34.411673 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:52:34.412727 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:52:34.975291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acbd50>]}
[0m03:52:35.019882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d16cc6290>]}
[0m03:52:35.021404 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:52:35.084190 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:52:35.209905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m03:52:35.211040 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_vehicle.sql
[0m03:52:35.211817 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m03:52:35.449778 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:52:35.463221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce6eb2e90>]}
[0m03:52:35.534400 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:52:35.539796 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:52:35.554360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4ef4050>]}
[0m03:52:35.555556 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:52:35.556727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce6c35390>]}
[0m03:52:35.560001 [info ] [MainThread]: 
[0m03:52:35.561074 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:52:35.561965 [info ] [MainThread]: 
[0m03:52:35.563230 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:52:35.568495 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:52:35.569612 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:52:36.059137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:52:36.059990 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:52:36.292422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14a668d0>]}
[0m03:52:36.293387 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:52:36.298922 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:52:36.299280 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:52:36.299817 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:52:36.300199 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:52:36.301256 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:52:36.302525 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:52:36.303743 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:52:36.304819 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:52:36.305904 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:52:36.307093 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:52:36.308099 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:52:36.308953 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:52:36.309717 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:52:36.310523 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:52:36.311449 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:52:36.312287 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:52:36.320882 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:52:36.324058 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:52:36.328077 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:52:36.332522 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:52:36.337689 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:52:36.338229 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:52:36.349609 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:52:36.349973 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:52:36.404600 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:52:36.428087 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:52:36.429149 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:52:36.432434 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:52:36.463644 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:52:36.487628 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
    );
  
[0m03:52:36.488093 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:52:36.490382 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:52:36.727963 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:52:36.731604 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:52:36.736612 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:52:36.737835 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:52:36.991392 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:3b14d6d9-cf1f-4053-89f3-bd4f4a87e22c&page=queryresults
[0m03:52:36.993419 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:3b14d6d9-cf1f-4053-89f3-bd4f4a87e22c&page=queryresults
[0m03:52:36.999488 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:52:37.002115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f6bf50>]}
[0m03:52:37.003624 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.70s]
[0m03:52:37.005887 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:52:37.008203 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:52:37.083185 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:0c115b79-c3a8-42f3-b535-5e101cf409a9&page=queryresults
[0m03:52:37.085011 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:0c115b79-c3a8-42f3-b535-5e101cf409a9&page=queryresults
[0m03:52:37.091496 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:52:37.092561 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f680d0>]}
[0m03:52:37.093857 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.79s]
[0m03:52:37.094960 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:52:37.096111 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:52:37.235539 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e74471db-864e-4bd5-b7ed-e966e126058a&page=queryresults
[0m03:52:38.120191 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1dc6c1d3-a482-46ee-af62-ac21695f3093&page=queryresults
[0m03:52:38.917728 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4eebd50>]}
[0m03:52:38.918881 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mCREATE TABLE (70.0 rows, 3.8 KiB processed)[0m in 2.61s]
[0m03:52:38.920028 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:52:39.679385 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de1a501b-b97a-415c-8de0-788dc80242eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ce4f5f290>]}
[0m03:52:39.680362 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.37s]
[0m03:52:39.681451 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:52:39.683459 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:52:39.686098 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:52:39.686767 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:52:39.687347 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:52:39.688064 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:52:39.688677 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:52:39.689405 [info ] [MainThread]: 
[0m03:52:39.690190 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.13 seconds (4.13s).
[0m03:52:39.691872 [debug] [MainThread]: Command end result
[0m03:52:39.724313 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:52:39.728477 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:52:39.737091 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:52:39.737790 [info ] [MainThread]: 
[0m03:52:39.738825 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:52:39.739745 [info ] [MainThread]: 
[0m03:52:39.740820 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:52:39.741979 [info ] [MainThread]: 
[0m03:52:39.743012 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:52:39.743991 [info ] [MainThread]: 
[0m03:52:39.744993 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:52:39.746473 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.3955393, "process_in_blocks": "0", "process_kernel_time": 0.179213, "process_mem_max_rss": "228640", "process_out_blocks": "0", "process_user_time": 3.494667}
[0m03:52:39.747372 [debug] [MainThread]: Command `dbt run` failed at 03:52:39.747265 after 5.40 seconds
[0m03:52:39.748166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14e4a290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acbf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d14acba50>]}
[0m03:52:39.749218 [debug] [MainThread]: Flushing usage events
[0m03:52:40.816296 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:54:09.824353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac2cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4efd8c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac2610>]}


============================== 03:54:09.826791 | dca53bf5-95ca-495c-a2d5-f385a35a5fe7 ==============================
[0m03:54:09.826791 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:54:09.828128 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:54:10.392039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eac9d90>]}
[0m03:54:10.444749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d50d3a190>]}
[0m03:54:10.446382 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:54:10.515417 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:54:10.668063 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m03:54:10.669476 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_driver.sql
[0m03:54:10.932783 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:54:10.945126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d24d8fa90>]}
[0m03:54:11.016954 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:11.022375 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:11.037186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d130fe950>]}
[0m03:54:11.038504 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:54:11.040006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d24a611d0>]}
[0m03:54:11.042707 [info ] [MainThread]: 
[0m03:54:11.043862 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:54:11.044906 [info ] [MainThread]: 
[0m03:54:11.046330 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:54:11.051326 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:54:11.052237 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:54:11.620969 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:54:11.621871 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:54:11.853218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d2485e910>]}
[0m03:54:11.854570 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:54:11.858863 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:54:11.859202 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:54:11.859759 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:54:11.860114 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:54:11.860800 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:54:11.862351 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:54:11.863397 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:54:11.864522 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:54:11.865737 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:54:11.867042 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:54:11.868162 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:54:11.869546 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:54:11.870647 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:54:11.871533 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:54:11.872319 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:54:11.873149 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:54:11.881753 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:54:11.885135 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:54:11.888635 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:54:11.892817 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:54:11.898729 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:54:11.899191 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:54:11.910645 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:54:11.921005 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:54:11.943261 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:54:11.943612 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:54:11.968643 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:54:11.973685 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:54:12.050539 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:54:12.051715 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:54:12.258156 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:54:12.265814 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:54:12.282459 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:54:12.285197 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:54:12.292256 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:54:12.293721 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:54:12.497365 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc35f3a9-4a3c-4aa0-9e92-a8e815d27132&page=queryresults
[0m03:54:12.498647 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc35f3a9-4a3c-4aa0-9e92-a8e815d27132&page=queryresults
[0m03:54:12.503409 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:54:12.505335 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d131ddf10>]}
[0m03:54:12.506641 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.64s]
[0m03:54:12.507699 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:54:12.508665 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:54:12.642837 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:81548928-2f7a-48f0-a02d-c57c47f1e53f&page=queryresults
[0m03:54:12.644081 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:81548928-2f7a-48f0-a02d-c57c47f1e53f&page=queryresults
[0m03:54:12.647977 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:54:12.650207 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d1319d850>]}
[0m03:54:12.653167 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.78s]
[0m03:54:12.654899 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:54:12.656314 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:54:12.860424 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a9427830-3516-49dd-9eb5-a2219a516405&page=queryresults
[0m03:54:13.771075 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e4333740-597d-4c81-a3c3-1f327fd88867&page=queryresults
[0m03:54:14.462404 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d131e4d90>]}
[0m03:54:14.463748 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.59s]
[0m03:54:14.464971 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:54:15.705479 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca53bf5-95ca-495c-a2d5-f385a35a5fe7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d0bf5ed50>]}
[0m03:54:15.706518 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.84s]
[0m03:54:15.708446 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:54:15.710841 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:54:15.714265 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:54:15.715176 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:54:15.716248 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:54:15.717148 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:54:15.718336 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:54:15.719294 [info ] [MainThread]: 
[0m03:54:15.720339 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.67 seconds (4.67s).
[0m03:54:15.722362 [debug] [MainThread]: Command end result
[0m03:54:15.756474 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:54:15.762363 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:54:15.772373 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:54:15.773330 [info ] [MainThread]: 
[0m03:54:15.774326 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:54:15.775362 [info ] [MainThread]: 
[0m03:54:15.776403 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Unexpected identifier "cleaned" at [20:1]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:54:15.778073 [info ] [MainThread]: 
[0m03:54:15.779409 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Unexpected identifier "cleaned" at [21:1]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:54:15.780443 [info ] [MainThread]: 
[0m03:54:15.781604 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:54:15.783321 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.004255, "process_in_blocks": "0", "process_kernel_time": 0.274545, "process_mem_max_rss": "226336", "process_out_blocks": "0", "process_user_time": 3.42674}
[0m03:54:15.784707 [debug] [MainThread]: Command `dbt run` failed at 03:54:15.784406 after 6.01 seconds
[0m03:54:15.785493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eebe650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eb41850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d4eb43c50>]}
[0m03:54:15.786593 [debug] [MainThread]: Flushing usage events
[0m03:54:16.902471 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:09.159775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4cbfcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a506a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c726d0>]}


============================== 03:55:09.162354 | b8cac8fb-cd27-41d4-8ccc-b907ce13dd9d ==============================
[0m03:55:09.162354 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:09.163683 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:09.242657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b8cac8fb-cd27-41d4-8ccc-b907ce13dd9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4ccd810>]}
[0m03:55:09.294947 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18828923, "process_in_blocks": "0", "process_kernel_time": 0.039608, "process_mem_max_rss": "89936", "process_out_blocks": "0", "process_user_time": 0.960514}
[0m03:55:09.296131 [debug] [MainThread]: Command `dbt clean` succeeded at 03:55:09.296013 after 0.19 seconds
[0m03:55:09.297179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c72ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a4c72190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f40a843cc10>]}
[0m03:55:09.298057 [debug] [MainThread]: Flushing usage events
[0m03:55:10.369621 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:24.770918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383cfe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383cf110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc383ce650>]}


============================== 03:55:24.774277 | 0c7ae357-769b-49ef-8725-7187896870d1 ==============================
[0m03:55:24.774277 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:24.775891 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:24.863354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c7ae357-769b-49ef-8725-7187896870d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc38302f10>]}
[0m03:55:24.872599 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:55:24.875455 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:55:24.876872 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15382788, "process_in_blocks": "0", "process_kernel_time": 0.090793, "process_mem_max_rss": "90180", "process_out_blocks": "0", "process_user_time": 0.978553}
[0m03:55:24.877995 [debug] [MainThread]: Command `dbt deps` succeeded at 03:55:24.877857 after 0.16 seconds
[0m03:55:24.878921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3841f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc38884310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc3bc24b90>]}
[0m03:55:24.879873 [debug] [MainThread]: Flushing usage events
[0m03:55:26.050892 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:55:28.807178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777b2078d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a54f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a8f8190>]}


============================== 03:55:28.810814 | 2963f7c2-f555-493c-bdd6-ed99d18b3bd1 ==============================
[0m03:55:28.810814 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:55:28.812027 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:55:29.417786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7753134b50>]}
[0m03:55:29.464029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775080f5d0>]}
[0m03:55:29.465558 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:55:29.538658 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:55:29.541544 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:55:29.542274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775086c750>]}
[0m03:55:30.548355 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m03:55:30.559047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7750557c10>]}
[0m03:55:30.623650 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:55:30.629340 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:55:30.644547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7750407650>]}
[0m03:55:30.645711 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:55:30.646988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f775012b390>]}
[0m03:55:30.649699 [info ] [MainThread]: 
[0m03:55:30.650862 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:55:30.651836 [info ] [MainThread]: 
[0m03:55:30.653009 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:55:30.657771 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:55:30.658952 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:55:31.214619 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:55:31.215562 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:55:31.431486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f77505cb690>]}
[0m03:55:31.432650 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:55:31.438165 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:55:31.438546 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:55:31.439004 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:55:31.439377 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:55:31.440151 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:55:31.441542 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:55:31.442821 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:55:31.443938 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:55:31.445307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:55:31.446572 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:55:31.448002 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:55:31.449149 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:55:31.450139 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:55:31.450927 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:55:31.451735 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:55:31.452862 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:55:31.461263 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:55:31.465636 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:55:31.469369 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:55:31.472947 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:55:31.486675 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:55:31.498362 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:55:31.522128 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:55:31.522470 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:55:31.538896 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:55:31.541798 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:55:31.567226 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:55:31.575318 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:55:31.669405 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
)

WITH cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:55:31.670530 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:55:31.918699 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:55:31.921156 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:55:31.922692 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:55:31.928621 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:55:31.931728 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
)

WITH cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:55:31.934284 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:55:32.182142 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:099f2d54-5d14-4ae4-9ffb-989e83538f9f&page=queryresults
[0m03:55:32.183346 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:099f2d54-5d14-4ae4-9ffb-989e83538f9f&page=queryresults
[0m03:55:32.187968 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:55:32.190308 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7702f8f150>]}
[0m03:55:32.191747 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.74s]
[0m03:55:32.193153 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:55:32.194571 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m03:55:32.199419 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8ef050e-ecc6-4976-bae6-17bd99d1396c&page=queryresults
[0m03:55:32.283921 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:9b6c3bff-c7bc-4c12-86a7-385f561c0395&page=queryresults
[0m03:55:32.285117 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:9b6c3bff-c7bc-4c12-86a7-385f561c0395&page=queryresults
[0m03:55:32.289236 [debug] [Thread-2 (]: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:55:32.290314 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f774a90fe90>]}
[0m03:55:32.291582 [error] [Thread-2 (]: 2 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_driver  [[31mERROR[0m in 0.84s]
[0m03:55:32.292890 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:55:32.294284 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_driver' to be skipped because of status 'error'.  Reason: Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql.
[0m03:55:32.472294 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5b3e4fc1-d0ad-4058-84bf-60127e0576f9&page=queryresults
[0m03:55:34.019349 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f774a9ef2d0>]}
[0m03:55:34.020819 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.57s]
[0m03:55:34.022224 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:55:34.274515 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2963f7c2-f555-493c-bdd6-ed99d18b3bd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7702fe1090>]}
[0m03:55:34.276259 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 2.83s]
[0m03:55:34.278487 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:55:34.281322 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:55:34.285203 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:55:34.285984 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:55:34.286849 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:55:34.287649 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:55:34.288407 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:55:34.289540 [info ] [MainThread]: 
[0m03:55:34.290431 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.64 seconds (3.64s).
[0m03:55:34.292046 [debug] [MainThread]: Command end result
[0m03:55:34.326600 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:55:34.330260 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:55:34.337377 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:55:34.338364 [info ] [MainThread]: 
[0m03:55:34.339345 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m03:55:34.340285 [info ] [MainThread]: 
[0m03:55:34.341190 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [20:6]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m03:55:34.342011 [info ] [MainThread]: 
[0m03:55:34.343022 [error] [MainThread]:   Database Error in model stg_driver (models/staging/stg_driver.sql)
  Syntax error: Expected keyword DEPTH but got identifier "cleaned" at [21:6]
  compiled code at target/run/hailing_project/models/staging/stg_driver.sql
[0m03:55:34.343830 [info ] [MainThread]: 
[0m03:55:34.344871 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m03:55:34.346684 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.5879216, "process_in_blocks": "0", "process_kernel_time": 0.23382, "process_mem_max_rss": "229560", "process_out_blocks": "0", "process_user_time": 4.188439}
[0m03:55:34.347840 [debug] [MainThread]: Command `dbt run` failed at 03:55:34.347695 after 5.59 seconds
[0m03:55:34.348837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a57b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777deb5190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f777a925f50>]}
[0m03:55:34.349649 [debug] [MainThread]: Flushing usage events
[0m03:55:35.369581 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:01.842205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18996e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ebbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18eb0a50>]}


============================== 03:57:01.845022 | faa07538-7d5c-40c2-b3fa-ba941cc648ea ==============================
[0m03:57:01.845022 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:01.846405 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:57:01.925705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'faa07538-7d5c-40c2-b3fa-ba941cc648ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee18828290>]}
[0m03:57:01.984078 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19159567, "process_in_blocks": "0", "process_kernel_time": 0.110106, "process_mem_max_rss": "90232", "process_out_blocks": "0", "process_user_time": 0.990958}
[0m03:57:01.985043 [debug] [MainThread]: Command `dbt clean` succeeded at 03:57:01.984933 after 0.19 seconds
[0m03:57:01.985741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ef010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee189ee250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee1c190c10>]}
[0m03:57:01.986387 [debug] [MainThread]: Flushing usage events
[0m03:57:03.102048 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:04.236538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e1db990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e22efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd60a89ed0>]}


============================== 03:57:04.239085 | 12044cc6-e7bf-4a2b-9974-6fa04b8997a3 ==============================
[0m03:57:04.239085 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:04.240329 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:57:04.321313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '12044cc6-e7bf-4a2b-9974-6fa04b8997a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e0e3dd0>]}
[0m03:57:04.330902 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:57:04.333293 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:57:04.334731 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.14978145, "process_in_blocks": "0", "process_kernel_time": 0.050052, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 1.02107}
[0m03:57:04.335828 [debug] [MainThread]: Command `dbt deps` succeeded at 03:57:04.335688 after 0.15 seconds
[0m03:57:04.336779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e22f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd5e26a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd61a34b90>]}
[0m03:57:04.337703 [debug] [MainThread]: Flushing usage events
[0m03:57:05.361502 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:10.069705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db55d7890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db597e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db5586e50>]}


============================== 03:57:10.072220 | 69de4a25-c58b-4675-beab-b2b8eff3ef12 ==============================
[0m03:57:10.072220 [info ] [MainThread]: Running with dbt=1.9.0
[0m03:57:10.074696 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:57:10.640124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8cd99ad0>]}
[0m03:57:10.688109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db77d8dd0>]}
[0m03:57:10.689656 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m03:57:10.758220 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m03:57:10.761682 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m03:57:10.762700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d877cf610>]}
[0m03:57:11.751320 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m03:57:11.764502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d877c16d0>]}
[0m03:57:11.835931 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:57:11.842835 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:57:11.860727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87396ad0>]}
[0m03:57:11.861885 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m03:57:11.863283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87369a10>]}
[0m03:57:11.867070 [info ] [MainThread]: 
[0m03:57:11.868330 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:57:11.869453 [info ] [MainThread]: 
[0m03:57:11.870892 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m03:57:11.876006 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m03:57:11.877128 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:12.483653 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m03:57:12.485001 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:12.697190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8746b290>]}
[0m03:57:12.701160 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:57:12.706561 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m03:57:12.706888 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m03:57:12.707224 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m03:57:12.707525 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m03:57:12.708027 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m03:57:12.708940 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m03:57:12.709867 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m03:57:12.710807 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m03:57:12.711929 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m03:57:12.712899 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m03:57:12.713772 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m03:57:12.714622 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m03:57:12.715332 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m03:57:12.716134 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m03:57:12.716881 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m03:57:12.717629 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m03:57:12.724464 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m03:57:12.728563 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m03:57:12.732520 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m03:57:12.736321 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m03:57:12.748694 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m03:57:12.749993 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m03:57:12.794869 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m03:57:12.795275 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m03:57:12.797594 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:57:12.797998 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m03:57:12.822461 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m03:57:12.827901 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m03:57:12.927185 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
    );
  
[0m03:57:12.928316 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:57:13.157076 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m03:57:13.161516 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m03:57:13.162911 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m03:57:13.168305 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m03:57:13.169715 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m03:57:13.173739 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m03:57:13.347744 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9c82e0b7-2856-4508-9a62-6e88dec4c098&page=queryresults
[0m03:57:13.452667 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:22fa7bdc-468c-48cd-8f1c-d452a15eeef1&page=queryresults
[0m03:57:13.509953 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2034e47d-b241-441c-96b7-b0377fa7389e&page=queryresults
[0m03:57:13.798102 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d09d99b6-dd3d-4f3b-b11a-6e5e01b7e7d3&page=queryresults
[0m03:57:15.216883 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d45f12190>]}
[0m03:57:15.218074 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 2.50s]
[0m03:57:15.219463 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m03:57:15.227541 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d8599fc50>]}
[0m03:57:15.228867 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mCREATE TABLE (70.0 rows, 4.8 KiB processed)[0m in 2.52s]
[0m03:57:15.230098 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m03:57:15.310368 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d85957850>]}
[0m03:57:15.311608 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (70.0 rows, 9.4 KiB processed)[0m in 2.60s]
[0m03:57:15.312911 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m03:57:15.334356 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69de4a25-c58b-4675-beab-b2b8eff3ef12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d859c6cd0>]}
[0m03:57:15.335323 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 2.62s]
[0m03:57:15.336578 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m03:57:15.339497 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:57:15.342938 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:57:15.343644 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m03:57:15.344402 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m03:57:15.345062 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m03:57:15.346048 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m03:57:15.346926 [info ] [MainThread]: 
[0m03:57:15.347830 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.48 seconds (3.48s).
[0m03:57:15.349520 [debug] [MainThread]: Command end result
[0m03:57:15.382035 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m03:57:15.386515 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m03:57:15.395721 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m03:57:15.396571 [info ] [MainThread]: 
[0m03:57:15.397619 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:57:15.398638 [info ] [MainThread]: 
[0m03:57:15.399671 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m03:57:15.401547 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3793664, "process_in_blocks": "0", "process_kernel_time": 0.191403, "process_mem_max_rss": "226976", "process_out_blocks": "0", "process_user_time": 4.200798}
[0m03:57:15.402517 [debug] [MainThread]: Command `dbt run` succeeded at 03:57:15.402401 after 5.38 seconds
[0m03:57:15.403554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db8d50b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87841410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3db597e150>]}
[0m03:57:15.404425 [debug] [MainThread]: Flushing usage events
[0m03:57:16.432072 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:14:24.057157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e3050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e2ed0>]}


============================== 07:14:24.062167 | 9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f ==============================
[0m07:14:24.062167 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:14:24.063873 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:14:24.739792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b247eb10>]}
[0m07:14:24.789404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e256e0d0>]}
[0m07:14:24.790645 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:14:24.876192 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:14:25.046511 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:14:25.047417 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:14:25.053276 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:14:25.080426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e111e0d0>]}
[0m07:14:25.204505 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:14:25.213125 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:14:25.236328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b233e390>]}
[0m07:14:25.237722 [info ] [MainThread]: Found 4 models, 4 sources, 487 macros
[0m07:14:25.238754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e2662310>]}
[0m07:14:25.243057 [info ] [MainThread]: 
[0m07:14:25.244300 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:14:25.245371 [info ] [MainThread]: 
[0m07:14:25.246653 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:14:25.251061 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:14:25.252149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:14:25.932829 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:14:25.934527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:14:26.181470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e08c53d0>]}
[0m07:14:26.183857 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:14:26.191654 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:14:26.192053 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:14:26.192475 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:14:26.192840 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:14:26.193442 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:14:26.196094 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:14:26.197379 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:14:26.198742 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:14:26.199964 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:14:26.203516 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:14:26.204699 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:14:26.206016 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:14:26.206896 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:14:26.209575 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:14:26.210992 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:14:26.212091 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:14:26.222007 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:14:26.226201 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:14:26.232466 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:14:26.237762 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:14:26.253551 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:14:26.255208 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:14:26.266408 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:14:26.289452 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:14:26.329708 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:14:26.331299 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:14:26.334154 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:14:26.337479 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:14:26.663888 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:14:26.666159 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:14:26.667965 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:14:26.669058 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:14:26.686209 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:14:26.692104 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:14:26.692943 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:14:26.695761 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:14:27.289022 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0bb9971d-ed97-4412-8de7-1cd4eb96858a&page=queryresults
[0m07:14:27.534418 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:30b64f7e-61b1-4cc3-88a0-49449c954f94&page=queryresults
[0m07:14:27.539028 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f5e5bea-79f6-44ed-b2be-3149264083f8&page=queryresults
[0m07:14:28.140278 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7df0087e-63ef-46b7-9232-2f978ab7357a&page=queryresults
[0m07:14:29.295070 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e08735d0>]}
[0m07:14:29.296256 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (70.0 rows, 9.5 KiB processed)[0m in 3.09s]
[0m07:14:29.297908 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:14:29.474888 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e10afa90>]}
[0m07:14:29.476368 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (70.0 rows, 7.7 KiB processed)[0m in 3.27s]
[0m07:14:29.477631 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:14:29.667286 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0b2142dd0>]}
[0m07:14:29.669166 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (70.0 rows, 12.4 KiB processed)[0m in 3.46s]
[0m07:14:29.671011 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:14:30.129711 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9217f315-1bb4-4d1d-a3d5-eb8a8b52fd2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e02e9b90>]}
[0m07:14:30.130940 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (70.0 rows, 9.4 KiB processed)[0m in 3.93s]
[0m07:14:30.133340 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:14:30.135664 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:14:30.138650 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:14:30.139566 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:14:30.140512 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:14:30.141337 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:14:30.142170 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:14:30.143229 [info ] [MainThread]: 
[0m07:14:30.144330 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.90 seconds (4.90s).
[0m07:14:30.146268 [debug] [MainThread]: Command end result
[0m07:14:30.181117 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:14:30.186507 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:14:30.194413 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:14:30.195439 [info ] [MainThread]: 
[0m07:14:30.196633 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:14:30.197755 [info ] [MainThread]: 
[0m07:14:30.198773 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:14:30.200481 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.2747736, "process_in_blocks": "0", "process_kernel_time": 0.386009, "process_mem_max_rss": "222724", "process_out_blocks": "0", "process_user_time": 3.741319}
[0m07:14:30.201630 [debug] [MainThread]: Command `dbt run` succeeded at 07:14:30.201452 after 6.28 seconds
[0m07:14:30.202788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e035f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e035f690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0e3adcb90>]}
[0m07:14:30.203700 [debug] [MainThread]: Flushing usage events
[0m07:14:31.324369 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:30:49.092343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243071950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243073710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243072a10>]}


============================== 07:30:49.094968 | 9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91 ==============================
[0m07:30:49.094968 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:30:49.096823 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:30:49.662161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb243185d50>]}
[0m07:30:49.707859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2452f4e50>]}
[0m07:30:49.709238 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:30:49.773126 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:30:49.898481 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 4 files changed.
[0m07:30:49.899480 [debug] [MainThread]: Partial parsing: added file: hailing_project://macros/check_if_incremental.sql
[0m07:30:49.900583 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_ride.sql
[0m07:30:49.901425 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_driver.sql
[0m07:30:49.902315 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_vehicle.sql
[0m07:30:49.903057 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m07:30:50.157347 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:30:50.169781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218f507d0>]}
[0m07:30:50.249233 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:30:50.255615 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:30:50.270170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218f04450>]}
[0m07:30:50.271348 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m07:30:50.272388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218d4e5d0>]}
[0m07:30:50.275228 [info ] [MainThread]: 
[0m07:30:50.276310 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:30:50.277605 [info ] [MainThread]: 
[0m07:30:50.279144 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:30:50.284100 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:30:50.285414 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:30:50.877964 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:30:50.879091 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:30:51.124803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218d4d4d0>]}
[0m07:30:51.126503 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:30:51.132518 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:30:51.132941 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:30:51.134089 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:30:51.134510 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:30:51.135150 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:30:51.136590 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:30:51.137744 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:30:51.138924 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:30:51.139939 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:30:51.141051 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:30:51.142063 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:30:51.142952 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:30:51.143863 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:30:51.144646 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:30:51.145421 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:30:51.146314 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:30:51.156291 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:30:51.160500 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:30:51.165748 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:30:51.169689 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:30:51.175006 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:30:51.175513 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:30:51.181812 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:30:51.192903 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:30:51.213840 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:30:51.216169 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:30:51.219998 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:30:51.223265 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:30:51.477753 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:30:51.486710 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:30:51.495854 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:30:51.501589 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:30:51.503763 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:30:51.511415 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:30:51.532187 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:30:51.538923 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:30:51.802681 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:090693f2-a77b-4dc8-a974-f80c6d37090c&page=queryresults
[0m07:30:51.866937 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1f396e0-69ee-46d7-be88-08796ccc7b23&page=queryresults
[0m07:30:52.912257 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:50043940-5a09-439b-8426-768bd85eb2cb&page=queryresults
[0m07:30:52.914930 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fd6c4e65-9a9f-4e70-89dd-ccfa76572ad6&page=queryresults
[0m07:30:53.702659 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218e9c590>]}
[0m07:30:53.703990 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 7.7 KiB processed)[0m in 2.56s]
[0m07:30:53.706127 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:30:53.754802 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218ddbb90>]}
[0m07:30:53.756838 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 9.5 KiB processed)[0m in 2.61s]
[0m07:30:53.758693 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:30:54.561517 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218dee910>]}
[0m07:30:54.564764 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 9.4 KiB processed)[0m in 3.42s]
[0m07:30:54.567154 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:30:54.798589 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9728cfc1-1b6b-4ee8-80a0-6b8a1269ab91', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb218ddc590>]}
[0m07:30:54.799938 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 12.4 KiB processed)[0m in 3.66s]
[0m07:30:54.801464 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:30:54.804555 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:30:54.807896 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:30:54.808619 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:30:54.809528 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:30:54.810651 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:30:54.811606 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:30:54.812830 [info ] [MainThread]: 
[0m07:30:54.814584 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.53 seconds (4.53s).
[0m07:30:54.816849 [debug] [MainThread]: Command end result
[0m07:30:54.849859 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:30:54.854511 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:30:54.863605 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:30:54.864344 [info ] [MainThread]: 
[0m07:30:54.865567 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:30:54.866583 [info ] [MainThread]: 
[0m07:30:54.867577 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:30:54.869308 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.824409, "process_in_blocks": "0", "process_kernel_time": 0.194672, "process_mem_max_rss": "226324", "process_out_blocks": "0", "process_user_time": 3.463129}
[0m07:30:54.870348 [debug] [MainThread]: Command `dbt run` succeeded at 07:30:54.870241 after 5.83 seconds
[0m07:30:54.871225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f1350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f10d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2469f1250>]}
[0m07:30:54.872311 [debug] [MainThread]: Flushing usage events
[0m07:30:55.990910 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:42:35.533356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fad10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fa310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda004fac90>]}


============================== 07:42:35.536888 | 3b0b4895-c001-42c0-9901-b182671f7801 ==============================
[0m07:42:35.536888 [info ] [MainThread]: Running with dbt=1.9.0
[0m07:42:35.538473 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:42:36.138255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2e81450>]}
[0m07:42:36.197358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda027ae2d0>]}
[0m07:42:36.198620 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m07:42:36.276413 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m07:42:36.427590 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:42:36.428428 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:42:36.433150 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m07:42:36.457172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2807790>]}
[0m07:42:36.590853 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:42:36.597347 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:42:36.615077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d25779d0>]}
[0m07:42:36.616421 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m07:42:36.617623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda01d2aa50>]}
[0m07:42:36.620269 [info ] [MainThread]: 
[0m07:42:36.621304 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:42:36.622260 [info ] [MainThread]: 
[0m07:42:36.623673 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:42:36.629307 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m07:42:36.630232 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:42:37.168645 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m07:42:37.169482 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:42:37.359274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d29c77d0>]}
[0m07:42:37.360592 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:42:37.366038 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m07:42:37.366422 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m07:42:37.366910 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m07:42:37.367290 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m07:42:37.368112 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m07:42:37.369831 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m07:42:37.370910 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m07:42:37.372130 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m07:42:37.373291 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m07:42:37.374617 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m07:42:37.376171 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m07:42:37.377221 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m07:42:37.378030 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m07:42:37.379097 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m07:42:37.380111 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m07:42:37.381012 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m07:42:37.398034 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m07:42:37.401786 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m07:42:37.406678 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m07:42:37.411604 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m07:42:37.417003 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m07:42:37.417593 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m07:42:37.418344 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m07:42:37.436542 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m07:42:37.465613 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m07:42:37.468608 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:42:37.471307 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:42:37.475882 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:42:37.750408 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m07:42:37.752883 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m07:42:37.754469 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m07:42:37.760311 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m07:42:37.761455 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m07:42:37.763542 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m07:42:37.767001 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m07:42:37.775191 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m07:42:38.030298 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:48c61271-4f05-40fe-a346-89e53ea76384&page=queryresults
[0m07:42:38.038643 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7c53dd75-39f1-4742-9386-016641bb0607&page=queryresults
[0m07:42:39.110434 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8c792602-497d-4efe-aaf1-5997c496371b&page=queryresults
[0m07:42:39.111976 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4eb10280-dad4-41fb-9670-9016ab9bc08e&page=queryresults
[0m07:42:39.873799 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d28c1b50>]}
[0m07:42:39.874953 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (15.0 rows, 13.8 KiB processed)[0m in 2.50s]
[0m07:42:39.876635 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m07:42:39.910703 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd9d2535450>]}
[0m07:42:39.912022 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (15.0 rows, 10.5 KiB processed)[0m in 2.54s]
[0m07:42:39.913738 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m07:42:40.607381 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda00a8fe50>]}
[0m07:42:40.609295 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (15.0 rows, 10.5 KiB processed)[0m in 3.23s]
[0m07:42:40.610912 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m07:42:40.629043 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b0b4895-c001-42c0-9901-b182671f7801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda0052db10>]}
[0m07:42:40.631131 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (15.0 rows, 8.5 KiB processed)[0m in 3.25s]
[0m07:42:40.633420 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m07:42:40.636556 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:42:40.639742 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:42:40.640702 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m07:42:40.641409 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m07:42:40.642052 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m07:42:40.642883 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m07:42:40.644114 [info ] [MainThread]: 
[0m07:42:40.645495 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.02 seconds (4.02s).
[0m07:42:40.647562 [debug] [MainThread]: Command end result
[0m07:42:40.684982 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m07:42:40.689692 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m07:42:40.698032 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m07:42:40.698780 [info ] [MainThread]: 
[0m07:42:40.699834 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:42:40.700859 [info ] [MainThread]: 
[0m07:42:40.701995 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:42:40.703611 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.221707, "process_in_blocks": "0", "process_kernel_time": 0.271276, "process_mem_max_rss": "222804", "process_out_blocks": "0", "process_user_time": 3.345746}
[0m07:42:40.704672 [debug] [MainThread]: Command `dbt run` succeeded at 07:42:40.704554 after 5.22 seconds
[0m07:42:40.705678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda03e13e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda03d2cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda008f65d0>]}
[0m07:42:40.706704 [debug] [MainThread]: Flushing usage events
[0m07:42:41.823814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:18:12.432832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75201ec90>]}


============================== 08:18:12.436866 | 873b1c9b-3fbb-4208-95d5-5d3038cd76f1 ==============================
[0m08:18:12.436866 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:18:12.438432 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:18:13.019581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7281f7fd0>]}
[0m08:18:13.068481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7542cc9d0>]}
[0m08:18:13.069551 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:18:13.133470 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:18:13.303393 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:18:13.304297 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:18:13.309036 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:18:13.334214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728340610>]}
[0m08:18:13.454205 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:18:13.459718 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:18:13.473409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc730bcc350>]}
[0m08:18:13.474285 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:18:13.475356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7283d30d0>]}
[0m08:18:13.478100 [info ] [MainThread]: 
[0m08:18:13.479228 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:18:13.480274 [info ] [MainThread]: 
[0m08:18:13.481633 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:18:13.486338 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:18:13.487277 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:18:14.120962 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:18:14.123822 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:18:14.328906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7298132d0>]}
[0m08:18:14.330246 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:18:14.335727 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:18:14.336095 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:18:14.336501 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:18:14.337017 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:18:14.337710 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:18:14.339459 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:18:14.340884 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:18:14.342085 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:18:14.343308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:18:14.344823 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:18:14.345920 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:18:14.346739 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:18:14.347521 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:18:14.348287 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:18:14.348945 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:18:14.349605 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:18:14.364590 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:18:14.368731 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:18:14.373105 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:18:14.376836 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:18:14.382847 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:18:14.383522 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:18:14.389653 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:18:14.400012 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:18:14.429197 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:18:14.429478 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:18:14.432490 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:18:14.435631 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:18:14.726733 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:18:14.728540 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:18:14.729286 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:18:14.730515 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:18:14.735505 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:18:14.736582 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:18:14.738965 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:18:14.739581 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:18:15.072113 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:49718984-e9aa-404c-99c2-2a8a9ee4778a&page=queryresults
[0m08:18:15.075968 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c27e9b31-331d-4ef1-a721-af21532687e2&page=queryresults
[0m08:18:15.078186 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a07a28b7-71de-49a1-880d-3110dd9b5c5f&page=queryresults
[0m08:18:15.078652 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b6fb1980-78c9-41e3-8fef-05578a1c4be1&page=queryresults
[0m08:18:16.682071 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728327bd0>]}
[0m08:18:16.682628 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc720185590>]}
[0m08:18:16.682909 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc728236210>]}
[0m08:18:16.683860 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.33s]
[0m08:18:16.685961 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.34s]
[0m08:18:16.687373 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.34s]
[0m08:18:16.688659 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:18:16.690023 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:18:16.691368 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:18:16.925810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '873b1c9b-3fbb-4208-95d5-5d3038cd76f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7284a0490>]}
[0m08:18:16.928615 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.58s]
[0m08:18:16.931276 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:18:16.933597 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:18:16.936740 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:18:16.937819 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:18:16.938708 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:18:16.939486 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:18:16.940531 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:18:16.941790 [info ] [MainThread]: 
[0m08:18:16.943806 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.46 seconds (3.46s).
[0m08:18:16.945513 [debug] [MainThread]: Command end result
[0m08:18:16.989803 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:18:16.997847 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:18:17.006172 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:18:17.007010 [info ] [MainThread]: 
[0m08:18:17.008111 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:18:17.009185 [info ] [MainThread]: 
[0m08:18:17.010118 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:18:17.011798 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.648351, "process_in_blocks": "0", "process_kernel_time": 0.190411, "process_mem_max_rss": "223264", "process_out_blocks": "0", "process_user_time": 3.397345}
[0m08:18:17.012890 [debug] [MainThread]: Command `dbt run` succeeded at 08:18:17.012744 after 4.65 seconds
[0m08:18:17.013849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc755874b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7559d1190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7559d1150>]}
[0m08:18:17.014724 [debug] [MainThread]: Flushing usage events
[0m08:18:18.388019 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:21:35.277834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa71026ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa71077610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa714229d0>]}


============================== 08:21:35.280368 | e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949 ==============================
[0m08:21:35.280368 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:21:35.282387 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:21:35.849786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa437f7d90>]}
[0m08:21:35.897980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e7dbe8e6-b9b2-4380-bcf9-6a7a4dcf4949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa4394edd0>]}
[0m08:21:35.899081 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:21:35.965936 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:21:36.099694 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:21:36.101230 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:21:36.392563 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.hailing_project.stg_customer' (models/staging/stg_customer.sql) depends on a source named 'source.customer_data' which was not found
[0m08:21:36.394691 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1627843, "process_in_blocks": "0", "process_kernel_time": 0.201076, "process_mem_max_rss": "215860", "process_out_blocks": "0", "process_user_time": 2.996037}
[0m08:21:36.395751 [debug] [MainThread]: Command `dbt run` failed at 08:21:36.395644 after 1.16 seconds
[0m08:21:36.396832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa710857d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa714228d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa749a1210>]}
[0m08:21:36.397751 [debug] [MainThread]: Flushing usage events
[0m08:21:37.585841 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:21:58.696691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527357390>]}


============================== 08:21:58.699223 | 3ac88093-f584-4fae-8042-6fc9b98c9baf ==============================
[0m08:21:58.699223 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:21:58.701425 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:21:59.258717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f952b4d0>]}
[0m08:21:59.304815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5295aa690>]}
[0m08:21:59.306289 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:21:59.373130 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:21:59.512444 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:21:59.513637 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:21:59.686979 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:21:59.699330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f921f790>]}
[0m08:21:59.771445 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:21:59.777832 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:21:59.792999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f8fc9550>]}
[0m08:21:59.794272 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:21:59.795320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb527a60c10>]}
[0m08:21:59.798178 [info ] [MainThread]: 
[0m08:21:59.799314 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:21:59.800266 [info ] [MainThread]: 
[0m08:21:59.801528 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:21:59.806732 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:21:59.807705 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:00.404796 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:22:00.405806 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:22:00.625979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5271c8490>]}
[0m08:22:00.627142 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:22:00.631898 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:22:00.632440 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:22:00.632851 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:22:00.633224 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:22:00.633784 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:22:00.634833 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:22:00.635791 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:22:00.636717 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:22:00.637766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:22:00.638723 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:22:00.639631 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:22:00.640452 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:22:00.641237 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:22:00.641989 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:22:00.642641 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:22:00.643469 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:22:00.657714 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:22:00.661531 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:22:00.666182 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:22:00.670362 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:22:00.676069 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:22:00.676537 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:22:00.682740 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:22:00.683077 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:22:00.728513 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:22:00.731399 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:22:00.731912 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:00.735429 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:22:01.021917 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:22:01.031763 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:22:01.032304 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:22:01.040120 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:22:01.042016 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:22:01.044675 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:22:01.047051 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:22:01.055653 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:22:01.320422 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bf34a7f2-05d8-4b66-8f93-38355ae08d44&page=queryresults
[0m08:22:01.331037 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9c67940c-8b6f-440b-8c72-e95e28d6caeb&page=queryresults
[0m08:22:01.346206 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9fcd591b-0bb1-4f74-87e7-94b821539846&page=queryresults
[0m08:22:01.587215 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:c36f477f-d378-4222-81ba-639f48b9ab5f&page=queryresults
[0m08:22:03.143042 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f86db890>]}
[0m08:22:03.143483 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f9060890>]}
[0m08:22:03.144057 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f9060fd0>]}
[0m08:22:03.144982 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.50s]
[0m08:22:03.146513 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m08:22:03.147929 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.50s]
[0m08:22:03.149289 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:22:03.150357 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:22:03.151275 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:22:03.396862 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ac88093-f584-4fae-8042-6fc9b98c9baf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f8696150>]}
[0m08:22:03.398466 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.76s]
[0m08:22:03.399879 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:22:03.402692 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:22:03.407263 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:03.408525 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:22:03.410677 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:22:03.411769 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:22:03.412743 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:22:03.414100 [info ] [MainThread]: 
[0m08:22:03.416519 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.61 seconds (3.61s).
[0m08:22:03.419113 [debug] [MainThread]: Command end result
[0m08:22:03.459681 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:03.464349 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:03.473447 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:22:03.474283 [info ] [MainThread]: 
[0m08:22:03.475524 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:22:03.476657 [info ] [MainThread]: 
[0m08:22:03.477740 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:22:03.479739 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8314342, "process_in_blocks": "0", "process_kernel_time": 0.144241, "process_mem_max_rss": "222996", "process_out_blocks": "0", "process_user_time": 3.451483}
[0m08:22:03.480925 [debug] [MainThread]: Command `dbt run` succeeded at 08:22:03.480799 after 4.83 seconds
[0m08:22:03.481928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52ab48c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52aca5350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb52aca5210>]}
[0m08:22:03.482989 [debug] [MainThread]: Flushing usage events
[0m08:22:04.544138 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:22:17.701112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44daecbb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dae7b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dae7aa10>]}


============================== 08:22:17.703736 | b4a8c7b2-0f48-4de6-bf00-984e84d2b338 ==============================
[0m08:22:17.703736 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:22:17.707145 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:22:18.292096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b4a8c7b2-0f48-4de6-bf00-984e84d2b338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b1103810>]}
[0m08:22:18.337217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b4a8c7b2-0f48-4de6-bf00-984e84d2b338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b117cf10>]}
[0m08:22:18.338226 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:22:18.406073 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:22:18.534804 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m08:22:18.536253 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:22:18.536954 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:22:18.833272 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.hailing_project.stg_driver' (models/staging/stg_driver.sql) depends on a source named 'source.driver_data' which was not found
[0m08:22:18.835370 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1823285, "process_in_blocks": "0", "process_kernel_time": 0.141755, "process_mem_max_rss": "215568", "process_out_blocks": "0", "process_user_time": 3.057857}
[0m08:22:18.836458 [debug] [MainThread]: Command `dbt run` failed at 08:22:18.836343 after 1.18 seconds
[0m08:22:18.837279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dacf9690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44dacfba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44b0cd05d0>]}
[0m08:22:18.838174 [debug] [MainThread]: Flushing usage events
[0m08:22:19.859620 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:22:41.760571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38887f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388c6e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888c36d0>]}


============================== 08:22:41.764248 | 971611f3-095f-4bdc-adff-384ed1f3b5dd ==============================
[0m08:22:41.764248 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:22:41.766273 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:22:42.405008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888df610>]}
[0m08:22:42.454837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38ab04a10>]}
[0m08:22:42.456489 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:22:42.528347 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:22:42.672747 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:22:42.673793 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:22:43.007607 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:22:43.020459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35aa23810>]}
[0m08:22:43.100224 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:43.105650 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:43.121002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a86ff50>]}
[0m08:22:43.122311 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:22:43.123673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a6d4390>]}
[0m08:22:43.126684 [info ] [MainThread]: 
[0m08:22:43.127817 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:22:43.128843 [info ] [MainThread]: 
[0m08:22:43.130513 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:22:43.136209 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:22:43.137209 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:22:43.637140 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:22:43.638417 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:22:43.886919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a673d50>]}
[0m08:22:43.888157 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:22:43.894076 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:22:43.894455 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:22:43.894891 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:22:43.895213 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:22:43.895744 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:22:43.896819 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:22:43.897984 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:22:43.899057 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:22:43.900200 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:22:43.901220 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:22:43.902148 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:22:43.903061 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:22:43.903774 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:22:43.904853 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:22:43.905711 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:22:43.906540 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:22:43.916133 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:22:43.920501 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:22:43.925880 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:22:43.930128 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:22:43.936002 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:22:43.936673 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:22:43.942979 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:22:43.953090 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:22:43.987034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:22:43.987499 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:22:43.989835 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:22:43.992680 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:22:44.286333 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:22:44.288181 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:22:44.292592 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:22:44.293746 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:22:44.296363 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:22:44.303643 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:22:44.305470 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:22:44.307945 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:22:44.560086 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:898bc365-4a1b-4083-b8c1-dfc45cf4a1f1&page=queryresults
[0m08:22:44.565353 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:077de461-4221-4a1c-af9d-237cbc305ec8&page=queryresults
[0m08:22:44.731529 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:077de461-4221-4a1c-af9d-237cbc305ec8&page=queryresults
[0m08:22:44.747043 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m08:22:44.749992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd358405ed0>]}
[0m08:22:44.751242 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source.stg_customer  [[31mERROR[0m in 0.85s]
[0m08:22:44.752903 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:22:44.754518 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.stg_customer' to be skipped because of status 'error'.  Reason: Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql.
[0m08:22:44.836801 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8a6a3c55-e78c-4954-9742-fd78f2485047&page=queryresults
[0m08:22:45.653035 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce572007-8886-46ca-9dbb-0cc80cf42a36&page=queryresults
[0m08:22:46.396178 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a5a1d10>]}
[0m08:22:46.398178 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.49s]
[0m08:22:46.399788 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:22:46.895988 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35842f9d0>]}
[0m08:22:46.897519 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.99s]
[0m08:22:46.899179 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:22:47.464938 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '971611f3-095f-4bdc-adff-384ed1f3b5dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35a5a1850>]}
[0m08:22:47.466621 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.56s]
[0m08:22:47.468175 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:22:47.470574 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:22:47.473975 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:22:47.474902 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:22:47.475720 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:22:47.476571 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:22:47.477315 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:22:47.478392 [info ] [MainThread]: 
[0m08:22:47.479390 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m08:22:47.482287 [debug] [MainThread]: Command end result
[0m08:22:47.516280 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:22:47.520396 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:22:47.528804 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:22:47.529804 [info ] [MainThread]: 
[0m08:22:47.531162 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:22:47.532243 [info ] [MainThread]: 
[0m08:22:47.533362 [error] [MainThread]:   Database Error in model stg_customer (models/staging/stg_customer.sql)
  Unrecognized name: created_at_at; Did you mean created_at? at [35:20]
  compiled code at target/run/hailing_project/models/staging/stg_customer.sql
[0m08:22:47.534328 [info ] [MainThread]: 
[0m08:22:47.535393 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m08:22:47.537137 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.833213, "process_in_blocks": "448", "process_kernel_time": 0.207239, "process_mem_max_rss": "228060", "process_out_blocks": "0", "process_user_time": 3.621758}
[0m08:22:47.538493 [debug] [MainThread]: Command `dbt run` failed at 08:22:47.538312 after 5.83 seconds
[0m08:22:47.539590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888b5790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34a6ba050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3888b4790>]}
[0m08:22:47.540485 [debug] [MainThread]: Flushing usage events
[0m08:22:48.770993 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:23:10.006409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d483bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d8d84d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d42f050>]}


============================== 08:23:10.009479 | e8c378eb-1201-41dc-995a-5ef9097b55f0 ==============================
[0m08:23:10.009479 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:23:10.010632 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:23:10.703903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df546e10>]}
[0m08:23:10.757024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e4e14f10>]}
[0m08:23:10.758564 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:23:10.834599 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:23:10.985412 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:23:10.986755 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/stg_customer.sql
[0m08:23:11.270486 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:23:11.286192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df502290>]}
[0m08:23:11.362266 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:23:11.368632 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:23:11.383211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df19ea10>]}
[0m08:23:11.384297 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:23:11.386028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df1a4610>]}
[0m08:23:11.389244 [info ] [MainThread]: 
[0m08:23:11.390372 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:23:11.391547 [info ] [MainThread]: 
[0m08:23:11.393473 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:23:11.398866 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:23:11.400111 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:23:11.874677 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:23:11.875625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:23:12.104283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df7d4b90>]}
[0m08:23:12.105692 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:23:12.112297 [debug] [Thread-1 (]: Began running node model.hailing_project.stg_customer
[0m08:23:12.112845 [debug] [Thread-2 (]: Began running node model.hailing_project.stg_driver
[0m08:23:12.113454 [debug] [Thread-3 (]: Began running node model.hailing_project.stg_ride
[0m08:23:12.114011 [debug] [Thread-4 (]: Began running node model.hailing_project.stg_vehicle
[0m08:23:12.114755 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.stg_customer ....... [RUN]
[0m08:23:12.116068 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.stg_driver ......... [RUN]
[0m08:23:12.117779 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.stg_ride ........... [RUN]
[0m08:23:12.119291 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.stg_vehicle ........ [RUN]
[0m08:23:12.121170 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.stg_customer)
[0m08:23:12.122695 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.stg_driver'
[0m08:23:12.124071 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.stg_ride'
[0m08:23:12.125413 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.stg_vehicle'
[0m08:23:12.126641 [debug] [Thread-1 (]: Began compiling node model.hailing_project.stg_customer
[0m08:23:12.127832 [debug] [Thread-2 (]: Began compiling node model.hailing_project.stg_driver
[0m08:23:12.129124 [debug] [Thread-3 (]: Began compiling node model.hailing_project.stg_ride
[0m08:23:12.130232 [debug] [Thread-4 (]: Began compiling node model.hailing_project.stg_vehicle
[0m08:23:12.144780 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.stg_customer"
[0m08:23:12.150053 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.stg_driver"
[0m08:23:12.157498 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.stg_ride"
[0m08:23:12.161654 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.stg_vehicle"
[0m08:23:12.167988 [debug] [Thread-1 (]: Began executing node model.hailing_project.stg_customer
[0m08:23:12.168905 [debug] [Thread-3 (]: Began executing node model.hailing_project.stg_ride
[0m08:23:12.174713 [debug] [Thread-4 (]: Began executing node model.hailing_project.stg_vehicle
[0m08:23:12.175104 [debug] [Thread-2 (]: Began executing node model.hailing_project.stg_driver
[0m08:23:12.211682 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:23:12.211969 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:23:12.214865 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:23:12.218302 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:23:12.538360 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.stg_driver"
[0m08:23:12.539920 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.stg_ride"
[0m08:23:12.540565 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.stg_vehicle"
[0m08:23:12.537091 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.stg_customer"
[0m08:23:12.545917 [debug] [Thread-2 (]: On model.hailing_project.stg_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:23:12.546812 [debug] [Thread-4 (]: On model.hailing_project.stg_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:23:12.548862 [debug] [Thread-3 (]: On model.hailing_project.stg_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:23:12.551573 [debug] [Thread-1 (]: On model.hailing_project.stg_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.stg_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`stg_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`stg_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:23:12.794914 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6988f829-1759-42d0-bb8d-9fadc9750f5c&page=queryresults
[0m08:23:12.795537 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4e4cccf0-ba08-4fe6-b244-40d31183711b&page=queryresults
[0m08:23:12.812820 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a3a3a744-253c-4f7b-b4c1-e911e23fb65b&page=queryresults
[0m08:23:12.840339 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27a1e004-58ca-4360-83e5-3d73608b0a5d&page=queryresults
[0m08:23:14.364948 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47df323a50>]}
[0m08:23:14.366262 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_vehicle ... [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.24s]
[0m08:23:14.368496 [debug] [Thread-4 (]: Finished running node model.hailing_project.stg_vehicle
[0m08:23:14.564064 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc75b890>]}
[0m08:23:14.568138 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc764ed0>]}
[0m08:23:14.569354 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_ride ...... [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.44s]
[0m08:23:14.572283 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_driver .... [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m08:23:14.574182 [debug] [Thread-3 (]: Finished running node model.hailing_project.stg_ride
[0m08:23:14.575777 [debug] [Thread-2 (]: Finished running node model.hailing_project.stg_driver
[0m08:23:14.609671 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8c378eb-1201-41dc-995a-5ef9097b55f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47dc74c590>]}
[0m08:23:14.610826 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.stg_customer .. [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.49s]
[0m08:23:14.622350 [debug] [Thread-1 (]: Finished running node model.hailing_project.stg_customer
[0m08:23:14.628976 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:23:14.632897 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:23:14.639967 [debug] [MainThread]: Connection 'model.hailing_project.stg_customer' was properly closed.
[0m08:23:14.641615 [debug] [MainThread]: Connection 'model.hailing_project.stg_driver' was properly closed.
[0m08:23:14.642475 [debug] [MainThread]: Connection 'model.hailing_project.stg_ride' was properly closed.
[0m08:23:14.643922 [debug] [MainThread]: Connection 'model.hailing_project.stg_vehicle' was properly closed.
[0m08:23:14.645390 [info ] [MainThread]: 
[0m08:23:14.646648 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m08:23:14.648508 [debug] [MainThread]: Command end result
[0m08:23:14.699662 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:23:14.705466 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:23:14.713966 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:23:14.714931 [info ] [MainThread]: 
[0m08:23:14.716212 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:23:14.717633 [info ] [MainThread]: 
[0m08:23:14.718841 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:23:14.720861 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.779687, "process_in_blocks": "0", "process_kernel_time": 0.161282, "process_mem_max_rss": "224496", "process_out_blocks": "0", "process_user_time": 3.769968}
[0m08:23:14.721979 [debug] [MainThread]: Command `dbt run` succeeded at 08:23:14.721862 after 4.78 seconds
[0m08:23:14.723011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f480d2abdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4810ce8a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4810d787d0>]}
[0m08:23:14.724382 [debug] [MainThread]: Flushing usage events
[0m08:23:15.791846 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:27:30.959413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316be3950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c33f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c2b7d0>]}


============================== 08:27:30.962303 | bea2439a-3348-4f55-a283-4c04192d726c ==============================
[0m08:27:30.962303 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:27:30.963575 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:27:31.561458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ed06a950>]}
[0m08:27:31.610933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3318e96150>]}
[0m08:27:31.612449 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:27:31.682920 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:27:31.822084 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 4 files added, 1 files changed.
[0m08:27:31.823302 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_ride_staging.sql
[0m08:27:31.824261 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_vehicle_staging.sql
[0m08:27:31.825284 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_customer_staging.sql
[0m08:27:31.826110 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_driver_staging.sql
[0m08:27:31.826988 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:27:31.827802 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_customer.sql
[0m08:27:31.828532 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_driver.sql
[0m08:27:31.829297 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_ride.sql
[0m08:27:31.830335 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/stg_vehicle.sql
[0m08:27:32.183624 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:27:32.197759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec9e8610>]}
[0m08:27:32.277301 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:27:32.283668 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:27:32.298710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec7f7290>]}
[0m08:27:32.299996 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:27:32.301759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33172d65d0>]}
[0m08:27:32.304783 [info ] [MainThread]: 
[0m08:27:32.306121 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:27:32.307523 [info ] [MainThread]: 
[0m08:27:32.309641 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:27:32.314422 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:27:32.316149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:27:32.905040 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:27:32.906245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:27:33.111609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ecf7c210>]}
[0m08:27:33.113027 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:27:33.120084 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.120622 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.121101 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.121634 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.123495 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [RUN]
[0m08:27:33.125415 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [RUN]
[0m08:27:33.127184 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [RUN]
[0m08:27:33.129172 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [RUN]
[0m08:27:33.131370 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_customer_staging)
[0m08:27:33.133550 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_driver_staging'
[0m08:27:33.136521 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_ride_staging'
[0m08:27:33.138106 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_vehicle_staging'
[0m08:27:33.139550 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.140992 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.142840 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.144255 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.154140 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_customer_staging"
[0m08:27:33.159558 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_driver_staging"
[0m08:27:33.165776 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_ride_staging"
[0m08:27:33.170662 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:27:33.176842 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_customer_staging
[0m08:27:33.183716 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:33.211126 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_driver_staging
[0m08:27:33.216911 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_ride_staging
[0m08:27:33.273959 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:27:33.274959 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_customer_staging"
[0m08:27:33.277939 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_driver_staging"
[0m08:27:33.282491 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_ride_staging"
[0m08:27:33.287572 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_customer_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_customer_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_source`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:27:33.288961 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:27:33.289427 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_vehicle_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_vehicle_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_source`
)

SELECT *
FROM source

    );
  
[0m08:27:33.290744 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_ride_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_ride_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_source`
)

SELECT *
FROM source

    );
  
[0m08:27:33.291570 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:27:33.292389 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_driver_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_driver_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_source`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:27:33.294527 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:27:33.318625 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:27:33.706692 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7fc33d6e-81d0-4263-95bf-1c8956f8c172&page=queryresults
[0m08:27:33.716220 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31085e80-a3cf-4850-9b4a-0e89417e82c9&page=queryresults
[0m08:27:33.722078 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bc8394a4-3750-4e31-b3a2-1d3aeabb0b44&page=queryresults
[0m08:27:33.726232 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9066ce79-d874-4f6f-a75a-2e05455cc4ce&page=queryresults
[0m08:27:35.593557 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ecfab0d0>]}
[0m08:27:35.595426 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec45b050>]}
[0m08:27:35.597305 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.46s]
[0m08:27:35.598170 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec283350>]}
[0m08:27:35.599250 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.46s]
[0m08:27:35.600598 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_customer_staging
[0m08:27:35.602178 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.46s]
[0m08:27:35.603419 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_vehicle_staging
[0m08:27:35.605232 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_driver_staging
[0m08:27:35.617693 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bea2439a-3348-4f55-a283-4c04192d726c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32ec7f5f50>]}
[0m08:27:35.618692 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.48s]
[0m08:27:35.619871 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_ride_staging
[0m08:27:35.622893 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:27:35.625989 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:27:35.626936 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_customer_staging' was properly closed.
[0m08:27:35.627933 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_driver_staging' was properly closed.
[0m08:27:35.628818 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_ride_staging' was properly closed.
[0m08:27:35.629777 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_vehicle_staging' was properly closed.
[0m08:27:35.630671 [info ] [MainThread]: 
[0m08:27:35.631722 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.32 seconds (3.32s).
[0m08:27:35.633318 [debug] [MainThread]: Command end result
[0m08:27:35.668417 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:27:35.673451 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:27:35.682040 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:27:35.682934 [info ] [MainThread]: 
[0m08:27:35.684269 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:27:35.686117 [info ] [MainThread]: 
[0m08:27:35.687174 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:27:35.688857 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7852182, "process_in_blocks": "0", "process_kernel_time": 0.270995, "process_mem_max_rss": "224704", "process_out_blocks": "0", "process_user_time": 3.663454}
[0m08:27:35.690050 [debug] [MainThread]: Command `dbt run` succeeded at 08:27:35.689879 after 4.79 seconds
[0m08:27:35.691191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316c2b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3316fddf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f331a508b10>]}
[0m08:27:35.692269 [debug] [MainThread]: Flushing usage events
[0m08:27:36.829557 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:39:38.577262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88def3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88def3510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88dea2d90>]}


============================== 08:39:38.580813 | 5b5196af-75b8-4e53-bbcd-ea4035cf723e ==============================
[0m08:39:38.580813 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:39:38.582552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:39:39.188386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8647dc2d0>]}
[0m08:39:39.233777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff890158b10>]}
[0m08:39:39.235247 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:39:39.307329 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:39:39.446764 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:39:39.448612 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m08:39:39.801061 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:39:39.812341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88ec64490>]}
[0m08:39:39.884185 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:39:39.891044 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:39:39.905683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8641aed50>]}
[0m08:39:39.906796 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:39:39.908433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85fcf7d90>]}
[0m08:39:39.911366 [info ] [MainThread]: 
[0m08:39:39.912489 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:39:39.913568 [info ] [MainThread]: 
[0m08:39:39.914949 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:39:39.920109 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:39:39.921037 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:39:40.503687 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:39:40.504818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:39:40.773147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88f098750>]}
[0m08:39:40.774127 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:39:40.779144 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.779498 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.779838 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.780118 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.780634 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [RUN]
[0m08:39:40.781653 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [RUN]
[0m08:39:40.782763 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [RUN]
[0m08:39:40.783878 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [RUN]
[0m08:39:40.784902 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_customer_staging)
[0m08:39:40.785951 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_driver_staging'
[0m08:39:40.786883 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_ride_staging'
[0m08:39:40.788751 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_vehicle_staging'
[0m08:39:40.789745 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.790628 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.791483 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.792417 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.800291 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_customer_staging"
[0m08:39:40.804776 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_driver_staging"
[0m08:39:40.809609 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_ride_staging"
[0m08:39:40.813770 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:39:40.820314 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_customer_staging
[0m08:39:40.821615 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:40.827934 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_ride_staging
[0m08:39:40.848484 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_driver_staging
[0m08:39:40.905256 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_customer_staging"
[0m08:39:40.905858 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_vehicle_staging"
[0m08:39:40.910465 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_ride_staging"
[0m08:39:40.915140 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_driver_staging"
[0m08:39:40.921371 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_customer_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_customer_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_customer_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:39:40.923021 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_driver_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_driver_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_driver_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:39:40.923574 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_ride_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_ride_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_ride_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m08:39:40.924351 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:39:40.925255 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_vehicle_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_vehicle_staging"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_vehicle_staging`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m08:39:40.925913 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:39:40.927023 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:39:40.929315 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:39:41.431996 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1363d983-f250-470b-82bc-904e80a950b5&page=queryresults
[0m08:39:41.439151 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9940b5b3-c090-43f4-a64b-faa6760986a4&page=queryresults
[0m08:39:41.448901 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:54c66f7a-af0b-476e-87a8-66e5049e5903&page=queryresults
[0m08:39:41.467382 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a16d22a3-38b6-46f5-b56a-2a38549df091&page=queryresults
[0m08:39:43.178411 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88e599f90>]}
[0m08:39:43.178990 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85c138210>]}
[0m08:39:43.179664 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85c11a9d0>]}
[0m08:39:43.180781 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_customer_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m08:39:43.182279 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_ride_staging  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.39s]
[0m08:39:43.183893 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_driver_staging  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m08:39:43.187346 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_customer_staging
[0m08:39:43.188234 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5196af-75b8-4e53-bbcd-ea4035cf723e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85fa78990>]}
[0m08:39:43.189308 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_ride_staging
[0m08:39:43.191172 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_driver_staging
[0m08:39:43.193714 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_vehicle_staging  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.40s]
[0m08:39:43.197053 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_vehicle_staging
[0m08:39:43.199905 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:39:43.204144 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:39:43.205339 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_customer_staging' was properly closed.
[0m08:39:43.206770 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_driver_staging' was properly closed.
[0m08:39:43.207741 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_ride_staging' was properly closed.
[0m08:39:43.208462 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_vehicle_staging' was properly closed.
[0m08:39:43.209673 [info ] [MainThread]: 
[0m08:39:43.210887 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.29 seconds (3.29s).
[0m08:39:43.212824 [debug] [MainThread]: Command end result
[0m08:39:43.250261 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:39:43.255282 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:39:43.264495 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:39:43.265487 [info ] [MainThread]: 
[0m08:39:43.266789 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:39:43.267931 [info ] [MainThread]: 
[0m08:39:43.269090 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:39:43.270753 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.754618, "process_in_blocks": "0", "process_kernel_time": 0.178834, "process_mem_max_rss": "224996", "process_out_blocks": "0", "process_user_time": 3.646234}
[0m08:39:43.271813 [debug] [MainThread]: Command `dbt run` succeeded at 08:39:43.271665 after 4.76 seconds
[0m08:39:43.272837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88e38b710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8917ba890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8917bbe10>]}
[0m08:39:43.273980 [debug] [MainThread]: Flushing usage events
[0m08:39:44.535912 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:41:44.508859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe0015f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc1db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc6ba90>]}


============================== 08:41:44.511995 | 9e13fda7-806a-4f8c-92f7-037962eb7068 ==============================
[0m08:41:44.511995 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:41:44.513392 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:41:45.091789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb81d5750>]}
[0m08:41:45.139722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe1e91f50>]}
[0m08:41:45.141190 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:41:45.208456 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:41:45.354277 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 4 files added, 0 files changed.
[0m08:41:45.355482 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_ride.sql
[0m08:41:45.356515 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m08:41:45.357617 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_driver.sql
[0m08:41:45.358502 [debug] [MainThread]: Partial parsing: added file: hailing_project://models/staging/production_hailing_staging_vehicle.sql
[0m08:41:45.359555 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_driver_staging.sql
[0m08:41:45.360456 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_customer_staging.sql
[0m08:41:45.361405 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_ride_staging.sql
[0m08:41:45.362254 [debug] [MainThread]: Partial parsing: deleted file: hailing_project://models/staging/production_hailing_vehicle_staging.sql
[0m08:41:45.630494 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m08:41:45.642505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1e46b10>]}
[0m08:41:45.720003 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:41:45.726872 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:41:45.741856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1d9ebd0>]}
[0m08:41:45.742934 [info ] [MainThread]: Found 4 models, 4 sources, 488 macros
[0m08:41:45.744183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1f1dd50>]}
[0m08:41:45.747599 [info ] [MainThread]: 
[0m08:41:45.748694 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:41:45.749705 [info ] [MainThread]: 
[0m08:41:45.750723 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:41:45.754864 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:41:45.755758 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:41:46.326346 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:41:46.327235 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:41:46.584013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1f1e310>]}
[0m08:41:46.585502 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:41:46.592811 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.593231 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.593562 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.593910 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.594450 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m08:41:46.596132 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m08:41:46.597253 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m08:41:46.598298 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m08:41:46.599467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m08:41:46.600500 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m08:41:46.601496 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m08:41:46.602530 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:41:46.603243 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.604029 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.604734 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.605536 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.614089 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:41:46.618498 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:41:46.622632 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:41:46.626572 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:41:46.631751 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:46.638684 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:41:46.660511 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:41:46.666438 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:41:46.716323 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:41:46.718476 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:41:46.722007 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:41:46.727807 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:41:46.736683 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:41:46.738298 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:41:46.739047 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m08:41:46.740751 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m08:41:46.741412 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m08:41:46.742243 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:41:46.746092 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:41:46.768762 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m08:41:47.228720 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cb0b32c7-6a70-428c-9c74-72a25cffcf1f&page=queryresults
[0m08:41:47.231334 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:486b0192-d722-449f-b154-09c4ef7334d7&page=queryresults
[0m08:41:47.234280 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:860fee08-ffe9-4668-8cbc-cf82af9cd63b&page=queryresults
[0m08:41:47.259504 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:05c35d65-43f5-47e1-a6c4-47b023f0b583&page=queryresults
[0m08:41:49.155470 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effa1f6c750>]}
[0m08:41:49.155836 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1fab690>]}
[0m08:41:49.156142 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe099ea90>]}
[0m08:41:49.157290 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.55s]
[0m08:41:49.158635 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.56s]
[0m08:41:49.160177 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.55s]
[0m08:41:49.161613 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:41:49.162813 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:41:49.164114 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:41:49.177392 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e13fda7-806a-4f8c-92f7-037962eb7068', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effb1a1ba90>]}
[0m08:41:49.178844 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.57s]
[0m08:41:49.180411 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:41:49.182571 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:41:49.185888 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:41:49.186909 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m08:41:49.187942 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:41:49.188715 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:41:49.189306 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:41:49.190023 [info ] [MainThread]: 
[0m08:41:49.190945 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.44 seconds (3.44s).
[0m08:41:49.193114 [debug] [MainThread]: Command end result
[0m08:41:49.226359 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:41:49.230612 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:41:49.238958 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:41:49.239950 [info ] [MainThread]: 
[0m08:41:49.241156 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:41:49.242717 [info ] [MainThread]: 
[0m08:41:49.244169 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m08:41:49.245833 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.790658, "process_in_blocks": "0", "process_kernel_time": 0.242733, "process_mem_max_rss": "224756", "process_out_blocks": "0", "process_user_time": 3.499414}
[0m08:41:49.247003 [debug] [MainThread]: Command `dbt run` succeeded at 08:41:49.246894 after 4.79 seconds
[0m08:41:49.247855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc6b110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effdfc9b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effe3438c10>]}
[0m08:41:49.248612 [debug] [MainThread]: Flushing usage events
[0m08:41:50.360982 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:53.438048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb843090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bbd23790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb842d90>]}


============================== 08:55:53.440785 | 188f2d7a-2cad-4b2f-9d3b-318ce69a68c5 ==============================
[0m08:55:53.440785 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:53.443792 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:55:53.541592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '188f2d7a-2cad-4b2f-9d3b-318ce69a68c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bb740590>]}
[0m08:55:53.616102 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.22455075, "process_in_blocks": "0", "process_kernel_time": 0.119231, "process_mem_max_rss": "89884", "process_out_blocks": "0", "process_user_time": 0.924043}
[0m08:55:53.616990 [debug] [MainThread]: Command `dbt clean` succeeded at 08:55:53.616891 after 0.23 seconds
[0m08:55:53.617840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bf305850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bf00cb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9bbc3a090>]}
[0m08:55:53.618611 [debug] [MainThread]: Flushing usage events
[0m08:55:54.719266 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:55.867510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eccfdb250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd016150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2eccfdad10>]}


============================== 08:55:55.870876 | ab56964a-a0bb-4c5d-8da2-9de161090d50 ==============================
[0m08:55:55.870876 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:55.872480 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:55:55.955841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab56964a-a0bb-4c5d-8da2-9de161090d50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecced5d90>]}
[0m08:55:55.967959 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m08:55:55.970791 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m08:55:55.972410 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1555311, "process_in_blocks": "0", "process_kernel_time": 0.109292, "process_mem_max_rss": "90120", "process_out_blocks": "0", "process_user_time": 0.963762}
[0m08:55:55.973544 [debug] [MainThread]: Command `dbt deps` succeeded at 08:55:55.973423 after 0.16 seconds
[0m08:55:55.974805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd04f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ecd016150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ed07f4b90>]}
[0m08:55:55.975714 [debug] [MainThread]: Flushing usage events
[0m08:55:57.027390 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:55:59.333091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec212f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec257910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec256f90>]}


============================== 08:55:59.336082 | 9be4d424-1a46-4f73-b13a-dc52af359668 ==============================
[0m08:55:59.336082 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:55:59.337134 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:55:59.954350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be4273d0>]}
[0m08:56:00.011637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ee486150>]}
[0m08:56:00.013063 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:00.111993 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:00.114820 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:56:00.116055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9be4d424-1a46-4f73-b13a-dc52af359668', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be40c890>]}
[0m08:56:00.959452 [error] [MainThread]: Encountered an error:
Compilation Error in model dim_customer (models/facts/dim_customer.sql)
  expected token ',', got 'partition_by'
    line 6
      partition_by={
[0m08:56:00.961679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6971128, "process_in_blocks": "0", "process_kernel_time": 0.173183, "process_mem_max_rss": "212028", "process_out_blocks": "0", "process_user_time": 3.545171}
[0m08:56:00.962928 [debug] [MainThread]: Command `dbt run` failed at 08:56:00.962774 after 1.70 seconds
[0m08:56:00.963870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec31dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6be517a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6ec242b90>]}
[0m08:56:00.964920 [debug] [MainThread]: Flushing usage events
[0m08:56:02.218201 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:56:14.289954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0d97190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d2ba9ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0d96610>]}


============================== 08:56:14.293297 | 47699dbc-bf56-4bee-86af-c67e838e11b7 ==============================
[0m08:56:14.293297 [info ] [MainThread]: Running with dbt=1.9.0
[0m08:56:14.294521 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m08:56:14.927525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a80db5d0>]}
[0m08:56:14.972869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d300c710>]}
[0m08:56:14.974099 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m08:56:15.043632 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m08:56:15.047056 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:56:15.048294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a9335c90>]}
[0m08:56:16.070617 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m08:56:16.083971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a321bd50>]}
[0m08:56:16.160529 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:56:16.166191 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:56:16.180220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2947010>]}
[0m08:56:16.181182 [info ] [MainThread]: Found 5 models, 4 sources, 488 macros
[0m08:56:16.182253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2b4c910>]}
[0m08:56:16.185224 [info ] [MainThread]: 
[0m08:56:16.186651 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m08:56:16.187777 [info ] [MainThread]: 
[0m08:56:16.189187 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:56:16.194044 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:16.194817 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m08:56:16.195635 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:16.196568 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:56:17.174266 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m08:56:17.175593 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m08:56:17.185112 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m08:56:17.185993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:18.033143 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:a4611c7b-5f04-4e83-a696-d54823fc335a&page=queryresults
[0m08:56:18.952582 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m08:56:18.953105 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m08:56:18.954022 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:18.955119 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:56:19.504221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2fb3650>]}
[0m08:56:19.505634 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:56:19.511265 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.511990 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.512357 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.512797 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.513537 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m08:56:19.514609 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m08:56:19.515507 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m08:56:19.516567 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m08:56:19.517726 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m08:56:19.519027 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_driver)
[0m08:56:19.520188 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m08:56:19.521117 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m08:56:19.521991 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.522896 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.523746 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.524590 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.535354 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m08:56:19.540152 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m08:56:19.545159 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m08:56:19.549713 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:56:19.564158 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m08:56:19.570611 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:19.589141 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m08:56:19.608163 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:19.609444 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m08:56:19.609835 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m08:56:19.612375 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:56:19.617880 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m08:56:19.911915 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m08:56:19.915510 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m08:56:19.916741 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m08:56:19.918280 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m08:56:19.929276 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m08:56:19.930726 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m08:56:19.934719 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m08:56:19.937538 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m08:56:20.261435 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d34d8f83-627d-4416-95ee-161fecb8b93d&page=queryresults
[0m08:56:20.261907 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b945e293-6643-4419-8c69-ba34c7d4dd22&page=queryresults
[0m08:56:20.264128 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:29ebc6f8-24cf-46ca-ad87-cb0162c9c32b&page=queryresults
[0m08:56:20.266154 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9bd397cb-b8f3-45da-a108-41ad7e513f76&page=queryresults
[0m08:56:21.808083 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a29acdd0>]}
[0m08:56:21.809431 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.29s]
[0m08:56:21.811020 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m08:56:21.812414 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m08:56:21.813620 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m08:56:21.814852 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.dim_customer)
[0m08:56:21.815989 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m08:56:21.820607 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m08:56:21.831710 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m08:56:21.857714 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a2937890>]}
[0m08:56:21.870866 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a16be7d0>]}
[0m08:56:21.872176 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m08:56:21.872998 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.34s]
[0m08:56:21.874492 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.35s]
[0m08:56:21.876872 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m08:56:21.877997 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m08:56:21.885955 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m08:56:21.887595 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m08:56:22.066828 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a1663c10>]}
[0m08:56:22.068223 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.55s]
[0m08:56:22.069559 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m08:56:22.145883 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27053855-795a-4b5e-a8d0-39f127d3302c&page=queryresults
[0m08:56:22.147182 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27053855-795a-4b5e-a8d0-39f127d3302c&page=queryresults
[0m08:56:22.152102 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m08:56:22.153159 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47699dbc-bf56-4bee-86af-c67e838e11b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66a03f1750>]}
[0m08:56:22.155106 [error] [Thread-1 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.34s]
[0m08:56:22.157201 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m08:56:22.158745 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m08:56:22.161659 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m08:56:22.165718 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:56:22.166637 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m08:56:22.167453 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m08:56:22.168136 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m08:56:22.168996 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m08:56:22.170079 [info ] [MainThread]: 
[0m08:56:22.171559 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.98 seconds (5.98s).
[0m08:56:22.174005 [debug] [MainThread]: Command end result
[0m08:56:22.211249 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m08:56:22.215917 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m08:56:22.225212 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m08:56:22.225981 [info ] [MainThread]: 
[0m08:56:22.226983 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m08:56:22.228025 [info ] [MainThread]: 
[0m08:56:22.229124 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m08:56:22.230038 [info ] [MainThread]: 
[0m08:56:22.231046 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m08:56:22.232740 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.001722, "process_in_blocks": "0", "process_kernel_time": 0.270523, "process_mem_max_rss": "227580", "process_out_blocks": "0", "process_user_time": 4.318353}
[0m08:56:22.233893 [debug] [MainThread]: Command `dbt run` failed at 08:56:22.233774 after 8.00 seconds
[0m08:56:22.234960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d1192250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d1192490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66d0e13650>]}
[0m08:56:22.235975 [debug] [MainThread]: Flushing usage events
[0m08:56:23.522471 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:02:51.542904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c3bd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058fde110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c3bad0>]}


============================== 09:02:51.545550 | 330823d6-ff0a-4567-87ad-72d7c9342a21 ==============================
[0m09:02:51.545550 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:02:51.546773 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:02:52.119321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058beac50>]}
[0m09:02:52.177202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f005ae5a250>]}
[0m09:02:52.178567 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:02:52.252413 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:02:52.400017 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m09:02:52.401572 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m09:02:52.402603 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m09:02:52.733720 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m09:02:52.745280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa17c10>]}
[0m09:02:52.819470 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:02:52.825069 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:02:52.840761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a9fea10>]}
[0m09:02:52.841995 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m09:02:52.843352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa0ce90>]}
[0m09:02:52.846181 [info ] [MainThread]: 
[0m09:02:52.847420 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:02:52.848474 [info ] [MainThread]: 
[0m09:02:52.849960 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:02:52.855113 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:02:52.856788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:02:53.499168 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m09:02:53.500207 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:02:53.728327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a9d5c50>]}
[0m09:02:53.729338 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:02:53.734358 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m09:02:53.734705 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.735116 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.735495 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.736050 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m09:02:53.737325 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m09:02:53.738564 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m09:02:53.739692 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m09:02:53.741038 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m09:02:53.742016 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m09:02:53.743448 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m09:02:53.744709 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m09:02:53.745860 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m09:02:53.747015 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.748515 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.749682 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.757780 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m09:02:53.764643 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m09:02:53.768179 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m09:02:53.772066 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m09:02:53.777580 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m09:02:53.778568 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m09:02:53.779070 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m09:02:53.779403 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m09:02:53.827489 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m09:02:53.828068 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m09:02:53.851716 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m09:02:53.858596 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m09:02:53.933183 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m09:02:53.934676 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:02:54.152322 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m09:02:54.153664 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m09:02:54.154833 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m09:02:54.159867 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m09:02:54.160491 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:02:54.161284 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m09:02:54.370648 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6923a34-c577-44dd-b997-85fd21cd509c&page=queryresults
[0m09:02:54.441687 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:293ccd08-85c5-4147-83ce-6594f1c73c86&page=queryresults
[0m09:02:54.481932 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:aa9af51f-d7d5-423b-804e-cd12e703d850&page=queryresults
[0m09:02:54.482568 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:59fc1ea1-e78f-42cd-bf0e-9d46f236fbb2&page=queryresults
[0m09:02:55.997230 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a799f90>]}
[0m09:02:55.998739 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m09:02:56.000818 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m09:02:56.001894 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.003167 [info ] [Thread-3 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m09:02:56.004397 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m09:02:56.005565 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.009769 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:02:56.016948 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:56.021384 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m09:02:56.254285 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:02:56.255329 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002aa03c10>]}
[0m09:02:56.258163 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.51s]
[0m09:02:56.260890 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m09:02:56.265466 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m09:02:56.308142 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00283a4350>]}
[0m09:02:56.309167 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.56s]
[0m09:02:56.310601 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m09:02:56.321177 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f002a7ea350>]}
[0m09:02:56.322610 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.58s]
[0m09:02:56.324235 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m09:02:56.536349 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d34e8e4e-03a9-4c73-8223-06ff0091a353&page=queryresults
[0m09:02:58.336631 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '330823d6-ff0a-4567-87ad-72d7c9342a21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00283bc6d0>]}
[0m09:02:58.337669 [info ] [Thread-3 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.33s]
[0m09:02:58.339068 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m09:02:58.341586 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:02:58.344499 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:02:58.346593 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m09:02:58.347619 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m09:02:58.348772 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m09:02:58.349562 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m09:02:58.350458 [info ] [MainThread]: 
[0m09:02:58.351800 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.50 seconds (5.50s).
[0m09:02:58.354845 [debug] [MainThread]: Command end result
[0m09:02:58.389635 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:02:58.393696 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:02:58.402108 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:02:58.402813 [info ] [MainThread]: 
[0m09:02:58.403912 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:02:58.404872 [info ] [MainThread]: 
[0m09:02:58.405898 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m09:02:58.407909 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.9183664, "process_in_blocks": "0", "process_kernel_time": 0.252014, "process_mem_max_rss": "225460", "process_out_blocks": "0", "process_user_time": 3.659243}
[0m09:02:58.409070 [debug] [MainThread]: Command `dbt run` succeeded at 09:02:58.408936 after 6.92 seconds
[0m09:02:58.410072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c5d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0058c5fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f005c400b90>]}
[0m09:02:58.411296 [debug] [MainThread]: Flushing usage events
[0m09:02:59.905363 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:05:40.652242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d047210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d09f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0d09f910>]}


============================== 09:05:40.655139 | 69f36ca5-b52f-4434-9df8-c01e6bfa18b1 ==============================
[0m09:05:40.655139 [info ] [MainThread]: Running with dbt=1.9.0
[0m09:05:40.657692 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:05:41.221983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadf7d8090>]}
[0m09:05:41.272996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0f2a18d0>]}
[0m09:05:41.274088 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m09:05:41.341978 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m09:05:41.506980 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:05:41.508246 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/sources.yml
[0m09:05:41.843912 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m09:05:41.857778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadf1e1210>]}
[0m09:05:41.924061 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:05:41.929959 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:05:41.945913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadee1c650>]}
[0m09:05:41.947028 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m09:05:41.948225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadecb8d90>]}
[0m09:05:41.951359 [info ] [MainThread]: 
[0m09:05:41.952641 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:05:41.953677 [info ] [MainThread]: 
[0m09:05:41.954813 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:05:41.959141 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m09:05:41.959976 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:05:42.505924 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m09:05:42.508689 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:05:42.705898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadee4bd50>]}
[0m09:05:42.707070 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:05:42.711777 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m09:05:42.712149 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.712530 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.712974 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.713593 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m09:05:42.714723 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m09:05:42.715762 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m09:05:42.716752 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m09:05:42.717724 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m09:05:42.718797 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m09:05:42.719745 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m09:05:42.720696 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m09:05:42.721593 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m09:05:42.722431 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.723343 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.724209 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.733091 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m09:05:42.737167 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m09:05:42.742361 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m09:05:42.747988 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m09:05:42.757199 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m09:05:42.758157 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m09:05:42.759121 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m09:05:42.759747 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m09:05:42.808084 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:05:42.809762 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m09:05:42.812481 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m09:05:42.815776 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m09:05:43.112639 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m09:05:43.113519 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m09:05:43.115071 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m09:05:43.116180 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m09:05:43.122014 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m09:05:43.122620 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m09:05:43.125599 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:05:43.127344 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m09:05:43.421019 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dc41b09a-2c91-4117-94e1-03dc32416fb4&page=queryresults
[0m09:05:43.421995 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2ebf480d-6083-4b76-b06f-cc075be5146f&page=queryresults
[0m09:05:43.445782 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f0f01d8c-25fa-49c7-abcb-197fde24211b&page=queryresults
[0m09:05:43.792253 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2a8b8531-8b06-4a7c-90b5-eb8b68f29216&page=queryresults
[0m09:05:43.793595 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2a8b8531-8b06-4a7c-90b5-eb8b68f29216&page=queryresults
[0m09:05:43.797989 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m09:05:43.800027 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc2c6610>]}
[0m09:05:43.800929 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.08s]
[0m09:05:43.802058 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m09:05:43.802775 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.803259 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m09:05:43.803975 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m09:05:43.806136 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m09:05:43.806851 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.811173 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:05:43.817349 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:43.821184 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:05:44.027398 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m09:05:44.035178 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m09:05:44.295538 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1650f28a-0e0d-472d-9078-a9b6e4b6dc61&page=queryresults
[0m09:05:44.982314 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc1a4910>]}
[0m09:05:44.984122 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.26s]
[0m09:05:44.985539 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m09:05:45.233156 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feac6ec44d0>]}
[0m09:05:45.235443 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.51s]
[0m09:05:45.237945 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m09:05:45.255788 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc2c0210>]}
[0m09:05:45.257290 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.54s]
[0m09:05:45.258591 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m09:05:46.947955 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69f36ca5-b52f-4434-9df8-c01e6bfa18b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feadc298f50>]}
[0m09:05:46.949453 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.14s]
[0m09:05:46.950578 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m09:05:46.952496 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:05:46.955351 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:05:46.955931 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m09:05:46.956816 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m09:05:46.957511 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m09:05:46.958173 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m09:05:46.959013 [info ] [MainThread]: 
[0m09:05:46.959783 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.00 seconds (5.00s).
[0m09:05:46.961654 [debug] [MainThread]: Command end result
[0m09:05:46.996389 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m09:05:47.001341 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m09:05:47.010074 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m09:05:47.010829 [info ] [MainThread]: 
[0m09:05:47.012168 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m09:05:47.013214 [info ] [MainThread]: 
[0m09:05:47.014350 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m09:05:47.015429 [info ] [MainThread]: 
[0m09:05:47.016467 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m09:05:47.018282 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.4130325, "process_in_blocks": "0", "process_kernel_time": 0.23354, "process_mem_max_rss": "228600", "process_out_blocks": "0", "process_user_time": 3.564031}
[0m09:05:47.019699 [debug] [MainThread]: Command `dbt run` failed at 09:05:47.019516 after 6.41 seconds
[0m09:05:47.020730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb0cec76d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb10995290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb10995390>]}
[0m09:05:47.021595 [debug] [MainThread]: Flushing usage events
[0m09:05:48.408742 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:47:05.225716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28ee70d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f293fc950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f29cad5d0>]}


============================== 10:47:05.228612 | 70065145-3523-41bc-992e-7d6e2fb95346 ==============================
[0m10:47:05.228612 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:47:05.230662 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --models dim_customer', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:47:05.808886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb096f50>]}
[0m10:47:05.852676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb152550>]}
[0m10:47:05.854086 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:47:05.916922 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:47:06.076192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:47:06.077099 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m10:47:06.328828 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m10:47:06.341285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb10ae90>]}
[0m10:47:06.413539 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:06.418740 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:06.434100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb0b46d0>]}
[0m10:47:06.435339 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:47:06.436370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '70065145-3523-41bc-992e-7d6e2fb95346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efb08f350>]}
[0m10:47:06.438724 [info ] [MainThread]: 
[0m10:47:06.439927 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:47:06.441276 [info ] [MainThread]: 
[0m10:47:06.442827 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:47:06.444437 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:06.445411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:17.822829 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m10:47:17.823799 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3efac27490>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m10:47:17.825410 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:47:17.829274 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:47:17.830451 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m10:47:17.831838 [info ] [MainThread]: 
[0m10:47:17.832922 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 11.39 seconds (11.39s).
[0m10:47:17.834442 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3efac27490>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m10:47:17.836759 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.658774, "process_in_blocks": "0", "process_kernel_time": 0.222013, "process_mem_max_rss": "214436", "process_out_blocks": "0", "process_user_time": 3.037542}
[0m10:47:17.838187 [debug] [MainThread]: Command `dbt run` failed at 10:47:17.837949 after 12.66 seconds
[0m10:47:17.839805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28f676d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f28f67550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3efac01090>]}
[0m10:47:17.840947 [debug] [MainThread]: Flushing usage events
[0m10:47:19.128927 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:47:29.890639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0d8d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0db390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010b0d9e50>]}


============================== 10:47:29.893103 | aed52596-fa5c-42f7-9590-4cbae6145803 ==============================
[0m10:47:29.893103 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:47:29.894280 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:47:30.446491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd2a1150>]}
[0m10:47:30.492198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010d3657d0>]}
[0m10:47:30.493549 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:47:30.565273 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:47:30.718687 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:47:30.719554 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:47:30.724595 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m10:47:30.749674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd336150>]}
[0m10:47:30.865414 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:30.873196 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:30.890421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd47add0>]}
[0m10:47:30.891309 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:47:30.893053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd470150>]}
[0m10:47:30.896264 [info ] [MainThread]: 
[0m10:47:30.897417 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:47:30.898724 [info ] [MainThread]: 
[0m10:47:30.900159 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:47:30.904676 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:30.905776 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:47:30.906319 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:30.907107 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:31.889457 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:47:31.890522 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m10:47:31.900627 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m10:47:31.901549 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:32.742313 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:8f19e5ce-566a-4a7d-b456-cfa1f1e47693&page=queryresults
[0m10:47:33.686668 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source)
[0m10:47:33.687280 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:47:33.687978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:33.688826 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:34.341070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010c8f6e90>]}
[0m10:47:34.342752 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:47:34.381884 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:47:34.382382 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.382793 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.383101 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.383898 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m10:47:34.386038 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m10:47:34.387942 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m10:47:34.389955 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m10:47:34.391547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m10:47:34.392633 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m10:47:34.393747 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m10:47:34.395249 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m10:47:34.396334 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:47:34.397367 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.398488 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.399620 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.413776 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:47:34.419657 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:47:34.423768 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:47:34.428177 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:47:34.434463 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:47:34.435678 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:47:34.436226 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:47:34.447262 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:47:34.487731 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:47:34.489182 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:47:34.513163 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:47:34.515725 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:47:34.567791 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m10:47:34.592349 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:47:34.875333 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:47:34.876068 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:47:34.877706 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:47:34.883807 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:47:34.884528 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:47:34.886993 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:47:35.172063 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:13e00322-d17c-4cbe-b915-cdd8192c84c0&page=queryresults
[0m10:47:35.178874 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:11c1d713-f50b-42d6-b111-2ff54ccb4fbb&page=queryresults
[0m10:47:35.277297 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5a647779-f690-45dc-a73b-bc1b9fada9a4&page=queryresults
[0m10:47:35.530748 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:4c8fb234-d042-4ba4-a29f-6efbe0a2a0fe&page=queryresults
[0m10:47:35.531684 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:4c8fb234-d042-4ba4-a29f-6efbe0a2a0fe&page=queryresults
[0m10:47:35.536624 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:47:35.538460 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc2c1350>]}
[0m10:47:35.539431 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 1.15s]
[0m10:47:35.540637 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:47:35.541617 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.542159 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m10:47:35.543001 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m10:47:35.545726 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m10:47:35.546761 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.552090 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:47:35.558583 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:35.564042 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:47:35.829480 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:47:35.835495 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:47:36.117440 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d05ca8ae-accb-459a-94c2-588490c5f08b&page=queryresults
[0m10:47:36.856692 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dd07cf10>]}
[0m10:47:36.858301 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.46s]
[0m10:47:36.859676 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:47:37.043756 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc38f510>]}
[0m10:47:37.045100 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.65s]
[0m10:47:37.046657 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:47:37.059635 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc417bd0>]}
[0m10:47:37.060893 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.66s]
[0m10:47:37.062248 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:47:37.944995 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aed52596-fa5c-42f7-9590-4cbae6145803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00dc31cf10>]}
[0m10:47:37.946232 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.40s]
[0m10:47:37.947712 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:47:37.950505 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:47:37.954244 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:47:37.955193 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:47:37.956014 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:47:37.956828 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:47:37.957779 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:47:37.958864 [info ] [MainThread]: 
[0m10:47:37.959765 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.06 seconds (7.06s).
[0m10:47:37.961967 [debug] [MainThread]: Command end result
[0m10:47:37.998440 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:47:38.003288 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:47:38.010868 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:47:38.011659 [info ] [MainThread]: 
[0m10:47:38.012678 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:47:38.013896 [info ] [MainThread]: 
[0m10:47:38.014928 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_facts was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:47:38.016006 [info ] [MainThread]: 
[0m10:47:38.017065 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m10:47:38.018943 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 8.172857, "process_in_blocks": "0", "process_kernel_time": 0.264918, "process_mem_max_rss": "222012", "process_out_blocks": "0", "process_user_time": 3.505078}
[0m10:47:38.019974 [debug] [MainThread]: Command `dbt run` failed at 10:47:38.019806 after 8.17 seconds
[0m10:47:38.021093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea59290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea59250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f010ea58950>]}
[0m10:47:38.022004 [debug] [MainThread]: Flushing usage events
[0m10:47:39.351814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:38.348914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682575d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682ab2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b682571d0>]}


============================== 10:52:38.351342 | 17fc23dc-a634-49a0-8b4c-e41baa1e2b8a ==============================
[0m10:52:38.351342 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:52:38.352826 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:38.432436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17fc23dc-a634-49a0-8b4c-e41baa1e2b8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6815fc90>]}
[0m10:52:38.503026 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.2023951, "process_in_blocks": "0", "process_kernel_time": 0.112961, "process_mem_max_rss": "89976", "process_out_blocks": "0", "process_user_time": 0.90369}
[0m10:52:38.504197 [debug] [MainThread]: Command `dbt clean` succeeded at 10:52:38.504075 after 0.20 seconds
[0m10:52:38.505002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6ba74b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6bbd1210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8b6bbd1150>]}
[0m10:52:38.505804 [debug] [MainThread]: Flushing usage events
[0m10:52:42.509533 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:52:43.744737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c806c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565cbda1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c84efd0>]}


============================== 10:52:43.748318 | 1c121a38-fa0e-401a-bf84-3f9485a1f1ce ==============================
[0m10:52:43.748318 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:52:43.749671 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:52:43.851136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1c121a38-fa0e-401a-bf84-3f9485a1f1ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c6f9510>]}
[0m10:52:43.864771 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:52:43.867773 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:52:43.869966 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.18397304, "process_in_blocks": "0", "process_kernel_time": 0.111166, "process_mem_max_rss": "90236", "process_out_blocks": "0", "process_user_time": 1.081347}
[0m10:52:43.871359 [debug] [MainThread]: Command `dbt deps` succeeded at 10:52:43.871158 after 0.19 seconds
[0m10:52:43.872336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c67d450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c67f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f565c74aa10>]}
[0m10:52:43.873362 [debug] [MainThread]: Flushing usage events
[0m10:52:47.878066 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:53:07.696733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d955cabd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d96414610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d9561b410>]}


============================== 10:53:07.699204 | 47bb5eb9-06b2-4690-b05d-35c68e8e2196 ==============================
[0m10:53:07.699204 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:53:07.702056 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:53:08.253466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d677635d0>]}
[0m10:53:08.299888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d9784ced0>]}
[0m10:53:08.301660 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m10:53:08.370858 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m10:53:08.372926 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m10:53:08.374931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d67e93b50>]}
[0m10:53:09.371956 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project
- models.dbt_project.example
[0m10:53:09.383773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d673785d0>]}
[0m10:53:09.450207 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:53:09.456044 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:53:09.471319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6711ebd0>]}
[0m10:53:09.472528 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m10:53:09.473825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d672ecd90>]}
[0m10:53:09.476804 [info ] [MainThread]: 
[0m10:53:09.477944 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:53:09.478929 [info ] [MainThread]: 
[0m10:53:09.480210 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:53:09.485253 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:53:09.485904 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m10:53:09.486780 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:09.487601 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:10.386444 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:53:10.387554 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m10:53:10.396096 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m10:53:10.397067 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:11.471603 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:55bcf902-10df-41de-8cc7-ca93e88efd24&page=queryresults
[0m10:53:12.348471 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m10:53:12.349105 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m10:53:12.350164 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:12.351336 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:53:12.931753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d67301b10>]}
[0m10:53:12.932660 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:53:12.938348 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m10:53:12.938922 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.939270 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m10:53:12.939618 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m10:53:12.940152 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m10:53:12.941465 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m10:53:12.942901 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m10:53:12.944061 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m10:53:12.945068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m10:53:12.945836 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m10:53:12.946885 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m10:53:12.948200 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m10:53:12.949027 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m10:53:12.949889 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.950723 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m10:53:12.951532 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m10:53:12.959698 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m10:53:12.965147 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m10:53:12.970622 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m10:53:12.976305 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m10:53:12.989110 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m10:53:12.990432 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m10:53:13.017386 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m10:53:13.028498 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m10:53:13.046872 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:53:13.057133 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:53:13.064165 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m10:53:13.067779 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:53:13.147882 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m10:53:13.148872 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:53:13.365141 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m10:53:13.366434 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m10:53:13.367792 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m10:53:13.373978 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m10:53:13.376038 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m10:53:13.379635 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m10:53:13.418202 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce26da19-9c35-42c5-8056-6834abd4339a&page=queryresults
[0m10:53:13.419318 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce26da19-9c35-42c5-8056-6834abd4339a&page=queryresults
[0m10:53:13.424529 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:53:13.426879 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65eb5590>]}
[0m10:53:13.428449 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.48s]
[0m10:53:13.429664 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m10:53:13.430940 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.431452 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m10:53:13.432424 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m10:53:13.435175 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m10:53:13.436277 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.441153 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:53:13.447412 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:13.452686 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:53:13.601966 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ecabaf8b-6d28-4398-b1b4-2b39571d7780&page=queryresults
[0m10:53:13.663075 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:528b00ba-53cb-426f-9c07-6cbd1426c40f&page=queryresults
[0m10:53:13.686981 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m10:53:13.693072 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m10:53:13.698507 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:edc7d4ea-af0c-450d-8f04-313b9cf6e6bb&page=queryresults
[0m10:53:13.922791 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a49f2bc7-c3a9-4cb0-abd9-20081e720dd5&page=queryresults
[0m10:53:15.169462 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65dfa290>]}
[0m10:53:15.171789 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.22s]
[0m10:53:15.174204 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m10:53:15.258051 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65da0950>]}
[0m10:53:15.259586 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m10:53:15.261503 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m10:53:15.403681 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d65d1d790>]}
[0m10:53:15.404760 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.46s]
[0m10:53:15.406012 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m10:53:15.477536 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47bb5eb9-06b2-4690-b05d-35c68e8e2196', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d64431c90>]}
[0m10:53:15.479227 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.04s]
[0m10:53:15.481202 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m10:53:15.484080 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:53:15.487689 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:53:15.488387 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m10:53:15.489117 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m10:53:15.490038 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m10:53:15.490682 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m10:53:15.491520 [info ] [MainThread]: 
[0m10:53:15.492565 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.01 seconds (6.01s).
[0m10:53:15.494432 [debug] [MainThread]: Command end result
[0m10:53:15.529215 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m10:53:15.533998 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m10:53:15.541987 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m10:53:15.542915 [info ] [MainThread]: 
[0m10:53:15.544038 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m10:53:15.545046 [info ] [MainThread]: 
[0m10:53:15.546174 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m10:53:15.547147 [info ] [MainThread]: 
[0m10:53:15.548413 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m10:53:15.549979 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.898837, "process_in_blocks": "0", "process_kernel_time": 0.119124, "process_mem_max_rss": "228720", "process_out_blocks": "0", "process_user_time": 4.308323}
[0m10:53:15.551121 [debug] [MainThread]: Command `dbt run` failed at 10:53:15.551007 after 7.90 seconds
[0m10:53:15.552392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f49350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f490d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d98f49210>]}
[0m10:53:15.553604 [debug] [MainThread]: Flushing usage events
[0m10:53:16.835917 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:56:36.132311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1ef6610>]}


============================== 10:56:36.135252 | 343c2afa-6065-4787-854b-1d60fb94f933 ==============================
[0m10:56:36.135252 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:56:36.136883 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:56:36.225961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '343c2afa-6065-4787-854b-1d60fb94f933', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1dc2bd0>]}
[0m10:56:36.292894 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.22640637, "process_in_blocks": "0", "process_kernel_time": 0.060813, "process_mem_max_rss": "90112", "process_out_blocks": "0", "process_user_time": 1.094648}
[0m10:56:36.294064 [debug] [MainThread]: Command `dbt clean` succeeded at 10:56:36.293919 after 0.23 seconds
[0m10:56:36.294837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3f410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a1f3ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6a574cb90>]}
[0m10:56:36.295788 [debug] [MainThread]: Flushing usage events
[0m10:56:37.666836 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:56:39.006991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dd66a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3e15e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3ddb32d0>]}


============================== 10:56:39.010429 | 815e6183-476d-460e-8e95-5e318e25ca22 ==============================
[0m10:56:39.010429 [info ] [MainThread]: Running with dbt=1.9.0
[0m10:56:39.012443 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:56:39.099022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '815e6183-476d-460e-8e95-5e318e25ca22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dbe3390>]}
[0m10:56:39.110292 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:56:39.113055 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m10:56:39.114874 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16012742, "process_in_blocks": "0", "process_kernel_time": 0.121413, "process_mem_max_rss": "90280", "process_out_blocks": "0", "process_user_time": 1.092723}
[0m10:56:39.116214 [debug] [MainThread]: Command `dbt deps` succeeded at 10:56:39.116067 after 0.16 seconds
[0m10:56:39.117329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e3dd65e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e41530b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8e416b5250>]}
[0m10:56:39.118296 [debug] [MainThread]: Flushing usage events
[0m10:56:40.153294 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:02:00.047549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ee036d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880f1aa110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880edb1e50>]}


============================== 11:02:00.050164 | e8a77b28-d12e-46be-b714-e83cca3e5af3 ==============================
[0m11:02:00.050164 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:02:00.051707 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:02:00.650740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4f5f290>]}
[0m11:02:00.699282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8811009ed0>]}
[0m11:02:00.700711 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:02:00.771486 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:02:00.774396 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:02:00.775527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e521ab10>]}
[0m11:02:01.812567 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m11:02:01.823962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4c4e050>]}
[0m11:02:01.894366 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:02:01.901120 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:02:01.917186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e49aa790>]}
[0m11:02:01.918126 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:02:01.919315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8a77b28-d12e-46be-b714-e83cca3e5af3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4fd8550>]}
[0m11:02:01.922066 [info ] [MainThread]: 
[0m11:02:01.923180 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:02:01.924383 [info ] [MainThread]: 
[0m11:02:01.925751 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:02:01.931864 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:02:01.933483 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:02:01.934266 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:01.935251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:17.970612 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m11:02:17.971668 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12510>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:17.994033 [debug] [ThreadPool]: BigQuery adapter: Unhandled error while running:
list dataset
[0m11:02:17.995312 [debug] [ThreadPool]: BigQuery adapter: HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12d10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:17.996782 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:02:17.999626 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:02:18.000517 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m11:02:18.001860 [debug] [MainThread]: Connection 'list_purwadika' was properly closed.
[0m11:02:18.002718 [info ] [MainThread]: 
[0m11:02:18.004022 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 16.08 seconds (16.08s).
[0m11:02:18.005311 [error] [MainThread]: Encountered an error:
Runtime Error
  HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f87e4a12510>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[0m11:02:18.006975 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 18.019152, "process_in_blocks": "0", "process_kernel_time": 0.139877, "process_mem_max_rss": "218452", "process_out_blocks": "0", "process_user_time": 3.826657}
[0m11:02:18.008146 [debug] [MainThread]: Command `dbt run` failed at 11:02:18.008016 after 18.02 seconds
[0m11:02:18.009454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ec33a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880ec31750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e4b4ae50>]}
[0m11:02:18.010433 [debug] [MainThread]: Flushing usage events
[0m11:02:22.012970 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:05:22.851114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f293450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f292f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f292610>]}


============================== 11:05:22.853931 | 61ffee6b-2d10-4073-8f6b-890c3396aa61 ==============================
[0m11:05:22.853931 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:05:22.855687 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:05:22.864717 [info ] [MainThread]: dbt version: 1.9.0
[0m11:05:22.865689 [info ] [MainThread]: python version: 3.11.2
[0m11:05:22.867034 [info ] [MainThread]: python path: /usr/local/bin/python
[0m11:05:22.868130 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m11:05:23.438647 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m11:05:23.439783 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m11:05:23.440969 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m11:05:23.442227 [info ] [MainThread]: adapter type: bigquery
[0m11:05:23.443197 [info ] [MainThread]: adapter version: 1.9.0
[0m11:05:23.529769 [info ] [MainThread]: Configuration:
[0m11:05:23.530977 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:05:23.532248 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:05:23.533740 [info ] [MainThread]: Required dependencies:
[0m11:05:23.534889 [debug] [MainThread]: Executing "git --help"
[0m11:05:23.556307 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:05:23.557605 [debug] [MainThread]: STDERR: "b''"
[0m11:05:23.558535 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:05:23.559501 [info ] [MainThread]: Connection:
[0m11:05:23.560601 [info ] [MainThread]:   method: service-account
[0m11:05:23.561561 [info ] [MainThread]:   database: purwadika
[0m11:05:23.562445 [info ] [MainThread]:   execution_project: purwadika
[0m11:05:23.563618 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m11:05:23.564728 [info ] [MainThread]:   location: None
[0m11:05:23.565897 [info ] [MainThread]:   priority: None
[0m11:05:23.567202 [info ] [MainThread]:   maximum_bytes_billed: None
[0m11:05:23.568244 [info ] [MainThread]:   impersonate_service_account: None
[0m11:05:23.569213 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m11:05:23.570893 [info ] [MainThread]:   job_retries: 1
[0m11:05:23.572461 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m11:05:23.573736 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m11:05:23.574676 [info ] [MainThread]:   timeout_seconds: None
[0m11:05:23.575692 [info ] [MainThread]:   client_id: None
[0m11:05:23.576686 [info ] [MainThread]:   token_uri: None
[0m11:05:23.578282 [info ] [MainThread]:   dataproc_region: None
[0m11:05:23.579453 [info ] [MainThread]:   dataproc_cluster_name: None
[0m11:05:23.580522 [info ] [MainThread]:   gcs_bucket: None
[0m11:05:23.581577 [info ] [MainThread]:   dataproc_batch: None
[0m11:05:23.582855 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:05:23.640826 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m11:05:23.641831 [debug] [MainThread]: On debug: select 1 as id
[0m11:05:23.642730 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:05:24.460305 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f0762509-4051-45ae-997f-9681928cc276&page=queryresults
[0m11:05:25.208408 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:05:25.209796 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:05:25.211732 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.416877, "process_in_blocks": "0", "process_kernel_time": 0.178668, "process_mem_max_rss": "211840", "process_out_blocks": "0", "process_user_time": 2.799132}
[0m11:05:25.213225 [debug] [MainThread]: Command `dbt debug` succeeded at 11:05:25.213029 after 2.42 seconds
[0m11:05:25.214754 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m11:05:25.215781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f2df010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5f2df8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb31503210>]}
[0m11:05:25.216958 [debug] [MainThread]: Flushing usage events
[0m11:05:30.425424 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:05:34.071442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6033d2f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6037ca110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6033d2c50>]}


============================== 11:05:34.074281 | 46d3eba4-928d-4033-bfca-d452898145e4 ==============================
[0m11:05:34.074281 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:05:34.075384 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:05:34.676214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d555b350>]}
[0m11:05:34.743263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60562d6d0>]}
[0m11:05:34.744618 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:05:34.816693 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:05:34.892881 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:05:34.894050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff603aba910>]}
[0m11:05:35.918442 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.example
- models.dbt_project
[0m11:05:35.931881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d52f23d0>]}
[0m11:05:36.006038 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:05:36.012005 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:05:36.028391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f836d0>]}
[0m11:05:36.029438 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:05:36.030755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d51e6810>]}
[0m11:05:36.033749 [info ] [MainThread]: 
[0m11:05:36.034940 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:05:36.036305 [info ] [MainThread]: 
[0m11:05:36.037869 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:05:36.043288 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:05:36.044276 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:05:36.045081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:05:36.046060 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:05:37.411332 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:05:37.412513 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_facts"
"
[0m11:05:37.420573 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`
  
[0m11:05:37.421400 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:38.452477 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:b6be366f-1712-44de-82f8-3906d6bac1b2&page=queryresults
[0m11:05:39.638740 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_source)
[0m11:05:39.639487 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:05:39.640697 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:39.641995 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:05:40.287210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f47990>]}
[0m11:05:40.288748 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:05:40.296401 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:05:40.297374 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.298037 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.298772 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.299870 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m11:05:40.301772 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:05:40.303407 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:05:40.304989 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:05:40.306409 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:05:40.307702 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m11:05:40.309240 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:05:40.310422 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:05:40.311479 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:05:40.312500 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.313399 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.314189 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.324907 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:05:40.331556 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:05:40.336841 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:05:40.341997 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:05:40.359449 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:05:40.360666 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:05:40.366628 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:05:40.377925 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:05:40.440805 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:05:40.447373 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:05:40.467845 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:05:40.475621 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:05:40.578089 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:05:40.579760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:05:40.832321 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:05:40.842349 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:05:40.861408 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:05:40.862738 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:05:40.868415 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:05:40.870179 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:05:40.962738 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca333fcf-3ee4-425c-aed5-397d6732d428&page=queryresults
[0m11:05:40.963808 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca333fcf-3ee4-425c-aed5-397d6732d428&page=queryresults
[0m11:05:40.969089 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:05:40.971603 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d420c790>]}
[0m11:05:40.973065 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.66s]
[0m11:05:40.975576 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:05:40.976946 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:40.977592 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:05:40.978523 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:05:40.981744 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:05:40.983278 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:40.990984 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:05:40.997556 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:41.001914 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:05:41.218352 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1132dcd3-cfdc-492b-ab44-c76d4f13ac12&page=queryresults
[0m11:05:41.222373 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7622e553-68e2-4e93-88c4-c0e70b4ed595&page=queryresults
[0m11:05:41.235992 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1de0a322-c038-4cd8-868b-8a98b0cc6910&page=queryresults
[0m11:05:41.639530 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:05:41.646522 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:05:41.899625 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d27816b5-e3b2-46fc-b5d0-a87a08a8e27a&page=queryresults
[0m11:05:43.074203 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d43d1310>]}
[0m11:05:43.075642 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.77s]
[0m11:05:43.077283 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:05:43.129154 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d43fe010>]}
[0m11:05:43.130337 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.82s]
[0m11:05:43.131493 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:05:43.369516 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d4f66150>]}
[0m11:05:43.370763 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 3.06s]
[0m11:05:43.372060 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:05:43.511571 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3eba4-928d-4033-bfca-d452898145e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5d44f24d0>]}
[0m11:05:43.512972 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.53s]
[0m11:05:43.514422 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:05:43.517059 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:05:43.519992 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:05:43.520852 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:05:43.521697 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:05:43.522483 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:05:43.523261 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:05:43.524372 [info ] [MainThread]: 
[0m11:05:43.525306 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.49 seconds (7.49s).
[0m11:05:43.527931 [debug] [MainThread]: Command end result
[0m11:05:43.564131 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:05:43.568963 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:05:43.577240 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:05:43.578018 [info ] [MainThread]: 
[0m11:05:43.579374 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:05:43.580443 [info ] [MainThread]: 
[0m11:05:43.581544 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:05:43.582646 [info ] [MainThread]: 
[0m11:05:43.583973 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:05:43.586203 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.566539, "process_in_blocks": "0", "process_kernel_time": 0.296034, "process_mem_max_rss": "227232", "process_out_blocks": "0", "process_user_time": 4.489856}
[0m11:05:43.587638 [debug] [MainThread]: Command `dbt run` failed at 11:05:43.587446 after 9.57 seconds
[0m11:05:43.588695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60342e810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60342c410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff606d21250>]}
[0m11:05:43.589646 [debug] [MainThread]: Flushing usage events
[0m11:05:44.881480 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:20.164168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29f7b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29f7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d29ae610>]}


============================== 11:11:20.166778 | 352c0ca1-4001-4c01-8397-e327d13dd56a ==============================
[0m11:11:20.166778 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:20.168006 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:11:20.256342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '352c0ca1-4001-4c01-8397-e327d13dd56a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d28a86d0>]}
[0m11:11:20.323215 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.21705097, "process_in_blocks": "0", "process_kernel_time": 0.108743, "process_mem_max_rss": "90040", "process_out_blocks": "0", "process_user_time": 1.038006}
[0m11:11:20.324693 [debug] [MainThread]: Command `dbt clean` succeeded at 11:11:20.324463 after 0.22 seconds
[0m11:11:20.325986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6204b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6361210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39d6361150>]}
[0m11:11:20.327026 [debug] [MainThread]: Flushing usage events
[0m11:11:21.868659 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:23.209801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045262450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045778990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452b3b50>]}


============================== 11:11:23.212936 | 64c026e8-c291-4d03-8efd-bec7f523fa8d ==============================
[0m11:11:23.212936 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:23.214231 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:11:23.309690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '64c026e8-c291-4d03-8efd-bec7f523fa8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452610d0>]}
[0m11:11:23.322896 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:11:23.325257 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:11:23.327692 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.18529142, "process_in_blocks": "0", "process_kernel_time": 0.110625, "process_mem_max_rss": "90144", "process_out_blocks": "0", "process_user_time": 1.1666}
[0m11:11:23.329095 [debug] [MainThread]: Command `dbt deps` succeeded at 11:11:23.328846 after 0.19 seconds
[0m11:11:23.330160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd045296650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0452ee310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd048ab8b90>]}
[0m11:11:23.331476 [debug] [MainThread]: Flushing usage events
[0m11:11:24.397499 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:11:42.220268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3aff210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be5ca7650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b57810>]}


============================== 11:11:42.222861 | 951a46fd-64bb-4334-b063-fdffaa2d940c ==============================
[0m11:11:42.222861 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:11:42.224076 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:11:42.788686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5f83510>]}
[0m11:11:42.840116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5d66550>]}
[0m11:11:42.841411 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:11:42.908166 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:11:42.911147 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:11:42.912494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb6ed3e90>]}
[0m11:11:43.903632 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:11:43.915702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb58d9b50>]}
[0m11:11:43.987068 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:11:43.991622 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:11:44.006116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb56fafd0>]}
[0m11:11:44.007283 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:11:44.008917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb59b1f50>]}
[0m11:11:44.011723 [info ] [MainThread]: 
[0m11:11:44.012827 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:11:44.013752 [info ] [MainThread]: 
[0m11:11:44.015404 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:11:44.020107 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:11:44.020755 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:11:44.021466 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:11:44.022580 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:11:45.077803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:11:45.078467 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts)
[0m11:11:45.079375 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:11:45.080256 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:11:45.606745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb5e7fe10>]}
[0m11:11:45.607694 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:11:45.612544 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:11:45.613015 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.613496 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.613902 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.614544 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [RUN]
[0m11:11:45.616005 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:11:45.617378 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:11:45.618688 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:11:45.620434 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m11:11:45.621737 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m11:11:45.623315 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:11:45.624563 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:11:45.625680 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:11:45.626993 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.628245 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.629529 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.637783 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:11:45.643857 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:11:45.648064 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:11:45.652542 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:11:45.665391 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:11:45.665934 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:11:45.672126 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:11:45.709201 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:11:45.726323 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:11:45.729442 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:11:45.741602 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:11:45.746049 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:11:45.833003 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:11:45.834212 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:11:46.036427 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:11:46.037638 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:11:46.042761 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:11:46.046576 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:11:46.059044 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:11:46.065029 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:11:46.126871 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b5c24cd-c51b-4d72-b832-035d9b243967&page=queryresults
[0m11:11:46.127883 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b5c24cd-c51b-4d72-b832-035d9b243967&page=queryresults
[0m11:11:46.132732 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:11:46.134563 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb45ff490>]}
[0m11:11:46.135995 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.51s]
[0m11:11:46.137393 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:11:46.138452 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.138968 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:11:46.139848 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:11:46.142630 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:11:46.143737 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.149646 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:11:46.156025 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:46.159630 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:11:46.332943 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b96bca9f-1657-4cf3-a094-831b10087ded&page=queryresults
[0m11:11:46.336542 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:35953e6c-bc42-4ddd-b24d-18f83626225b&page=queryresults
[0m11:11:46.377864 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:dfd5267b-1445-4f2b-848e-1bc7b4effcb3&page=queryresults
[0m11:11:46.401031 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:11:46.408214 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:11:46.729761 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1b452ab-4521-43c1-9361-c7ea548ab8ed&page=queryresults
[0m11:11:48.233971 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb44f92d0>]}
[0m11:11:48.234544 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb44f8b50>]}
[0m11:11:48.237558 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.61s]
[0m11:11:48.239409 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.61s]
[0m11:11:48.240963 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:11:48.242361 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:11:48.279723 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb58f72d0>]}
[0m11:11:48.281245 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.66s]
[0m11:11:48.282955 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:11:48.296531 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '951a46fd-64bb-4334-b063-fdffaa2d940c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb46120d0>]}
[0m11:11:48.297992 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.15s]
[0m11:11:48.299640 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:11:48.302491 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:11:48.305778 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:11:48.306497 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:11:48.307274 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:11:48.308344 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:11:48.309371 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:11:48.310188 [info ] [MainThread]: 
[0m11:11:48.311066 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m11:11:48.313469 [debug] [MainThread]: Command end result
[0m11:11:48.348560 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:11:48.353288 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:11:48.362728 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:11:48.363757 [info ] [MainThread]: 
[0m11:11:48.364988 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:11:48.366078 [info ] [MainThread]: 
[0m11:11:48.367355 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_facts was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:11:48.368556 [info ] [MainThread]: 
[0m11:11:48.369628 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:11:48.371639 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1992674, "process_in_blocks": "0", "process_kernel_time": 0.298109, "process_mem_max_rss": "227780", "process_out_blocks": "0", "process_user_time": 4.204377}
[0m11:11:48.372981 [debug] [MainThread]: Command `dbt run` failed at 11:11:48.372826 after 6.20 seconds
[0m11:11:48.374238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b324d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3efa550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5be3b47810>]}
[0m11:11:48.375474 [debug] [MainThread]: Flushing usage events
[0m11:11:49.706061 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:12:25.320633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98aafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98aadd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f98ab150>]}


============================== 11:12:25.323756 | 2b240de7-a472-4645-b8df-4bdf24c599ea ==============================
[0m11:12:25.323756 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:12:25.325092 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:12:25.887941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d0be1b10>]}
[0m11:12:25.938949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fbaf9ed0>]}
[0m11:12:25.940241 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:12:26.007729 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:12:26.175082 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:12:26.176573 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/facts/dim_customer.sql
[0m11:12:26.436688 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:12:26.451352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cbba5810>]}
[0m11:12:26.525465 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:12:26.531183 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:12:26.545458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb6a19d0>]}
[0m11:12:26.546755 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:12:26.548077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb822890>]}
[0m11:12:26.550811 [info ] [MainThread]: 
[0m11:12:26.551901 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:12:26.553091 [info ] [MainThread]: 
[0m11:12:26.554544 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:12:26.559116 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:12:26.560109 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:12:34.211726 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:12:34.212503 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:12:34.470207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fa66f250>]}
[0m11:12:34.471056 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:12:34.475300 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:12:34.475679 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.475995 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.476297 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.476975 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:12:34.477920 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:12:34.478937 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:12:34.479946 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:12:34.480911 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:12:34.481748 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:12:34.482741 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:12:34.484178 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:12:34.485349 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:12:34.486270 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.487022 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.487777 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.495748 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:12:34.501918 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:12:34.506390 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:12:34.510269 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:12:34.515758 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:12:34.516234 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:12:34.516760 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:12:34.522763 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:12:34.565873 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:12:34.573741 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:12:34.592254 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:12:34.596978 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:12:34.670137 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_facts`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:12:34.671361 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:34.984724 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:12:34.985119 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:12:34.986380 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:12:34.992659 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:12:34.993482 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:12:34.995019 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:12:35.051475 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:58485596-4c07-4919-aba5-39d3708490dd&page=queryresults
[0m11:12:35.052612 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:58485596-4c07-4919-aba5-39d3708490dd&page=queryresults
[0m11:12:35.057574 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:12:35.059448 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c83cd1d0>]}
[0m11:12:35.060747 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.58s]
[0m11:12:35.062111 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:12:35.063052 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.063739 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:12:35.064818 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:12:35.067871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:12:35.069988 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.074579 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:12:35.080069 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:35.083419 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:35.244916 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b662c5d1-b248-487d-a215-5163d58cad88&page=queryresults
[0m11:12:35.342687 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:12:35.352437 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:12:35.355985 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:344f6acf-49ac-4c9d-a26e-faecba5d993b&page=queryresults
[0m11:12:35.387883 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f22020a1-4bf8-4992-9c40-613b8b4400d3&page=queryresults
[0m11:12:35.629978 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:66395169-37e2-4ed0-bea4-b525be61dcec&page=queryresults
[0m11:12:36.815843 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb5a6650>]}
[0m11:12:36.817069 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.33s]
[0m11:12:36.818448 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:12:36.933345 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1cb5f5590>]}
[0m11:12:36.939146 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m11:12:36.941234 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:12:37.223626 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c841a410>]}
[0m11:12:37.225240 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.74s]
[0m11:12:37.226891 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:12:37.458452 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b240de7-a472-4645-b8df-4bdf24c599ea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c848a750>]}
[0m11:12:37.459453 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.39s]
[0m11:12:37.460734 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:12:37.463097 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:12:37.466102 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:12:37.466934 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:12:37.467664 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:12:37.468464 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:12:37.469206 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:12:37.470360 [info ] [MainThread]: 
[0m11:12:37.471412 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 10.92 seconds (10.92s).
[0m11:12:37.473852 [debug] [MainThread]: Command end result
[0m11:12:37.512961 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:12:37.520492 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:12:37.529380 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:12:37.530390 [info ] [MainThread]: 
[0m11:12:37.531448 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:12:37.532708 [info ] [MainThread]: 
[0m11:12:37.534027 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_facts.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:12:37.535102 [info ] [MainThread]: 
[0m11:12:37.536267 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:12:37.538520 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.267568, "process_in_blocks": "0", "process_kernel_time": 0.23348, "process_mem_max_rss": "227292", "process_out_blocks": "0", "process_user_time": 3.583422}
[0m11:12:37.540330 [debug] [MainThread]: Command `dbt run` failed at 11:12:37.540085 after 12.27 seconds
[0m11:12:37.541902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f9725510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1f97275d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1fd1f55d0>]}
[0m11:12:37.543415 [debug] [MainThread]: Flushing usage events
[0m11:12:39.269721 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:27.443642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5d5eb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a6159e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5d5e910>]}


============================== 11:20:27.446031 | 9b67a5a3-0d8d-411c-a510-77a5b190e2f0 ==============================
[0m11:20:27.446031 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:27.447464 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m11:20:27.525330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b67a5a3-0d8d-411c-a510-77a5b190e2f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5db3f90>]}
[0m11:20:27.584287 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.18763956, "process_in_blocks": "0", "process_kernel_time": 0.078613, "process_mem_max_rss": "90040", "process_out_blocks": "0", "process_user_time": 0.943366}
[0m11:20:27.585554 [debug] [MainThread]: Command `dbt clean` succeeded at 11:20:27.585450 after 0.19 seconds
[0m11:20:27.586382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a615a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a5e6db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8a9590c10>]}
[0m11:20:27.587250 [debug] [MainThread]: Flushing usage events
[0m11:20:28.646025 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:29.854527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc06bef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc0a6a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc066b210>]}


============================== 11:20:29.857240 | e90511b4-1b19-43da-92b3-ff1550aa43eb ==============================
[0m11:20:29.857240 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:29.858571 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:20:29.953347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e90511b4-1b19-43da-92b3-ff1550aa43eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc06bfb50>]}
[0m11:20:29.965825 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:20:29.968839 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:20:29.971013 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1771441, "process_in_blocks": "0", "process_kernel_time": 0.079526, "process_mem_max_rss": "90148", "process_out_blocks": "0", "process_user_time": 1.063671}
[0m11:20:29.972289 [debug] [MainThread]: Command `dbt deps` succeeded at 11:20:29.972107 after 0.18 seconds
[0m11:20:29.973136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc3e64b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc059ae10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2cc0a6a190>]}
[0m11:20:29.974071 [debug] [MainThread]: Flushing usage events
[0m11:20:31.219106 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:20:33.980730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d229dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d622110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d621e90>]}


============================== 11:20:33.983266 | a771e0bb-ed61-46fe-a139-720c065cd1f3 ==============================
[0m11:20:33.983266 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:20:33.984569 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m11:20:34.566815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f37e1d0>]}
[0m11:20:34.614149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923f47e3d0>]}
[0m11:20:34.615591 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:20:34.685479 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:20:34.687614 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:20:34.688615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d08fa90>]}
[0m11:20:35.729350 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:20:35.740322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f077d90>]}
[0m11:20:35.817748 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:20:35.824563 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:20:35.841278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920ee024d0>]}
[0m11:20:35.842419 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:20:35.843517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920eff4fd0>]}
[0m11:20:35.846663 [info ] [MainThread]: 
[0m11:20:35.848101 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:20:35.849379 [info ] [MainThread]: 
[0m11:20:35.851115 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:20:35.858595 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:20:35.860301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:20:36.453988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:20:36.455136 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:20:36.695701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f3c9690>]}
[0m11:20:36.696687 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:20:36.702114 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:20:36.702501 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.702804 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.703113 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.703845 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:20:36.705257 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:20:36.707224 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:20:36.708730 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:20:36.709954 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:20:36.711035 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:20:36.712250 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:20:36.713205 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:20:36.714081 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:20:36.714867 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.715727 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.716642 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.725944 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:20:36.730154 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:20:36.734238 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:20:36.738111 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:20:36.747403 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:20:36.756381 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:20:36.779545 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:20:36.779929 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:20:36.851541 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:20:36.852982 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:20:36.855206 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:20:36.858156 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:20:36.872845 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m11:20:36.874934 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:20:36.875476 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:20:36.875985 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m11:20:36.876852 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:20:36.877592 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m11:20:36.880134 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:20:36.904900 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:20:37.369839 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6b52e01-2696-4ea6-9523-64de850e7ad8&page=queryresults
[0m11:20:37.388237 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6382486-ba08-46f2-8335-6610e6beb10c&page=queryresults
[0m11:20:37.421711 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b1777447-7bfc-4032-b9f5-ff862fe1a271&page=queryresults
[0m11:20:38.064083 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:00e7b0ef-594b-4484-b356-33d133c24926&page=queryresults
[0m11:20:38.065191 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:00e7b0ef-594b-4484-b356-33d133c24926&page=queryresults
[0m11:20:38.070635 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:20:38.072445 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c4c5f90>]}
[0m11:20:38.073881 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.36s]
[0m11:20:38.075365 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:20:38.076586 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.077162 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:20:38.078203 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:20:38.081383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:20:38.082594 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.087693 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:20:38.093370 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:38.098268 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:20:38.104465 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m11:20:38.105649 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:20:38.503930 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9fc61d43-09a8-4f16-bd7c-04550e44920f&page=queryresults
[0m11:20:39.102115 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c3f5450>]}
[0m11:20:39.104756 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.39s]
[0m11:20:39.106413 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:20:39.340020 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920c4d9a90>]}
[0m11:20:39.341390 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.63s]
[0m11:20:39.342718 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:20:39.360347 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920efcb2d0>]}
[0m11:20:39.361927 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.65s]
[0m11:20:39.363386 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:20:40.189894 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a771e0bb-ed61-46fe-a139-720c065cd1f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f920f0cc890>]}
[0m11:20:40.192303 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.11s]
[0m11:20:40.194044 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:20:40.196901 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:20:40.199773 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:20:40.200525 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:20:40.201387 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:20:40.202206 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:20:40.202856 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:20:40.203644 [info ] [MainThread]: 
[0m11:20:40.204832 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m11:20:40.207210 [debug] [MainThread]: Command end result
[0m11:20:40.238458 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:20:40.242663 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:20:40.251589 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:20:40.252487 [info ] [MainThread]: 
[0m11:20:40.253674 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:20:40.254787 [info ] [MainThread]: 
[0m11:20:40.255908 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:20:40.256898 [info ] [MainThread]: 
[0m11:20:40.257988 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:20:40.259969 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.3339143, "process_in_blocks": "0", "process_kernel_time": 0.209476, "process_mem_max_rss": "227272", "process_out_blocks": "0", "process_user_time": 4.279306}
[0m11:20:40.261109 [debug] [MainThread]: Command `dbt run` failed at 11:20:40.260953 after 6.34 seconds
[0m11:20:40.262139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d08f8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f923d22acd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9240b79110>]}
[0m11:20:40.263170 [debug] [MainThread]: Flushing usage events
[0m11:20:41.820755 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:29:56.540319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ea450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487e9d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ea610>]}


============================== 11:29:56.544016 | ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5 ==============================
[0m11:29:56.544016 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:29:56.545489 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:29:57.121455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1ac66c90>]}
[0m11:29:57.165259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4aa98750>]}
[0m11:29:57.166671 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:29:57.240947 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:29:57.313350 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:29:57.314733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d48ee2910>]}
[0m11:29:58.342206 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m11:29:58.355375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a60e890>]}
[0m11:29:58.440070 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:29:58.447031 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:29:58.468438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a3dbf10>]}
[0m11:29:58.469825 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:29:58.471833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a622d10>]}
[0m11:29:58.475310 [info ] [MainThread]: 
[0m11:29:58.476828 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:29:58.478305 [info ] [MainThread]: 
[0m11:29:58.480066 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:29:58.486059 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:29:58.487598 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:59.680488 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:29:59.681527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:29:59.923577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d487ff210>]}
[0m11:29:59.924538 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:29:59.929705 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:29:59.930226 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.930836 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.931245 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:29:59.931817 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:29:59.933046 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:29:59.934316 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:29:59.935803 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:29:59.937120 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:29:59.938440 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:29:59.939512 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:29:59.940606 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:29:59.941484 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:29:59.942579 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.943365 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.944245 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:29:59.952524 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:29:59.958464 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:29:59.962952 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:29:59.968267 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:29:59.974277 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:29:59.975295 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:29:59.981335 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:29:59.991581 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:30:00.021812 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:30:00.043121 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:30:00.053845 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:30:00.057226 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:30:00.131298 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:30:00.133422 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:00.332358 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:30:00.334040 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:30:00.338121 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:30:00.340543 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:30:00.360936 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:30:00.365280 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:30:00.647026 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d86aa73d-a630-4d34-9f1a-49826350d02e&page=queryresults
[0m11:30:00.649911 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f2fb1a3-ddeb-4695-8d7e-a6ed791adeea&page=queryresults
[0m11:30:00.663450 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6c1b27a-599d-49a8-a140-409e60da88a8&page=queryresults
[0m11:30:00.986754 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1467d589-0f46-4073-8c82-286e9a012290&page=queryresults
[0m11:30:00.988629 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1467d589-0f46-4073-8c82-286e9a012290&page=queryresults
[0m11:30:00.994584 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:30:00.997004 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a86d790>]}
[0m11:30:00.998075 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.06s]
[0m11:30:00.999252 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:30:01.000417 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.000933 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:30:01.002284 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:30:01.005060 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:30:01.006277 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.011150 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:30:01.018174 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:01.021974 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:01.257937 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:30:01.267681 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:30:01.538987 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2f58b09c-7625-4f60-929b-7ad2f4b9bc2d&page=queryresults
[0m11:30:02.244034 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a85c8d0>]}
[0m11:30:02.244911 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a3c0a50>]}
[0m11:30:02.246158 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m11:30:02.247660 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.31s]
[0m11:30:02.249052 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:30:02.250160 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:30:02.524172 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d1a439790>]}
[0m11:30:02.525662 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.58s]
[0m11:30:02.527230 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:30:03.094638 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed49ee63-15dd-48a1-bb5d-7672ccf4d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d18280c50>]}
[0m11:30:03.096520 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.09s]
[0m11:30:03.098403 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:30:03.101199 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:30:03.104463 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:30:03.105364 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:30:03.106211 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:30:03.106894 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:30:03.108831 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:30:03.110057 [info ] [MainThread]: 
[0m11:30:03.111554 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.63 seconds (4.63s).
[0m11:30:03.113928 [debug] [MainThread]: Command end result
[0m11:30:03.147483 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:30:03.151863 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:30:03.160322 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:30:03.161196 [info ] [MainThread]: 
[0m11:30:03.162282 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:30:03.163459 [info ] [MainThread]: 
[0m11:30:03.164644 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:30:03.166103 [info ] [MainThread]: 
[0m11:30:03.167099 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:30:03.169012 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6820965, "process_in_blocks": "0", "process_kernel_time": 0.219308, "process_mem_max_rss": "226096", "process_out_blocks": "0", "process_user_time": 4.256585}
[0m11:30:03.170354 [debug] [MainThread]: Command `dbt run` failed at 11:30:03.170209 after 6.68 seconds
[0m11:30:03.171440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d48847cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4c19d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d4c19d210>]}
[0m11:30:03.172615 [debug] [MainThread]: Flushing usage events
[0m11:30:04.723165 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:16.787903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708f0e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708fc8490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b136d0>]}


============================== 11:31:16.790503 | febe273f-97c8-4d1e-a3c5-1b5309a8ad37 ==============================
[0m11:31:16.790503 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:16.791783 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:31:16.872313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'febe273f-97c8-4d1e-a3c5-1b5309a8ad37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708a53350>]}
[0m11:31:16.943002 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20395628, "process_in_blocks": "0", "process_kernel_time": 0.100567, "process_mem_max_rss": "90060", "process_out_blocks": "0", "process_user_time": 1.00567}
[0m11:31:16.944342 [debug] [MainThread]: Command `dbt clean` succeeded at 11:31:16.944168 after 0.21 seconds
[0m11:31:16.945223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b674d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5708b67610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f570c308c10>]}
[0m11:31:16.946003 [debug] [MainThread]: Flushing usage events
[0m11:31:18.444590 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:19.597744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3e450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3ee10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb3e610>]}


============================== 11:31:19.600594 | 1e4a9a36-06ea-4465-9085-f4fc67040004 ==============================
[0m11:31:19.600594 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:19.602123 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:31:19.693590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e4a9a36-06ea-4465-9085-f4fc67040004', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfbc5a50>]}
[0m11:31:19.702885 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:31:19.705661 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m11:31:19.707187 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.1626803, "process_in_blocks": "0", "process_kernel_time": 0.1001, "process_mem_max_rss": "90184", "process_out_blocks": "0", "process_user_time": 1.001008}
[0m11:31:19.708434 [debug] [MainThread]: Command `dbt deps` succeeded at 11:31:19.708296 after 0.16 seconds
[0m11:31:19.709318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfb909d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfa6cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dfbc6e50>]}
[0m11:31:19.710130 [debug] [MainThread]: Flushing usage events
[0m11:31:20.735242 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:23.537188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d03edd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d08f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d523890>]}


============================== 11:31:23.540272 | 73b3fc82-725f-477e-919d-9ee5848fe7da ==============================
[0m11:31:23.540272 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:31:23.541492 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:31:24.129548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73f1d0a50>]}
[0m11:31:24.175174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76f2b63d0>]}
[0m11:31:24.176515 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:31:24.254757 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:31:24.258020 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:31:24.259904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73f946a90>]}
[0m11:31:25.274792 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:31:25.287905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee82050>]}
[0m11:31:25.360629 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:31:25.366480 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:31:25.383246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ec31590>]}
[0m11:31:25.384365 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:31:25.385720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee13150>]}
[0m11:31:25.388441 [info ] [MainThread]: 
[0m11:31:25.389516 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:31:25.390843 [info ] [MainThread]: 
[0m11:31:25.392273 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:31:25.397443 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:31:25.398444 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:25.953231 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:31:25.954095 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:31:26.191683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ee2dd10>]}
[0m11:31:26.192718 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:31:26.198018 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:31:26.198456 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.198856 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.199185 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.199944 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:31:26.201527 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:31:26.202695 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:31:26.203808 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:31:26.204911 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:31:26.206116 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:31:26.207273 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:31:26.208412 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:31:26.209404 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:31:26.210246 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.211117 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.211959 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.221437 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:31:26.227588 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:31:26.231827 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:31:26.236500 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:31:26.250849 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:31:26.251438 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:31:26.263176 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:31:26.263537 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:31:26.300317 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:31:26.308005 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:31:26.330526 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:31:26.333010 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:31:26.421902 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:31:26.422856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:31:26.648026 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:31:26.650380 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:31:26.651645 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:31:26.661727 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:31:26.664696 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:31:26.667607 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:31:26.953683 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e627a688-b717-4be2-921a-c1d386c5f7a7&page=queryresults
[0m11:31:26.964758 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:626ad3a7-5ec2-4afb-8657-1e44348cc223&page=queryresults
[0m11:31:27.131845 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0c64b30a-05d3-4f76-812e-2f8ecb112c93&page=queryresults
[0m11:31:27.132814 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0c64b30a-05d3-4f76-812e-2f8ecb112c93&page=queryresults
[0m11:31:27.137643 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m11:31:27.139426 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c29f650>]}
[0m11:31:27.140429 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.93s]
[0m11:31:27.141491 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:31:27.142368 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.142826 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m11:31:27.143649 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:31:27.145609 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:31:27.146613 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.151116 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:31:27.157023 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:27.160343 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:31:27.392380 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:31:27.397854 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:31:27.533938 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b7a29872-a4b8-4bda-a7a9-c9488af202d0&page=queryresults
[0m11:31:27.535141 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b7a29872-a4b8-4bda-a7a9-c9488af202d0&page=queryresults
[0m11:31:27.539058 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:31:27.540285 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73ef25490>]}
[0m11:31:27.541427 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.34s]
[0m11:31:27.542617 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:31:27.543817 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:31:27.708547 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6b2c0b6-363b-4479-86eb-a02749b1cef5&page=queryresults
[0m11:31:28.567941 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc726fb0f50>]}
[0m11:31:28.568638 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c21c650>]}
[0m11:31:28.569909 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.36s]
[0m11:31:28.571811 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.36s]
[0m11:31:28.572861 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:31:28.574116 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:31:29.254945 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73b3fc82-725f-477e-919d-9ee5848fe7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc73c211bd0>]}
[0m11:31:29.256190 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.11s]
[0m11:31:29.257463 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:31:29.259692 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:31:29.262780 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:31:29.263611 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m11:31:29.264414 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:31:29.265257 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:31:29.266061 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:31:29.267086 [info ] [MainThread]: 
[0m11:31:29.268095 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 3.87 seconds (3.87s).
[0m11:31:29.270300 [debug] [MainThread]: Command end result
[0m11:31:29.306391 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:31:29.310744 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:31:29.318935 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:31:29.319616 [info ] [MainThread]: 
[0m11:31:29.320607 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m11:31:29.321777 [info ] [MainThread]: 
[0m11:31:29.322694 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m11:31:29.323548 [info ] [MainThread]: 
[0m11:31:29.324854 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:31:29.325662 [info ] [MainThread]: 
[0m11:31:29.326777 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=0 TOTAL=5
[0m11:31:29.328661 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.852827, "process_in_blocks": "0", "process_kernel_time": 0.211902, "process_mem_max_rss": "230036", "process_out_blocks": "0", "process_user_time": 4.227959}
[0m11:31:29.329755 [debug] [MainThread]: Command `dbt run` failed at 11:31:29.329625 after 5.85 seconds
[0m11:31:29.330616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bbad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bb790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc76d0bbf10>]}
[0m11:31:29.331708 [debug] [MainThread]: Flushing usage events
[0m11:31:30.889761 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:32:28.758726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53e83e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edbf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edb7d0>]}


============================== 11:32:28.761494 | d0b34ed4-d42a-48ef-a4ca-757c75494cba ==============================
[0m11:32:28.761494 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:32:28.763028 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:32:29.350576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f26056990>]}
[0m11:32:29.402656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f560f9e10>]}
[0m11:32:29.403761 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:32:29.467202 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:32:29.615293 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:32:29.616167 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m11:32:29.862117 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:32:29.874187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25cbf250>]}
[0m11:32:29.946424 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:32:29.952012 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:32:29.966328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25b97510>]}
[0m11:32:29.967645 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:32:29.969098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25caf590>]}
[0m11:32:29.972076 [info ] [MainThread]: 
[0m11:32:29.973231 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:32:29.974416 [info ] [MainThread]: 
[0m11:32:29.975815 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:32:29.980270 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:32:29.981222 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:32:30.873793 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:32:30.874816 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:32:31.101657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25e6b3d0>]}
[0m11:32:31.102801 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:32:31.108242 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:32:31.108711 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.109201 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.109542 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.110126 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:32:31.111513 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:32:31.112736 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:32:31.114865 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:32:31.116877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:32:31.118347 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:32:31.119413 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:32:31.121163 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:32:31.122299 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:32:31.123237 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.124011 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.125347 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.134551 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:32:31.140042 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:32:31.145315 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:32:31.149604 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:32:31.154068 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:32:31.155135 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:32:31.161077 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:32:31.161446 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:32:31.199080 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:32:31.199558 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:32:31.223711 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:32:31.231045 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:32:31.314574 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:32:31.315558 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:32:31.530156 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:32:31.532487 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:32:31.534156 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:32:31.539096 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:32:31.540457 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:32:31.542348 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:32:31.799093 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:812b7ba0-7fe3-4f01-9131-e8a5e39837dd&page=queryresults
[0m11:32:31.809849 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4db3d389-ceb3-4800-a15f-05cb5ade3d14&page=queryresults
[0m11:32:31.921972 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2fc360aa-15ad-48a2-85bc-2445f6641954&page=queryresults
[0m11:32:32.368277 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5ba88e81-5ff8-4b0f-8969-7402cf217734&page=queryresults
[0m11:32:32.372431 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5ba88e81-5ff8-4b0f-8969-7402cf217734&page=queryresults
[0m11:32:32.380728 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:32:32.382760 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f2423f150>]}
[0m11:32:32.384072 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.27s]
[0m11:32:32.385546 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:32:32.386873 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.387401 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:32:32.388192 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:32:32.390369 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:32:32.391516 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.396610 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:32:32.403395 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:32.407603 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:32:32.672519 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:32:32.680353 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:32:32.933038 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:03c381a0-3fc2-4abb-bbaf-c9ed0e0c4a46&page=queryresults
[0m11:32:33.365948 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f25bcf210>]}
[0m11:32:33.369038 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.24s]
[0m11:32:33.370529 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:32:33.685075 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f2422bc50>]}
[0m11:32:33.686697 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.57s]
[0m11:32:33.688850 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:32:33.742697 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f241d53d0>]}
[0m11:32:33.746797 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.62s]
[0m11:32:33.749397 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:32:34.762458 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0b34ed4-d42a-48ef-a4ca-757c75494cba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f241fbcd0>]}
[0m11:32:34.763796 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.37s]
[0m11:32:34.765047 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:32:34.767131 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:32:34.770250 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:32:34.770955 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:32:34.771590 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:32:34.772307 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:32:34.772946 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:32:34.774337 [info ] [MainThread]: 
[0m11:32:34.775570 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.80 seconds (4.80s).
[0m11:32:34.777497 [debug] [MainThread]: Command end result
[0m11:32:34.811082 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:32:34.815173 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:32:34.823165 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:32:34.824056 [info ] [MainThread]: 
[0m11:32:34.825051 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:32:34.826157 [info ] [MainThread]: 
[0m11:32:34.827215 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:32:34.828033 [info ] [MainThread]: 
[0m11:32:34.829288 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:32:34.831162 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1225686, "process_in_blocks": "0", "process_kernel_time": 0.285821, "process_mem_max_rss": "226000", "process_out_blocks": "0", "process_user_time": 3.511524}
[0m11:32:34.832401 [debug] [MainThread]: Command `dbt run` failed at 11:32:34.832272 after 6.12 seconds
[0m11:32:34.833284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f53edb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f5427e210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f560e9190>]}
[0m11:32:34.834042 [debug] [MainThread]: Flushing usage events
[0m11:32:38.837431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:33:17.063249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfc9f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c0987990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfc9eb50>]}


============================== 11:33:17.066039 | 10575560-8b1f-4499-9aec-bb1a9e4d8e1c ==============================
[0m11:33:17.066039 [info ] [MainThread]: Running with dbt=1.9.0
[0m11:33:17.067494 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:33:17.722606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791fb5d90>]}
[0m11:33:17.775893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c1f2a3d0>]}
[0m11:33:17.777070 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m11:33:17.865471 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m11:33:17.946309 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m11:33:17.947560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c0aa43d0>]}
[0m11:33:19.042025 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m11:33:19.056027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791d09510>]}
[0m11:33:19.133452 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:33:19.139021 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:33:19.153720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f879187c210>]}
[0m11:33:19.154698 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m11:33:19.158501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791aac990>]}
[0m11:33:19.161634 [info ] [MainThread]: 
[0m11:33:19.162818 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:33:19.164082 [info ] [MainThread]: 
[0m11:33:19.165427 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:33:19.170550 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m11:33:19.171478 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:20.213818 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m11:33:20.214859 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:20.471933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791b72690>]}
[0m11:33:20.472967 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:33:20.478036 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m11:33:20.478402 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.478782 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.479072 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.479575 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m11:33:20.480825 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m11:33:20.482278 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m11:33:20.483390 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m11:33:20.484538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m11:33:20.485603 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m11:33:20.486577 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m11:33:20.487584 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m11:33:20.488621 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m11:33:20.489506 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.490298 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.491311 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.499441 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m11:33:20.506367 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m11:33:20.511362 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m11:33:20.516952 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m11:33:20.523007 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m11:33:20.523646 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m11:33:20.524098 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m11:33:20.529979 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m11:33:20.570112 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:33:20.579419 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:33:20.605013 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:33:20.605248 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m11:33:20.680230 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m11:33:20.681345 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:33:20.919728 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m11:33:20.921154 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m11:33:20.923024 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m11:33:20.928663 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m11:33:20.929348 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m11:33:20.933097 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m11:33:21.204316 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f19c1f4e-abe1-4a59-aa7a-49c90325e418&page=queryresults
[0m11:33:21.208815 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a2e4a738-9fb5-4e70-8ab4-660b9511f8f4&page=queryresults
[0m11:33:21.209455 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:54bc30b8-c0e4-4c55-9b62-076cc18ddd51&page=queryresults
[0m11:33:21.455132 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8804f99-cdf1-4573-bfa3-3d7e985a1fcc&page=queryresults
[0m11:33:21.456440 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a8804f99-cdf1-4573-bfa3-3d7e985a1fcc&page=queryresults
[0m11:33:21.461028 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:33:21.463527 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781f1c290>]}
[0m11:33:21.464948 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.98s]
[0m11:33:21.466103 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m11:33:21.467203 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.467813 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m11:33:21.468764 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m11:33:21.471720 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m11:33:21.472880 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.477840 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:33:21.485397 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:21.489400 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:33:21.742332 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m11:33:21.750118 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m11:33:22.001026 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:086fd329-0363-4989-b014-c834262650d3&page=queryresults
[0m11:33:22.762427 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781e5ce10>]}
[0m11:33:22.763846 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.27s]
[0m11:33:22.765328 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m11:33:23.005717 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8781f35f50>]}
[0m11:33:23.007378 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.52s]
[0m11:33:23.008674 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m11:33:23.018617 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f879192fc90>]}
[0m11:33:23.019901 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.53s]
[0m11:33:23.021728 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m11:33:23.521383 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10575560-8b1f-4499-9aec-bb1a9e4d8e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8791af0a10>]}
[0m11:33:23.522532 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.05s]
[0m11:33:23.523719 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m11:33:23.525823 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:33:23.528833 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:33:23.529574 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m11:33:23.530432 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m11:33:23.531397 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m11:33:23.532075 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m11:33:23.532881 [info ] [MainThread]: 
[0m11:33:23.534070 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.37 seconds (4.37s).
[0m11:33:23.535951 [debug] [MainThread]: Command end result
[0m11:33:23.570109 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m11:33:23.574183 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m11:33:23.581754 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m11:33:23.582822 [info ] [MainThread]: 
[0m11:33:23.584013 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:33:23.585231 [info ] [MainThread]: 
[0m11:33:23.586496 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m11:33:23.587460 [info ] [MainThread]: 
[0m11:33:23.588465 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:33:23.590500 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.589186, "process_in_blocks": "0", "process_kernel_time": 0.188083, "process_mem_max_rss": "230292", "process_out_blocks": "0", "process_user_time": 4.484314}
[0m11:33:23.592600 [debug] [MainThread]: Command `dbt run` failed at 11:33:23.592435 after 6.59 seconds
[0m11:33:23.593608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfcd1250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87c3791850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bfcefd50>]}
[0m11:33:23.594555 [debug] [MainThread]: Flushing usage events
[0m11:33:24.907413 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:01:23.041808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2caf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2cb110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c2cb1d0>]}


============================== 12:01:23.044429 | 2ba89753-9768-4f8a-b7f2-6b094f0fe7b7 ==============================
[0m12:01:23.044429 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:01:23.047094 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:01:23.680012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180f61add0>]}
[0m12:01:23.733319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183e544b90>]}
[0m12:01:23.734714 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:01:23.806481 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:01:23.877494 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:01:23.879576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e4b61d0>]}
[0m12:01:25.118524 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:01:25.132728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e108ad0>]}
[0m12:01:25.217637 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:01:25.225075 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:01:25.245321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de88150>]}
[0m12:01:25.246613 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:01:25.248027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180dea6e10>]}
[0m12:01:25.250992 [info ] [MainThread]: 
[0m12:01:25.252512 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:01:25.253530 [info ] [MainThread]: 
[0m12:01:25.255032 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:01:25.260178 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:01:25.261626 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:01:25.900015 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:01:25.903003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:01:26.170599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e59eb50>]}
[0m12:01:26.172041 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:01:26.178845 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:01:26.179249 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.179681 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.180075 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.180842 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:01:26.182127 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:01:26.183529 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:01:26.184622 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:01:26.186030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:01:26.187461 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:01:26.188740 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:01:26.189763 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:01:26.190717 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:01:26.191588 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.192329 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.193016 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.200604 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:01:26.206393 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:01:26.210531 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:01:26.215356 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:01:26.222096 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:01:26.223400 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:01:26.229143 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:01:26.239452 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:01:26.282538 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:01:26.292039 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:01:26.311097 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:01:26.314172 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:01:26.367791 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:01:26.393723 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:01:26.636590 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:01:26.645750 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:01:26.647494 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:01:26.654944 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:01:26.667413 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:01:26.675209 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:01:27.003611 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fd0297e6-69fc-4cae-b438-e94d1a05b14b&page=queryresults
[0m12:01:27.201704 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:79769e63-e351-4cae-994b-7c78c08b6e0e&page=queryresults
[0m12:01:27.218517 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:162be8a4-aaf8-4df4-9526-5d502be3b88c&page=queryresults
[0m12:01:27.310780 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db1111d1-93e1-44e8-b511-5a1989193ce3&page=queryresults
[0m12:01:27.311802 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db1111d1-93e1-44e8-b511-5a1989193ce3&page=queryresults
[0m12:01:27.316815 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:01:27.319057 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e08a610>]}
[0m12:01:27.320309 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.13s]
[0m12:01:27.321488 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:01:27.322630 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.323145 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:01:27.324294 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:01:27.326713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:01:27.327614 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.333135 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:01:27.344289 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:27.348855 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:01:27.615966 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:01:27.622104 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:01:27.919878 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ee21e364-b539-45b7-b799-5c4d9e7d44e3&page=queryresults
[0m12:01:28.917833 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180e0bccd0>]}
[0m12:01:28.919708 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.73s]
[0m12:01:28.921311 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:01:29.114175 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de82750>]}
[0m12:01:29.115991 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.92s]
[0m12:01:29.119290 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:01:29.119987 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180de88d10>]}
[0m12:01:29.121583 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.93s]
[0m12:01:29.122565 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:01:29.532469 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ba89753-9768-4f8a-b7f2-6b094f0fe7b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f180c56a390>]}
[0m12:01:29.533427 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.21s]
[0m12:01:29.534626 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:01:29.536609 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:01:29.539546 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:01:29.540232 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:01:29.540783 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:01:29.541380 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:01:29.542334 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:01:29.543443 [info ] [MainThread]: 
[0m12:01:29.544933 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m12:01:29.547106 [debug] [MainThread]: Command end result
[0m12:01:29.581528 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:01:29.585508 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:01:29.593859 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:01:29.594594 [info ] [MainThread]: 
[0m12:01:29.595587 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:01:29.596569 [info ] [MainThread]: 
[0m12:01:29.597515 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:01:29.598491 [info ] [MainThread]: 
[0m12:01:29.599484 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:01:29.601208 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.6118755, "process_in_blocks": "0", "process_kernel_time": 0.223851, "process_mem_max_rss": "226992", "process_out_blocks": "0", "process_user_time": 4.466847}
[0m12:01:29.602333 [debug] [MainThread]: Command `dbt run` failed at 12:01:29.602155 after 6.61 seconds
[0m12:01:29.603455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c6c6710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183c31b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183fc44a50>]}
[0m12:01:29.605309 [debug] [MainThread]: Flushing usage events
[0m12:01:31.039522 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:05:38.304484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da673810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dab4b990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da6735d0>]}


============================== 12:05:38.307713 | f9c893d6-2bde-4050-a55e-1e02c4b8110f ==============================
[0m12:05:38.307713 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:05:38.309552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:05:38.892751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9c893d6-2bde-4050-a55e-1e02c4b8110f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b088b690>]}
[0m12:05:38.938640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9c893d6-2bde-4050-a55e-1e02c4b8110f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0dc8cdf10>]}
[0m12:05:38.940110 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:05:39.013672 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:05:39.168197 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:05:39.169719 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:05:39.374120 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:05:39.376534 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1221713, "process_in_blocks": "0", "process_kernel_time": 0.229939, "process_mem_max_rss": "214568", "process_out_blocks": "0", "process_user_time": 2.869246}
[0m12:05:39.377851 [debug] [MainThread]: Command `dbt run` failed at 12:05:39.377708 after 1.12 seconds
[0m12:05:39.378768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da4d1710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0da4d0690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0b0840190>]}
[0m12:05:39.379824 [debug] [MainThread]: Flushing usage events
[0m12:05:40.687083 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:06:54.076428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de3150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3de2890>]}


============================== 12:06:54.078947 | a3ead25e-b070-4466-9b8a-0b6f3629b4eb ==============================
[0m12:06:54.078947 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:06:54.081273 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:06:54.168819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3ead25e-b070-4466-9b8a-0b6f3629b4eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc41da3d0>]}
[0m12:06:54.229774 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.1988981, "process_in_blocks": "0", "process_kernel_time": 0.097518, "process_mem_max_rss": "90112", "process_out_blocks": "0", "process_user_time": 0.955679}
[0m12:06:54.230916 [debug] [MainThread]: Command `dbt clean` succeeded at 12:06:54.230744 after 0.20 seconds
[0m12:06:54.231757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3d1bf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc3e15c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fc75d4c10>]}
[0m12:06:54.232854 [debug] [MainThread]: Flushing usage events
[0m12:06:55.275371 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:06:56.473248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fcaf490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6ae10>]}


============================== 12:06:56.476038 | 355a9074-6bed-498a-bab7-e6e35b153367 ==============================
[0m12:06:56.476038 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:06:56.477140 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:06:56.564639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '355a9074-6bed-498a-bab7-e6e35b153367', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fafd090>]}
[0m12:06:56.575520 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:06:56.578000 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:06:56.579474 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16740432, "process_in_blocks": "0", "process_kernel_time": 0.100529, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 1.025405}
[0m12:06:56.580816 [debug] [MainThread]: Command `dbt deps` succeeded at 12:06:56.580648 after 0.17 seconds
[0m12:06:56.581819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc9ce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f121fc6b010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1223434b90>]}
[0m12:06:56.582708 [debug] [MainThread]: Flushing usage events
[0m12:06:57.645667 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:07:00.830664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83737ff210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373cdf790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373cdf6d0>]}


============================== 12:07:00.833489 | be01370c-820b-4130-93b4-4aa76e8fbb28 ==============================
[0m12:07:00.833489 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:07:00.834617 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:07:01.418288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83459a6e10>]}
[0m12:07:01.470950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8375a51ed0>]}
[0m12:07:01.472459 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:07:01.558442 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:07:01.561315 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:07:01.562420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'be01370c-820b-4130-93b4-4aa76e8fbb28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8346fe6ed0>]}
[0m12:07:02.471392 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:07:02.472929 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6912909, "process_in_blocks": "0", "process_kernel_time": 0.180507, "process_mem_max_rss": "212280", "process_out_blocks": "0", "process_user_time": 3.610142}
[0m12:07:02.474009 [debug] [MainThread]: Command `dbt run` failed at 12:07:02.473886 after 1.69 seconds
[0m12:07:02.474781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373663450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8373663910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8345f49410>]}
[0m12:07:02.475586 [debug] [MainThread]: Flushing usage events
[0m12:07:03.520886 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:18.671457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d36a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d36890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d368d0>]}


============================== 12:08:18.674089 | 3ce10335-4778-4cac-9a10-29aae94e2109 ==============================
[0m12:08:18.674089 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:18.675315 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:08:18.761271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3ce10335-4778-4cac-9a10-29aae94e2109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8c73510>]}
[0m12:08:18.789072 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.1728333, "process_in_blocks": "0", "process_kernel_time": 0.08973, "process_mem_max_rss": "90128", "process_out_blocks": "0", "process_user_time": 1.016945}
[0m12:08:18.790539 [debug] [MainThread]: Command `dbt clean` succeeded at 12:08:18.790425 after 0.17 seconds
[0m12:08:18.791706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d69290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56e8d69b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56ec685110>]}
[0m12:08:18.793608 [debug] [MainThread]: Flushing usage events
[0m12:08:20.093374 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:21.263507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef476f050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef47c2fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef4b6a0d0>]}


============================== 12:08:21.266440 | d910b610-cd9a-4cdc-8642-8e8bab061d93 ==============================
[0m12:08:21.266440 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:21.267776 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:08:21.355016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd910b610-cd9a-4cdc-8642-8e8bab061d93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef466c350>]}
[0m12:08:21.366077 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:08:21.368873 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:08:21.370410 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16112548, "process_in_blocks": "0", "process_kernel_time": 0.050841, "process_mem_max_rss": "90184", "process_out_blocks": "0", "process_user_time": 1.057495}
[0m12:08:21.371464 [debug] [MainThread]: Command `dbt deps` succeeded at 12:08:21.371321 after 0.16 seconds
[0m12:08:21.372222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef47c3110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef471b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef7fc8b90>]}
[0m12:08:21.373043 [debug] [MainThread]: Flushing usage events
[0m12:08:22.411523 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:08:26.840281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba1e2090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba2377d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba237550>]}


============================== 12:08:26.842899 | ca4c587d-64de-4d11-9d71-104282f79f41 ==============================
[0m12:08:26.842899 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:08:26.844168 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:08:27.440523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f089058b4d0>]}
[0m12:08:27.489054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08bc492310>]}
[0m12:08:27.490483 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:08:27.566023 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:08:27.568812 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:08:27.569792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ca4c587d-64de-4d11-9d71-104282f79f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba239c90>]}
[0m12:08:28.466267 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m12:08:28.468284 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6833, "process_in_blocks": "0", "process_kernel_time": 0.178624, "process_mem_max_rss": "212036", "process_out_blocks": "0", "process_user_time": 3.572497}
[0m12:08:28.470348 [debug] [MainThread]: Command `dbt run` failed at 12:08:28.470195 after 1.69 seconds
[0m12:08:28.471674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba23b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0890253a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08ba23b9d0>]}
[0m12:08:28.472719 [debug] [MainThread]: Flushing usage events
[0m12:08:29.525590 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:10:05.913438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b92bec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b9307590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b979f750>]}


============================== 12:10:05.916133 | 68d81414-eb80-436b-8f13-72f9f9356c39 ==============================
[0m12:10:05.916133 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:10:05.920392 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:10:06.493126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b5430d0>]}
[0m12:10:06.543156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bb51a1d0>]}
[0m12:10:06.545057 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:10:06.611318 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:10:06.613544 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:10:06.614389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b268c90>]}
[0m12:10:07.615662 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:10:07.627172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b177f90>]}
[0m12:10:07.696145 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:10:07.701545 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:10:07.716025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38aec4d10>]}
[0m12:10:07.717143 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:10:07.718269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38aee3710>]}
[0m12:10:07.720782 [info ] [MainThread]: 
[0m12:10:07.722121 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:10:07.723205 [info ] [MainThread]: 
[0m12:10:07.724862 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:10:07.731481 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:10:07.732627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:08.346235 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:10:08.347658 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:10:08.610951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b0ba0d0>]}
[0m12:10:08.612421 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:10:08.619143 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:10:08.619599 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.620004 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.620504 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.621248 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:10:08.622600 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:10:08.624011 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:10:08.625412 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:10:08.626773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:10:08.627862 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:10:08.628841 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:10:08.629920 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:10:08.630809 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:10:08.631794 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.632768 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.633627 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.642909 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:10:08.650212 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:10:08.654891 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:10:08.659401 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:10:08.673388 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:10:08.673943 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:10:08.685425 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:10:08.714156 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:10:08.717154 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:10:08.736582 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:10:08.748058 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:10:08.751051 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:10:08.836389 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:10:08.837254 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:09.051461 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:10:09.052854 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:10:09.058874 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:10:09.061367 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:10:09.077703 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:10:09.082892 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:10:09.440854 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a77580ae-74d7-4082-945e-1557dcd44eb3&page=queryresults
[0m12:10:09.444775 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5de3a9cf-f8f8-4fd6-927c-73b22a522df2&page=queryresults
[0m12:10:09.445230 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f11cbfee-0399-46d4-91a6-108a550c3f25&page=queryresults
[0m12:10:09.660010 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6e52364-52f9-4897-a96e-199f121bf859&page=queryresults
[0m12:10:09.661133 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f6e52364-52f9-4897-a96e-199f121bf859&page=queryresults
[0m12:10:09.665395 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:10:09.667377 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3885b8350>]}
[0m12:10:09.668387 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 1.04s]
[0m12:10:09.670203 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:10:09.671349 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.671869 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:10:09.672662 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:10:09.675555 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:10:09.676387 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.681006 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:10:09.686430 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:09.690206 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:10:09.951947 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:10:09.959043 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:10:10.237203 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:86441706-7148-489f-9571-02540b89f3e9&page=queryresults
[0m12:10:11.054244 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3882d1110>]}
[0m12:10:11.055069 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd38b05e790>]}
[0m12:10:11.056035 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.43s]
[0m12:10:11.057364 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.43s]
[0m12:10:11.058794 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:10:11.059985 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:10:11.074131 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388517dd0>]}
[0m12:10:11.075411 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m12:10:11.076808 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:10:12.113754 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68d81414-eb80-436b-8f13-72f9f9356c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd388499850>]}
[0m12:10:12.115368 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.44s]
[0m12:10:12.116850 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:10:12.120018 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:10:12.123544 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:10:12.124481 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:10:12.125629 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:10:12.126520 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:10:12.127419 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:10:12.128389 [info ] [MainThread]: 
[0m12:10:12.129362 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.40 seconds (4.40s).
[0m12:10:12.131340 [debug] [MainThread]: Command end result
[0m12:10:12.173739 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:10:12.178852 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:10:12.188667 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:10:12.189541 [info ] [MainThread]: 
[0m12:10:12.190646 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:10:12.191954 [info ] [MainThread]: 
[0m12:10:12.193119 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:10:12.194426 [info ] [MainThread]: 
[0m12:10:12.195568 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:10:12.197869 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.334941, "process_in_blocks": "0", "process_kernel_time": 0.357176, "process_mem_max_rss": "227504", "process_out_blocks": "0", "process_user_time": 4.010581}
[0m12:10:12.199660 [debug] [MainThread]: Command `dbt run` failed at 12:10:12.199414 after 6.34 seconds
[0m12:10:12.200837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b99a1f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bcc0d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3bcc0c910>]}
[0m12:10:12.202260 [debug] [MainThread]: Flushing usage events
[0m12:10:13.536417 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:35.168713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4887bb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48c70190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb488cfb50>]}


============================== 12:11:35.171253 | 47c6053b-faf4-41c5-a733-a1dd39b8a577 ==============================
[0m12:11:35.171253 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:35.176483 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:11:35.256286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47c6053b-faf4-41c5-a733-a1dd39b8a577', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb488d2210>]}
[0m12:11:35.314893 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19363533, "process_in_blocks": "0", "process_kernel_time": 0.08905, "process_mem_max_rss": "90032", "process_out_blocks": "0", "process_user_time": 0.959763}
[0m12:11:35.315982 [debug] [MainThread]: Command `dbt clean` succeeded at 12:11:35.315862 after 0.19 seconds
[0m12:11:35.316715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48c72950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb48766950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb4c044c10>]}
[0m12:11:35.317586 [debug] [MainThread]: Flushing usage events
[0m12:11:36.402937 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:37.603564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc71b090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dcbd0490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc71bdd0>]}


============================== 12:11:37.606573 | 684b4dc2-2ab3-424a-8bde-28c45ccc22ee ==============================
[0m12:11:37.606573 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:37.608495 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:11:37.691974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '684b4dc2-2ab3-424a-8bde-28c45ccc22ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc65ae10>]}
[0m12:11:37.702257 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:11:37.704740 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:11:37.706480 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15209816, "process_in_blocks": "0", "process_kernel_time": 0.111289, "process_mem_max_rss": "90192", "process_out_blocks": "0", "process_user_time": 0.991485}
[0m12:11:37.707620 [debug] [MainThread]: Command `dbt deps` succeeded at 12:11:37.707487 after 0.15 seconds
[0m12:11:37.708400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dc76edd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dff10c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25dcb163d0>]}
[0m12:11:37.709156 [debug] [MainThread]: Flushing usage events
[0m12:11:38.942306 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:11:41.650625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed506d7310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed513b7990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed506d6fd0>]}


============================== 12:11:41.653819 | 073d100a-dfe2-4ee1-9503-299194de87b3 ==============================
[0m12:11:41.653819 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:11:41.655146 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:11:42.258854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed228a73d0>]}
[0m12:11:42.309621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed52930bd0>]}
[0m12:11:42.310934 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:11:42.381136 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:11:42.385700 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:11:42.386707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed50bb7790>]}
[0m12:11:43.508970 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:11:43.519654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed22609690>]}
[0m12:11:43.598261 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:11:43.605464 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:11:43.621321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222da6d0>]}
[0m12:11:43.622368 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:11:43.623326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222fe110>]}
[0m12:11:43.626204 [info ] [MainThread]: 
[0m12:11:43.627503 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:11:43.628455 [info ] [MainThread]: 
[0m12:11:43.629659 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:11:43.633839 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:11:43.635054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:11:44.154201 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:11:44.155576 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:11:44.401719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed22512cd0>]}
[0m12:11:44.402882 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:11:44.410050 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:11:44.410402 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.410831 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.411275 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.411854 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:11:44.413065 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:11:44.414307 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:11:44.415469 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:11:44.416435 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:11:44.417560 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:11:44.418619 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:11:44.419483 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:11:44.420249 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:11:44.421223 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.422172 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.423786 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.432352 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:11:44.438179 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:11:44.442372 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:11:44.446291 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:11:44.458565 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:11:44.459090 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:11:44.465786 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:11:44.475922 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:11:44.519929 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:11:44.532109 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:11:44.541641 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:11:44.545307 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:11:44.628486 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:11:44.629488 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:11:44.848938 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:11:44.850431 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:11:44.851554 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:11:44.862853 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:11:44.865903 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:11:44.869830 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:11:45.016089 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:53a73ffb-79b6-48c9-8489-6a88a8382c0e&page=queryresults
[0m12:11:45.102723 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:197f5a52-0a08-4a33-8bb6-39402abe47cd&page=queryresults
[0m12:11:45.108728 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:313f6ff8-f2da-45f7-a325-eb66ba5c750c&page=queryresults
[0m12:11:45.123873 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7d479716-f885-4c5f-952d-34846b43049f&page=queryresults
[0m12:11:46.672117 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed201d7550>]}
[0m12:11:46.672494 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed2232c9d0>]}
[0m12:11:46.673577 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m12:11:46.675150 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.25s]
[0m12:11:46.676771 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:11:46.677936 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:11:46.678940 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.681084 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:11:46.682336 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:11:46.683373 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.688350 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:11:46.693224 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed2017a0d0>]}
[0m12:11:46.695192 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.27s]
[0m12:11:46.696817 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:11:46.700049 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:46.705266 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:11:46.897861 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed222af610>]}
[0m12:11:46.899345 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.48s]
[0m12:11:46.900838 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:11:46.941289 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:11:46.948468 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:11:47.298041 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6c829dee-2bf7-409f-aa18-1248149b1271&page=queryresults
[0m12:11:48.873005 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '073d100a-dfe2-4ee1-9503-299194de87b3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed124749d0>]}
[0m12:11:48.874508 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.19s]
[0m12:11:48.875890 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:11:48.878734 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:11:48.882337 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:11:48.883237 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:11:48.884050 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:11:48.884835 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:11:48.885837 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:11:48.886720 [info ] [MainThread]: 
[0m12:11:48.887577 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.26 seconds (5.26s).
[0m12:11:48.889466 [debug] [MainThread]: Command end result
[0m12:11:48.926176 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:11:48.930205 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:11:48.938203 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:11:48.938973 [info ] [MainThread]: 
[0m12:11:48.940020 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:11:48.941212 [info ] [MainThread]: 
[0m12:11:48.942310 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:11:48.943887 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.3556, "process_in_blocks": "0", "process_kernel_time": 0.329294, "process_mem_max_rss": "229256", "process_out_blocks": "0", "process_user_time": 4.270848}
[0m12:11:48.945162 [debug] [MainThread]: Command `dbt run` succeeded at 12:11:48.945016 after 7.36 seconds
[0m12:11:48.946035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed50ace090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed53ea0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed54024910>]}
[0m12:11:48.946878 [debug] [MainThread]: Flushing usage events
[0m12:11:50.262714 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:19.473043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c32bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c87d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c30950>]}


============================== 12:14:19.475646 | 9bc05b03-72be-4f12-bad1-482f86995b7b ==============================
[0m12:14:19.475646 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:19.478172 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m12:14:19.565999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9bc05b03-72be-4f12-bad1-482f86995b7b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6ac0c90>]}
[0m12:14:19.625509 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20065594, "process_in_blocks": "0", "process_kernel_time": 0.0879, "process_mem_max_rss": "90048", "process_out_blocks": "0", "process_user_time": 0.947373}
[0m12:14:19.626680 [debug] [MainThread]: Command `dbt clean` succeeded at 12:14:19.626575 after 0.20 seconds
[0m12:14:19.627353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c8db90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbf6c8c950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffbfa428c90>]}
[0m12:14:19.628047 [debug] [MainThread]: Flushing usage events
[0m12:14:20.943576 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:22.121699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303976990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303e57790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa303976890>]}


============================== 12:14:22.124290 | d9546f3a-3557-4e9d-a57c-42d8ecafd4cb ==============================
[0m12:14:22.124290 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:22.125415 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:14:22.211035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9546f3a-3557-4e9d-a57c-42d8ecafd4cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa304667290>]}
[0m12:14:22.221264 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:14:22.223764 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:14:22.226094 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15758468, "process_in_blocks": "0", "process_kernel_time": 0.079564, "process_mem_max_rss": "90244", "process_out_blocks": "0", "process_user_time": 1.024392}
[0m12:14:22.227380 [debug] [MainThread]: Command `dbt deps` succeeded at 12:14:22.227240 after 0.16 seconds
[0m12:14:22.228215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3039cf150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3072c5110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3072c5390>]}
[0m12:14:22.229115 [debug] [MainThread]: Flushing usage events
[0m12:14:23.276970 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:26.250444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2541131dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f254161b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2541132fd0>]}


============================== 12:14:26.253042 | 04c831b9-45ce-431c-b173-055c55d37ab0 ==============================
[0m12:14:26.253042 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:14:26.254557 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:14:26.839004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2513557590>]}
[0m12:14:26.888323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25433b9f50>]}
[0m12:14:26.890098 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:14:26.956775 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:14:26.958759 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:14:26.959673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25132986d0>]}
[0m12:14:28.038029 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:14:28.049247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512fa3c50>]}
[0m12:14:28.122172 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:14:28.129770 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:14:28.144730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512cd9550>]}
[0m12:14:28.145949 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:14:28.147221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d9ab10>]}
[0m12:14:28.150270 [info ] [MainThread]: 
[0m12:14:28.151515 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:14:28.152554 [info ] [MainThread]: 
[0m12:14:28.154108 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:14:28.159369 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:14:28.160494 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:14:28.634639 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:14:28.642530 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:14:28.866016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d99c90>]}
[0m12:14:28.867438 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:14:28.873152 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:14:28.873632 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.873976 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.874345 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.875011 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:14:28.876268 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:14:28.877460 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:14:28.878555 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:14:28.879884 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:14:28.881012 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:14:28.882001 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:14:28.882858 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:14:28.883917 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:14:28.884945 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.885731 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.886833 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.897534 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:14:28.901822 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:14:28.906517 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:14:28.912908 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:14:28.928453 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:14:28.929203 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:14:28.951625 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:14:28.957849 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:14:28.978371 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:14:28.979788 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:14:28.983259 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:14:28.987543 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:14:29.283489 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:14:29.285377 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:14:29.286867 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:14:29.288281 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:14:29.305352 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:14:29.307366 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:14:29.308202 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:14:29.308895 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:14:29.572549 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bf07f2b2-99ea-4d53-89cd-6901a3997f16&page=queryresults
[0m12:14:29.575205 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:513296c1-c5c5-46cf-812d-6bc9c80f7d67&page=queryresults
[0m12:14:29.575962 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:83d3ae75-aa55-4a3c-a3ed-eec7fe88ccae&page=queryresults
[0m12:14:29.587219 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:31dd3710-8939-4d31-925f-55686ab54e26&page=queryresults
[0m12:14:31.092116 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f251037f690>]}
[0m12:14:31.092999 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2510388990>]}
[0m12:14:31.093884 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512e89350>]}
[0m12:14:31.096518 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.20s]
[0m12:14:31.098289 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.21s]
[0m12:14:31.100123 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.21s]
[0m12:14:31.101913 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:14:31.103510 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:14:31.105221 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:14:31.106477 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.109959 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:14:31.111271 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:14:31.112564 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.117440 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:14:31.123234 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:31.127103 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:14:31.158249 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f251038b550>]}
[0m12:14:31.159826 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.28s]
[0m12:14:31.161157 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:14:31.331237 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:14:31.339277 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:14:31.588307 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ca60e0b1-0e1d-4b54-b1d4-1d7d56ea477c&page=queryresults
[0m12:14:33.191816 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04c831b9-45ce-431c-b173-055c55d37ab0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2512d4e390>]}
[0m12:14:33.193413 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.08s]
[0m12:14:33.195094 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:14:33.197792 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:14:33.201545 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:14:33.202508 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:14:33.203175 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:14:33.203946 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:14:33.204876 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:14:33.205791 [info ] [MainThread]: 
[0m12:14:33.206684 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.05 seconds (5.05s).
[0m12:14:33.208978 [debug] [MainThread]: Command end result
[0m12:14:33.247311 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:14:33.252699 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:14:33.263204 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:14:33.264377 [info ] [MainThread]: 
[0m12:14:33.265811 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:14:33.267101 [info ] [MainThread]: 
[0m12:14:33.268162 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:14:33.269810 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.077331, "process_in_blocks": "0", "process_kernel_time": 0.182434, "process_mem_max_rss": "227056", "process_out_blocks": "0", "process_user_time": 4.317616}
[0m12:14:33.270949 [debug] [MainThread]: Command `dbt run` succeeded at 12:14:33.270824 after 7.08 seconds
[0m12:14:33.271860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f254181df50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2544ab1110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2544ab0910>]}
[0m12:14:33.272989 [debug] [MainThread]: Flushing usage events
[0m12:14:34.815361 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:28.535967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb7597ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d26410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb7592b710>]}


============================== 12:22:28.538465 | 00707613-d893-44b3-8421-9ece7ed0ae42 ==============================
[0m12:22:28.538465 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:28.540221 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:22:28.623364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '00707613-d893-44b3-8421-9ece7ed0ae42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75ddc550>]}
[0m12:22:28.687460 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20204052, "process_in_blocks": "0", "process_kernel_time": 0.079582, "process_mem_max_rss": "90048", "process_out_blocks": "0", "process_user_time": 0.97489}
[0m12:22:28.688389 [debug] [MainThread]: Command `dbt clean` succeeded at 12:22:28.688259 after 0.20 seconds
[0m12:22:28.689175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d268d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75d264d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffb75817d10>]}
[0m12:22:28.689874 [debug] [MainThread]: Flushing usage events
[0m12:22:30.188452 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:31.357624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2bffb150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c3f2110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c4ac290>]}


============================== 12:22:31.360329 | 4e26e73a-e023-46db-864a-94a0378ce498 ==============================
[0m12:22:31.360329 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:31.361514 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:22:31.448064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4e26e73a-e023-46db-864a-94a0378ce498', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c055350>]}
[0m12:22:31.461030 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:22:31.463759 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:22:31.465446 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16211414, "process_in_blocks": "0", "process_kernel_time": 0.079951, "process_mem_max_rss": "90168", "process_out_blocks": "0", "process_user_time": 1.039364}
[0m12:22:31.466440 [debug] [MainThread]: Command `dbt deps` succeeded at 12:22:31.466299 after 0.16 seconds
[0m12:22:31.467225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c4ac350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2c3f2110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2f7c4b90>]}
[0m12:22:31.468047 [debug] [MainThread]: Flushing usage events
[0m12:22:32.711996 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:22:37.279476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e1133090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e152a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e1183690>]}


============================== 12:22:37.282021 | e8e934d5-ebb0-4544-b08e-ea96d9089c6e ==============================
[0m12:22:37.282021 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:22:37.285912 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:22:37.925687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b32b3b90>]}
[0m12:22:37.974327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e338ddd0>]}
[0m12:22:37.975900 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:22:38.048025 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:22:38.051182 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:22:38.052136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e8e934d5-ebb0-4544-b08e-ea96d9089c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b3a051d0>]}
[0m12:22:38.912227 [error] [MainThread]: Encountered an error:
Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  invalid syntax for function call expression
    line 1
      {{ config(
[0m12:22:38.913720 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6879505, "process_in_blocks": "0", "process_kernel_time": 0.2304, "process_mem_max_rss": "211984", "process_out_blocks": "0", "process_user_time": 3.49608}
[0m12:22:38.914912 [debug] [MainThread]: Command `dbt run` failed at 12:22:38.914760 after 1.69 seconds
[0m12:22:38.916136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e116a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20e4a81290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f20b385d410>]}
[0m12:22:38.917693 [debug] [MainThread]: Flushing usage events
[0m12:22:40.225349 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:24:50.347572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a02b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a02a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a01e90>]}


============================== 12:24:50.351031 | 5e7a04af-ab2c-429a-b9a2-5fd6defde211 ==============================
[0m12:24:50.351031 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:24:50.353079 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m12:24:50.361777 [info ] [MainThread]: dbt version: 1.9.0
[0m12:24:50.363262 [info ] [MainThread]: python version: 3.11.2
[0m12:24:50.364666 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:24:50.366517 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:24:50.907611 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:24:50.908813 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:24:50.909750 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:24:50.990226 [info ] [MainThread]: Configuration:
[0m12:24:50.991664 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m12:24:50.992923 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:24:50.993884 [info ] [MainThread]: Required dependencies:
[0m12:24:50.994803 [debug] [MainThread]: Executing "git --help"
[0m12:24:50.998514 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:24:50.999350 [debug] [MainThread]: STDERR: "b''"
[0m12:24:51.000211 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:24:51.001056 [info ] [MainThread]: Connection test skipped since no profile was found
[0m12:24:51.002568 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:24:51.003524 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "hailing_project", target "dev" invalid: Runtime Error
    Must specify schema


[0m12:24:51.005126 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.70546657, "process_in_blocks": "0", "process_kernel_time": 0.192204, "process_mem_max_rss": "206772", "process_out_blocks": "0", "process_user_time": 2.569475}
[0m12:24:51.006267 [debug] [MainThread]: Command `dbt debug` failed at 12:24:51.006128 after 0.71 seconds
[0m12:24:51.007996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b64a57310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b36c36a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b3736b150>]}
[0m12:24:51.009173 [debug] [MainThread]: Flushing usage events
[0m12:24:52.114373 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:02.227394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caea7290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cb38b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0cb38b6d0>]}


============================== 12:25:02.230811 | 42bce0e9-25c5-4560-a6d4-37ab17094f2a ==============================
[0m12:25:02.230811 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:25:02.232172 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:25:02.239302 [info ] [MainThread]: dbt version: 1.9.0
[0m12:25:02.240291 [info ] [MainThread]: python version: 3.11.2
[0m12:25:02.241268 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:25:02.242526 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:25:02.773632 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:25:02.774683 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:25:02.775972 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:25:02.777199 [info ] [MainThread]: adapter type: bigquery
[0m12:25:02.778140 [info ] [MainThread]: adapter version: 1.9.0
[0m12:25:02.859356 [info ] [MainThread]: Configuration:
[0m12:25:02.860768 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:25:02.861994 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:25:02.863064 [info ] [MainThread]: Required dependencies:
[0m12:25:02.863977 [debug] [MainThread]: Executing "git --help"
[0m12:25:02.866047 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:25:02.866783 [debug] [MainThread]: STDERR: "b''"
[0m12:25:02.867742 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:25:02.868702 [info ] [MainThread]: Connection:
[0m12:25:02.870019 [info ] [MainThread]:   method: service-account
[0m12:25:02.871601 [info ] [MainThread]:   database: purwadika
[0m12:25:02.872664 [info ] [MainThread]:   execution_project: purwadika
[0m12:25:02.873606 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m12:25:02.874874 [info ] [MainThread]:   location: None
[0m12:25:02.876224 [info ] [MainThread]:   priority: None
[0m12:25:02.877343 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:25:02.878250 [info ] [MainThread]:   impersonate_service_account: None
[0m12:25:02.879179 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:25:02.880040 [info ] [MainThread]:   job_retries: 1
[0m12:25:02.881541 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:25:02.882636 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:25:02.883719 [info ] [MainThread]:   timeout_seconds: None
[0m12:25:02.884683 [info ] [MainThread]:   client_id: None
[0m12:25:02.885697 [info ] [MainThread]:   token_uri: None
[0m12:25:02.887209 [info ] [MainThread]:   dataproc_region: None
[0m12:25:02.888398 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:25:02.889561 [info ] [MainThread]:   gcs_bucket: None
[0m12:25:02.890798 [info ] [MainThread]:   dataproc_batch: None
[0m12:25:02.892004 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:25:02.945830 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:25:02.946883 [debug] [MainThread]: On debug: select 1 as id
[0m12:25:02.947681 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:25:03.617215 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:fc931634-228d-4b58-82f4-4600c2cb892c&page=queryresults
[0m12:25:04.366891 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:25:04.368622 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:25:04.370913 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1982403, "process_in_blocks": "0", "process_kernel_time": 0.190733, "process_mem_max_rss": "212356", "process_out_blocks": "0", "process_user_time": 2.680304}
[0m12:25:04.371960 [debug] [MainThread]: Command `dbt debug` succeeded at 12:25:04.371855 after 2.20 seconds
[0m12:25:04.372729 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:25:04.373547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caf1f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0caf1f290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0ce69cc10>]}
[0m12:25:04.374454 [debug] [MainThread]: Flushing usage events
[0m12:25:05.434130 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:27:08.731101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7b76bd0>]}


============================== 12:27:08.735636 | 2d6f5382-0d24-42c2-a797-dd2a7bdc0c10 ==============================
[0m12:27:08.735636 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:27:08.738532 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:27:08.747167 [info ] [MainThread]: dbt version: 1.9.0
[0m12:27:08.749696 [info ] [MainThread]: python version: 3.11.2
[0m12:27:08.751053 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:27:08.752173 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:27:09.244898 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:27:09.248064 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:27:09.249293 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:27:09.250749 [info ] [MainThread]: adapter type: bigquery
[0m12:27:09.253528 [info ] [MainThread]: adapter version: 1.9.0
[0m12:27:09.335546 [info ] [MainThread]: Configuration:
[0m12:27:09.336904 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:27:09.338304 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:27:09.339333 [info ] [MainThread]: Required dependencies:
[0m12:27:09.340379 [debug] [MainThread]: Executing "git --help"
[0m12:27:09.342518 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:27:09.343447 [debug] [MainThread]: STDERR: "b''"
[0m12:27:09.344307 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:27:09.345287 [info ] [MainThread]: Connection:
[0m12:27:09.346476 [info ] [MainThread]:   method: service-account
[0m12:27:09.347409 [info ] [MainThread]:   database: purwadika
[0m12:27:09.348385 [info ] [MainThread]:   execution_project: purwadika
[0m12:27:09.349459 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m12:27:09.350324 [info ] [MainThread]:   location: None
[0m12:27:09.351261 [info ] [MainThread]:   priority: None
[0m12:27:09.352361 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:27:09.353185 [info ] [MainThread]:   impersonate_service_account: None
[0m12:27:09.354030 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:27:09.354903 [info ] [MainThread]:   job_retries: 1
[0m12:27:09.355721 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:27:09.356701 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:27:09.357587 [info ] [MainThread]:   timeout_seconds: None
[0m12:27:09.358371 [info ] [MainThread]:   client_id: None
[0m12:27:09.359542 [info ] [MainThread]:   token_uri: None
[0m12:27:09.360405 [info ] [MainThread]:   dataproc_region: None
[0m12:27:09.361317 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:27:09.362109 [info ] [MainThread]:   gcs_bucket: None
[0m12:27:09.362929 [info ] [MainThread]:   dataproc_batch: None
[0m12:27:09.363861 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:27:09.419090 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:27:09.420242 [debug] [MainThread]: On debug: select 1 as id
[0m12:27:09.421033 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:27:10.103520 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:d560c700-4198-4148-a916-ecc982868603&page=queryresults
[0m12:27:10.827252 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:27:10.829173 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:27:10.831613 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.150948, "process_in_blocks": "0", "process_kernel_time": 0.142167, "process_mem_max_rss": "214748", "process_out_blocks": "0", "process_user_time": 2.741803}
[0m12:27:10.832989 [debug] [MainThread]: Command `dbt debug` succeeded at 12:27:10.832802 after 2.15 seconds
[0m12:27:10.834598 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:27:10.836028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cdb661850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ca9cc64d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cd7f72310>]}
[0m12:27:10.837288 [debug] [MainThread]: Flushing usage events
[0m12:27:11.950725 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:04.068492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19879f6f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987f10c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19879f6e90>]}


============================== 12:35:04.071731 | f84d009d-3405-42d6-90ea-73e2a8b99d79 ==============================
[0m12:35:04.071731 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:04.074743 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:35:04.675180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987a3e3d0>]}
[0m12:35:04.728646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1989ca9fd0>]}
[0m12:35:04.729926 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:04.797959 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:35:04.799988 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:35:04.801138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959cdef10>]}
[0m12:35:05.827022 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:35:05.837875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959d61750>]}
[0m12:35:05.907689 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:05.913855 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:05.932847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19595ef490>]}
[0m12:35:05.933946 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:35:05.935229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959615d10>]}
[0m12:35:05.937988 [info ] [MainThread]: 
[0m12:35:05.939417 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:35:05.940607 [info ] [MainThread]: 
[0m12:35:05.942773 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:35:05.947710 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:35:05.948888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:35:06.619118 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_staging)
[0m12:35:06.621289 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_staging"
"
[0m12:35:06.629410 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_staging`
  
[0m12:35:06.630746 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:07.669352 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f94c82ed-3ee3-4d95-a86f-b35b0b08b108&page=queryresults
[0m12:35:08.621745 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_staging)
[0m12:35:08.622808 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:09.185113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1959be1750>]}
[0m12:35:09.186288 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:09.191852 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:35:09.192202 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.192633 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.193007 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.193538 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m12:35:09.194694 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m12:35:09.195909 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m12:35:09.196976 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m12:35:09.198094 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m12:35:09.199187 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:35:09.200130 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:35:09.201399 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:35:09.202741 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:35:09.204027 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.205064 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.206099 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.215127 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:35:09.219018 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:09.223146 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:09.227159 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:09.244137 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.244637 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:35:09.250834 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.277877 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.326644 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:35:09.329615 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:09.324564 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:09.333413 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:09.348764 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m12:35:09.349395 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    );
  
[0m12:35:09.350516 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:35:09.351654 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m12:35:09.352217 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:09.353753 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m12:35:09.354796 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:35:09.381099 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:35:09.713385 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:352fa713-7282-4532-91ac-48e7d7c9fd3c&page=queryresults
[0m12:35:09.714761 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:352fa713-7282-4532-91ac-48e7d7c9fd3c&page=queryresults
[0m12:35:09.719095 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m12:35:09.721633 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b826d0>]}
[0m12:35:09.723173 [error] [Thread-3 (]: 3 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[31mERROR[0m in 0.52s]
[0m12:35:09.725411 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:35:09.726776 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.728961 [info ] [Thread-3 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m12:35:09.727795 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_driver' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql.
[0m12:35:09.730813 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:35:09.733449 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.738642 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:09.740316 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:34e3ada8-b940-4fd9-9dd7-85c5c8805f47&page=queryresults
[0m12:35:09.741838 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:34e3ada8-b940-4fd9-9dd7-85c5c8805f47&page=queryresults
[0m12:35:09.746416 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33b2d751-c286-44fd-aac9-bb75cae310bb&page=queryresults
[0m12:35:09.747878 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m12:35:09.748603 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33b2d751-c286-44fd-aac9-bb75cae310bb&page=queryresults
[0m12:35:09.749252 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:09.750339 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b5eb90>]}
[0m12:35:09.754365 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m12:35:09.758314 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:09.759958 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.55s]
[0m12:35:09.761183 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f195962d7d0>]}
[0m12:35:09.763429 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:35:09.764696 [error] [Thread-4 (]: 4 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[31mERROR[0m in 0.56s]
[0m12:35:09.766007 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m12:35:09.767545 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:35:09.769903 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m12:35:09.770828 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_ride' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql.
[0m12:35:09.771806 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:35:10.055438 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:71d0a539-5076-4f7a-9818-e399bd338ee0&page=queryresults
[0m12:35:10.056663 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:71d0a539-5076-4f7a-9818-e399bd338ee0&page=queryresults
[0m12:35:10.060669 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m12:35:10.061991 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958b63890>]}
[0m12:35:10.063334 [error] [Thread-3 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[31mERROR[0m in 0.33s]
[0m12:35:10.064640 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:10.065856 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql.
[0m12:35:10.122443 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e357a4e2-0d1c-4229-94b7-3606ac8b9cfb&page=queryresults
[0m12:35:10.123704 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e357a4e2-0d1c-4229-94b7-3606ac8b9cfb&page=queryresults
[0m12:35:10.127682 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:10.129198 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f84d009d-3405-42d6-90ea-73e2a8b99d79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1958a0edd0>]}
[0m12:35:10.131220 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.dim_customer  [[31mERROR[0m in 0.93s]
[0m12:35:10.132622 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:35:10.134163 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:35:10.136862 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:35:10.141750 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:35:10.142881 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m12:35:10.143817 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:35:10.144725 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:35:10.145687 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:35:10.146686 [info ] [MainThread]: 
[0m12:35:10.147711 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.20 seconds (4.20s).
[0m12:35:10.150147 [debug] [MainThread]: Command end result
[0m12:35:10.184708 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:10.189132 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:10.196887 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:35:10.197597 [info ] [MainThread]: 
[0m12:35:10.198781 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m12:35:10.199910 [info ] [MainThread]: 
[0m12:35:10.201024 [error] [MainThread]:   Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m12:35:10.202095 [info ] [MainThread]: 
[0m12:35:10.203354 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m12:35:10.204557 [info ] [MainThread]: 
[0m12:35:10.205835 [error] [MainThread]:   Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m12:35:10.207134 [info ] [MainThread]: 
[0m12:35:10.208569 [error] [MainThread]:   Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m12:35:10.209700 [info ] [MainThread]: 
[0m12:35:10.210951 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:10.212219 [info ] [MainThread]: 
[0m12:35:10.213799 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m12:35:10.216211 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1943884, "process_in_blocks": "0", "process_kernel_time": 0.218868, "process_mem_max_rss": "229740", "process_out_blocks": "0", "process_user_time": 4.188339}
[0m12:35:10.217388 [debug] [MainThread]: Command `dbt run` failed at 12:35:10.217250 after 6.20 seconds
[0m12:35:10.218490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1987a779d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f198b3ad190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f195999aa10>]}
[0m12:35:10.219479 [debug] [MainThread]: Flushing usage events
[0m12:35:11.899031 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:24.781940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944bd7190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944c2b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944bd6cd0>]}


============================== 12:35:24.784962 | a7cf52e0-3a42-472a-a444-5c0691b23049 ==============================
[0m12:35:24.784962 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:24.786074 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:35:24.793244 [info ] [MainThread]: dbt version: 1.9.0
[0m12:35:24.794469 [info ] [MainThread]: python version: 3.11.2
[0m12:35:24.795776 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:35:24.797085 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m12:35:25.342777 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m12:35:25.343847 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m12:35:25.344761 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m12:35:25.345889 [info ] [MainThread]: adapter type: bigquery
[0m12:35:25.346786 [info ] [MainThread]: adapter version: 1.9.0
[0m12:35:25.425664 [info ] [MainThread]: Configuration:
[0m12:35:25.427205 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:35:25.428354 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:35:25.429525 [info ] [MainThread]: Required dependencies:
[0m12:35:25.430730 [debug] [MainThread]: Executing "git --help"
[0m12:35:25.432704 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:35:25.433991 [debug] [MainThread]: STDERR: "b''"
[0m12:35:25.434875 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:35:25.436078 [info ] [MainThread]: Connection:
[0m12:35:25.437308 [info ] [MainThread]:   method: service-account
[0m12:35:25.438423 [info ] [MainThread]:   database: purwadika
[0m12:35:25.439661 [info ] [MainThread]:   execution_project: purwadika
[0m12:35:25.440629 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m12:35:25.441662 [info ] [MainThread]:   location: None
[0m12:35:25.443336 [info ] [MainThread]:   priority: None
[0m12:35:25.444898 [info ] [MainThread]:   maximum_bytes_billed: None
[0m12:35:25.445953 [info ] [MainThread]:   impersonate_service_account: None
[0m12:35:25.446972 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m12:35:25.447964 [info ] [MainThread]:   job_retries: 1
[0m12:35:25.448949 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m12:35:25.450109 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m12:35:25.451116 [info ] [MainThread]:   timeout_seconds: None
[0m12:35:25.452085 [info ] [MainThread]:   client_id: None
[0m12:35:25.452895 [info ] [MainThread]:   token_uri: None
[0m12:35:25.453846 [info ] [MainThread]:   dataproc_region: None
[0m12:35:25.455107 [info ] [MainThread]:   dataproc_cluster_name: None
[0m12:35:25.456096 [info ] [MainThread]:   gcs_bucket: None
[0m12:35:25.457028 [info ] [MainThread]:   dataproc_batch: None
[0m12:35:25.458245 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:25.515866 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m12:35:25.516671 [debug] [MainThread]: On debug: select 1 as id
[0m12:35:25.517560 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:26.182606 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:5dd687be-1a3a-43e9-b75f-24f363e7c354&page=queryresults
[0m12:35:26.906317 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:35:26.910046 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:35:26.914259 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1825113, "process_in_blocks": "0", "process_kernel_time": 0.216603, "process_mem_max_rss": "212388", "process_out_blocks": "0", "process_user_time": 2.737082}
[0m12:35:26.918161 [debug] [MainThread]: Command `dbt debug` succeeded at 12:35:26.917918 after 2.19 seconds
[0m12:35:26.919472 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:35:26.921367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7916e47790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7948408c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7916d47110>]}
[0m12:35:26.922968 [debug] [MainThread]: Flushing usage events
[0m12:35:27.954886 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:35.128813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8427390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8472a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8472b90>]}


============================== 12:35:35.132311 | e44f0043-5b68-49aa-aa98-d702a4eff2e0 ==============================
[0m12:35:35.132311 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:35.133532 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:35:35.226883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e44f0043-5b68-49aa-aa98-d702a4eff2e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a847d890>]}
[0m12:35:35.291775 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.21464151, "process_in_blocks": "0", "process_kernel_time": 0.08995, "process_mem_max_rss": "90152", "process_out_blocks": "0", "process_user_time": 1.029437}
[0m12:35:35.292995 [debug] [MainThread]: Command `dbt clean` succeeded at 12:35:35.292876 after 0.22 seconds
[0m12:35:35.293816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a8427010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1abbf0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1a9107310>]}
[0m12:35:35.294743 [debug] [MainThread]: Flushing usage events
[0m12:35:36.338119 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:37.536545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18b8ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18bdff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18b8ec10>]}


============================== 12:35:37.540987 | deaf3887-16cb-4d4f-b5f1-26be96e016fb ==============================
[0m12:35:37.540987 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:37.542517 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m12:35:37.673678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'deaf3887-16cb-4d4f-b5f1-26be96e016fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18bdfd90>]}
[0m12:35:37.692677 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:35:37.696532 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:35:37.698928 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.24335356, "process_in_blocks": "0", "process_kernel_time": 0.160146, "process_mem_max_rss": "90096", "process_out_blocks": "0", "process_user_time": 1.030945}
[0m12:35:37.700486 [debug] [MainThread]: Command `dbt deps` succeeded at 12:35:37.700283 after 0.25 seconds
[0m12:35:37.701784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18be1850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd18be31d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd1c3bcc10>]}
[0m12:35:37.702952 [debug] [MainThread]: Flushing usage events
[0m12:35:38.771242 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:42.196966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c203190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c5fa2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c5f9f10>]}


============================== 12:35:42.200034 | 03123977-0378-4c9c-a69f-0bf3ad79167a ==============================
[0m12:35:42.200034 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:35:42.201396 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:35:42.829783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e3c47d0>]}
[0m12:35:42.876135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e504f10>]}
[0m12:35:42.877503 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:35:42.950039 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:35:42.952711 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:35:42.953606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e983b50>]}
[0m12:35:44.040659 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:35:44.054036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e387410>]}
[0m12:35:44.130108 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:44.135162 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:44.150344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1ddf2510>]}
[0m12:35:44.151657 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:35:44.153365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1e256490>]}
[0m12:35:44.157258 [info ] [MainThread]: 
[0m12:35:44.158604 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:35:44.159848 [info ] [MainThread]: 
[0m12:35:44.161462 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:35:44.167067 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:35:44.168288 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:35:44.953393 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:35:44.955842 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:45.228815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1df8d310>]}
[0m12:35:45.230372 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:35:45.237270 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:35:45.237620 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.238032 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.238414 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.239222 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:35:45.240468 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:35:45.242137 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:35:45.243358 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:35:45.244818 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:35:45.246008 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:35:45.247466 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:35:45.248547 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:35:45.249537 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:35:45.250610 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.251461 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.252484 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.263383 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:35:45.268115 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:45.273416 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:45.277587 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:45.290847 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:35:45.291334 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:35:45.303153 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:35:45.330171 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:35:45.330556 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:35:45.334013 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:45.337165 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:35:45.340848 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:35:45.672109 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:35:45.675954 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:35:45.679573 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:35:45.681724 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:35:45.689368 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:35:45.689959 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:35:45.692577 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:35:45.694630 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:35:45.924486 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6f216068-b27c-4e17-b374-12982d4a3c97&page=queryresults
[0m12:35:45.925606 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6f216068-b27c-4e17-b374-12982d4a3c97&page=queryresults
[0m12:35:45.931143 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:45.933100 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c43f2d0>]}
[0m12:35:45.934971 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.69s]
[0m12:35:45.936375 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:35:45.937684 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.938230 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:35:45.939219 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:35:45.941332 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:35:45.942200 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.946801 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:45.953178 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:45.957034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:35:46.035462 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6be76204-0106-45db-8e0b-351a846328bd&page=queryresults
[0m12:35:46.048460 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0fe0823f-427e-4ddd-8dfb-5ceb41d603c3&page=queryresults
[0m12:35:46.096361 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:697a74cf-f6ef-4511-9189-64f1aad1ac9d&page=queryresults
[0m12:35:46.306248 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:35:46.313577 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:35:46.603670 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cd5bcbee-bd2d-416b-b912-17de78c692ba&page=queryresults
[0m12:35:47.750441 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c3ada50>]}
[0m12:35:47.751006 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c3b1710>]}
[0m12:35:47.752082 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:35:47.753540 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:35:47.754817 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:35:47.756088 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:35:47.760978 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c481d50>]}
[0m12:35:47.762665 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.51s]
[0m12:35:47.764203 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:35:48.204856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '03123977-0378-4c9c-a69f-0bf3ad79167a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1c481690>]}
[0m12:35:48.205864 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.26s]
[0m12:35:48.207254 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:35:48.209746 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:35:48.213135 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:35:48.214094 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:35:48.215136 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:35:48.216503 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:35:48.217501 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:35:48.218750 [info ] [MainThread]: 
[0m12:35:48.219867 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.06 seconds (4.06s).
[0m12:35:48.222086 [debug] [MainThread]: Command end result
[0m12:35:48.258089 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:35:48.262037 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:35:48.271323 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:35:48.272381 [info ] [MainThread]: 
[0m12:35:48.273544 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:35:48.274744 [info ] [MainThread]: 
[0m12:35:48.275702 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:35:48.276591 [info ] [MainThread]: 
[0m12:35:48.277614 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:35:48.279407 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.1315765, "process_in_blocks": "0", "process_kernel_time": 0.241492, "process_mem_max_rss": "227800", "process_out_blocks": "0", "process_user_time": 4.296552}
[0m12:35:48.280698 [debug] [MainThread]: Command `dbt run` failed at 12:35:48.280532 after 6.13 seconds
[0m12:35:48.281712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c081290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4c083690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b4fb515d0>]}
[0m12:35:48.282635 [debug] [MainThread]: Flushing usage events
[0m12:35:49.612867 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:38:00.616728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe1b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fcc21790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe1b5d0>]}


============================== 12:38:00.620358 | 67a234b6-9058-4d4c-a33a-a03b021aace6 ==============================
[0m12:38:00.620358 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:38:00.622428 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:38:01.222524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47ce777fd0>]}
[0m12:38:01.272648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fe0a5d90>]}
[0m12:38:01.273822 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:38:01.340824 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:38:01.407525 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:38:01.410508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fcc20410>]}
[0m12:38:02.421856 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:38:02.432965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdbcda10>]}
[0m12:38:02.506942 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:38:02.512595 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:38:02.527154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cd9e1510>]}
[0m12:38:02.528071 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m12:38:02.529448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdc12250>]}
[0m12:38:02.532344 [info ] [MainThread]: 
[0m12:38:02.533594 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:38:02.534886 [info ] [MainThread]: 
[0m12:38:02.536327 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:38:02.541633 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:38:02.542823 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:38:03.132534 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:38:03.133388 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:38:03.395520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdbceb50>]}
[0m12:38:03.396511 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:38:03.401000 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m12:38:03.401334 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.401644 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.401965 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.402623 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m12:38:03.403748 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:38:03.405269 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:38:03.406422 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:38:03.407508 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m12:38:03.408504 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m12:38:03.409548 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:38:03.410879 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:38:03.412195 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m12:38:03.413284 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.414371 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.415550 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.424881 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m12:38:03.428970 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:38:03.433974 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:38:03.439798 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:38:03.446476 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:38:03.446995 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:38:03.447392 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m12:38:03.447732 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:38:03.496875 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:38:03.498401 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:38:03.501996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:38:03.505118 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:38:03.832636 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:38:03.833467 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:38:03.835501 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m12:38:03.836763 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:38:03.842273 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:38:03.842808 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:38:03.843320 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:38:03.845430 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:38:04.060908 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7672eb36-f05c-4022-a962-14265aff265c&page=queryresults
[0m12:38:04.062019 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7672eb36-f05c-4022-a962-14265aff265c&page=queryresults
[0m12:38:04.066939 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:38:04.068696 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cdc27f90>]}
[0m12:38:04.070294 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source.dim_customer  [[31mERROR[0m in 0.66s]
[0m12:38:04.072564 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m12:38:04.074814 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.075599 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m12:38:04.076716 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:38:04.079499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m12:38:04.081543 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.086519 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:38:04.089455 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:adfbbf34-4e18-442f-86f7-bb1b7d267442&page=queryresults
[0m12:38:04.095950 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:04.099569 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:38:04.126292 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:61f6272e-dcc3-46d5-b629-ba526e2feb0a&page=queryresults
[0m12:38:04.126836 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9f8a9487-0cd8-41c1-a734-e205ae14d043&page=queryresults
[0m12:38:04.369037 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:38:04.378019 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:38:04.638641 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1a38cf87-7f2a-442c-b83f-e02fcbdb63de&page=queryresults
[0m12:38:05.667709 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47bdf58790>]}
[0m12:38:05.669970 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47bdcc7c90>]}
[0m12:38:05.670698 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.26s]
[0m12:38:05.671922 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.26s]
[0m12:38:05.672969 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:38:05.674037 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:38:05.835757 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cda35850>]}
[0m12:38:05.837024 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.43s]
[0m12:38:05.838897 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:38:06.164209 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67a234b6-9058-4d4c-a33a-a03b021aace6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47cc0e2610>]}
[0m12:38:06.165612 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.08s]
[0m12:38:06.166981 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:38:06.169280 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:38:06.172684 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:38:06.173700 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:38:06.174716 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:38:06.175989 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:38:06.177080 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:38:06.179000 [info ] [MainThread]: 
[0m12:38:06.180564 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 3.64 seconds (3.64s).
[0m12:38:06.183075 [debug] [MainThread]: Command end result
[0m12:38:06.223587 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:38:06.230096 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:38:06.239402 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:38:06.240794 [info ] [MainThread]: 
[0m12:38:06.241981 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:38:06.243320 [info ] [MainThread]: 
[0m12:38:06.244643 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m12:38:06.245911 [info ] [MainThread]: 
[0m12:38:06.247227 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m12:38:06.249252 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.686209, "process_in_blocks": "0", "process_kernel_time": 0.241691, "process_mem_max_rss": "228712", "process_out_blocks": "0", "process_user_time": 4.179252}
[0m12:38:06.250777 [debug] [MainThread]: Command `dbt run` failed at 12:38:06.250652 after 5.69 seconds
[0m12:38:06.251855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe74090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47fbe75c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47ff799250>]}
[0m12:38:06.252941 [debug] [MainThread]: Flushing usage events
[0m12:38:07.684839 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:22.716955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06afffed50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b04e7690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b004bfd0>]}


============================== 12:40:22.719605 | e8364ab3-67c4-429a-99b4-7126fb79e266 ==============================
[0m12:40:22.719605 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:22.721157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt clean', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:40:22.804962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8364ab3-67c4-429a-99b4-7126fb79e266', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b0059d10>]}
[0m12:40:22.869526 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.20637281, "process_in_blocks": "0", "process_kernel_time": 0.122746, "process_mem_max_rss": "89996", "process_out_blocks": "0", "process_user_time": 0.971743}
[0m12:40:22.870857 [debug] [MainThread]: Command `dbt clean` succeeded at 12:40:22.870556 after 0.21 seconds
[0m12:40:22.871698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b0058ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b00319d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f06b3924b10>]}
[0m12:40:22.872543 [debug] [MainThread]: Flushing usage events
[0m12:40:26.876124 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:27.998908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e13ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e623690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e13e9d0>]}


============================== 12:40:28.001850 | 62e82b7e-ff14-41b3-9a12-987090e68aba ==============================
[0m12:40:28.001850 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:28.003047 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:40:28.087268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62e82b7e-ff14-41b3-9a12-987090e68aba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e192f10>]}
[0m12:40:28.096846 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:40:28.099842 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:40:28.101655 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15786701, "process_in_blocks": "0", "process_kernel_time": 0.081048, "process_mem_max_rss": "90252", "process_out_blocks": "0", "process_user_time": 0.982718}
[0m12:40:28.102856 [debug] [MainThread]: Command `dbt deps` succeeded at 12:40:28.102729 after 0.16 seconds
[0m12:40:28.103739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e53a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e1b5010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f938e02bd10>]}
[0m12:40:28.104642 [debug] [MainThread]: Flushing usage events
[0m12:40:31.985681 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:34.752626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bab2af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18baf264d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bab2ac90>]}


============================== 12:40:34.755367 | 5b93f61f-8719-40db-b2f0-a7334df7040a ==============================
[0m12:40:34.755367 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:40:34.756644 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:40:35.371648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f189370b6d0>]}
[0m12:40:35.421232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bcddc8d0>]}
[0m12:40:35.422389 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:40:35.495821 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:40:35.499338 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:40:35.500407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f189370aad0>]}
[0m12:40:36.540615 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:40:36.553984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890a9b5d0>]}
[0m12:40:36.640200 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:40:36.647392 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:40:36.665754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890717790>]}
[0m12:40:36.666806 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:40:36.668410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890ad8950>]}
[0m12:40:36.671304 [info ] [MainThread]: 
[0m12:40:36.672464 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:40:36.673590 [info ] [MainThread]: 
[0m12:40:36.675612 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:40:36.681736 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:40:36.682846 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:40:37.251390 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:40:37.252299 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:40:37.501569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18bba63f90>]}
[0m12:40:37.502605 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:40:37.508984 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.509420 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.509861 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.510338 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.511102 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:40:37.512541 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:40:37.514017 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:40:37.515758 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:40:37.517247 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:40:37.518580 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:40:37.519897 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:40:37.521430 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:40:37.522988 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.524365 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.525887 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.527215 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.538773 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:40:37.543207 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:40:37.548034 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:40:37.553786 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:40:37.569493 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:40:37.571031 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:37.603358 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:40:37.614444 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:40:37.624815 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:40:37.625394 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:40:37.628085 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:40:37.631753 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:40:37.951004 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:40:37.953262 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:40:37.954853 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:40:37.956501 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:40:37.971504 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:40:37.972425 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:40:37.976284 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:40:37.978296 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:40:38.217058 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:04fa07f2-9e8a-447c-bac9-6f52330976fb&page=queryresults
[0m12:40:38.255553 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8ecf0cfd-a580-48fa-b11e-40eb2ab7387b&page=queryresults
[0m12:40:38.261291 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3faf8c96-e29d-4593-a958-af0802db3e5b&page=queryresults
[0m12:40:38.344578 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:285274e9-d77a-4f26-8962-b07558cd260e&page=queryresults
[0m12:40:39.811462 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890628410>]}
[0m12:40:39.812599 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.29s]
[0m12:40:39.813860 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:40:39.867814 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18907f7510>]}
[0m12:40:39.869189 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.35s]
[0m12:40:39.870696 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:40:39.972164 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18907a7650>]}
[0m12:40:39.973479 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.46s]
[0m12:40:39.974926 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:40:40.011624 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b93f61f-8719-40db-b2f0-a7334df7040a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890614810>]}
[0m12:40:40.013345 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.49s]
[0m12:40:40.014678 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:40:40.017324 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:40:40.020334 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:40:40.021199 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:40:40.021992 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:40:40.023670 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:40:40.024822 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:40:40.026228 [info ] [MainThread]: 
[0m12:40:40.027341 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.35 seconds (3.35s).
[0m12:40:40.029574 [debug] [MainThread]: Command end result
[0m12:40:40.064933 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:40:40.069320 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:40:40.079259 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:40:40.080168 [info ] [MainThread]: 
[0m12:40:40.081253 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:40:40.082343 [info ] [MainThread]: 
[0m12:40:40.083555 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:40:40.085552 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3841953, "process_in_blocks": "0", "process_kernel_time": 0.231955, "process_mem_max_rss": "226544", "process_out_blocks": "0", "process_user_time": 4.265955}
[0m12:40:40.086775 [debug] [MainThread]: Command `dbt run` succeeded at 12:40:40.086611 after 5.39 seconds
[0m12:40:40.087869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18be384b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1890233690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18baf26910>]}
[0m12:40:40.089226 [debug] [MainThread]: Flushing usage events
[0m12:40:41.151013 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:03.946633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7954fa74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79553a6110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7954fa7110>]}


============================== 12:41:03.949221 | 95b15488-65bc-469d-83e6-67fee15d43e9 ==============================
[0m12:41:03.949221 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:41:03.950262 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:41:04.522735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792715a390>]}
[0m12:41:04.567364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792729ff10>]}
[0m12:41:04.568557 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:41:04.638132 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:41:04.771246 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:41:04.772161 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:41:05.019694 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m12:41:05.035177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926db5c50>]}
[0m12:41:05.106925 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:05.112412 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:05.127712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926c65c50>]}
[0m12:41:05.129069 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:41:05.130229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926e27f10>]}
[0m12:41:05.132924 [info ] [MainThread]: 
[0m12:41:05.134239 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:41:05.135447 [info ] [MainThread]: 
[0m12:41:05.136881 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:41:05.142071 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:41:05.143035 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:05.675811 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:41:05.677302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:05.889896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79554fcc50>]}
[0m12:41:05.891701 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:05.897709 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.898084 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.898405 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.898735 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.899419 [info ] [Thread-1 (]: 1 of 4 START sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:41:05.900791 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:41:05.902280 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:41:05.903657 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:41:05.905067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:41:05.906173 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:41:05.907271 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:41:05.908564 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:41:05.909571 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.910417 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.911391 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.916546 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.928405 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:05.935301 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:05.941944 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:05.946522 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:05.957399 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:41:05.958167 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:41:05.958737 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:05.975675 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:41:05.975385 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:06.008982 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:41:06.011314 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:41:06.013878 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:41:06.069309 [debug] [Thread-1 (]: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m12:41:06.095417 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f792437f510>]}
[0m12:41:06.096711 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.19s]
[0m12:41:06.097896 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:41:06.099096 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql).
[0m12:41:06.318785 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:06.319505 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:06.324337 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:41:06.326238 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:41:06.592375 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:06.603481 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:41:06.626595 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fb186b7a-c146-4103-99fd-a540f000dc68&page=queryresults
[0m12:41:06.730600 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5c854dc4-e8f0-4b69-acd4-105569b8e022&page=queryresults
[0m12:41:06.857379 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a169fed4-a8bc-4c83-b82a-94ff1a63fd8f&page=queryresults
[0m12:41:08.161064 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926d19650>]}
[0m12:41:08.162903 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.25s]
[0m12:41:08.164836 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:08.243634 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7926cf3b50>]}
[0m12:41:08.245632 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.34s]
[0m12:41:08.247603 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:41:08.368400 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95b15488-65bc-469d-83e6-67fee15d43e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79243c5f90>]}
[0m12:41:08.369534 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.46s]
[0m12:41:08.371239 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:41:08.374407 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:41:08.378606 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:41:08.379402 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:41:08.380190 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:41:08.380806 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:41:08.381481 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:41:08.382217 [info ] [MainThread]: 
[0m12:41:08.383081 [info ] [MainThread]: Finished running 3 incremental models, 1 view model in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m12:41:08.385579 [debug] [MainThread]: Command end result
[0m12:41:08.420532 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:08.425800 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:08.435161 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:41:08.436026 [info ] [MainThread]: 
[0m12:41:08.437231 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:41:08.438397 [info ] [MainThread]: 
[0m12:41:08.439610 [error] [MainThread]:   Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m12:41:08.440711 [info ] [MainThread]: 
[0m12:41:08.441861 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m12:41:08.443647 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.549744, "process_in_blocks": "16", "process_kernel_time": 0.243292, "process_mem_max_rss": "225336", "process_out_blocks": "0", "process_user_time": 3.466916}
[0m12:41:08.444751 [debug] [MainThread]: Command `dbt run` failed at 12:41:08.444567 after 4.55 seconds
[0m12:41:08.445886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7927158910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f790efb3450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f795721d710>]}
[0m12:41:08.446672 [debug] [MainThread]: Flushing usage events
[0m12:41:09.512271 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:41:26.454650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4eeafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4eeae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f435d0>]}


============================== 12:41:26.457455 | 819d282b-95c4-42a4-8aa3-4f78cafa4317 ==============================
[0m12:41:26.457455 [info ] [MainThread]: Running with dbt=1.9.0
[0m12:41:26.458586 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:41:27.014207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a977e3a90>]}
[0m12:41:27.062840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac7164b10>]}
[0m12:41:27.064062 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m12:41:27.135174 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m12:41:27.278006 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:41:27.279276 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m12:41:27.537153 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m12:41:27.550252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac5cb0610>]}
[0m12:41:27.630504 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:27.636094 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:27.649680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96d02150>]}
[0m12:41:27.650781 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m12:41:27.651861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96b9c0d0>]}
[0m12:41:27.654530 [info ] [MainThread]: 
[0m12:41:27.655814 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:41:27.656833 [info ] [MainThread]: 
[0m12:41:27.658356 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m12:41:27.662693 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m12:41:27.663928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:41:28.169416 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m12:41:28.170332 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:41:28.385373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a971da490>]}
[0m12:41:28.386506 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:41:28.391210 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.391536 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.391981 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.392418 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.393016 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m12:41:28.394269 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m12:41:28.395312 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m12:41:28.396500 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m12:41:28.397615 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m12:41:28.398738 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m12:41:28.399736 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m12:41:28.400864 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m12:41:28.401741 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.402883 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.403713 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.404556 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.413910 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:28.418039 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:28.423070 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:28.427072 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:28.434206 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m12:41:28.434823 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m12:41:28.441705 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m12:41:28.442216 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:28.476357 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m12:41:28.476759 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m12:41:28.480058 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:41:28.482888 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:41:28.778709 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m12:41:28.781342 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m12:41:28.783555 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m12:41:28.784828 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m12:41:28.793103 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m12:41:28.793837 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m12:41:28.795181 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m12:41:28.798734 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m12:41:29.025528 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9acce181-9288-4590-b114-ae1db5f62339&page=queryresults
[0m12:41:29.029475 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:de479302-a0a6-482b-8751-94e0aee19e75&page=queryresults
[0m12:41:29.073980 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d1cd8456-6637-4927-9730-ce0ea608069c&page=queryresults
[0m12:41:29.110758 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:76ae07ed-c020-4db6-a99d-47fc7d78a5a8&page=queryresults
[0m12:41:30.595164 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96e912d0>]}
[0m12:41:30.596844 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.19s]
[0m12:41:30.599156 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m12:41:30.890796 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a7ee39290>]}
[0m12:41:30.895371 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a96c3f050>]}
[0m12:41:30.896135 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.49s]
[0m12:41:30.898220 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.50s]
[0m12:41:30.900702 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m12:41:30.906534 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '819d282b-95c4-42a4-8aa3-4f78cafa4317', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a942524d0>]}
[0m12:41:30.907710 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m12:41:30.910096 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.51s]
[0m12:41:30.912362 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m12:41:30.914979 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:41:30.918982 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:41:30.920023 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m12:41:30.922273 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m12:41:30.923799 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m12:41:30.925339 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m12:41:30.926698 [info ] [MainThread]: 
[0m12:41:30.927822 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.27 seconds (3.27s).
[0m12:41:30.930023 [debug] [MainThread]: Command end result
[0m12:41:30.966979 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m12:41:30.971968 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m12:41:30.980023 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m12:41:30.980776 [info ] [MainThread]: 
[0m12:41:30.981881 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:41:30.983115 [info ] [MainThread]: 
[0m12:41:30.984479 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:41:30.986027 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.583139, "process_in_blocks": "0", "process_kernel_time": 0.172975, "process_mem_max_rss": "224628", "process_out_blocks": "0", "process_user_time": 3.571426}
[0m12:41:30.986960 [debug] [MainThread]: Command `dbt run` succeeded at 12:41:30.986851 after 4.58 seconds
[0m12:41:30.987839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f67c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac4f67910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ac8708b90>]}
[0m12:41:30.988843 [debug] [MainThread]: Flushing usage events
[0m12:41:32.116889 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:30.215006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd90578750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd905cfd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd90a90a50>]}


============================== 13:04:30.217578 | aa6da955-2f8a-48a3-918e-e20a8e100b45 ==============================
[0m13:04:30.217578 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:04:30.218910 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt clean', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:04:30.299867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aa6da955-2f8a-48a3-918e-e20a8e100b45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd905d0050>]}
[0m13:04:30.362748 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19812414, "process_in_blocks": "0", "process_kernel_time": 0.098588, "process_mem_max_rss": "90064", "process_out_blocks": "0", "process_user_time": 0.946453}
[0m13:04:30.363980 [debug] [MainThread]: Command `dbt clean` succeeded at 13:04:30.363867 after 0.20 seconds
[0m13:04:30.364971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd905cf050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd90976710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd93e64b10>]}
[0m13:04:30.365897 [debug] [MainThread]: Flushing usage events
[0m13:04:31.533743 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:32.727574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd37f490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd3d3d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd3d3b10>]}


============================== 13:04:32.730744 | 8be0ee3e-ff6a-4c75-bf6b-a942a96b7829 ==============================
[0m13:04:32.730744 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:04:32.731849 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:04:32.820152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8be0ee3e-ff6a-4c75-bf6b-a942a96b7829', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd3d3210>]}
[0m13:04:32.830306 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:04:32.833007 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:04:32.834931 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15978639, "process_in_blocks": "0", "process_kernel_time": 0.070179, "process_mem_max_rss": "90252", "process_out_blocks": "0", "process_user_time": 1.042672}
[0m13:04:32.836058 [debug] [MainThread]: Command `dbt deps` succeeded at 13:04:32.835939 after 0.16 seconds
[0m13:04:32.836886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd894b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3dd77a8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3e0c68b10>]}
[0m13:04:32.837818 [debug] [MainThread]: Flushing usage events
[0m13:04:33.899913 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:37.238260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6247ff050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe62490db90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6247fed90>]}


============================== 13:04:37.240947 | 57bb519e-32be-47f6-8474-1a6959e2f6dd ==============================
[0m13:04:37.240947 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:04:37.242157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:04:37.847743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe62487bdd0>]}
[0m13:04:37.895403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe626a76150>]}
[0m13:04:37.897073 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:04:37.971236 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:04:37.973711 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:04:37.974758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f713ea90>]}
[0m13:04:39.001832 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m13:04:39.014727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f65beed0>]}
[0m13:04:39.086344 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:04:39.090968 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:04:39.105433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f63d4250>]}
[0m13:04:39.106284 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:04:39.107262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f65c3310>]}
[0m13:04:39.110229 [info ] [MainThread]: 
[0m13:04:39.111425 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:04:39.112411 [info ] [MainThread]: 
[0m13:04:39.114564 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:04:39.119013 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:04:39.119804 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:39.721601 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:04:39.722370 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:04:39.969512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f6863110>]}
[0m13:04:39.970598 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:04:39.975512 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:04:39.975881 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:04:39.976276 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:04:39.976730 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:04:39.977455 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m13:04:39.978680 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m13:04:39.979799 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m13:04:39.981148 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m13:04:39.982493 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m13:04:39.983596 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m13:04:39.984837 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:04:39.985908 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:04:39.986924 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:04:39.987816 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:04:39.988709 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:04:39.989590 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:04:40.001208 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:04:40.005148 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:04:40.010924 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:04:40.015304 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:04:40.026408 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:04:40.032887 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:04:40.061284 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:04:40.064559 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:04:40.067313 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:04:40.067679 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:04:40.070353 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:40.097056 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:04:40.407452 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:04:40.406883 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:04:40.408814 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:04:40.409995 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:04:40.422678 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:04:40.425588 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:04:40.428801 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:04:40.431344 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:04:40.776294 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f42f04e-80f8-4c1b-b3ee-5b3d73f3ee0c&page=queryresults
[0m13:04:40.779280 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ecaf25ce-6b16-4d3d-9d31-6a2f03a2e657&page=queryresults
[0m13:04:40.781904 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f9766849-24a6-4566-b815-627a8d889cae&page=queryresults
[0m13:04:40.804274 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:934d088e-b302-46ae-882d-5ace413cc7df&page=queryresults
[0m13:04:42.427825 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f42c02d0>]}
[0m13:04:42.429256 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.44s]
[0m13:04:42.430621 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:04:42.625174 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5e6644590>]}
[0m13:04:42.626305 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.64s]
[0m13:04:42.627335 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:04:42.645697 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f42e0310>]}
[0m13:04:42.649622 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.66s]
[0m13:04:42.651444 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:04:43.221335 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57bb519e-32be-47f6-8474-1a6959e2f6dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5f42d5dd0>]}
[0m13:04:43.222646 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.24s]
[0m13:04:43.223943 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:04:43.226654 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:04:43.229553 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:04:43.230486 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:04:43.231279 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:04:43.232318 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:04:43.233312 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:04:43.234466 [info ] [MainThread]: 
[0m13:04:43.236076 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m13:04:43.238329 [debug] [MainThread]: Command end result
[0m13:04:43.280106 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:04:43.285816 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:04:43.295542 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:04:43.296686 [info ] [MainThread]: 
[0m13:04:43.297828 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:04:43.299244 [info ] [MainThread]: 
[0m13:04:43.300338 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:04:43.302167 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.118044, "process_in_blocks": "0", "process_kernel_time": 0.279574, "process_mem_max_rss": "226860", "process_out_blocks": "0", "process_user_time": 4.143692}
[0m13:04:43.303254 [debug] [MainThread]: Command `dbt run` succeeded at 13:04:43.303128 after 6.12 seconds
[0m13:04:43.304636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe62487b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe6254e3410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe627ff4c10>]}
[0m13:04:43.306021 [debug] [MainThread]: Flushing usage events
[0m13:04:44.332051 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:59.894249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9697016c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96974fb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96974fb6d0>]}


============================== 13:04:59.897387 | df1191e8-082e-415c-a1b1-1d6436904ad5 ==============================
[0m13:04:59.897387 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:04:59.898512 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:05:00.494732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966d31f510>]}
[0m13:05:00.539864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96992c61d0>]}
[0m13:05:00.541071 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:05:00.614183 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:05:00.698105 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:05:00.699261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f969770e9d0>]}
[0m13:05:01.738866 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m13:05:01.752419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966d040750>]}
[0m13:05:01.826316 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:05:01.831651 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:05:01.846511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966cc03ad0>]}
[0m13:05:01.847735 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:05:01.848913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966ced55d0>]}
[0m13:05:01.851629 [info ] [MainThread]: 
[0m13:05:01.852850 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:05:01.853808 [info ] [MainThread]: 
[0m13:05:01.855147 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:05:01.860370 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:05:01.861398 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:05:02.362027 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:05:02.363021 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:05:02.596490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9698204590>]}
[0m13:05:02.597756 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:05:02.603834 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:05:02.604187 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:05:02.604612 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:05:02.605022 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:05:02.605549 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m13:05:02.606661 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m13:05:02.607741 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m13:05:02.609115 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m13:05:02.610453 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m13:05:02.611505 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m13:05:02.612838 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:05:02.613924 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:05:02.615208 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:05:02.616333 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:05:02.617440 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:05:02.618372 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:05:02.628897 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:05:02.633021 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:05:02.638292 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:05:02.642896 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:05:02.648808 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:05:02.649307 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:05:02.650103 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:05:02.678445 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:05:02.694909 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:05:02.695266 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:05:02.698260 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:05:02.702739 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:05:03.020345 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:05:03.023164 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:05:03.024401 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:05:03.027278 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:05:03.032974 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:05:03.033803 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:05:03.034346 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:05:03.037070 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:05:03.294893 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:44931d65-5ad1-455c-a4e0-1ecec25dcb8f&page=queryresults
[0m13:05:03.310916 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9250afe5-4c20-4546-af43-045413354c82&page=queryresults
[0m13:05:03.343923 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:3b29a5f9-b7a0-477e-87c6-cd3cda73b8e8&page=queryresults
[0m13:05:03.396303 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:74deef52-0b46-4e23-a205-c85ebbd1e329&page=queryresults
[0m13:05:04.870040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966c2aaf90>]}
[0m13:05:04.871594 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.26s]
[0m13:05:04.873007 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:05:05.129408 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966ccb4450>]}
[0m13:05:05.131010 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.52s]
[0m13:05:05.132426 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:05:05.193083 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966cd42250>]}
[0m13:05:05.194580 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.58s]
[0m13:05:05.195996 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:05:05.230248 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df1191e8-082e-415c-a1b1-1d6436904ad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f966ccb5f10>]}
[0m13:05:05.232258 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.62s]
[0m13:05:05.234525 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:05:05.237889 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:05:05.242282 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:05:05.243733 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:05:05.244724 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:05:05.245697 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:05:05.246670 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:05:05.248299 [info ] [MainThread]: 
[0m13:05:05.249576 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.39 seconds (3.39s).
[0m13:05:05.251631 [debug] [MainThread]: Command end result
[0m13:05:05.293374 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:05:05.298518 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:05:05.307696 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:05:05.308545 [info ] [MainThread]: 
[0m13:05:05.309795 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:05:05.311029 [info ] [MainThread]: 
[0m13:05:05.312173 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:05:05.314372 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.480524, "process_in_blocks": "0", "process_kernel_time": 0.232791, "process_mem_max_rss": "229904", "process_out_blocks": "0", "process_user_time": 4.271217}
[0m13:05:05.315613 [debug] [MainThread]: Command `dbt run` succeeded at 13:05:05.315456 after 5.48 seconds
[0m13:05:05.316564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9697091310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96974fb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f969a92be10>]}
[0m13:05:05.317526 [debug] [MainThread]: Flushing usage events
[0m13:05:06.349827 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:07:59.053840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6eeaf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6eeac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6eeaf50>]}


============================== 13:07:59.056481 | a6bb6628-fde7-4881-a1a4-e4119e95a538 ==============================
[0m13:07:59.056481 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:07:59.057724 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:07:59.662090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6eedf90>]}
[0m13:07:59.707876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c915c790>]}
[0m13:07:59.709599 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:07:59.775706 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:07:59.846358 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:07:59.847741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c75d69d0>]}
[0m13:08:00.887434 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m13:08:00.899538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569f477d10>]}
[0m13:08:00.978183 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:08:00.985351 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:08:01.003787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569caf3d90>]}
[0m13:08:01.005332 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:08:01.006653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569ced3510>]}
[0m13:08:01.010142 [info ] [MainThread]: 
[0m13:08:01.011601 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:08:01.012837 [info ] [MainThread]: 
[0m13:08:01.014242 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:08:01.019706 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:08:01.020659 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:08:01.583141 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:08:01.584093 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:08:01.862589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c9011f90>]}
[0m13:08:01.863838 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:08:01.869286 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:08:01.869655 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:08:01.870024 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:08:01.870367 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:08:01.871091 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m13:08:01.872168 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m13:08:01.873359 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m13:08:01.874548 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m13:08:01.876041 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m13:08:01.877495 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m13:08:01.879093 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:08:01.880479 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:08:01.881487 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:08:01.882801 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:08:01.883818 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:08:01.884823 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:08:01.895753 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:08:01.900230 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:08:01.905087 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:08:01.910425 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:08:01.915782 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:08:01.916723 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:08:01.922616 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:08:01.935532 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:08:01.967987 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:08:01.968460 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:08:01.971402 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:08:01.975677 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:08:02.313802 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:08:02.314877 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:08:02.316303 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:08:02.317721 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:08:02.323491 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:08:02.324241 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:08:02.327012 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:08:02.328715 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:08:02.572851 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8d29f365-e9c5-4ff0-b47f-69fe7f095339&page=queryresults
[0m13:08:02.603562 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:78ed6424-d9d1-440e-8db9-4e5a0311335d&page=queryresults
[0m13:08:02.609181 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f47deb5-a31d-491f-8381-fbbe6608b888&page=queryresults
[0m13:08:02.672347 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:55ada9be-9e72-4779-b980-94410cfa83b9&page=queryresults
[0m13:08:04.263629 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569c167a50>]}
[0m13:08:04.265050 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.38s]
[0m13:08:04.266601 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:08:04.390753 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569c14e190>]}
[0m13:08:04.392072 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.51s]
[0m13:08:04.393526 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:08:04.399426 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569cb77850>]}
[0m13:08:04.400685 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.52s]
[0m13:08:04.402032 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:08:04.431138 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6bb6628-fde7-4881-a1a4-e4119e95a538', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f569c1f3710>]}
[0m13:08:04.432821 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.55s]
[0m13:08:04.434791 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:08:04.437055 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:08:04.439585 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:08:04.440345 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:08:04.441189 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:08:04.441913 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:08:04.442575 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:08:04.443360 [info ] [MainThread]: 
[0m13:08:04.444348 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.43 seconds (3.43s).
[0m13:08:04.446096 [debug] [MainThread]: Command end result
[0m13:08:04.480727 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:08:04.485320 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:08:04.493109 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:08:04.494210 [info ] [MainThread]: 
[0m13:08:04.495661 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:08:04.496924 [info ] [MainThread]: 
[0m13:08:04.498314 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:08:04.500114 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.502689, "process_in_blocks": "0", "process_kernel_time": 0.243895, "process_mem_max_rss": "227840", "process_out_blocks": "0", "process_user_time": 4.23768}
[0m13:08:04.501419 [debug] [MainThread]: Command `dbt run` succeeded at 13:08:04.501265 after 5.50 seconds
[0m13:08:04.502663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6f2af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56c6f29410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56ca704b90>]}
[0m13:08:04.503900 [debug] [MainThread]: Flushing usage events
[0m13:08:05.622675 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:15:09.496157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed474e6d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed478de110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed474e69d0>]}


============================== 13:15:09.499642 | 5df33357-857e-4641-bfd0-be65f9d9be07 ==============================
[0m13:15:09.499642 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:15:09.502193 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m13:15:09.511900 [info ] [MainThread]: dbt version: 1.9.0
[0m13:15:09.513016 [info ] [MainThread]: python version: 3.11.2
[0m13:15:09.514060 [info ] [MainThread]: python path: /usr/local/bin/python
[0m13:15:09.516140 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m13:15:10.021621 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m13:15:10.022995 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m13:15:10.024367 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m13:15:10.025953 [info ] [MainThread]: adapter type: bigquery
[0m13:15:10.027026 [info ] [MainThread]: adapter version: 1.9.0
[0m13:15:10.102573 [info ] [MainThread]: Configuration:
[0m13:15:10.104006 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:15:10.105584 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:15:10.106948 [info ] [MainThread]: Required dependencies:
[0m13:15:10.108149 [debug] [MainThread]: Executing "git --help"
[0m13:15:10.112662 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:15:10.113782 [debug] [MainThread]: STDERR: "b''"
[0m13:15:10.114725 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:15:10.116260 [info ] [MainThread]: Connection:
[0m13:15:10.117483 [info ] [MainThread]:   method: service-account
[0m13:15:10.118576 [info ] [MainThread]:   database: purwadika
[0m13:15:10.119814 [info ] [MainThread]:   execution_project: purwadika
[0m13:15:10.120805 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m13:15:10.121726 [info ] [MainThread]:   location: None
[0m13:15:10.122595 [info ] [MainThread]:   priority: None
[0m13:15:10.123468 [info ] [MainThread]:   maximum_bytes_billed: None
[0m13:15:10.124538 [info ] [MainThread]:   impersonate_service_account: None
[0m13:15:10.125550 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m13:15:10.126605 [info ] [MainThread]:   job_retries: 1
[0m13:15:10.127539 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m13:15:10.128511 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m13:15:10.129337 [info ] [MainThread]:   timeout_seconds: None
[0m13:15:10.130437 [info ] [MainThread]:   client_id: None
[0m13:15:10.131816 [info ] [MainThread]:   token_uri: None
[0m13:15:10.133473 [info ] [MainThread]:   dataproc_region: None
[0m13:15:10.134729 [info ] [MainThread]:   dataproc_cluster_name: None
[0m13:15:10.135837 [info ] [MainThread]:   gcs_bucket: None
[0m13:15:10.136687 [info ] [MainThread]:   dataproc_batch: None
[0m13:15:10.137942 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:15:10.192550 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m13:15:10.193555 [debug] [MainThread]: On debug: select 1 as id
[0m13:15:10.194505 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:15:10.944013 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:35e2048f-d81b-41f3-9268-46082b060f01&page=queryresults
[0m13:15:11.676046 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:15:11.677687 [info ] [MainThread]: [32mAll checks passed![0m
[0m13:15:11.680547 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2425096, "process_in_blocks": "0", "process_kernel_time": 0.181806, "process_mem_max_rss": "211980", "process_out_blocks": "0", "process_user_time": 2.716993}
[0m13:15:11.681957 [debug] [MainThread]: Command `dbt debug` succeeded at 13:15:11.681840 after 2.24 seconds
[0m13:15:11.683081 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m13:15:11.685136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed475432d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed47543210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fed478ddfd0>]}
[0m13:15:11.686212 [debug] [MainThread]: Flushing usage events
[0m13:15:12.988319 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:15:15.944842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370cb2e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370dbdc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370cb2dd0>]}


============================== 13:15:15.947648 | 8923e300-2883-4069-84a0-c7d9da18900e ==============================
[0m13:15:15.947648 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:15:15.950000 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:15:16.555650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8923e300-2883-4069-84a0-c7d9da18900e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0343423f90>]}
[0m13:15:16.611401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8923e300-2883-4069-84a0-c7d9da18900e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0372f0d990>]}
[0m13:15:16.612637 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:15:16.682719 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:15:16.822717 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:15:16.824089 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m13:15:17.016867 [error] [MainThread]: Encountered an error:
Runtime Error
  Got duplicate keys: (dataset) all map to "schema"
[0m13:15:17.019515 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.1228918, "process_in_blocks": "0", "process_kernel_time": 0.212611, "process_mem_max_rss": "212360", "process_out_blocks": "0", "process_user_time": 2.966443}
[0m13:15:17.020983 [debug] [MainThread]: Command `dbt run` failed at 13:15:17.020790 after 1.12 seconds
[0m13:15:17.022436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370b13b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0370b13a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0342aa8b90>]}
[0m13:15:17.023701 [debug] [MainThread]: Flushing usage events
[0m13:15:18.122710 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:16:34.406950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63a53510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63e4e690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63a52e90>]}


============================== 13:16:34.409694 | f109e6c3-730b-4b0c-a1f2-158774552dbc ==============================
[0m13:16:34.409694 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:16:34.411322 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select production_hailing_staging_customers', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:16:34.981295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f109e6c3-730b-4b0c-a1f2-158774552dbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd35d909d0>]}
[0m13:16:35.031014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f109e6c3-730b-4b0c-a1f2-158774552dbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd65cd4a90>]}
[0m13:16:35.032246 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:16:35.103208 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:16:35.233286 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:16:35.234391 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m13:16:35.441728 [error] [MainThread]: Encountered an error:
Runtime Error
  Got duplicate keys: (dataset) all map to "schema"
[0m13:16:35.443818 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0867047, "process_in_blocks": "0", "process_kernel_time": 0.168808, "process_mem_max_rss": "213880", "process_out_blocks": "0", "process_user_time": 2.949179}
[0m13:16:35.445055 [debug] [MainThread]: Command `dbt run` failed at 13:16:35.444914 after 1.09 seconds
[0m13:16:35.446039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63aab850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd63aabb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdd35ddb550>]}
[0m13:16:35.446854 [debug] [MainThread]: Flushing usage events
[0m13:16:36.631813 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:17:12.051500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b24fb890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b254b390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b28f1f50>]}


============================== 13:17:12.054295 | c664f7b9-f272-4053-b7c7-a46fd89fe508 ==============================
[0m13:17:12.054295 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:17:12.055633 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:17:12.667561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01886a2210>]}
[0m13:17:12.724263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b4756410>]}
[0m13:17:12.726088 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:17:12.797115 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:17:12.958292 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:17:12.959479 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m13:17:13.227769 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m13:17:13.242489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01886d7850>]}
[0m13:17:13.318146 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:17:13.323368 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:17:13.339467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f018832afd0>]}
[0m13:17:13.340778 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:17:13.342040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b3288290>]}
[0m13:17:13.344391 [info ] [MainThread]: 
[0m13:17:13.345598 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:17:13.346529 [info ] [MainThread]: 
[0m13:17:13.347708 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:17:13.350033 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:17:13.351079 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:17:13.967585 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:17:13.969034 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_staging"
"
[0m13:17:13.977918 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`
  
[0m13:17:13.978918 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:14.792965 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:843c2bd2-6b87-4bf9-822c-5d171463b07d&page=queryresults
[0m13:17:15.789447 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:17:15.790205 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source'
[0m13:17:15.791137 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:17:15.792049 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:17:16.555990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0188495b10>]}
[0m13:17:16.557024 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:17:16.561923 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:17:16.563281 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:17:16.565004 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:17:16.566082 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:17:16.574353 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:17:16.583028 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:17:16.649507 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:17:16.658202 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:17:16.659518 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:17:16.989538 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b513af43-7d0b-4501-b241-838bb223ce4e&page=queryresults
[0m13:17:16.990834 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b513af43-7d0b-4501-b241-838bb223ce4e&page=queryresults
[0m13:17:16.996454 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:17:16.998680 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c664f7b9-f272-4053-b7c7-a46fd89fe508', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01836a1d50>]}
[0m13:17:17.000033 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.43s]
[0m13:17:17.001561 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:17:17.002937 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:17:17.005664 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:17:17.008553 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:17:17.009345 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:17:17.010169 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_source' was properly closed.
[0m13:17:17.011008 [info ] [MainThread]: 
[0m13:17:17.011831 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.66 seconds (3.66s).
[0m13:17:17.013447 [debug] [MainThread]: Command end result
[0m13:17:17.046926 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:17:17.050887 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:17:17.058718 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:17:17.059607 [info ] [MainThread]: 
[0m13:17:17.060690 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:17:17.061741 [info ] [MainThread]: 
[0m13:17:17.062804 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:17:17.063806 [info ] [MainThread]: 
[0m13:17:17.064791 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:17:17.066496 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.069591, "process_in_blocks": "0", "process_kernel_time": 0.203535, "process_mem_max_rss": "222448", "process_out_blocks": "0", "process_user_time": 3.500809}
[0m13:17:17.067955 [debug] [MainThread]: Command `dbt run` failed at 13:17:17.067745 after 5.07 seconds
[0m13:17:17.069033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b235ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b23580d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01b35d19d0>]}
[0m13:17:17.070055 [debug] [MainThread]: Flushing usage events
[0m13:17:18.345895 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:18:09.299081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de4007c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de3373610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de4007550>]}


============================== 13:18:09.301595 | ba3a0f5b-d76a-496c-8e26-8c32da4bb23d ==============================
[0m13:18:09.301595 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:18:09.303019 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:18:09.885550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db953e690>]}
[0m13:18:09.931295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db9586550>]}
[0m13:18:09.932427 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:18:09.997513 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:18:10.061856 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:18:10.063055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db9c3bb50>]}
[0m13:18:11.033328 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:18:11.045516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db954c2d0>]}
[0m13:18:11.119950 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:18:11.126930 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:18:11.142246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db8f1be90>]}
[0m13:18:11.143445 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:18:11.144605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db90d6f90>]}
[0m13:18:11.147200 [info ] [MainThread]: 
[0m13:18:11.148498 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:18:11.149511 [info ] [MainThread]: 
[0m13:18:11.151083 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:18:11.155766 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:18:11.156717 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:18:11.157226 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:11.157957 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:12.138147 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:18:12.138924 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:18:12.140093 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:12.141264 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:12.689001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de3329550>]}
[0m13:18:12.691589 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:18:12.696604 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:18:12.697010 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:18:12.697389 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:18:12.697951 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:18:12.698797 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:18:12.699820 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m13:18:12.701651 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m13:18:12.702955 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m13:18:12.704189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:18:12.705383 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_driver)
[0m13:18:12.706589 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:18:12.707597 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:18:12.708724 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:18:12.709552 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:18:12.710669 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:18:12.711577 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:18:12.721508 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:18:12.727763 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:18:12.732179 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:18:12.737160 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:18:12.743382 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:18:12.743886 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:18:12.755096 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:18:12.765280 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:18:12.788921 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:18:12.808818 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:18:12.812110 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:18:12.815767 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:18:12.901126 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:18:12.902419 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:13.131369 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:18:13.136914 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m13:18:13.150439 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:18:13.153696 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:18:13.157429 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m13:18:13.159342 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m13:18:13.219993 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:51f18cbc-3486-4311-b2a5-a5d7dc81fabc&page=queryresults
[0m13:18:13.221359 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:51f18cbc-3486-4311-b2a5-a5d7dc81fabc&page=queryresults
[0m13:18:13.226564 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:18:13.228474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db8592650>]}
[0m13:18:13.229791 [error] [Thread-1 (]: 1 of 4 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.52s]
[0m13:18:13.231108 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:18:13.232281 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:18:13.430359 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:fd8fc93c-67d7-442e-9e0a-0ecbf5683778&page=queryresults
[0m13:18:13.441282 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b3181c64-6878-4ad9-b23b-1a504d11e9be&page=queryresults
[0m13:18:13.446357 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1d66b080-2788-437c-8d52-d7f9c5b1d049&page=queryresults
[0m13:18:15.437184 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db84d1ed0>]}
[0m13:18:15.438466 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db84d16d0>]}
[0m13:18:15.440846 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba3a0f5b-d76a-496c-8e26-8c32da4bb23d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1db85be290>]}
[0m13:18:15.441582 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.73s]
[0m13:18:15.443181 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.73s]
[0m13:18:15.444498 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.73s]
[0m13:18:15.445862 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:18:15.446972 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:18:15.447920 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:18:15.450690 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:18:15.453770 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:18:15.454818 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:18:15.455866 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:18:15.456877 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:18:15.458650 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:18:15.460110 [info ] [MainThread]: 
[0m13:18:15.461152 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 4.31 seconds (4.31s).
[0m13:18:15.463076 [debug] [MainThread]: Command end result
[0m13:18:15.500162 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:18:15.507358 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:18:15.520133 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:18:15.521370 [info ] [MainThread]: 
[0m13:18:15.522709 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:18:15.524071 [info ] [MainThread]: 
[0m13:18:15.525448 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:18:15.526614 [info ] [MainThread]: 
[0m13:18:15.527610 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m13:18:15.529653 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.280024, "process_in_blocks": "0", "process_kernel_time": 0.301807, "process_mem_max_rss": "227316", "process_out_blocks": "0", "process_user_time": 4.174999}
[0m13:18:15.531042 [debug] [MainThread]: Command `dbt run` failed at 13:18:15.530833 after 6.28 seconds
[0m13:18:15.532274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de371e510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de339ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1de339fa10>]}
[0m13:18:15.533322 [debug] [MainThread]: Flushing usage events
[0m13:18:16.702574 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:18:36.511580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd203fb0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd20447e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd203faf90>]}


============================== 13:18:36.514423 | 04ea4408-25db-4cb9-a242-d365727bf5aa ==============================
[0m13:18:36.514423 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:18:36.515799 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:18:37.118026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf25a8950>]}
[0m13:18:37.164382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd2264e250>]}
[0m13:18:37.165828 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:18:37.240461 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:18:37.380530 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:18:37.381529 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:18:37.386926 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:18:37.415041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf89ab690>]}
[0m13:18:37.548577 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:18:37.555947 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:18:37.571105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf25899d0>]}
[0m13:18:37.572117 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:18:37.573558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf2580550>]}
[0m13:18:37.576317 [info ] [MainThread]: 
[0m13:18:37.577850 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:18:37.579128 [info ] [MainThread]: 
[0m13:18:37.580805 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:18:37.582875 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:18:37.583787 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:38.125972 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:18:38.126762 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source'
[0m13:18:38.127699 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:18:38.128752 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:18:38.665419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf2391cd0>]}
[0m13:18:38.666698 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:18:38.673847 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:18:38.675504 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:18:38.677060 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:18:38.678037 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:18:38.694982 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:18:38.703412 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:18:38.775952 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:18:38.784893 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:18:38.786446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:18:39.079955 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:724037aa-9a76-4ed8-ba4f-31e596e19122&page=queryresults
[0m13:18:39.081025 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:724037aa-9a76-4ed8-ba4f-31e596e19122&page=queryresults
[0m13:18:39.086770 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:18:39.089138 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04ea4408-25db-4cb9-a242-d365727bf5aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccf25fe790>]}
[0m13:18:39.090601 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.41s]
[0m13:18:39.092584 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:18:39.094222 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:18:39.097431 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:18:39.100862 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:18:39.101808 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:18:39.102657 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_source' was properly closed.
[0m13:18:39.103674 [info ] [MainThread]: 
[0m13:18:39.104668 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.52 seconds (1.52s).
[0m13:18:39.106533 [debug] [MainThread]: Command end result
[0m13:18:39.144478 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:18:39.149528 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:18:39.159515 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:18:39.160535 [info ] [MainThread]: 
[0m13:18:39.162043 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:18:39.163380 [info ] [MainThread]: 
[0m13:18:39.164766 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:18:39.166014 [info ] [MainThread]: 
[0m13:18:39.167132 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:18:39.169299 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.7154295, "process_in_blocks": "0", "process_kernel_time": 0.18182, "process_mem_max_rss": "216208", "process_out_blocks": "0", "process_user_time": 3.292972}
[0m13:18:39.170757 [debug] [MainThread]: Command `dbt run` failed at 13:18:39.170536 after 2.72 seconds
[0m13:18:39.171960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd204472d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd209a0610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd20505b50>]}
[0m13:18:39.173070 [debug] [MainThread]: Flushing usage events
[0m13:18:40.210200 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:20:03.106688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a13da910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a13daf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a17d2390>]}


============================== 13:20:03.109393 | 33ab6204-76d1-47e7-a2eb-015985276d0c ==============================
[0m13:20:03.109393 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:20:03.110598 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:20:03.667820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85736b3210>]}
[0m13:20:03.715076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a3688850>]}
[0m13:20:03.716764 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:20:03.785839 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:20:03.852772 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:20:03.854079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a1ad2a50>]}
[0m13:20:04.815046 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:20:04.831872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f857312cbd0>]}
[0m13:20:04.921506 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:20:04.928300 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:20:04.944693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8572f191d0>]}
[0m13:20:04.946412 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:20:04.947673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85731b9cd0>]}
[0m13:20:04.950352 [info ] [MainThread]: 
[0m13:20:04.951606 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:20:04.952712 [info ] [MainThread]: 
[0m13:20:04.954105 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:20:04.956284 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:20:04.957730 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:20:05.552532 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m13:20:05.553973 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source'
[0m13:20:05.555650 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:20:05.557119 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:20:06.106065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8572f33190>]}
[0m13:20:06.107787 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:20:06.115685 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:20:06.116950 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:20:06.118233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:20:06.119399 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:20:06.131026 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:20:06.139524 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:20:06.212713 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:20:06.220020 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:20:06.221467 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:20:06.516893 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e2c42fc-2497-411c-ba3e-590bd46d8218&page=queryresults
[0m13:20:06.517944 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e2c42fc-2497-411c-ba3e-590bd46d8218&page=queryresults
[0m13:20:06.523249 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:20:06.525146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33ab6204-76d1-47e7-a2eb-015985276d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85730b60d0>]}
[0m13:20:06.526354 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.41s]
[0m13:20:06.527445 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:20:06.529005 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:20:06.531885 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:20:06.534889 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:20:06.535983 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:20:06.536933 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_source' was properly closed.
[0m13:20:06.537971 [info ] [MainThread]: 
[0m13:20:06.539068 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.58 seconds (1.58s).
[0m13:20:06.540712 [debug] [MainThread]: Command end result
[0m13:20:06.580584 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:20:06.585040 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:20:06.594274 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:20:06.595192 [info ] [MainThread]: 
[0m13:20:06.596327 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:20:06.597514 [info ] [MainThread]: 
[0m13:20:06.598963 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:20:06.599879 [info ] [MainThread]: 
[0m13:20:06.600976 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:20:06.603651 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.555093, "process_in_blocks": "0", "process_kernel_time": 0.23179, "process_mem_max_rss": "221320", "process_out_blocks": "0", "process_user_time": 3.990819}
[0m13:20:06.605493 [debug] [MainThread]: Command `dbt run` failed at 13:20:06.605312 after 3.56 seconds
[0m13:20:06.606651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a4cfca50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a4d8d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85a4d8d090>]}
[0m13:20:06.607911 [debug] [MainThread]: Flushing usage events
[0m13:20:07.908198 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:21:52.375956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ffc8fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ffc8f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3600036110>]}


============================== 13:21:52.378542 | b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d ==============================
[0m13:21:52.378542 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:21:52.379874 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:21:52.976826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d2d7a310>]}
[0m13:21:53.031705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3601e99750>]}
[0m13:21:53.034182 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:21:53.106189 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:21:53.261028 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:21:53.262256 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m13:21:53.534698 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:21:53.546949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1f8e850>]}
[0m13:21:53.620568 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:21:53.628256 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:21:53.645167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1a86010>]}
[0m13:21:53.646471 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:21:53.647821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1bf9050>]}
[0m13:21:53.650558 [info ] [MainThread]: 
[0m13:21:53.651815 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:21:53.652923 [info ] [MainThread]: 
[0m13:21:53.654416 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:21:53.656713 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:21:53.657987 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:21:54.687003 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m13:21:54.687897 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:21:54.918316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1e91dd0>]}
[0m13:21:54.920559 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:21:54.925700 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:21:54.926719 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m13:21:54.927783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m13:21:54.928736 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:21:54.936416 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:21:54.942225 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:21:55.007441 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:21:55.014768 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:21:55.016096 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:21:55.471181 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:efa6d99e-c855-406f-9d57-28ac167cdfad&page=queryresults
[0m13:21:57.417096 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c1bdd6-e923-4ad0-96ca-7d3fbfb43e0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35d1a875d0>]}
[0m13:21:57.418800 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.49s]
[0m13:21:57.420128 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:21:57.421971 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:21:57.425615 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:21:57.426606 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:21:57.427716 [info ] [MainThread]: 
[0m13:21:57.428966 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.77 seconds (3.77s).
[0m13:21:57.430813 [debug] [MainThread]: Command end result
[0m13:21:57.465006 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:21:57.469273 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:21:57.477248 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:21:57.477938 [info ] [MainThread]: 
[0m13:21:57.478926 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:21:57.480020 [info ] [MainThread]: 
[0m13:21:57.481124 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:21:57.482885 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.162988, "process_in_blocks": "0", "process_kernel_time": 0.128869, "process_mem_max_rss": "223124", "process_out_blocks": "0", "process_user_time": 3.558785}
[0m13:21:57.483807 [debug] [MainThread]: Command `dbt run` succeeded at 13:21:57.483699 after 5.16 seconds
[0m13:21:57.484842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3603408cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35c1b22bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f360358c9d0>]}
[0m13:21:57.485865 [debug] [MainThread]: Flushing usage events
[0m13:21:58.622811 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:24:58.619842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99da2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99ea9c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99df3690>]}


============================== 13:24:58.622800 | 4388e728-0f0d-471d-9e5c-e9af4a810ed9 ==============================
[0m13:24:58.622800 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:24:58.624149 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:24:58.707148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4388e728-0f0d-471d-9e5c-e9af4a810ed9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99df6090>]}
[0m13:24:58.762513 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19943619, "process_in_blocks": "0", "process_kernel_time": 0.119847, "process_mem_max_rss": "90060", "process_out_blocks": "0", "process_user_time": 0.988741}
[0m13:24:58.763735 [debug] [MainThread]: Command `dbt clean` succeeded at 13:24:58.763573 after 0.20 seconds
[0m13:24:58.764676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb99dd5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb9d590c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb9a196090>]}
[0m13:24:58.765891 [debug] [MainThread]: Flushing usage events
[0m13:25:00.044199 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:25:01.216045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b962ad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9ba30ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b965f910>]}


============================== 13:25:01.219314 | f3c424e0-5af2-4aff-be03-0bbe4245d811 ==============================
[0m13:25:01.219314 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:25:01.220900 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:25:01.302345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f3c424e0-5af2-4aff-be03-0bbe4245d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b952e510>]}
[0m13:25:01.315481 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:25:01.318906 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:25:01.320701 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15545255, "process_in_blocks": "0", "process_kernel_time": 0.069638, "process_mem_max_rss": "90104", "process_out_blocks": "0", "process_user_time": 1.034623}
[0m13:25:01.322161 [debug] [MainThread]: Command `dbt deps` succeeded at 13:25:01.322016 after 0.16 seconds
[0m13:25:01.323102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b96738d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9b94ba310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9bcfa1010>]}
[0m13:25:01.324039 [debug] [MainThread]: Flushing usage events
[0m13:25:02.569701 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:25:15.994659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc69d2c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc69d2b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc69d2e10>]}


============================== 13:25:15.997386 | ec9afc33-20f9-48e5-a74c-7c1bd377728b ==============================
[0m13:25:15.997386 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:25:15.999537 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'send_anonymous_usage_stats': 'True'}
[0m13:25:16.584538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9cb7ae90>]}
[0m13:25:16.629962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9ccdf550>]}
[0m13:25:16.631086 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:25:16.700095 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:25:16.702159 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:25:16.703229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9d7f3150>]}
[0m13:25:17.745963 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:25:17.759955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9cb8b890>]}
[0m13:25:17.837093 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:25:17.843893 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:25:17.860759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9c5af350>]}
[0m13:25:17.862182 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:25:17.863290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9c7c0d10>]}
[0m13:25:17.865834 [info ] [MainThread]: 
[0m13:25:17.867163 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:25:17.868273 [info ] [MainThread]: 
[0m13:25:17.870064 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:25:17.873291 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:25:17.874321 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:25:18.467030 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:25:18.468004 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:25:18.957214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9c8a8410>]}
[0m13:25:18.958335 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:25:18.963463 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:25:18.964619 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:25:18.966410 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:25:18.967393 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:25:18.976168 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:25:18.988797 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:25:19.054443 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:25:19.072342 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:25:19.074293 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:25:19.440535 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:92b935d8-1a63-4911-ae53-31c4cfef5d6d&page=queryresults
[0m13:25:19.441925 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:92b935d8-1a63-4911-ae53-31c4cfef5d6d&page=queryresults
[0m13:25:19.447439 [debug] [Thread-1 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:25:19.449621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec9afc33-20f9-48e5-a74c-7c1bd377728b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9c623010>]}
[0m13:25:19.450932 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.48s]
[0m13:25:19.452766 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:25:19.454342 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m13:25:19.457303 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:25:19.460621 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:25:19.461522 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:25:19.462900 [info ] [MainThread]: 
[0m13:25:19.464068 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 1.59 seconds (1.59s).
[0m13:25:19.465633 [debug] [MainThread]: Command end result
[0m13:25:19.499885 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:25:19.504194 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:25:19.513237 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:25:19.514020 [info ] [MainThread]: 
[0m13:25:19.515229 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:25:19.516671 [info ] [MainThread]: 
[0m13:25:19.517998 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m13:25:19.519000 [info ] [MainThread]: 
[0m13:25:19.520219 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:25:19.522197 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.5749357, "process_in_blocks": "0", "process_kernel_time": 0.243853, "process_mem_max_rss": "219532", "process_out_blocks": "0", "process_user_time": 4.023579}
[0m13:25:19.523343 [debug] [MainThread]: Command `dbt run` failed at 13:25:19.523212 after 3.58 seconds
[0m13:25:19.524347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc6a4ff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc6a4fa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dca34d210>]}
[0m13:25:19.525814 [debug] [MainThread]: Flushing usage events
[0m13:25:20.606022 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:26:59.008725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b7572f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b7572ef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b7572f290>]}


============================== 13:26:59.011526 | 772cb824-f634-4804-8cca-be6ca583e19d ==============================
[0m13:26:59.011526 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:26:59.013050 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'send_anonymous_usage_stats': 'True'}
[0m13:26:59.566218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b4781f590>]}
[0m13:26:59.617539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b779a2010>]}
[0m13:26:59.618995 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:26:59.694603 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:26:59.824112 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:26:59.825152 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:26:59.830204 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:26:59.855725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b4dcca990>]}
[0m13:26:59.972972 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:26:59.978550 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:26:59.992563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b4d01d390>]}
[0m13:26:59.993565 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:26:59.994562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b479fc150>]}
[0m13:26:59.997066 [info ] [MainThread]: 
[0m13:26:59.998438 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:26:59.999649 [info ] [MainThread]: 
[0m13:27:00.001111 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:27:00.003961 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:27:00.005276 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:27:00.621443 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:27:00.623102 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:27:00.905838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b4752fc10>]}
[0m13:27:00.907199 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:27:00.911996 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:27:00.913149 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:27:00.914728 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:27:00.915627 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:27:00.929121 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:27:00.938152 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:27:00.999666 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:27:01.005908 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:27:01.007009 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:27:01.671168 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ce5173bd-ad03-4cb0-ab94-6ea5d94af2ec&page=queryresults
[0m13:27:03.835109 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '772cb824-f634-4804-8cca-be6ca583e19d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b476881d0>]}
[0m13:27:03.836333 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.92s]
[0m13:27:03.837934 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:27:03.840315 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:27:03.843017 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:27:03.843981 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:27:03.845151 [info ] [MainThread]: 
[0m13:27:03.846149 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.84 seconds (3.84s).
[0m13:27:03.847826 [debug] [MainThread]: Command end result
[0m13:27:03.887706 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:27:03.892416 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:27:03.901233 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:27:03.901978 [info ] [MainThread]: 
[0m13:27:03.903118 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:27:03.904143 [info ] [MainThread]: 
[0m13:27:03.905433 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:27:03.907830 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9503984, "process_in_blocks": "0", "process_kernel_time": 0.212752, "process_mem_max_rss": "219764", "process_out_blocks": "0", "process_user_time": 3.089977}
[0m13:27:03.909026 [debug] [MainThread]: Command `dbt run` succeeded at 13:27:03.908895 after 4.95 seconds
[0m13:27:03.909815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b75b26710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b79014a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b78f48bd0>]}
[0m13:27:03.910703 [debug] [MainThread]: Flushing usage events
[0m13:27:05.056599 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:54:50.255905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62f4dee10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6301bf690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb62f8d6110>]}


============================== 13:54:50.258916 | dde81cc7-4e54-401d-8918-ba886b5d4763 ==============================
[0m13:54:50.258916 [info ] [MainThread]: Running with dbt=1.9.0
[0m13:54:50.260006 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m13:54:50.869604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601681790>]}
[0m13:54:50.918630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601832c50>]}
[0m13:54:50.920320 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m13:54:50.984634 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m13:54:51.163290 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:54:51.165614 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:54:51.170573 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_project.staging
[0m13:54:51.195285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601515310>]}
[0m13:54:51.313021 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:54:51.318427 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:54:51.335786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb60168b5d0>]}
[0m13:54:51.336835 [info ] [MainThread]: Found 4 models, 8 sources, 488 macros
[0m13:54:51.338251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6014c1550>]}
[0m13:54:51.340893 [info ] [MainThread]: 
[0m13:54:51.342141 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:54:51.343216 [info ] [MainThread]: 
[0m13:54:51.344840 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m13:54:51.349561 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m13:54:51.350594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:54:52.012706 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m13:54:52.013786 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:54:52.243500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb60e2cd310>]}
[0m13:54:52.246330 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:54:52.252221 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m13:54:52.252907 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m13:54:52.253394 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m13:54:52.253746 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m13:54:52.254676 [info ] [Thread-1 (]: 1 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m13:54:52.255835 [info ] [Thread-2 (]: 2 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m13:54:52.257159 [info ] [Thread-3 (]: 3 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m13:54:52.258514 [info ] [Thread-4 (]: 4 of 4 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m13:54:52.259959 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m13:54:52.261268 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m13:54:52.262295 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m13:54:52.263312 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_vehicle'
[0m13:54:52.264026 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m13:54:52.265263 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m13:54:52.266182 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m13:54:52.266923 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m13:54:52.282445 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m13:54:52.286935 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m13:54:52.291915 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m13:54:52.296615 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:54:52.302819 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m13:54:52.305112 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m13:54:52.312352 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m13:54:52.318400 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m13:54:52.382823 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:54:52.427351 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m13:54:52.425385 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m13:54:52.430405 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m13:54:52.458271 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m13:54:52.459976 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:54:52.460427 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m13:54:52.462458 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m13:54:52.463081 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:54:52.465304 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:54:52.690311 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m13:54:52.696681 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m13:54:52.888587 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0adc48c6-d4d2-46b7-b3f1-0e37fc1b1425&page=queryresults
[0m13:54:52.892619 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d04fd668-dc05-4028-8fd5-f8b7bf1ec648&page=queryresults
[0m13:54:53.044576 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:33593c9a-be8a-4b37-ad73-4eacc0def65d&page=queryresults
[0m13:54:53.096117 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:505ce8f2-9600-4f47-855f-6a2f49504828&page=queryresults
[0m13:54:54.614677 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5f9500d50>]}
[0m13:54:54.615745 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.35s]
[0m13:54:54.617416 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m13:54:54.689170 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601830d50>]}
[0m13:54:54.690463 [info ] [Thread-3 (]: 3 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.43s]
[0m13:54:54.691678 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m13:54:54.915896 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb60129d590>]}
[0m13:54:54.917199 [info ] [Thread-2 (]: 2 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.65s]
[0m13:54:54.919051 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m13:54:55.109216 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dde81cc7-4e54-401d-8918-ba886b5d4763', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb601479a10>]}
[0m13:54:55.110821 [info ] [Thread-4 (]: 4 of 4 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.85s]
[0m13:54:55.112372 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m13:54:55.115083 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:54:55.119577 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:54:55.120440 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m13:54:55.121098 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m13:54:55.121700 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m13:54:55.122515 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m13:54:55.123390 [info ] [MainThread]: 
[0m13:54:55.124445 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 3.78 seconds (3.78s).
[0m13:54:55.126731 [debug] [MainThread]: Command end result
[0m13:54:55.172366 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m13:54:55.177986 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m13:54:55.192154 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m13:54:55.192938 [info ] [MainThread]: 
[0m13:54:55.194050 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:54:55.195230 [info ] [MainThread]: 
[0m13:54:55.196174 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m13:54:55.197696 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0081086, "process_in_blocks": "0", "process_kernel_time": 0.340253, "process_mem_max_rss": "223988", "process_out_blocks": "0", "process_user_time": 3.382524}
[0m13:54:55.198676 [debug] [MainThread]: Command `dbt run` succeeded at 13:54:55.198558 after 5.01 seconds
[0m13:54:55.199491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb632e2d390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb632e2d110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb632e2d290>]}
[0m13:54:55.200227 [debug] [MainThread]: Flushing usage events
[0m13:54:56.653405 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:03:44.754148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f7712be90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f774da110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f770de210>]}


============================== 14:03:44.757626 | 998797d1-caa4-4baf-93ac-f135b54deab4 ==============================
[0m14:03:44.757626 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:03:44.758680 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:03:44.765801 [info ] [MainThread]: dbt version: 1.9.0
[0m14:03:44.766642 [info ] [MainThread]: python version: 3.11.2
[0m14:03:44.767844 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:03:44.769023 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:03:45.283825 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:03:45.285019 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:03:45.286065 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:03:45.287981 [error] [MainThread]: Encountered an error:
Internal Error
  Profile should not be None if loading profile completed
[0m14:03:45.290202 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.5915002, "process_in_blocks": "0", "process_kernel_time": 0.118833, "process_mem_max_rss": "204716", "process_out_blocks": "0", "process_user_time": 2.624243}
[0m14:03:45.291679 [debug] [MainThread]: Command `dbt debug` failed at 14:03:45.291528 after 0.59 seconds
[0m14:03:45.292976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f4988af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f4a48a3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1f49a58f90>]}
[0m14:03:45.294072 [debug] [MainThread]: Flushing usage events
[0m14:03:46.416460 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:04:03.621246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be5f2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be5f3590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be5f2610>]}


============================== 14:04:03.624595 | 53330be2-2b71-4fd9-b3ab-1f57917e1cfc ==============================
[0m14:04:03.624595 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:04:03.625925 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:04:03.716898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '53330be2-2b71-4fd9-b3ab-1f57917e1cfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be5f0f50>]}
[0m14:04:03.770990 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.2020723, "process_in_blocks": "0", "process_kernel_time": 0.059387, "process_mem_max_rss": "90132", "process_out_blocks": "0", "process_user_time": 1.138268}
[0m14:04:03.772290 [debug] [MainThread]: Command `dbt clean` succeeded at 14:04:03.772092 after 0.20 seconds
[0m14:04:03.773259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be646a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79be646350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79c1e10b90>]}
[0m14:04:03.774280 [debug] [MainThread]: Flushing usage events
[0m14:04:04.833132 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:04:06.076006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f081fb9ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f081ff9a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f081fb9b550>]}


============================== 14:04:06.078941 | 09da480d-60cf-4123-ae30-f8b41c1c5d59 ==============================
[0m14:04:06.078941 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:04:06.080228 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m14:04:06.166402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '09da480d-60cf-4123-ae30-f8b41c1c5d59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f081fad6950>]}
[0m14:04:06.176491 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:04:06.179142 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:04:06.180934 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.15953642, "process_in_blocks": "0", "process_kernel_time": 0.050109, "process_mem_max_rss": "90248", "process_out_blocks": "0", "process_user_time": 1.102411}
[0m14:04:06.182052 [debug] [MainThread]: Command `dbt deps` succeeded at 14:04:06.181912 after 0.16 seconds
[0m14:04:06.182765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0823394b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0823519290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0823519250>]}
[0m14:04:06.183548 [debug] [MainThread]: Flushing usage events
[0m14:04:07.211759 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:04:10.113722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f183316e610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18331bf610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18331bffd0>]}


============================== 14:04:10.116618 | 31f492ea-3657-4f5c-9241-fba033c3866a ==============================
[0m14:04:10.116618 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:04:10.118609 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:04:10.126108 [info ] [MainThread]: dbt version: 1.9.0
[0m14:04:10.127419 [info ] [MainThread]: python version: 3.11.2
[0m14:04:10.128733 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:04:10.129809 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:04:10.675577 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:04:10.676745 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:04:10.677800 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:04:10.678666 [info ] [MainThread]: adapter type: bigquery
[0m14:04:10.679527 [info ] [MainThread]: adapter version: 1.9.0
[0m14:04:10.761024 [info ] [MainThread]: Configuration:
[0m14:04:10.762134 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:04:10.763999 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:04:10.765107 [info ] [MainThread]: Required dependencies:
[0m14:04:10.766194 [debug] [MainThread]: Executing "git --help"
[0m14:04:10.768538 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:04:10.769452 [debug] [MainThread]: STDERR: "b''"
[0m14:04:10.770195 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:04:10.771104 [info ] [MainThread]: Connection:
[0m14:04:10.772367 [info ] [MainThread]:   method: service-account
[0m14:04:10.773469 [info ] [MainThread]:   database: purwadika
[0m14:04:10.774719 [info ] [MainThread]:   execution_project: purwadika
[0m14:04:10.776061 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:04:10.777085 [info ] [MainThread]:   location: None
[0m14:04:10.778245 [info ] [MainThread]:   priority: None
[0m14:04:10.779420 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:04:10.780401 [info ] [MainThread]:   impersonate_service_account: None
[0m14:04:10.781574 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:04:10.782515 [info ] [MainThread]:   job_retries: 1
[0m14:04:10.783336 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:04:10.784190 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:04:10.785373 [info ] [MainThread]:   timeout_seconds: None
[0m14:04:10.786360 [info ] [MainThread]:   client_id: None
[0m14:04:10.787392 [info ] [MainThread]:   token_uri: None
[0m14:04:10.788398 [info ] [MainThread]:   dataproc_region: None
[0m14:04:10.789284 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:04:10.790191 [info ] [MainThread]:   gcs_bucket: None
[0m14:04:10.791078 [info ] [MainThread]:   dataproc_batch: None
[0m14:04:10.792286 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:04:10.853854 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:04:10.855028 [debug] [MainThread]: On debug: select 1 as id
[0m14:04:10.856016 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:04:11.555173 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:67a4a5cd-aad4-4aa3-94a9-193502ff120e&page=queryresults
[0m14:04:12.258679 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:04:12.260366 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:04:12.262060 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2002223, "process_in_blocks": "0", "process_kernel_time": 0.196612, "process_mem_max_rss": "214536", "process_out_blocks": "0", "process_user_time": 2.783617}
[0m14:04:12.263167 [debug] [MainThread]: Command `dbt debug` succeeded at 14:04:12.263051 after 2.20 seconds
[0m14:04:12.264296 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:04:12.265190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18331c5190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f18331c4510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1805360f90>]}
[0m14:04:12.266060 [debug] [MainThread]: Flushing usage events
[0m14:04:13.334154 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:06:10.430779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d1de3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d1de7e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d1de3810>]}


============================== 14:06:10.433530 | 990edc3b-c853-4c58-9e99-9d80e2109395 ==============================
[0m14:06:10.433530 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:06:10.434951 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_customer', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:06:11.028688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a9ac6390>]}
[0m14:06:11.076154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d4030e10>]}
[0m14:06:11.077636 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:06:11.145870 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:06:11.148101 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:06:11.149073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a8bfead0>]}
[0m14:06:12.241094 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:06:12.254288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a3c436d0>]}
[0m14:06:12.334517 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:06:12.343611 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:06:12.363695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a3955a10>]}
[0m14:06:12.365179 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:06:12.366575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a3a1c050>]}
[0m14:06:12.369732 [info ] [MainThread]: 
[0m14:06:12.371259 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:06:12.372508 [info ] [MainThread]: 
[0m14:06:12.374027 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:06:12.376163 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:06:12.377645 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:06:14.013618 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m14:06:14.014536 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:06:14.304146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a3a170d0>]}
[0m14:06:14.305200 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:06:14.310370 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:06:14.311589 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m14:06:14.313201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m14:06:14.314169 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:06:14.322578 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:06:14.337217 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:06:14.396859 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:06:14.410379 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m14:06:14.411659 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:06:14.890413 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:de0ef1e4-1b53-4b35-a70e-c9728a594e59&page=queryresults
[0m14:06:16.920227 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '990edc3b-c853-4c58-9e99-9d80e2109395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a39b2690>]}
[0m14:06:16.922020 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.61s]
[0m14:06:16.923895 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:06:16.926664 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:06:16.929954 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:06:16.930864 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:06:16.931794 [info ] [MainThread]: 
[0m14:06:16.932884 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.56 seconds (4.56s).
[0m14:06:16.934825 [debug] [MainThread]: Command end result
[0m14:06:16.973219 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:06:16.977673 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:06:16.986841 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:06:16.987655 [info ] [MainThread]: 
[0m14:06:16.989328 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:06:16.990642 [info ] [MainThread]: 
[0m14:06:16.991902 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:06:16.993619 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.616357, "process_in_blocks": "0", "process_kernel_time": 0.230728, "process_mem_max_rss": "223072", "process_out_blocks": "0", "process_user_time": 4.012675}
[0m14:06:16.994731 [debug] [MainThread]: Command `dbt run` succeeded at 14:06:16.994602 after 6.62 seconds
[0m14:06:16.995963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d55d0e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d572d490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d572d710>]}
[0m14:06:16.996866 [debug] [MainThread]: Flushing usage events
[0m14:06:18.905618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:13:10.558763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ff5297910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ff539dc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ff5296e50>]}


============================== 14:13:10.561754 | ab91b90e-be4d-4b1d-8048-2f4ea986bd24 ==============================
[0m14:13:10.561754 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:13:10.562949 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:13:10.585508 [info ] [MainThread]: dbt version: 1.9.0
[0m14:13:10.586438 [info ] [MainThread]: python version: 3.11.2
[0m14:13:10.587614 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:13:10.588936 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:13:11.115417 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:13:11.116920 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:13:11.118209 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:13:11.119774 [info ] [MainThread]: adapter type: bigquery
[0m14:13:11.121179 [info ] [MainThread]: adapter version: 1.9.0
[0m14:13:11.200435 [info ] [MainThread]: Configuration:
[0m14:13:11.201622 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:13:11.202815 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:13:11.204216 [info ] [MainThread]: Required dependencies:
[0m14:13:11.205637 [debug] [MainThread]: Executing "git --help"
[0m14:13:11.208228 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:13:11.209338 [debug] [MainThread]: STDERR: "b''"
[0m14:13:11.210191 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:13:11.211179 [info ] [MainThread]: Connection:
[0m14:13:11.212506 [info ] [MainThread]:   method: service-account
[0m14:13:11.213583 [info ] [MainThread]:   database: purwadika
[0m14:13:11.214643 [info ] [MainThread]:   execution_project: purwadika
[0m14:13:11.215725 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:13:11.216762 [info ] [MainThread]:   location: None
[0m14:13:11.217903 [info ] [MainThread]:   priority: None
[0m14:13:11.218963 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:13:11.220594 [info ] [MainThread]:   impersonate_service_account: None
[0m14:13:11.222055 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:13:11.223425 [info ] [MainThread]:   job_retries: 1
[0m14:13:11.224673 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:13:11.225873 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:13:11.227110 [info ] [MainThread]:   timeout_seconds: None
[0m14:13:11.228412 [info ] [MainThread]:   client_id: None
[0m14:13:11.229999 [info ] [MainThread]:   token_uri: None
[0m14:13:11.231185 [info ] [MainThread]:   dataproc_region: None
[0m14:13:11.232362 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:13:11.233565 [info ] [MainThread]:   gcs_bucket: None
[0m14:13:11.235824 [info ] [MainThread]:   dataproc_batch: None
[0m14:13:11.237387 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:13:11.302183 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:13:11.303166 [debug] [MainThread]: On debug: select 1 as id
[0m14:13:11.303812 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:13:12.026184 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:71981590-2bbc-48cb-8f69-83307cdbc353&page=queryresults
[0m14:13:12.760155 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:13:12.762535 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:13:12.765976 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2612748, "process_in_blocks": "0", "process_kernel_time": 0.331915, "process_mem_max_rss": "213060", "process_out_blocks": "24", "process_user_time": 2.615088}
[0m14:13:12.767553 [debug] [MainThread]: Command `dbt debug` succeeded at 14:13:12.767406 after 2.26 seconds
[0m14:13:12.768641 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:13:12.769837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc72bf590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fc73efc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ff568a1d0>]}
[0m14:13:12.770892 [debug] [MainThread]: Flushing usage events
[0m14:13:14.103131 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:15:24.714527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef474e6450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef474e4190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef474e7410>]}


============================== 14:15:24.717663 | 89cf1819-3008-4c48-9e53-948c54b82096 ==============================
[0m14:15:24.717663 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:15:24.719175 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m14:15:24.726887 [info ] [MainThread]: dbt version: 1.9.0
[0m14:15:24.728129 [info ] [MainThread]: python version: 3.11.2
[0m14:15:24.729618 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:15:24.730910 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:15:24.742067 [info ] [MainThread]: target not specified in profile 'hailing_project', using 'default'
[0m14:15:24.743604 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:15:24.744792 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:15:24.745895 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:15:24.833783 [info ] [MainThread]: Configuration:
[0m14:15:24.834811 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:15:24.835959 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:15:24.836918 [info ] [MainThread]: Required dependencies:
[0m14:15:24.838019 [debug] [MainThread]: Executing "git --help"
[0m14:15:24.840544 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:15:24.841567 [debug] [MainThread]: STDERR: "b''"
[0m14:15:24.842505 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:15:24.843463 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:15:24.845028 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:15:24.846680 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'default'. The valid target names for this profile are:
   - source_data
   - staging_data


[0m14:15:24.849427 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.19467512, "process_in_blocks": "0", "process_kernel_time": 0.079991, "process_mem_max_rss": "90508", "process_out_blocks": "0", "process_user_time": 1.079891}
[0m14:15:24.850830 [debug] [MainThread]: Command `dbt debug` failed at 14:15:24.850672 after 0.20 seconds
[0m14:15:24.851953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef475121d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4ae99210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4ae99150>]}
[0m14:15:24.853103 [debug] [MainThread]: Flushing usage events
[0m14:15:26.208393 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:16:16.244148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b8543b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b84f6d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b84f6e50>]}


============================== 14:16:16.247476 | 5276e3cf-e951-4c37-a3fc-aa961ee047f9 ==============================
[0m14:16:16.247476 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:16:16.248646 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:16:16.257558 [info ] [MainThread]: dbt version: 1.9.0
[0m14:16:16.258682 [info ] [MainThread]: python version: 3.11.2
[0m14:16:16.260112 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:16:16.261656 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:16:16.272771 [info ] [MainThread]: target not specified in profile 'hailing_project', using 'default'
[0m14:16:16.273829 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:16:16.274880 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:16:16.276120 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:16:16.362925 [info ] [MainThread]: Configuration:
[0m14:16:16.364157 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:16:16.365511 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:16:16.366673 [info ] [MainThread]: Required dependencies:
[0m14:16:16.367750 [debug] [MainThread]: Executing "git --help"
[0m14:16:16.369949 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:16:16.370778 [debug] [MainThread]: STDERR: "b''"
[0m14:16:16.371657 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:16:16.372805 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:16:16.373973 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:16:16.375268 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'default'. The valid target names for this profile are:
   - source_data
   - staging_data


[0m14:16:16.377004 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.18434772, "process_in_blocks": "0", "process_kernel_time": 0.148561, "process_mem_max_rss": "90508", "process_out_blocks": "0", "process_user_time": 1.039932}
[0m14:16:16.378175 [debug] [MainThread]: Command `dbt debug` failed at 14:16:16.378053 after 0.19 seconds
[0m14:16:16.379188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b849aa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bbead210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bbead150>]}
[0m14:16:16.380649 [debug] [MainThread]: Flushing usage events
[0m14:16:17.868058 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:16:44.864849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3e2d2850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3e2d3450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3e2d2d90>]}


============================== 14:16:44.867575 | 01289af6-0bdf-462b-85ab-5a7f5f93bb20 ==============================
[0m14:16:44.867575 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:16:44.870114 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:16:44.877834 [info ] [MainThread]: dbt version: 1.9.0
[0m14:16:44.879646 [info ] [MainThread]: python version: 3.11.2
[0m14:16:44.881091 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:16:44.882459 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:16:44.892050 [info ] [MainThread]: target not specified in profile 'hailing_project', using 'default'
[0m14:16:44.893325 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:16:44.894392 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:16:44.895407 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:16:44.976796 [info ] [MainThread]: Configuration:
[0m14:16:44.977929 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:16:44.979281 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:16:44.980494 [info ] [MainThread]: Required dependencies:
[0m14:16:44.981551 [debug] [MainThread]: Executing "git --help"
[0m14:16:44.983637 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:16:44.984373 [debug] [MainThread]: STDERR: "b''"
[0m14:16:44.985237 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:16:44.986190 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:16:44.987793 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:16:44.988865 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'default'. The valid target names for this profile are:
   - source_data
   - staging_data


[0m14:16:44.990661 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.17773876, "process_in_blocks": "0", "process_kernel_time": 0.069498, "process_mem_max_rss": "90576", "process_out_blocks": "0", "process_user_time": 0.982904}
[0m14:16:44.991916 [debug] [MainThread]: Command `dbt debug` failed at 14:16:44.991763 after 0.18 seconds
[0m14:16:44.993370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e41c21350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e41c210d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2e3e14f0d0>]}
[0m14:16:44.994434 [debug] [MainThread]: Flushing usage events
[0m14:16:46.285431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:17:38.677407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d00d13f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d00d12990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d00d121d0>]}


============================== 14:17:38.680469 | 0cc35554-7fa5-4052-984f-b9671c1f93a0 ==============================
[0m14:17:38.680469 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:17:38.681692 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:17:38.689453 [info ] [MainThread]: dbt version: 1.9.0
[0m14:17:38.690623 [info ] [MainThread]: python version: 3.11.2
[0m14:17:38.692007 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:17:38.693121 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:17:39.189776 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:17:39.191197 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:17:39.192497 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:17:39.193624 [info ] [MainThread]: adapter type: bigquery
[0m14:17:39.195135 [info ] [MainThread]: adapter version: 1.9.0
[0m14:17:39.279036 [info ] [MainThread]: Configuration:
[0m14:17:39.281161 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:17:39.282639 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:17:39.284006 [info ] [MainThread]: Required dependencies:
[0m14:17:39.285121 [debug] [MainThread]: Executing "git --help"
[0m14:17:39.287184 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:17:39.288275 [debug] [MainThread]: STDERR: "b''"
[0m14:17:39.289176 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:17:39.290007 [info ] [MainThread]: Connection:
[0m14:17:39.291262 [info ] [MainThread]:   method: service-account
[0m14:17:39.292264 [info ] [MainThread]:   database: purwadika
[0m14:17:39.293397 [info ] [MainThread]:   execution_project: purwadika
[0m14:17:39.294633 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:17:39.295701 [info ] [MainThread]:   location: None
[0m14:17:39.297023 [info ] [MainThread]:   priority: None
[0m14:17:39.298391 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:17:39.299349 [info ] [MainThread]:   impersonate_service_account: None
[0m14:17:39.300248 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:17:39.301121 [info ] [MainThread]:   job_retries: 1
[0m14:17:39.302043 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:17:39.303801 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:17:39.305045 [info ] [MainThread]:   timeout_seconds: None
[0m14:17:39.305928 [info ] [MainThread]:   client_id: None
[0m14:17:39.306989 [info ] [MainThread]:   token_uri: None
[0m14:17:39.307880 [info ] [MainThread]:   dataproc_region: None
[0m14:17:39.309145 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:17:39.310492 [info ] [MainThread]:   gcs_bucket: None
[0m14:17:39.312097 [info ] [MainThread]:   dataproc_batch: None
[0m14:17:39.313269 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:17:39.368995 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:17:39.370189 [debug] [MainThread]: On debug: select 1 as id
[0m14:17:39.371563 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:17:40.039431 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:c58d470b-e5eb-4df8-abfc-43665ab7d00a&page=queryresults
[0m14:17:40.772093 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:17:40.773378 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:17:40.775894 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.151395, "process_in_blocks": "0", "process_kernel_time": 0.111987, "process_mem_max_rss": "212340", "process_out_blocks": "0", "process_user_time": 2.789518}
[0m14:17:40.776971 [debug] [MainThread]: Command `dbt debug` succeeded at 14:17:40.776842 after 2.15 seconds
[0m14:17:40.777632 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:17:40.778427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d00d66f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d0110e810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d04544c10>]}
[0m14:17:40.779267 [debug] [MainThread]: Flushing usage events
[0m14:17:41.815485 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:17:44.792228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd187270d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd18726dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd18727150>]}


============================== 14:17:44.795022 | 82d178b7-1440-48e2-b384-f6ba05410009 ==============================
[0m14:17:44.795022 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:17:44.796246 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:17:45.405307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbceaa8e850>]}
[0m14:17:45.463871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1a9988d0>]}
[0m14:17:45.465190 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:17:45.541786 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:17:45.715714 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:17:45.716663 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:17:45.721648 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m14:17:45.751584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea9862d0>]}
[0m14:17:45.874217 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:17:45.879739 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:17:45.903700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea8c8bd0>]}
[0m14:17:45.905204 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:17:45.906911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea8bda90>]}
[0m14:17:45.910075 [info ] [MainThread]: 
[0m14:17:45.911336 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:17:45.912237 [info ] [MainThread]: 
[0m14:17:45.913713 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:17:45.918689 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:17:45.919632 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:17:46.484667 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m14:17:46.485507 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:17:46.748433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1aabb690>]}
[0m14:17:46.749742 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:17:46.755543 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:17:46.756004 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:17:46.756476 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:17:46.756901 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:17:46.757658 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m14:17:46.759116 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m14:17:46.760349 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m14:17:46.761561 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m14:17:46.762857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m14:17:46.764178 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:17:46.765409 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:17:46.766428 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:17:46.767543 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:17:46.768562 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:17:46.769639 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:17:46.770635 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:17:46.787047 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:17:46.792358 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:17:46.796628 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:17:46.800694 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:17:46.808964 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:17:46.809516 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:17:46.821300 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:17:46.834143 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:17:46.858466 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:17:46.876091 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:17:46.889372 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:17:46.891948 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:17:46.945228 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m14:17:46.970946 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:17:47.249108 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:17:47.249913 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:17:47.251477 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:17:47.258394 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:17:47.260867 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:17:47.265164 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:17:47.514742 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2471bffc-48ea-4371-8064-c336f467eb84&page=queryresults
[0m14:17:47.585751 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:40e7c351-484f-474d-9379-8bad3db7614c&page=queryresults
[0m14:17:47.604839 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9fd93cf9-1b74-4744-8a33-011de5f884ef&page=queryresults
[0m14:17:47.658042 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b134efc-42cc-4278-a428-2323928894a3&page=queryresults
[0m14:17:49.032656 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea6c69d0>]}
[0m14:17:49.034035 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.27s]
[0m14:17:49.035576 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:17:49.036681 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:17:49.037668 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m14:17:49.039074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:17:49.040401 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:17:49.045211 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:17:49.052215 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:17:49.056935 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:17:49.201617 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea4f5910>]}
[0m14:17:49.203180 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.44s]
[0m14:17:49.204573 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:17:49.245025 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcea513e90>]}
[0m14:17:49.246292 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.48s]
[0m14:17:49.247941 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:17:49.316128 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce838fcd0>]}
[0m14:17:49.317468 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.55s]
[0m14:17:49.318605 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:17:49.335929 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:17:49.342636 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:17:49.647967 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:775a5d31-b8ab-411d-94a7-d322e682123d&page=queryresults
[0m14:17:51.239621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82d178b7-1440-48e2-b384-f6ba05410009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbce80e9a90>]}
[0m14:17:51.241622 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.20s]
[0m14:17:51.243119 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:17:51.245655 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:17:51.248863 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:17:51.249682 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:17:51.250472 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:17:51.251161 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:17:51.251852 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m14:17:51.252669 [info ] [MainThread]: 
[0m14:17:51.253616 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.34 seconds (5.34s).
[0m14:17:51.256353 [debug] [MainThread]: Command end result
[0m14:17:51.291054 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:17:51.295554 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:17:51.303483 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:17:51.304408 [info ] [MainThread]: 
[0m14:17:51.305501 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:17:51.306856 [info ] [MainThread]: 
[0m14:17:51.307939 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:17:51.309527 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.5712976, "process_in_blocks": "0", "process_kernel_time": 0.229025, "process_mem_max_rss": "223216", "process_out_blocks": "120", "process_user_time": 3.48517}
[0m14:17:51.310455 [debug] [MainThread]: Command `dbt run` succeeded at 14:17:51.310341 after 6.57 seconds
[0m14:17:51.311415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1879fa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1c211790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbd1bf40c10>]}
[0m14:17:51.312337 [debug] [MainThread]: Flushing usage events
[0m14:17:52.694159 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:19:18.008064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b1817410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b186b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b3bac9d0>]}


============================== 14:19:18.010837 | 129bac6e-7cd5-423e-b3cc-f19a47468701 ==============================
[0m14:19:18.010837 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:19:18.012247 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt debug', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:19:18.019972 [info ] [MainThread]: dbt version: 1.9.0
[0m14:19:18.021093 [info ] [MainThread]: python version: 3.11.2
[0m14:19:18.022484 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:19:18.023827 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:19:18.583568 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:19:18.584738 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:19:18.586014 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:19:18.587072 [info ] [MainThread]: adapter type: bigquery
[0m14:19:18.588382 [info ] [MainThread]: adapter version: 1.9.0
[0m14:19:18.675931 [info ] [MainThread]: Configuration:
[0m14:19:18.677037 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:19:18.678609 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:19:18.679585 [info ] [MainThread]: Required dependencies:
[0m14:19:18.680628 [debug] [MainThread]: Executing "git --help"
[0m14:19:18.682891 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:19:18.683649 [debug] [MainThread]: STDERR: "b''"
[0m14:19:18.684406 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:19:18.685562 [info ] [MainThread]: Connection:
[0m14:19:18.687254 [info ] [MainThread]:   method: service-account
[0m14:19:18.688712 [info ] [MainThread]:   database: purwadika
[0m14:19:18.690166 [info ] [MainThread]:   execution_project: purwadika
[0m14:19:18.691084 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:19:18.692249 [info ] [MainThread]:   location: None
[0m14:19:18.694277 [info ] [MainThread]:   priority: None
[0m14:19:18.695748 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:19:18.696688 [info ] [MainThread]:   impersonate_service_account: None
[0m14:19:18.697642 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:19:18.698547 [info ] [MainThread]:   job_retries: 1
[0m14:19:18.699713 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:19:18.700916 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:19:18.701835 [info ] [MainThread]:   timeout_seconds: None
[0m14:19:18.702855 [info ] [MainThread]:   client_id: None
[0m14:19:18.703853 [info ] [MainThread]:   token_uri: None
[0m14:19:18.704854 [info ] [MainThread]:   dataproc_region: None
[0m14:19:18.706249 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:19:18.707705 [info ] [MainThread]:   gcs_bucket: None
[0m14:19:18.708841 [info ] [MainThread]:   dataproc_batch: None
[0m14:19:18.709950 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:19:18.777520 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:19:18.778647 [debug] [MainThread]: On debug: select 1 as id
[0m14:19:18.779551 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:19:19.465508 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:23be2415-d9c4-4976-a6b8-5a15ebb2c423&page=queryresults
[0m14:19:20.240156 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:19:20.242282 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:19:20.244168 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.303079, "process_in_blocks": "0", "process_kernel_time": 0.210186, "process_mem_max_rss": "212480", "process_out_blocks": "0", "process_user_time": 2.812492}
[0m14:19:20.245270 [debug] [MainThread]: Command `dbt debug` succeeded at 14:19:20.245146 after 2.30 seconds
[0m14:19:20.246092 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:19:20.246821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b1c125d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b184dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b181c650>]}
[0m14:19:20.247832 [debug] [MainThread]: Flushing usage events
[0m14:19:21.871541 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:19:24.816482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6aef250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6eee690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6aeed50>]}


============================== 14:19:24.820542 | 5d25e228-44bd-42f6-96b1-69d249746859 ==============================
[0m14:19:24.820542 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:19:24.821736 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:19:25.460164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6b20d90>]}
[0m14:19:25.510372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de8d79850>]}
[0m14:19:25.512680 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:19:25.594217 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:19:25.768636 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:19:25.769460 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:19:25.774526 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:19:25.801373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dc5601e50>]}
[0m14:19:25.927914 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:19:25.933552 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:19:25.951910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbce785d0>]}
[0m14:19:25.953283 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:19:25.954483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbce6d0d0>]}
[0m14:19:25.957367 [info ] [MainThread]: 
[0m14:19:25.958432 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:19:25.959455 [info ] [MainThread]: 
[0m14:19:25.960639 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:19:25.965490 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:19:25.966500 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:26.457433 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m14:19:26.459095 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:19:26.649652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de7907690>]}
[0m14:19:26.651202 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:19:26.656542 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:19:26.657366 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:19:26.657865 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:19:26.658209 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:19:26.658904 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m14:19:26.659992 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m14:19:26.660932 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m14:19:26.661950 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m14:19:26.663038 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m14:19:26.664044 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:19:26.665804 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:19:26.667023 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:19:26.667970 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:19:26.668815 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:19:26.669500 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:19:26.670296 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:19:26.688634 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:19:26.692810 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:19:26.697443 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:19:26.701634 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:19:26.707886 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:19:26.708897 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:19:26.714676 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:19:26.724968 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:19:26.752786 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:19:26.753243 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:19:26.756172 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:19:26.760111 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:19:27.024028 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:19:27.028508 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:19:27.030497 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:19:27.032244 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:19:27.037890 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:19:27.038524 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:19:27.039458 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:19:27.040992 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:19:27.289968 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:850e034c-4be3-46a0-92f3-ebbe6bea7d85&page=queryresults
[0m14:19:27.297566 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:95afeeb9-7b7f-4504-b977-2aa619dceb68&page=queryresults
[0m14:19:27.361265 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:89c10ba0-07ee-48f8-9b53-82a1bfbf9f56&page=queryresults
[0m14:19:27.361799 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d2bc393d-d245-4e90-b0d4-eef873e32206&page=queryresults
[0m14:19:28.900561 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbc943ed0>]}
[0m14:19:28.902242 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.23s]
[0m14:19:28.903737 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:19:28.904850 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:19:28.905907 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m14:19:28.906969 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:19:28.908298 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:19:28.912771 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:19:28.920921 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:19:28.925203 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m14:19:29.048734 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9db4c4b350>]}
[0m14:19:29.049979 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.38s]
[0m14:19:29.051255 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:19:29.085448 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbc94cb90>]}
[0m14:19:29.088522 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dbcb18ed0>]}
[0m14:19:29.089613 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.42s]
[0m14:19:29.090996 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.43s]
[0m14:19:29.092236 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:19:29.093350 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:19:29.170558 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:19:29.177394 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:19:29.473608 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b5dd4f33-c2dd-42ff-a4bf-1b674aaf4b86&page=queryresults
[0m14:19:31.006223 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d25e228-44bd-42f6-96b1-69d249746859', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6af5d10>]}
[0m14:19:31.008099 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.10s]
[0m14:19:31.009900 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:19:31.012994 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:19:31.016513 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:19:31.017366 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:19:31.018304 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:19:31.019493 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:19:31.020686 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:19:31.021733 [info ] [MainThread]: 
[0m14:19:31.022930 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.06 seconds (5.06s).
[0m14:19:31.025113 [debug] [MainThread]: Command end result
[0m14:19:31.066445 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:19:31.072630 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:19:31.084429 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:19:31.085428 [info ] [MainThread]: 
[0m14:19:31.086699 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:19:31.088260 [info ] [MainThread]: 
[0m14:19:31.089604 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:19:31.092007 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.337032, "process_in_blocks": "0", "process_kernel_time": 0.168976, "process_mem_max_rss": "222724", "process_out_blocks": "0", "process_user_time": 3.508751}
[0m14:19:31.094173 [debug] [MainThread]: Command `dbt run` succeeded at 14:19:31.093962 after 6.34 seconds
[0m14:19:31.095978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6b4c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9de6b4c2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9dea310c90>]}
[0m14:19:31.097932 [debug] [MainThread]: Flushing usage events
[0m14:19:32.645756 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:21:02.265651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1c15b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1c1a3c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1c15b5d0>]}


============================== 14:21:02.269413 | 2f93d259-b38e-4a47-bf46-437955dd32a5 ==============================
[0m14:21:02.269413 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:21:02.272203 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:21:02.279962 [info ] [MainThread]: dbt version: 1.9.0
[0m14:21:02.281231 [info ] [MainThread]: python version: 3.11.2
[0m14:21:02.283212 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:21:02.285136 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:21:02.295612 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:21:02.297274 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:21:02.298986 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:21:02.380606 [info ] [MainThread]: Configuration:
[0m14:21:02.382231 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:21:02.383387 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:21:02.384499 [info ] [MainThread]: Required dependencies:
[0m14:21:02.385768 [debug] [MainThread]: Executing "git --help"
[0m14:21:02.388639 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:21:02.389678 [debug] [MainThread]: STDERR: "b''"
[0m14:21:02.390457 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:21:02.391460 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:21:02.392813 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:21:02.394112 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'dev'. The valid target names for this profile are:
   - staging
   - facts


[0m14:21:02.396026 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.18709344, "process_in_blocks": "0", "process_kernel_time": 0.03997, "process_mem_max_rss": "90368", "process_out_blocks": "0", "process_user_time": 1.109182}
[0m14:21:02.397032 [debug] [MainThread]: Command `dbt debug` failed at 14:21:02.396925 after 0.19 seconds
[0m14:21:02.398223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1c1861d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1fad1210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a1fad1150>]}
[0m14:21:02.399065 [debug] [MainThread]: Flushing usage events
[0m14:21:03.540504 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:21:29.440030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa2740d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fb061550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa2befd0>]}


============================== 14:21:29.442554 | 280159b5-8ac2-4177-ad64-ce9951fcdf36 ==============================
[0m14:21:29.442554 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:21:29.444701 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m14:21:29.451847 [info ] [MainThread]: dbt version: 1.9.0
[0m14:21:29.452786 [info ] [MainThread]: python version: 3.11.2
[0m14:21:29.453739 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:21:29.454884 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:21:29.997814 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:21:29.998891 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:21:30.000373 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:21:30.001717 [info ] [MainThread]: adapter type: bigquery
[0m14:21:30.002845 [info ] [MainThread]: adapter version: 1.9.0
[0m14:21:30.085528 [info ] [MainThread]: Configuration:
[0m14:21:30.086697 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:21:30.088051 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:21:30.090598 [info ] [MainThread]: Required dependencies:
[0m14:21:30.092013 [debug] [MainThread]: Executing "git --help"
[0m14:21:30.094328 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:21:30.095457 [debug] [MainThread]: STDERR: "b''"
[0m14:21:30.096501 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:21:30.097893 [info ] [MainThread]: Connection:
[0m14:21:30.099658 [info ] [MainThread]:   method: service-account
[0m14:21:30.101071 [info ] [MainThread]:   database: purwadika
[0m14:21:30.101917 [info ] [MainThread]:   execution_project: purwadika
[0m14:21:30.102739 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:21:30.104332 [info ] [MainThread]:   location: None
[0m14:21:30.105939 [info ] [MainThread]:   priority: None
[0m14:21:30.107807 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:21:30.110995 [info ] [MainThread]:   impersonate_service_account: None
[0m14:21:30.112422 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:21:30.113680 [info ] [MainThread]:   job_retries: 1
[0m14:21:30.115099 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:21:30.116008 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:21:30.116885 [info ] [MainThread]:   timeout_seconds: None
[0m14:21:30.117962 [info ] [MainThread]:   client_id: None
[0m14:21:30.119003 [info ] [MainThread]:   token_uri: None
[0m14:21:30.120003 [info ] [MainThread]:   dataproc_region: None
[0m14:21:30.120979 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:21:30.121844 [info ] [MainThread]:   gcs_bucket: None
[0m14:21:30.122662 [info ] [MainThread]:   dataproc_batch: None
[0m14:21:30.123656 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:21:30.181321 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:21:30.182275 [debug] [MainThread]: On debug: select 1 as id
[0m14:21:30.183076 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:21:30.876971 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:f99d9e6c-98a9-44dc-9ff6-b8f3a04e353e&page=queryresults
[0m14:21:31.580049 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:21:31.581064 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:21:31.582724 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1959321, "process_in_blocks": "0", "process_kernel_time": 0.180092, "process_mem_max_rss": "211908", "process_out_blocks": "0", "process_user_time": 2.801439}
[0m14:21:31.584265 [debug] [MainThread]: Command `dbt debug` succeeded at 14:21:31.584051 after 2.20 seconds
[0m14:21:31.585467 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:21:31.586430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa72c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa2c9210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00fa278710>]}
[0m14:21:31.587394 [debug] [MainThread]: Flushing usage events
[0m14:21:32.838069 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:22:00.572477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6485c26f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6486907450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6485c26510>]}


============================== 14:22:00.575573 | 0add5a11-981a-4f48-877c-b7811cf2739b ==============================
[0m14:22:00.575573 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:22:00.576865 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:22:00.584214 [info ] [MainThread]: dbt version: 1.9.0
[0m14:22:00.585635 [info ] [MainThread]: python version: 3.11.2
[0m14:22:00.586911 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:22:00.588182 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:22:01.151103 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:22:01.152530 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:22:01.154102 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:22:01.156065 [info ] [MainThread]: adapter type: bigquery
[0m14:22:01.157551 [info ] [MainThread]: adapter version: 1.9.0
[0m14:22:01.239754 [info ] [MainThread]: Configuration:
[0m14:22:01.241109 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:22:01.242192 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:22:01.243253 [info ] [MainThread]: Required dependencies:
[0m14:22:01.244304 [debug] [MainThread]: Executing "git --help"
[0m14:22:01.246608 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:22:01.247407 [debug] [MainThread]: STDERR: "b''"
[0m14:22:01.248128 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:22:01.249507 [info ] [MainThread]: Connection:
[0m14:22:01.250615 [info ] [MainThread]:   method: service-account
[0m14:22:01.251755 [info ] [MainThread]:   database: purwadika
[0m14:22:01.253550 [info ] [MainThread]:   execution_project: purwadika
[0m14:22:01.254847 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:22:01.255892 [info ] [MainThread]:   location: None
[0m14:22:01.256938 [info ] [MainThread]:   priority: None
[0m14:22:01.257825 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:22:01.259247 [info ] [MainThread]:   impersonate_service_account: None
[0m14:22:01.260766 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:22:01.261943 [info ] [MainThread]:   job_retries: 1
[0m14:22:01.262996 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:22:01.263887 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:22:01.265003 [info ] [MainThread]:   timeout_seconds: None
[0m14:22:01.266388 [info ] [MainThread]:   client_id: None
[0m14:22:01.267585 [info ] [MainThread]:   token_uri: None
[0m14:22:01.268716 [info ] [MainThread]:   dataproc_region: None
[0m14:22:01.269960 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:22:01.270993 [info ] [MainThread]:   gcs_bucket: None
[0m14:22:01.271925 [info ] [MainThread]:   dataproc_batch: None
[0m14:22:01.273474 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:22:01.331644 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:22:01.332644 [debug] [MainThread]: On debug: select 1 as id
[0m14:22:01.333585 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:22:01.991757 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:c4f31956-dde8-44eb-a9fd-e101c16b7b98&page=queryresults
[0m14:22:02.706573 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:22:02.707952 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:22:02.710007 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.191244, "process_in_blocks": "0", "process_kernel_time": 0.168452, "process_mem_max_rss": "212356", "process_out_blocks": "0", "process_user_time": 2.814151}
[0m14:22:02.711404 [debug] [MainThread]: Command `dbt debug` succeeded at 14:22:02.711224 after 2.19 seconds
[0m14:22:02.712539 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:22:02.713429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6457cc2390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6457d78f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6485c28710>]}
[0m14:22:02.714452 [debug] [MainThread]: Flushing usage events
[0m14:22:04.266274 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:22:43.228833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1a5eebd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1a9e6690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1a6431d0>]}


============================== 14:22:43.231718 | 75cbbe04-b220-4aaa-a9c5-bb49bfb3808d ==============================
[0m14:22:43.231718 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:22:43.232839 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:22:43.241543 [info ] [MainThread]: dbt version: 1.9.0
[0m14:22:43.242963 [info ] [MainThread]: python version: 3.11.2
[0m14:22:43.244729 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:22:43.246019 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:22:43.780920 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:22:43.782032 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:22:43.783622 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:22:43.785641 [info ] [MainThread]: adapter type: bigquery
[0m14:22:43.786857 [info ] [MainThread]: adapter version: 1.9.0
[0m14:22:43.869235 [info ] [MainThread]: Configuration:
[0m14:22:43.870428 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:22:43.871524 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:22:43.872780 [info ] [MainThread]: Required dependencies:
[0m14:22:43.874138 [debug] [MainThread]: Executing "git --help"
[0m14:22:43.876528 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:22:43.877289 [debug] [MainThread]: STDERR: "b''"
[0m14:22:43.878102 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:22:43.878969 [info ] [MainThread]: Connection:
[0m14:22:43.880195 [info ] [MainThread]:   method: service-account
[0m14:22:43.881549 [info ] [MainThread]:   database: purwadika
[0m14:22:43.883084 [info ] [MainThread]:   execution_project: purwadika
[0m14:22:43.884092 [info ] [MainThread]:   schema: rizky_dwh_hailing_facts
[0m14:22:43.885125 [info ] [MainThread]:   location: None
[0m14:22:43.886190 [info ] [MainThread]:   priority: None
[0m14:22:43.887447 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:22:43.888770 [info ] [MainThread]:   impersonate_service_account: None
[0m14:22:43.890047 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:22:43.891065 [info ] [MainThread]:   job_retries: 1
[0m14:22:43.892026 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:22:43.892956 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:22:43.893875 [info ] [MainThread]:   timeout_seconds: None
[0m14:22:43.895245 [info ] [MainThread]:   client_id: None
[0m14:22:43.896924 [info ] [MainThread]:   token_uri: None
[0m14:22:43.898205 [info ] [MainThread]:   dataproc_region: None
[0m14:22:43.899205 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:22:43.900213 [info ] [MainThread]:   gcs_bucket: None
[0m14:22:43.901183 [info ] [MainThread]:   dataproc_batch: None
[0m14:22:43.902662 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:22:43.961700 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:22:43.962680 [debug] [MainThread]: On debug: select 1 as id
[0m14:22:43.963618 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:22:44.569898 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:133408e0-1e67-484c-be0c-245451e7d5bb&page=queryresults
[0m14:22:45.378632 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:22:45.379884 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:22:45.382698 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.2135456, "process_in_blocks": "0", "process_kernel_time": 0.110118, "process_mem_max_rss": "212264", "process_out_blocks": "0", "process_user_time": 2.873085}
[0m14:22:45.384382 [debug] [MainThread]: Command `dbt debug` succeeded at 14:22:45.384243 after 2.22 seconds
[0m14:22:45.385233 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:22:45.386243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef0783690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1a9e6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f1deaca90>]}
[0m14:22:45.387300 [debug] [MainThread]: Flushing usage events
[0m14:22:46.422689 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:22:55.316100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46ec677490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46eca75ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46eca75fd0>]}


============================== 14:22:55.319192 | cd2da8bb-217b-4e71-b4dc-8daf99e2d7de ==============================
[0m14:22:55.319192 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:22:55.320411 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:22:55.327546 [info ] [MainThread]: dbt version: 1.9.0
[0m14:22:55.328464 [info ] [MainThread]: python version: 3.11.2
[0m14:22:55.329698 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:22:55.330998 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:22:55.345372 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:22:55.346475 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:22:55.347408 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:22:55.423513 [info ] [MainThread]: Configuration:
[0m14:22:55.424676 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:22:55.426167 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:22:55.427293 [info ] [MainThread]: Required dependencies:
[0m14:22:55.428282 [debug] [MainThread]: Executing "git --help"
[0m14:22:55.430808 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:22:55.431664 [debug] [MainThread]: STDERR: "b''"
[0m14:22:55.432489 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:22:55.433254 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:22:55.434556 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:22:55.435557 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'dev, facts'. The valid target names for this profile are:
   - dev
   - facts


[0m14:22:55.438009 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.17276138, "process_in_blocks": "0", "process_kernel_time": 0.089727, "process_mem_max_rss": "90612", "process_out_blocks": "0", "process_user_time": 1.116606}
[0m14:22:55.439276 [debug] [MainThread]: Command `dbt debug` failed at 14:22:55.439153 after 0.17 seconds
[0m14:22:55.440062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46efff5290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46efff4910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f46efff5250>]}
[0m14:22:55.440816 [debug] [MainThread]: Flushing usage events
[0m14:22:56.495375 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:23:15.429839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81882ef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81882f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81882e990>]}


============================== 14:23:15.433061 | 73f5604a-2c09-42fb-81ff-cb1ba5c513e1 ==============================
[0m14:23:15.433061 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:23:15.434278 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:23:15.442041 [info ] [MainThread]: dbt version: 1.9.0
[0m14:23:15.443220 [info ] [MainThread]: python version: 3.11.2
[0m14:23:15.444323 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:23:15.446229 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:23:15.459847 [info ] [MainThread]: target not specified in profile 'hailing_project', using 'default'
[0m14:23:15.461064 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:23:15.462518 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:23:15.463509 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:23:15.556615 [info ] [MainThread]: Configuration:
[0m14:23:15.557968 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:23:15.559307 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:23:15.560377 [info ] [MainThread]: Required dependencies:
[0m14:23:15.561365 [debug] [MainThread]: Executing "git --help"
[0m14:23:15.563418 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:23:15.564409 [debug] [MainThread]: STDERR: "b''"
[0m14:23:15.565541 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:23:15.566663 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:23:15.567557 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:23:15.568674 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  The profile 'hailing_project' does not have a target named 'default'. The valid target names for this profile are:
   - dev
   - facts


[0m14:23:15.570464 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.19949, "process_in_blocks": "0", "process_kernel_time": 0.020305, "process_mem_max_rss": "90468", "process_out_blocks": "0", "process_user_time": 1.137084}
[0m14:23:15.572414 [debug] [MainThread]: Command `dbt debug` failed at 14:23:15.572225 after 0.20 seconds
[0m14:23:15.573366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81887ee10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe818792a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe81c1a4850>]}
[0m14:23:15.574386 [debug] [MainThread]: Flushing usage events
[0m14:23:16.899149 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:26:14.906284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c915a450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c9269c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c915a610>]}


============================== 14:26:14.909494 | 55db6db5-2d0e-4f14-85f2-8e1792aa8e42 ==============================
[0m14:26:14.909494 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:26:14.910755 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:26:14.917704 [info ] [MainThread]: dbt version: 1.9.0
[0m14:26:14.918672 [info ] [MainThread]: python version: 3.11.2
[0m14:26:14.920090 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:26:14.921617 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:26:15.458033 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:26:15.459293 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:26:15.460331 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:26:15.537946 [info ] [MainThread]: Configuration:
[0m14:26:15.539033 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:26:15.539974 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:26:15.540952 [info ] [MainThread]: Required dependencies:
[0m14:26:15.542278 [debug] [MainThread]: Executing "git --help"
[0m14:26:15.544330 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:26:15.545166 [debug] [MainThread]: STDERR: "b''"
[0m14:26:15.545893 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:26:15.546821 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:26:15.548105 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:26:15.549313 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "hailing_project", target "dev" invalid: Runtime Error
    Must specify schema


[0m14:26:15.551287 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.69950664, "process_in_blocks": "0", "process_kernel_time": 0.151951, "process_mem_max_rss": "208568", "process_out_blocks": "0", "process_user_time": 2.633829}
[0m14:26:15.552334 [debug] [MainThread]: Command `dbt debug` failed at 14:26:15.552206 after 0.70 seconds
[0m14:26:15.553247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c91ab110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f759b318050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75c91d3650>]}
[0m14:26:15.554444 [debug] [MainThread]: Flushing usage events
[0m14:26:16.946074 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:29:29.422640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa21f250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa649f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa707710>]}


============================== 14:29:29.425374 | 2f11b091-eb6a-4b46-800a-11581e404d15 ==============================
[0m14:29:29.425374 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:29:29.426471 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m14:29:29.433368 [info ] [MainThread]: dbt version: 1.9.0
[0m14:29:29.434726 [info ] [MainThread]: python version: 3.11.2
[0m14:29:29.435933 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:29:29.437197 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:29:29.939045 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:29:29.940896 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:29:29.942342 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:29:29.944452 [info ] [MainThread]: adapter type: bigquery
[0m14:29:29.945675 [info ] [MainThread]: adapter version: 1.9.0
[0m14:29:30.022359 [info ] [MainThread]: Configuration:
[0m14:29:30.023588 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:29:30.024689 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:29:30.025983 [info ] [MainThread]: Required dependencies:
[0m14:29:30.027086 [debug] [MainThread]: Executing "git --help"
[0m14:29:30.029304 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:29:30.030025 [debug] [MainThread]: STDERR: "b''"
[0m14:29:30.030805 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:29:30.031710 [info ] [MainThread]: Connection:
[0m14:29:30.032809 [info ] [MainThread]:   method: service-account
[0m14:29:30.033942 [info ] [MainThread]:   database: purwadika
[0m14:29:30.035173 [info ] [MainThread]:   execution_project: purwadika
[0m14:29:30.036796 [info ] [MainThread]:   schema: rizky_dwh_hailing_staging
[0m14:29:30.038447 [info ] [MainThread]:   location: None
[0m14:29:30.039418 [info ] [MainThread]:   priority: None
[0m14:29:30.040473 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:29:30.041599 [info ] [MainThread]:   impersonate_service_account: None
[0m14:29:30.042605 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:29:30.043723 [info ] [MainThread]:   job_retries: 1
[0m14:29:30.045105 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:29:30.045954 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:29:30.046837 [info ] [MainThread]:   timeout_seconds: None
[0m14:29:30.047686 [info ] [MainThread]:   client_id: None
[0m14:29:30.048515 [info ] [MainThread]:   token_uri: None
[0m14:29:30.049817 [info ] [MainThread]:   dataproc_region: None
[0m14:29:30.051788 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:29:30.053108 [info ] [MainThread]:   gcs_bucket: None
[0m14:29:30.054074 [info ] [MainThread]:   dataproc_batch: None
[0m14:29:30.055292 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:29:30.115934 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:29:30.117019 [debug] [MainThread]: On debug: select 1 as id
[0m14:29:30.117964 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:29:30.810283 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:290e0302-7e1b-41fc-aee3-93f2d8975e93&page=queryresults
[0m14:29:31.531832 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:29:31.533154 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:29:31.535029 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1681876, "process_in_blocks": "0", "process_kernel_time": 0.21207, "process_mem_max_rss": "212280", "process_out_blocks": "0", "process_user_time": 2.706418}
[0m14:29:31.536240 [debug] [MainThread]: Command `dbt debug` succeeded at 14:29:31.536126 after 2.17 seconds
[0m14:29:31.537071 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:29:31.537834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa2544d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa255590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5faa2248d0>]}
[0m14:29:31.538695 [debug] [MainThread]: Flushing usage events
[0m14:29:32.857047 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:29:36.352344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb82587690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb82587310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb82586b50>]}


============================== 14:29:36.355536 | a46a4e95-cffb-45a2-9134-694d682cd294 ==============================
[0m14:29:36.355536 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:29:36.356958 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:29:36.908677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb58893dd0>]}
[0m14:29:36.955733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb8480cdd0>]}
[0m14:29:36.957047 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:29:37.029382 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:29:37.180391 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:29:37.181135 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:29:37.188016 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:29:37.213849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb59392a10>]}
[0m14:29:37.338333 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:29:37.343971 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:29:37.359163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb58734a50>]}
[0m14:29:37.360429 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:29:37.361749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb5872b490>]}
[0m14:29:37.364928 [info ] [MainThread]: 
[0m14:29:37.366141 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:29:37.367409 [info ] [MainThread]: 
[0m14:29:37.368866 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:29:37.374653 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:29:37.375651 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:29:37.923106 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m14:29:37.923943 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:29:38.204848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb588339d0>]}
[0m14:29:38.205961 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:29:38.210939 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:29:38.211285 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:29:38.211609 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:29:38.211903 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:29:38.212425 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m14:29:38.213460 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m14:29:38.214848 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m14:29:38.215999 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m14:29:38.217217 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m14:29:38.218193 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:29:38.219055 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:29:38.219969 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:29:38.220918 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:29:38.221795 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:29:38.222640 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:29:38.223813 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:29:38.240471 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:29:38.244350 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:29:38.249144 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:29:38.252879 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:29:38.258222 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:29:38.259098 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:29:38.269961 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:29:38.295762 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:29:38.297909 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:29:38.300609 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:29:38.304126 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:29:38.307214 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:29:38.676607 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:29:38.680532 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:29:38.683295 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:29:38.685143 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:29:38.690340 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:29:38.693590 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:29:38.694271 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:29:38.695048 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:29:38.993599 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e6191c3a-35f4-4ce6-a19f-a36e0fb2c684&page=queryresults
[0m14:29:38.994294 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:b622a155-ab62-4920-a7b4-5f9ed5034a89&page=queryresults
[0m14:29:38.995622 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:53a26851-6978-4058-9d0c-4adc760db68b&page=queryresults
[0m14:29:38.999240 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:46cc4866-f465-4d5b-ab90-28bae0e46c2c&page=queryresults
[0m14:29:40.556360 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb584925d0>]}
[0m14:29:40.557915 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.34s]
[0m14:29:40.559831 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:29:40.560968 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:29:40.563019 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m14:29:40.567306 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:29:40.568298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb58606190>]}
[0m14:29:40.571823 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb833a6690>]}
[0m14:29:40.572531 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:29:40.575519 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.35s]
[0m14:29:40.576902 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.35s]
[0m14:29:40.581446 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:29:40.582659 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:29:40.583840 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:29:40.591236 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:29:40.594715 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m14:29:40.623376 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb585d3610>]}
[0m14:29:40.624546 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.41s]
[0m14:29:40.625683 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:29:40.878575 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:29:40.884018 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:29:41.154707 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ee3527dd-f162-4e8f-84b3-42fc4cf0432d&page=queryresults
[0m14:29:43.356731 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a46a4e95-cffb-45a2-9134-694d682cd294', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb590d4690>]}
[0m14:29:43.358353 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.79s]
[0m14:29:43.359975 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:29:43.362132 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:29:43.364771 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:29:43.365542 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:29:43.366289 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:29:43.367351 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:29:43.368064 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:29:43.368876 [info ] [MainThread]: 
[0m14:29:43.369782 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.00 seconds (6.00s).
[0m14:29:43.372010 [debug] [MainThread]: Command end result
[0m14:29:43.410015 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:29:43.414323 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:29:43.422110 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:29:43.422841 [info ] [MainThread]: 
[0m14:29:43.423932 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:29:43.425125 [info ] [MainThread]: 
[0m14:29:43.426472 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:29:43.428128 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.1249037, "process_in_blocks": "0", "process_kernel_time": 0.178991, "process_mem_max_rss": "221544", "process_out_blocks": "0", "process_user_time": 3.420732}
[0m14:29:43.429231 [debug] [MainThread]: Command `dbt run` succeeded at 14:29:43.429120 after 7.13 seconds
[0m14:29:43.430044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb823ffbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb823ffa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb85da4c10>]}
[0m14:29:43.430951 [debug] [MainThread]: Flushing usage events
[0m14:29:44.732955 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:39:24.287117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64057f6f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64057f6e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64057f60d0>]}


============================== 14:39:24.289637 | 4d1bde08-f870-458f-bee7-60fdb81249dd ==============================
[0m14:39:24.289637 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:39:24.291595 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:39:24.298682 [info ] [MainThread]: dbt version: 1.9.0
[0m14:39:24.299908 [info ] [MainThread]: python version: 3.11.2
[0m14:39:24.301161 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:39:24.302206 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:39:24.858791 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:39:24.860248 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:39:24.861535 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:39:24.955245 [info ] [MainThread]: Configuration:
[0m14:39:24.956657 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:39:24.958037 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:39:24.959209 [info ] [MainThread]: Required dependencies:
[0m14:39:24.960688 [debug] [MainThread]: Executing "git --help"
[0m14:39:24.963036 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:39:24.964514 [debug] [MainThread]: STDERR: "b''"
[0m14:39:24.965512 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:39:24.967090 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:39:24.969078 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:39:24.970019 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "hailing_project", target "dev" invalid: Runtime Error
    Must specify schema


[0m14:39:24.972285 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.7399506, "process_in_blocks": "0", "process_kernel_time": 0.191108, "process_mem_max_rss": "207272", "process_out_blocks": "0", "process_user_time": 2.625221}
[0m14:39:24.973905 [debug] [MainThread]: Command `dbt debug` failed at 14:39:24.973779 after 0.74 seconds
[0m14:39:24.975120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6405835890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64058471d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63d7fe3f90>]}
[0m14:39:24.976261 [debug] [MainThread]: Flushing usage events
[0m14:39:26.925810 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:41:27.514733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e92ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e928090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e92a850>]}


============================== 14:41:27.517375 | 1ab5ab76-602f-490b-9ba4-e7e7c6234b57 ==============================
[0m14:41:27.517375 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:41:27.518559 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:41:28.078596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e24d97090>]}
[0m14:41:28.123474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e50bda110>]}
[0m14:41:28.124648 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:41:28.191751 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:41:28.256099 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m14:41:28.258144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4f7502d0>]}
[0m14:41:29.243278 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m14:41:29.255434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e24750a90>]}
[0m14:41:29.328444 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:41:29.336339 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:41:29.351793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e246b8090>]}
[0m14:41:29.352794 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:41:29.353986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2472fb10>]}
[0m14:41:29.356948 [info ] [MainThread]: 
[0m14:41:29.358117 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:41:29.359076 [info ] [MainThread]: 
[0m14:41:29.360125 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:41:29.365878 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:41:29.366894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:41:30.015104 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:41:30.016380 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:41:30.268856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e249e6610>]}
[0m14:41:30.269858 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:41:30.275109 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:41:30.275422 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:41:30.275792 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:41:30.276271 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:41:30.276782 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m14:41:30.277887 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:41:30.278934 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m14:41:30.280098 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m14:41:30.281426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m14:41:30.282658 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:41:30.283971 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:41:30.285122 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:41:30.286003 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:41:30.286904 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:41:30.287837 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:41:30.288746 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:41:30.300030 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:41:30.305399 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:41:30.311335 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:41:30.315946 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:41:30.322564 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:41:30.323895 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:41:30.324433 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:41:30.330632 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:41:30.384503 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:41:30.421102 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:41:30.422008 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:41:30.425105 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:41:30.458543 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m14:41:30.459342 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m14:41:30.460409 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:41:30.460890 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m14:41:30.461908 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:41:30.464129 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:41:30.752045 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:41:30.760246 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:41:30.956362 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2a1108c4-c46e-426c-918f-7f1e3964bb25&page=queryresults
[0m14:41:30.958830 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6dbabaf5-565c-4c1b-a081-2064147f9eca&page=queryresults
[0m14:41:31.050193 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e9b02dc5-d17e-4d21-b593-08dca78f7781&page=queryresults
[0m14:41:31.070649 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:a006c98f-8ea2-478f-9fba-2ab67e7843ff&page=queryresults
[0m14:41:32.974304 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e245a2610>]}
[0m14:41:32.977012 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e243d97d0>]}
[0m14:41:32.979339 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e245684d0>]}
[0m14:41:32.979865 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e243f8990>]}
[0m14:41:32.980551 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.69s]
[0m14:41:32.982156 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.69s]
[0m14:41:32.983923 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.70s]
[0m14:41:32.985374 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 2.70s]
[0m14:41:32.986774 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:41:32.988471 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:41:32.989649 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:41:32.991253 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:41:32.992971 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:41:32.998152 [info ] [Thread-3 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m14:41:32.999891 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:41:33.001443 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:41:33.006309 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:41:33.012812 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:41:33.018632 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:41:33.026081 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m14:41:33.027480 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m14:41:33.445504 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1f406ed8-eb49-4f20-8ddb-e942fe759251&page=queryresults
[0m14:41:35.264320 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab5ab76-602f-490b-9ba4-e7e7c6234b57', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e24932b90>]}
[0m14:41:35.265486 [info ] [Thread-3 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.26s]
[0m14:41:35.267057 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:41:35.269033 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:41:35.271678 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:41:35.272376 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:41:35.273053 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:41:35.273719 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:41:35.274370 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m14:41:35.275248 [info ] [MainThread]: 
[0m14:41:35.276038 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.92 seconds (5.92s).
[0m14:41:35.277979 [debug] [MainThread]: Command end result
[0m14:41:35.316914 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:41:35.321489 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:41:35.329407 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:41:35.330107 [info ] [MainThread]: 
[0m14:41:35.331328 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:41:35.332309 [info ] [MainThread]: 
[0m14:41:35.333263 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:41:35.334806 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.873193, "process_in_blocks": "0", "process_kernel_time": 0.202649, "process_mem_max_rss": "225936", "process_out_blocks": "0", "process_user_time": 4.204975}
[0m14:41:35.335685 [debug] [MainThread]: Command `dbt run` succeeded at 14:41:35.335587 after 7.87 seconds
[0m14:41:35.336505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e9a3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e4e9a38d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e52180b90>]}
[0m14:41:35.337285 [debug] [MainThread]: Flushing usage events
[0m14:41:39.340941 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:42:33.955316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3954b33010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3954b876d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3954f2a110>]}


============================== 14:42:33.957805 | 7970e4f3-8290-4c4b-a5ef-3d6d0e944a99 ==============================
[0m14:42:33.957805 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:42:33.959086 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:42:33.965750 [info ] [MainThread]: dbt version: 1.9.0
[0m14:42:33.966747 [info ] [MainThread]: python version: 3.11.2
[0m14:42:33.967883 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:42:33.969116 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:42:34.483275 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:42:34.484327 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:42:34.485337 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:42:34.486220 [info ] [MainThread]: adapter type: bigquery
[0m14:42:34.487264 [info ] [MainThread]: adapter version: 1.9.0
[0m14:42:34.568520 [info ] [MainThread]: Configuration:
[0m14:42:34.569983 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:42:34.571251 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:42:34.572485 [info ] [MainThread]: Required dependencies:
[0m14:42:34.573636 [debug] [MainThread]: Executing "git --help"
[0m14:42:34.575601 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:42:34.576629 [debug] [MainThread]: STDERR: "b''"
[0m14:42:34.577336 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:42:34.578412 [info ] [MainThread]: Connection:
[0m14:42:34.580167 [info ] [MainThread]:   method: service-account
[0m14:42:34.581263 [info ] [MainThread]:   database: purwadika
[0m14:42:34.582474 [info ] [MainThread]:   execution_project: purwadika
[0m14:42:34.583483 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m14:42:34.584372 [info ] [MainThread]:   location: None
[0m14:42:34.585600 [info ] [MainThread]:   priority: None
[0m14:42:34.586468 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:42:34.587481 [info ] [MainThread]:   impersonate_service_account: None
[0m14:42:34.588654 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:42:34.589956 [info ] [MainThread]:   job_retries: 1
[0m14:42:34.591000 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:42:34.591929 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:42:34.592908 [info ] [MainThread]:   timeout_seconds: None
[0m14:42:34.593914 [info ] [MainThread]:   client_id: None
[0m14:42:34.594938 [info ] [MainThread]:   token_uri: None
[0m14:42:34.596028 [info ] [MainThread]:   dataproc_region: None
[0m14:42:34.597082 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:42:34.597866 [info ] [MainThread]:   gcs_bucket: None
[0m14:42:34.598686 [info ] [MainThread]:   dataproc_batch: None
[0m14:42:34.599723 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:42:34.653039 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:42:34.653907 [debug] [MainThread]: On debug: select 1 as id
[0m14:42:34.654642 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:42:35.248512 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:6c69fc97-627a-49b9-b9d5-add5e35a7982&page=queryresults
[0m14:42:35.979619 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:42:35.980957 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:42:35.982931 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.0755594, "process_in_blocks": "0", "process_kernel_time": 0.24968, "process_mem_max_rss": "212356", "process_out_blocks": "0", "process_user_time": 2.596672}
[0m14:42:35.984119 [debug] [MainThread]: Command `dbt debug` succeeded at 14:42:35.984010 after 2.08 seconds
[0m14:42:35.985022 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:42:35.985841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3926c89ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3954b38990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3926d65250>]}
[0m14:42:35.986660 [debug] [MainThread]: Flushing usage events
[0m14:42:37.040818 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:42:40.549746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b1ccbb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b1d17790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b1d17c90>]}


============================== 14:42:40.552986 | 2281f77f-dd31-4988-95e5-7840e93cfc2a ==============================
[0m14:42:40.552986 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:42:40.554644 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:42:41.127998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683fd2490>]}
[0m14:42:41.179905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b3f79f10>]}
[0m14:42:41.181295 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:42:41.256574 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:42:41.325508 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:42:41.326788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b23c29d0>]}
[0m14:42:42.384260 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:42:42.395888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683a6bd50>]}
[0m14:42:42.466669 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:42:42.471706 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:42:42.486501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f868381ff10>]}
[0m14:42:42.487569 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:42:42.488810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683a1c990>]}
[0m14:42:42.491688 [info ] [MainThread]: 
[0m14:42:42.492807 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:42:42.493976 [info ] [MainThread]: 
[0m14:42:42.495322 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:42:42.500514 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:42:42.501396 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:42:43.062063 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:42:43.063118 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:43.328266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683e07bd0>]}
[0m14:42:43.329555 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:42:43.336748 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:42:43.337101 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:42:43.337450 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:42:43.337804 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:42:43.338529 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m14:42:43.339589 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:42:43.340835 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m14:42:43.341909 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m14:42:43.343005 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m14:42:43.344366 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:42:43.345375 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:42:43.346297 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:42:43.347137 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:42:43.347863 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:42:43.348649 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:42:43.349379 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:42:43.358945 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:42:43.362771 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:42:43.366823 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:42:43.371126 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:42:43.377489 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:42:43.377973 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:42:43.378421 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:42:43.384755 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:42:43.430010 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:42:43.431786 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:42:43.435445 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:42:43.438533 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:42:43.773267 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:42:43.776795 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:42:43.778731 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:42:43.780214 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:42:43.785943 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:42:43.786738 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:42:43.787518 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:42:43.788217 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:42:44.103321 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5773aacd-e50f-49e1-a3b4-874238629c29&page=queryresults
[0m14:42:44.109139 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e9a4fa3-b2bb-44a3-927f-1c8316d46283&page=queryresults
[0m14:42:44.113337 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:39d97e41-180b-42d9-8f69-f5bfeb9fb494&page=queryresults
[0m14:42:44.116247 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b297844-f6ed-45f9-b197-9f2484341fe4&page=queryresults
[0m14:42:45.685656 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683a1c450>]}
[0m14:42:45.685988 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8680713a10>]}
[0m14:42:45.686474 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f868384ef90>]}
[0m14:42:45.687361 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.34s]
[0m14:42:45.689201 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.34s]
[0m14:42:45.691267 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.34s]
[0m14:42:45.694692 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:42:45.695497 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8680742190>]}
[0m14:42:45.696429 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:42:45.697535 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:42:45.698989 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:42:45.700682 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.35s]
[0m14:42:45.703647 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m14:42:45.705210 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:42:45.706288 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:42:45.708011 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:42:45.713103 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:42:45.720713 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:42:45.724886 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:42:45.989530 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:42:45.996473 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:42:46.267287 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:19e22eca-e201-4a10-b740-854a1b7c82c2&page=queryresults
[0m14:42:47.909078 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2281f77f-dd31-4988-95e5-7840e93cfc2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8680438490>]}
[0m14:42:47.910300 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.20s]
[0m14:42:47.911976 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:42:47.914091 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:42:47.916832 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:42:47.917396 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m14:42:47.918101 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:42:47.918785 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:42:47.919804 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m14:42:47.921057 [info ] [MainThread]: 
[0m14:42:47.922357 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.43 seconds (5.43s).
[0m14:42:47.924597 [debug] [MainThread]: Command end result
[0m14:42:47.961349 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:42:47.965948 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:42:47.974054 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:42:47.974984 [info ] [MainThread]: 
[0m14:42:47.976122 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:42:47.977225 [info ] [MainThread]: 
[0m14:42:47.978295 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:42:47.979911 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.4806395, "process_in_blocks": "0", "process_kernel_time": 0.194092, "process_mem_max_rss": "227496", "process_out_blocks": "0", "process_user_time": 4.270027}
[0m14:42:47.980941 [debug] [MainThread]: Command `dbt run` succeeded at 14:42:47.980833 after 7.48 seconds
[0m14:42:47.981730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b2180410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b5520c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86b567c810>]}
[0m14:42:47.982550 [debug] [MainThread]: Flushing usage events
[0m14:42:49.331309 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:34.643144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94260f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94265f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94265f690>]}


============================== 14:46:34.646101 | 10bb215d-1733-4f55-b955-b6fdf6abed54 ==============================
[0m14:46:34.646101 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:46:34.648646 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'send_anonymous_usage_stats': 'True'}
[0m14:46:35.235979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9189bb290>]}
[0m14:46:35.280020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9448c6350>]}
[0m14:46:35.281589 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:46:35.347515 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:46:35.495509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:46:35.496593 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m14:46:35.734171 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m14:46:35.747844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc918926dd0>]}
[0m14:46:35.821048 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:46:35.827609 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:46:35.842488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc91812c850>]}
[0m14:46:35.843611 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:46:35.845147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc91841c6d0>]}
[0m14:46:35.847284 [info ] [MainThread]: 
[0m14:46:35.848246 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:46:35.849196 [info ] [MainThread]: 
[0m14:46:35.850369 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:46:35.852144 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:46:35.853747 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:46:36.501205 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:46:36.502151 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:36.774661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9184979d0>]}
[0m14:46:36.776096 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:46:36.780975 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:46:36.782003 [info ] [Thread-1 (]: 1 of 1 START sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:46:36.783113 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m14:46:36.784347 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:46:36.792187 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:46:36.797636 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:46:36.814812 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:36.821906 [debug] [Thread-1 (]: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m14:46:36.823797 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10bb215d-1733-4f55-b955-b6fdf6abed54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc91842b0d0>]}
[0m14:46:36.825003 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.04s]
[0m14:46:36.826435 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:46:36.827722 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql).
[0m14:46:36.830718 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:46:36.834045 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:46:36.835098 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:46:36.835971 [info ] [MainThread]: 
[0m14:46:36.837017 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.99 seconds (0.99s).
[0m14:46:36.838483 [debug] [MainThread]: Command end result
[0m14:46:36.873323 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:46:36.878241 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:46:36.886010 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:46:36.886847 [info ] [MainThread]: 
[0m14:46:36.887832 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:46:36.888965 [info ] [MainThread]: 
[0m14:46:36.889966 [error] [MainThread]:   Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m14:46:36.891178 [info ] [MainThread]: 
[0m14:46:36.892523 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:46:36.894281 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.3020587, "process_in_blocks": "0", "process_kernel_time": 0.22278, "process_mem_max_rss": "221712", "process_out_blocks": "0", "process_user_time": 3.199941}
[0m14:46:36.895630 [debug] [MainThread]: Command `dbt run` failed at 14:46:36.895500 after 2.30 seconds
[0m14:46:36.896651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94266b590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94266b6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc945fc5210>]}
[0m14:46:36.897542 [debug] [MainThread]: Flushing usage events
[0m14:46:38.536411 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:47:13.419972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31975777d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3197576610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3197577190>]}


============================== 14:47:13.422506 | 1be0a91f-3376-4cd6-8758-d567c37db97e ==============================
[0m14:47:13.422506 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:47:13.425036 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select production_hailing_staging_customer', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:47:14.029324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31705bf210>]}
[0m14:47:14.078991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31997ca410>]}
[0m14:47:14.080118 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:47:14.154922 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:47:14.306195 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:47:14.307062 [debug] [MainThread]: Partial parsing: updated file: hailing_project://models/staging/production_hailing_staging_customer.sql
[0m14:47:14.542472 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m14:47:14.554774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f316977c710>]}
[0m14:47:14.634255 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:47:14.639929 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:47:14.653891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f316977f6d0>]}
[0m14:47:14.654928 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:47:14.656275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31693b9090>]}
[0m14:47:14.658747 [info ] [MainThread]: 
[0m14:47:14.659697 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:47:14.660643 [info ] [MainThread]: 
[0m14:47:14.662056 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:47:14.663593 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:47:14.664574 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:15.205448 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:47:15.206406 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:47:15.468951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3169717d10>]}
[0m14:47:15.470603 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:47:15.476724 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:47:15.477820 [info ] [Thread-1 (]: 1 of 1 START sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:47:15.478928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m14:47:15.479832 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:47:15.487599 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:47:15.498526 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:47:15.517220 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:47:15.522732 [debug] [Thread-1 (]: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m14:47:15.525099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1be0a91f-3376-4cd6-8758-d567c37db97e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31680b0790>]}
[0m14:47:15.526766 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model rizky_dwh_hailing_source.production_hailing_staging_customer  [[31mERROR[0m in 0.05s]
[0m14:47:15.528251 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:47:15.529428 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql).
[0m14:47:15.531912 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:47:15.534575 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:47:15.535453 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:47:15.536336 [info ] [MainThread]: 
[0m14:47:15.537729 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.87 seconds (0.87s).
[0m14:47:15.539345 [debug] [MainThread]: Command end result
[0m14:47:15.573509 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:47:15.577732 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:47:15.586736 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:47:15.587483 [info ] [MainThread]: 
[0m14:47:15.588536 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:47:15.589544 [info ] [MainThread]: 
[0m14:47:15.590548 [error] [MainThread]:   Compilation Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Trying to create view `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`, but it currently exists as a table. Either drop `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/relations/view/replace.sql)
  > called by macro bigquery__create_or_replace_view (macros/relations/view/replace.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
[0m14:47:15.591460 [info ] [MainThread]: 
[0m14:47:15.592419 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:47:15.593906 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.222357, "process_in_blocks": "0", "process_kernel_time": 0.259944, "process_mem_max_rss": "217420", "process_out_blocks": "0", "process_user_time": 3.15932}
[0m14:47:15.594895 [debug] [MainThread]: Command `dbt run` failed at 14:47:15.594777 after 2.22 seconds
[0m14:47:15.595719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31973f79d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f31973f74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3197672c10>]}
[0m14:47:15.596513 [debug] [MainThread]: Flushing usage events
[0m14:47:16.591356 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:31.881337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e510b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e5deb8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e510b250>]}


============================== 14:50:31.883990 | b3e5adf5-74fc-4648-b3c2-3aa6b3354be7 ==============================
[0m14:50:31.883990 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:50:31.885341 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m14:50:31.892821 [info ] [MainThread]: dbt version: 1.9.0
[0m14:50:31.893722 [info ] [MainThread]: python version: 3.11.2
[0m14:50:31.894858 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:50:31.896687 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m14:50:32.393368 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m14:50:32.395050 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m14:50:32.396378 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m14:50:32.397691 [info ] [MainThread]: adapter type: bigquery
[0m14:50:32.398905 [info ] [MainThread]: adapter version: 1.9.0
[0m14:50:32.475084 [info ] [MainThread]: Configuration:
[0m14:50:32.476602 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:50:32.477877 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:50:32.478854 [info ] [MainThread]: Required dependencies:
[0m14:50:32.479822 [debug] [MainThread]: Executing "git --help"
[0m14:50:32.481705 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:50:32.482513 [debug] [MainThread]: STDERR: "b''"
[0m14:50:32.483225 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:50:32.484010 [info ] [MainThread]: Connection:
[0m14:50:32.484976 [info ] [MainThread]:   method: service-account
[0m14:50:32.486510 [info ] [MainThread]:   database: purwadika
[0m14:50:32.487548 [info ] [MainThread]:   execution_project: purwadika
[0m14:50:32.488744 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m14:50:32.489982 [info ] [MainThread]:   location: None
[0m14:50:32.491640 [info ] [MainThread]:   priority: None
[0m14:50:32.492722 [info ] [MainThread]:   maximum_bytes_billed: None
[0m14:50:32.493684 [info ] [MainThread]:   impersonate_service_account: None
[0m14:50:32.494489 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m14:50:32.495266 [info ] [MainThread]:   job_retries: 1
[0m14:50:32.496292 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m14:50:32.497335 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m14:50:32.498371 [info ] [MainThread]:   timeout_seconds: None
[0m14:50:32.499354 [info ] [MainThread]:   client_id: None
[0m14:50:32.500156 [info ] [MainThread]:   token_uri: None
[0m14:50:32.500928 [info ] [MainThread]:   dataproc_region: None
[0m14:50:32.501661 [info ] [MainThread]:   dataproc_cluster_name: None
[0m14:50:32.502411 [info ] [MainThread]:   gcs_bucket: None
[0m14:50:32.503861 [info ] [MainThread]:   dataproc_batch: None
[0m14:50:32.505610 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:50:32.559900 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m14:50:32.560954 [debug] [MainThread]: On debug: select 1 as id
[0m14:50:32.561751 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:33.230982 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:edb4007d-8964-4e9a-9c73-0df99ce9298a&page=queryresults
[0m14:50:33.942307 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:50:33.943287 [info ] [MainThread]: [32mAll checks passed![0m
[0m14:50:33.945212 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.1210358, "process_in_blocks": "0", "process_kernel_time": 0.230108, "process_mem_max_rss": "216508", "process_out_blocks": "0", "process_user_time": 2.601223}
[0m14:50:33.946210 [debug] [MainThread]: Command `dbt debug` succeeded at 14:50:33.946102 after 2.12 seconds
[0m14:50:33.947037 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:50:33.948508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e4f68a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e4f69f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e89c8a90>]}
[0m14:50:33.949362 [debug] [MainThread]: Flushing usage events
[0m14:50:35.186159 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:54.768595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf4df2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf4ddb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf4decd0>]}


============================== 14:50:54.771172 | a2ff1450-8af9-455b-b7b7-c38843de779b ==============================
[0m14:50:54.771172 [info ] [MainThread]: Running with dbt=1.9.0
[0m14:50:54.772869 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:50:55.347976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf4e2890>]}
[0m14:50:55.395601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d17508d0>]}
[0m14:50:55.398280 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m14:50:55.470862 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m14:50:55.540272 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:50:55.542162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cfbca9d0>]}
[0m14:50:56.552038 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m14:50:56.564091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a154a990>]}
[0m14:50:56.642957 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:50:56.649684 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:50:56.668803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a1095010>]}
[0m14:50:56.670159 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m14:50:56.671451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a12a8f10>]}
[0m14:50:56.673947 [info ] [MainThread]: 
[0m14:50:56.674974 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:50:56.675863 [info ] [MainThread]: 
[0m14:50:56.677004 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m14:50:56.681597 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m14:50:56.682497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:57.298722 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m14:50:57.299625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:57.566663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a168cc90>]}
[0m14:50:57.567753 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:57.572072 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m14:50:57.572412 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m14:50:57.572764 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m14:50:57.573128 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m14:50:57.573719 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m14:50:57.574624 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m14:50:57.575822 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m14:50:57.576846 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m14:50:57.577924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m14:50:57.578891 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m14:50:57.579966 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m14:50:57.581218 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m14:50:57.582214 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m14:50:57.583027 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m14:50:57.583911 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m14:50:57.584760 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m14:50:57.596166 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m14:50:57.600889 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m14:50:57.606153 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m14:50:57.610894 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m14:50:57.617772 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m14:50:57.618726 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m14:50:57.619249 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m14:50:57.619622 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m14:50:57.669905 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:50:57.671635 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:57.675408 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:50:57.678254 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:50:58.019698 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m14:50:58.021045 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m14:50:58.022661 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m14:50:58.023629 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m14:50:58.035248 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:50:58.036042 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m14:50:58.037211 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m14:50:58.039495 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m14:50:58.346302 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:653dbe29-baba-48eb-8784-73693c6b4666&page=queryresults
[0m14:50:58.365846 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:15cf562c-c8cf-4e07-af0a-55c4c3164163&page=queryresults
[0m14:50:58.392548 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0c820435-5b76-4a56-99a5-c26a0b59d57b&page=queryresults
[0m14:50:58.425879 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1b5416ce-91f4-44ec-9251-0e6fa77277c5&page=queryresults
[0m14:51:00.120795 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a12d0c90>]}
[0m14:51:00.122185 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.54s]
[0m14:51:00.124461 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m14:51:00.125697 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m14:51:00.126766 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m14:51:00.128248 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m14:51:00.129461 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m14:51:00.134553 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:51:00.142681 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m14:51:00.146331 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:51:00.206349 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a110a390>]}
[0m14:51:00.208020 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.63s]
[0m14:51:00.209976 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m14:51:00.227473 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4a1118e10>]}
[0m14:51:00.228915 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.65s]
[0m14:51:00.230241 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m14:51:00.259012 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb499708a90>]}
[0m14:51:00.260339 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.68s]
[0m14:51:00.261845 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m14:51:00.423886 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m14:51:00.429716 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m14:51:00.688653 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5ebc8b07-25bf-4c76-8ec9-a24216c39fa7&page=queryresults
[0m14:51:02.534480 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ff1450-8af9-455b-b7b7-c38843de779b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4994b84d0>]}
[0m14:51:02.535701 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.41s]
[0m14:51:02.536817 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m14:51:02.538800 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:51:02.541334 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:51:02.542104 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m14:51:02.542780 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m14:51:02.543465 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m14:51:02.544082 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m14:51:02.544864 [info ] [MainThread]: 
[0m14:51:02.545759 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 5.87 seconds (5.87s).
[0m14:51:02.548010 [debug] [MainThread]: Command end result
[0m14:51:02.583241 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m14:51:02.587289 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m14:51:02.596083 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m14:51:02.596955 [info ] [MainThread]: 
[0m14:51:02.598033 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:51:02.599090 [info ] [MainThread]: 
[0m14:51:02.599997 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m14:51:02.601521 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.883269, "process_in_blocks": "0", "process_kernel_time": 0.230647, "process_mem_max_rss": "226976", "process_out_blocks": "0", "process_user_time": 4.141631}
[0m14:51:02.602831 [debug] [MainThread]: Command `dbt run` succeeded at 14:51:02.602710 after 7.88 seconds
[0m14:51:02.603565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf8d6490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4cf531790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4d2cf8c10>]}
[0m14:51:02.604321 [debug] [MainThread]: Flushing usage events
[0m14:51:03.893149 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:10:36.327408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e27b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e249d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e26750>]}


============================== 02:10:36.331818 | d683627a-ccec-461c-99fa-e11171d0a5eb ==============================
[0m02:10:36.331818 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:10:36.333274 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:10:36.355487 [info ] [MainThread]: dbt version: 1.9.0
[0m02:10:36.357902 [info ] [MainThread]: python version: 3.11.2
[0m02:10:36.359103 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:10:36.360458 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:10:36.879415 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:10:36.880613 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:10:36.881827 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:10:36.884156 [info ] [MainThread]: adapter type: bigquery
[0m02:10:36.885808 [info ] [MainThread]: adapter version: 1.9.0
[0m02:10:36.965652 [info ] [MainThread]: Configuration:
[0m02:10:36.966885 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:10:36.968124 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:10:36.969337 [info ] [MainThread]: Required dependencies:
[0m02:10:36.970294 [debug] [MainThread]: Executing "git --help"
[0m02:10:36.987016 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:10:36.987826 [debug] [MainThread]: STDERR: "b''"
[0m02:10:36.988603 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:10:36.990094 [info ] [MainThread]: Connection:
[0m02:10:36.991000 [info ] [MainThread]:   method: service-account
[0m02:10:36.992036 [info ] [MainThread]:   database: purwadika
[0m02:10:36.993070 [info ] [MainThread]:   execution_project: purwadika
[0m02:10:36.994054 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:10:36.995241 [info ] [MainThread]:   location: None
[0m02:10:36.996224 [info ] [MainThread]:   priority: None
[0m02:10:36.997617 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:10:36.998830 [info ] [MainThread]:   impersonate_service_account: None
[0m02:10:36.999798 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:10:37.001099 [info ] [MainThread]:   job_retries: 1
[0m02:10:37.002331 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:10:37.003954 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:10:37.005128 [info ] [MainThread]:   timeout_seconds: None
[0m02:10:37.006228 [info ] [MainThread]:   client_id: None
[0m02:10:37.007089 [info ] [MainThread]:   token_uri: None
[0m02:10:37.008181 [info ] [MainThread]:   dataproc_region: None
[0m02:10:37.009223 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:10:37.010146 [info ] [MainThread]:   gcs_bucket: None
[0m02:10:37.011074 [info ] [MainThread]:   dataproc_batch: None
[0m02:10:37.012145 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:10:37.080429 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:10:37.081249 [debug] [MainThread]: On debug: select 1 as id
[0m02:10:37.082051 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:10:37.943055 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:aed2efae-e88a-4be5-a10a-1eaea2225369&page=queryresults
[0m02:10:38.697288 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:10:38.698914 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:10:38.701888 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.4557347, "process_in_blocks": "5472", "process_kernel_time": 0.195529, "process_mem_max_rss": "212456", "process_out_blocks": "0", "process_user_time": 2.737414}
[0m02:10:38.703633 [debug] [MainThread]: Command `dbt debug` succeeded at 02:10:38.703511 after 2.46 seconds
[0m02:10:38.704529 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:10:38.705303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e80b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2482e82050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f245904fa50>]}
[0m02:10:38.706118 [debug] [MainThread]: Flushing usage events
[0m02:10:39.799106 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:10:44.164395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f1adb650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f1b23190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f1adb690>]}


============================== 02:10:44.166871 | 6cc69579-6e6d-44ad-9f90-9aa357bf3902 ==============================
[0m02:10:44.166871 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:10:44.169732 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:10:44.734717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f1b48350>]}
[0m02:10:44.780136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f3d65750>]}
[0m02:10:44.781355 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:10:44.850621 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:10:45.067420 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:10:45.068373 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:10:45.073284 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m02:10:45.098604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3c12850>]}
[0m02:10:45.210696 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:10:45.216055 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:10:45.235108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3ddcf50>]}
[0m02:10:45.236311 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m02:10:45.237569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3932e10>]}
[0m02:10:45.240423 [info ] [MainThread]: 
[0m02:10:45.241538 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:10:45.242521 [info ] [MainThread]: 
[0m02:10:45.243961 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:10:45.248991 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:10:45.250022 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:10:45.772081 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m02:10:45.773862 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:10:45.990344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c82c4d50>]}
[0m02:10:45.991979 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:10:45.997879 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:10:45.998273 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:10:45.998632 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:10:45.998978 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:10:45.999511 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m02:10:46.001280 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m02:10:46.002507 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m02:10:46.003812 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m02:10:46.004978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m02:10:46.006306 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m02:10:46.007506 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:10:46.008588 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:10:46.009494 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:10:46.010789 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:10:46.012257 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:10:46.013260 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:10:46.029001 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:10:46.032676 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:10:46.036766 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:10:46.040937 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:10:46.047586 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:10:46.048234 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:10:46.054578 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:10:46.085718 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:10:46.093141 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:10:46.091023 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:10:46.095938 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:10:46.099475 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:10:46.394885 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:10:46.396477 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:10:46.398574 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:10:46.400131 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:10:46.406476 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:10:46.407392 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:10:46.412233 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:10:46.412983 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:10:47.026423 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:97f542b5-c20a-4f56-8be0-dd569945bdf7&page=queryresults
[0m02:10:47.261321 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:edf8b36f-16ae-4b86-8569-87beee01ab72&page=queryresults
[0m02:10:48.093517 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:348cc37a-3fb9-4377-81ec-724d61041f50&page=queryresults
[0m02:10:48.115214 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:516daaca-7943-49dd-972f-b15167e3b04b&page=queryresults
[0m02:10:48.704391 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c38b7790>]}
[0m02:10:48.705596 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.70s]
[0m02:10:48.707436 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:10:48.708806 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:10:48.710204 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m02:10:48.711541 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:10:48.712519 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:10:48.717317 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:10:48.726097 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:10:48.729952 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:10:48.933726 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3bc3090>]}
[0m02:10:48.935218 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.93s]
[0m02:10:48.936492 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:10:48.958160 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:10:48.967754 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:10:49.647248 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3823210>]}
[0m02:10:49.649361 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.64s]
[0m02:10:49.651702 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:10:49.752537 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c393c790>]}
[0m02:10:49.755418 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 3.74s]
[0m02:10:49.758460 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:10:50.410219 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f2a91f00-3156-460a-b32c-f53813cf18f2&page=queryresults
[0m02:10:52.324193 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6cc69579-6e6d-44ad-9f90-9aa357bf3902', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c043aad0>]}
[0m02:10:52.325590 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.61s]
[0m02:10:52.329077 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:10:52.331875 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:10:52.334793 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:10:52.335477 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:10:52.336234 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:10:52.336905 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:10:52.337675 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:10:52.338445 [info ] [MainThread]: 
[0m02:10:52.339365 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.09 seconds (7.09s).
[0m02:10:52.341160 [debug] [MainThread]: Command end result
[0m02:10:52.378407 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:10:52.382634 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:10:52.391396 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:10:52.392173 [info ] [MainThread]: 
[0m02:10:52.393233 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:10:52.394350 [info ] [MainThread]: 
[0m02:10:52.395359 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:10:52.396922 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.279099, "process_in_blocks": "3584", "process_kernel_time": 0.182669, "process_mem_max_rss": "221620", "process_out_blocks": "0", "process_user_time": 3.328637}
[0m02:10:52.397999 [debug] [MainThread]: Command `dbt run` succeeded at 02:10:52.397893 after 8.28 seconds
[0m02:10:52.398892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f52d4b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f5459290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13f5458950>]}
[0m02:10:52.399858 [debug] [MainThread]: Flushing usage events
[0m02:10:53.905083 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:11:26.029856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b340b2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b34107610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b34107210>]}


============================== 02:11:26.032427 | acd78ac1-732e-43b5-bb85-054270dab60f ==============================
[0m02:11:26.032427 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:11:26.034673 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:11:26.605387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b0cceedd0>]}
[0m02:11:26.648528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b36364ad0>]}
[0m02:11:26.650015 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:11:26.718735 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:11:26.786920 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m02:11:26.788731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b347aa8d0>]}
[0m02:11:27.751780 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m02:11:27.763809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b340caf10>]}
[0m02:11:27.848547 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:11:27.854500 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:11:27.872513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05ca7f10>]}
[0m02:11:27.873852 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m02:11:27.875350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05ec7dd0>]}
[0m02:11:27.878443 [info ] [MainThread]: 
[0m02:11:27.879542 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:11:27.880441 [info ] [MainThread]: 
[0m02:11:27.881890 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:11:27.887380 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:11:27.888707 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:11:28.365102 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:11:28.366511 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:11:28.564972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b060a46d0>]}
[0m02:11:28.565930 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:11:28.571444 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:11:28.571822 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:11:28.572173 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:11:28.572645 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:11:28.573300 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_staging.dim_customer ...... [RUN]
[0m02:11:28.574733 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:11:28.575842 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:11:28.577025 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:11:28.578565 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:11:28.579483 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m02:11:28.580690 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:11:28.581655 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:11:28.582422 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:11:28.583915 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:11:28.584852 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:11:28.585937 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:11:28.595584 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:11:28.599484 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:11:28.603628 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:11:28.608668 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:11:28.614559 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:11:28.615166 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:11:28.615843 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:11:28.627263 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:11:28.661050 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:11:28.663494 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:11:28.667176 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:11:28.670148 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:11:28.907828 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:11:28.916335 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:11:28.922643 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:11:28.930223 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:11:28.934048 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:11:28.939484 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:11:28.945347 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:11:28.950906 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:11:29.180886 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9b3ac838-edc7-4a9b-878a-7d7dd9c123da&page=queryresults
[0m02:11:29.205660 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2b1f2ec2-b9c6-4638-8c80-93f16e43ffeb&page=queryresults
[0m02:11:29.447817 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:da128dcd-5b2b-44d6-ad12-7aeca859fa95&page=queryresults
[0m02:11:29.472117 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:857ee306-e1d0-4552-8e74-3366d31ba073&page=queryresults
[0m02:11:30.783971 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05cecf90>]}
[0m02:11:30.785192 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.20s]
[0m02:11:30.786612 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:11:30.787740 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:11:30.788724 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:11:30.789865 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:11:30.790637 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:11:30.794638 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:11:30.801996 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:11:30.806809 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:11:30.958975 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b040eaf10>]}
[0m02:11:30.960314 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.38s]
[0m02:11:30.961751 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:11:31.033659 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05ccfe90>]}
[0m02:11:31.035394 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:11:31.036405 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.45s]
[0m02:11:31.038500 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:11:31.043590 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:11:31.237824 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b06086350>]}
[0m02:11:31.239061 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_staging.dim_customer . [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.66s]
[0m02:11:31.240466 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:11:32.450687 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:14f79502-e60f-4ca8-96de-9ee4ed5415d7&page=queryresults
[0m02:11:34.278562 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acd78ac1-732e-43b5-bb85-054270dab60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b05d010d0>]}
[0m02:11:34.279944 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.49s]
[0m02:11:34.281758 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:11:34.284269 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:11:34.287412 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:11:34.288108 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:11:34.288894 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:11:34.289603 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:11:34.290298 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:11:34.291040 [info ] [MainThread]: 
[0m02:11:34.292262 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.41 seconds (6.41s).
[0m02:11:34.294364 [debug] [MainThread]: Command end result
[0m02:11:34.330217 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:11:34.334943 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:11:34.343244 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:11:34.343997 [info ] [MainThread]: 
[0m02:11:34.345006 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:11:34.346255 [info ] [MainThread]: 
[0m02:11:34.347173 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:11:34.349281 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.365765, "process_in_blocks": "280", "process_kernel_time": 0.133668, "process_mem_max_rss": "227792", "process_out_blocks": "0", "process_user_time": 4.195144}
[0m02:11:34.350498 [debug] [MainThread]: Command `dbt run` succeeded at 02:11:34.350381 after 8.37 seconds
[0m02:11:34.351300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b3412f650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b3412f6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b378e4c90>]}
[0m02:11:34.352143 [debug] [MainThread]: Flushing usage events
[0m02:11:35.637233 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:17:21.570401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67c2b7910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67c6b2310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67c2b6dd0>]}


============================== 02:17:21.574868 | 2ad818e6-6b33-45ee-8245-97c605127d51 ==============================
[0m02:17:21.574868 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:17:21.576814 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:17:22.148150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64e5fae50>]}
[0m02:17:22.194118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67e52c990>]}
[0m02:17:22.195445 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:17:22.271832 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:17:22.339175 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m02:17:22.340418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64e5bf3d0>]}
[0m02:17:23.350994 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m02:17:23.363854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64e5baed0>]}
[0m02:17:23.438461 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:17:23.443073 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:17:23.457865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64de93e90>]}
[0m02:17:23.458822 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m02:17:23.459851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64dead1d0>]}
[0m02:17:23.462538 [info ] [MainThread]: 
[0m02:17:23.463795 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:17:23.464760 [info ] [MainThread]: 
[0m02:17:23.466074 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:17:23.470704 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:17:23.471538 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:17:23.472387 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:17:23.473173 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:17:24.452552 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m02:17:24.453512 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_source_rizky_dwh_hailing_staging"
"
[0m02:17:24.461943 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`
  
[0m02:17:24.462958 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:17:25.300177 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:45fe1c4b-cacd-494b-a720-a16137bf7142&page=queryresults
[0m02:17:26.222842 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_source)
[0m02:17:26.223391 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging)
[0m02:17:26.224250 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:17:26.225212 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:17:26.801546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64e221ad0>]}
[0m02:17:26.802647 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:17:26.808812 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:17:26.809204 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:17:26.809561 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:17:26.810064 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:17:26.810719 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m02:17:26.811927 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:17:26.812867 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m02:17:26.814108 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m02:17:26.815240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:17:26.816128 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m02:17:26.817162 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:17:26.818097 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:17:26.819009 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:17:26.819888 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:17:26.820721 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:17:26.821580 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:17:26.831860 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:17:26.835845 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:17:26.840509 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:17:26.844729 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:17:26.852817 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:17:26.853415 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:17:26.853872 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:17:26.859947 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:17:26.914765 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:17:26.928693 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:17:26.939838 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:17:26.943765 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:17:26.997636 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_source_rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:17:27.021971 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:17:27.251443 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:17:27.253090 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:17:27.255411 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:17:27.259881 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:17:27.260524 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:17:27.262658 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:17:27.318014 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4e14d9fa-306e-4d77-b311-56c17f51f967&page=queryresults
[0m02:17:27.319142 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:4e14d9fa-306e-4d77-b311-56c17f51f967&page=queryresults
[0m02:17:27.328956 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:17:27.331529 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64cb8bd10>]}
[0m02:17:27.332655 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_source_rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.51s]
[0m02:17:27.334014 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:17:27.335243 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:17:27.335805 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m02:17:27.337093 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m02:17:27.339886 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:17:27.341035 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:17:27.346598 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:17:27.352865 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:17:27.356838 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:17:27.516994 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6416c4d4-4122-4f19-a380-d451daf20cfe&page=queryresults
[0m02:17:27.553366 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:27e3f992-a965-4bc2-ae0c-85a9486e25e8&page=queryresults
[0m02:17:27.587210 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:17:27.595234 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:17:27.810163 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:797c2fb9-38d1-43ce-bd63-635de56c8ff0&page=queryresults
[0m02:17:28.979978 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:14146503-2cf8-46f9-970a-d1644d6219dd&page=queryresults
[0m02:17:29.045941 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64c01dd50>]}
[0m02:17:29.047816 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.23s]
[0m02:17:29.049669 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:17:29.163170 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64caf5450>]}
[0m02:17:29.164750 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.35s]
[0m02:17:29.167497 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:17:29.343190 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64cae3e10>]}
[0m02:17:29.344746 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.53s]
[0m02:17:29.346137 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:17:30.522977 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad818e6-6b33-45ee-8245-97c605127d51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe64ca188d0>]}
[0m02:17:30.524276 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 3.18s]
[0m02:17:30.525409 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:17:30.527454 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:17:30.529826 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:17:30.530530 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:17:30.531328 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:17:30.531991 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:17:30.532574 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:17:30.533368 [info ] [MainThread]: 
[0m02:17:30.534169 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 7.07 seconds (7.07s).
[0m02:17:30.535979 [debug] [MainThread]: Command end result
[0m02:17:30.568403 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:17:30.572391 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:17:30.582117 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:17:30.583405 [info ] [MainThread]: 
[0m02:17:30.584508 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:17:30.585615 [info ] [MainThread]: 
[0m02:17:30.586726 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_source_rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:17:30.587926 [info ] [MainThread]: 
[0m02:17:30.588973 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m02:17:30.590472 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.094556, "process_in_blocks": "576", "process_kernel_time": 0.22974, "process_mem_max_rss": "227476", "process_out_blocks": "0", "process_user_time": 4.315124}
[0m02:17:30.591569 [debug] [MainThread]: Command `dbt run` failed at 02:17:30.591452 after 9.10 seconds
[0m02:17:30.592399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67c2ea410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67fc31390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe67fc30a10>]}
[0m02:17:30.593572 [debug] [MainThread]: Flushing usage events
[0m02:17:32.282315 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:22:34.102459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8518b0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf85663950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf85582650>]}


============================== 02:22:34.104859 | 9ca4a319-9d6f-472b-8715-0f7a75b2772a ==============================
[0m02:22:34.104859 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:22:34.106676 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m02:22:34.118936 [info ] [MainThread]: dbt version: 1.9.0
[0m02:22:34.120184 [info ] [MainThread]: python version: 3.11.2
[0m02:22:34.121137 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:22:34.122513 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:22:34.630392 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:22:34.631396 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:22:34.632228 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:22:34.632996 [info ] [MainThread]: adapter type: bigquery
[0m02:22:34.633809 [info ] [MainThread]: adapter version: 1.9.0
[0m02:22:34.708842 [info ] [MainThread]: Configuration:
[0m02:22:34.709922 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:22:34.710951 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:22:34.711943 [info ] [MainThread]: Required dependencies:
[0m02:22:34.712933 [debug] [MainThread]: Executing "git --help"
[0m02:22:34.715500 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:22:34.716329 [debug] [MainThread]: STDERR: "b''"
[0m02:22:34.717111 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:22:34.718084 [info ] [MainThread]: Connection:
[0m02:22:34.719179 [info ] [MainThread]:   method: service-account
[0m02:22:34.720307 [info ] [MainThread]:   database: purwadika
[0m02:22:34.721375 [info ] [MainThread]:   execution_project: purwadika
[0m02:22:34.722323 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:22:34.723139 [info ] [MainThread]:   location: None
[0m02:22:34.724089 [info ] [MainThread]:   priority: None
[0m02:22:34.725459 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:22:34.728646 [info ] [MainThread]:   impersonate_service_account: None
[0m02:22:34.730620 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:22:34.732770 [info ] [MainThread]:   job_retries: 1
[0m02:22:34.734752 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:22:34.736236 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:22:34.738268 [info ] [MainThread]:   timeout_seconds: None
[0m02:22:34.740278 [info ] [MainThread]:   client_id: None
[0m02:22:34.742060 [info ] [MainThread]:   token_uri: None
[0m02:22:34.744104 [info ] [MainThread]:   dataproc_region: None
[0m02:22:34.745413 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:22:34.746691 [info ] [MainThread]:   gcs_bucket: None
[0m02:22:34.748000 [info ] [MainThread]:   dataproc_batch: None
[0m02:22:34.750047 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:22:34.807477 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:22:34.808411 [debug] [MainThread]: On debug: select 1 as id
[0m02:22:34.809154 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:22:35.515508 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:c5cf89fd-cf71-4cdf-ac70-2d829ca6deda&page=queryresults
[0m02:22:36.332109 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:22:36.334707 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:22:36.336755 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.280742, "process_in_blocks": "0", "process_kernel_time": 0.236359, "process_mem_max_rss": "214436", "process_out_blocks": "0", "process_user_time": 2.630787}
[0m02:22:36.337760 [debug] [MainThread]: Command `dbt debug` succeeded at 02:22:36.337637 after 2.28 seconds
[0m02:22:36.338763 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:22:36.339911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf572c6190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf85580250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf8897cc10>]}
[0m02:22:36.340768 [debug] [MainThread]: Flushing usage events
[0m02:22:37.698431 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:22:42.902639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38545f7090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38545f71d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38545f6fd0>]}


============================== 02:22:42.905224 | 03293c56-7bcb-4733-8ab2-56343b3cd326 ==============================
[0m02:22:42.905224 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:22:42.906544 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt compile', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m02:22:43.464239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f382677e290>]}
[0m02:22:43.508034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38269e8f10>]}
[0m02:22:43.509341 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:22:43.577778 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:22:43.761872 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:22:43.762785 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:22:43.767413 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m02:22:43.790618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f382cc64f90>]}
[0m02:22:43.907492 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:22:43.912726 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:22:43.927689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3826914590>]}
[0m02:22:43.928856 [info ] [MainThread]: Found 5 models, 8 sources, 488 macros
[0m02:22:43.929933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f382ccab3d0>]}
[0m02:22:43.932569 [info ] [MainThread]: 
[0m02:22:43.933665 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:22:43.934659 [info ] [MainThread]: 
[0m02:22:43.935809 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:22:43.940170 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source'
[0m02:22:43.940914 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging'
[0m02:22:43.941785 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:22:43.942738 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:22:44.488578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03293c56-7bcb-4733-8ab2-56343b3cd326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38268e4790>]}
[0m02:22:44.489537 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:22:44.495060 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:22:44.495409 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:22:44.495780 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:22:44.496144 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:22:44.497135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:22:44.498188 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m02:22:44.499489 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:22:44.500475 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:22:44.501289 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:22:44.502386 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:22:44.503429 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:22:44.504564 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:22:44.521039 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:22:44.524394 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:22:44.528470 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:22:44.531949 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:22:44.537368 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:22:44.537897 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:22:44.539362 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:22:44.539789 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:22:44.540733 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:22:44.541268 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:22:44.542218 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:22:44.543969 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:22:44.546156 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:22:44.549255 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:22:44.550094 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:22:44.551643 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:22:44.553368 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:22:44.554689 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_driver, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:22:44.556981 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:22:44.561858 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:22:44.569152 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:22:44.570379 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m02:22:44.575088 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:22:44.577301 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:22:44.578369 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:22:44.579352 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:22:44.580262 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:22:44.581374 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:22:44.583045 [debug] [MainThread]: Command end result
[0m02:22:44.623022 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:22:44.627722 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:22:44.636874 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:22:44.638129 [debug] [MainThread]: Resource report: {"command_name": "compile", "command_success": true, "command_wall_clock_time": 1.7960105, "process_in_blocks": "0", "process_kernel_time": 0.16216, "process_mem_max_rss": "214432", "process_out_blocks": "0", "process_user_time": 3.030382}
[0m02:22:44.639074 [debug] [MainThread]: Command `dbt compile` succeeded at 02:22:44.638966 after 1.80 seconds
[0m02:22:44.639826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38553a31d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f385464d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3857de8c10>]}
[0m02:22:44.640694 [debug] [MainThread]: Flushing usage events
[0m02:22:45.653547 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:33:21.909961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef2277990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef275b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef22beb10>]}


============================== 02:33:21.912425 | 19fd3d24-093d-4274-a03e-4a209f1a03c3 ==============================
[0m02:33:21.912425 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:33:21.914815 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:33:22.478493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec85e0110>]}
[0m02:33:22.528385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef44ecad0>]}
[0m02:33:22.529592 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:33:22.601453 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:33:22.753288 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m02:33:22.754483 [debug] [MainThread]: Partial parsing: added file: hailing_project://macros/generate_schema_name.sql
[0m02:33:22.757499 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m02:33:23.662505 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.facts
- models.dbt_project.staging
[0m02:33:23.675251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3f7c250>]}
[0m02:33:23.752712 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:33:23.758684 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:33:23.774686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec85a1950>]}
[0m02:33:23.775961 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:33:23.777337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec826bc50>]}
[0m02:33:23.780003 [info ] [MainThread]: 
[0m02:33:23.781072 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:33:23.782004 [info ] [MainThread]: 
[0m02:33:23.783315 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:33:23.789173 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:33:23.789982 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:33:23.790761 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:33:23.791562 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:33:24.807726 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:33:24.808309 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m02:33:24.809044 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:33:24.809863 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:33:25.043630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec8279690>]}
[0m02:33:25.045227 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:33:25.051708 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:33:25.052290 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:33:25.052786 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:33:25.053226 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:33:25.053939 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m02:33:25.055398 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:33:25.056923 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m02:33:25.058780 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m02:33:25.060814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:33:25.063696 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.production_hailing_staging_customer)
[0m02:33:25.065441 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:33:25.066988 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:33:25.068489 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:33:25.069949 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:33:25.071445 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:33:25.073048 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:33:25.089767 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:33:25.093789 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:33:25.098515 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:33:25.102524 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:33:25.108022 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:33:25.108520 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:33:25.108928 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:33:25.114899 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:33:25.160739 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:33:25.161183 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:33:25.164409 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:33:25.168179 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:33:25.441257 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:33:25.442597 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:33:25.443646 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:33:25.448719 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:33:25.450049 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:33:25.450542 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:33:25.457451 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:33:25.465413 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:33:25.762392 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:15c1e607-c97b-4b6c-a94e-2cca849f84a7&page=queryresults
[0m02:33:26.020233 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:43dad530-b22e-40cd-b1e4-16d0d0b46692&page=queryresults
[0m02:33:26.043343 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ba84851a-40e6-480a-8896-784603fe8b41&page=queryresults
[0m02:33:26.857897 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:db04bfab-fffa-4768-809a-89782af27b10&page=queryresults
[0m02:33:27.512598 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec8106290>]}
[0m02:33:27.513870 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.44s]
[0m02:33:27.514976 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:33:27.515715 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:33:27.516446 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m02:33:27.517333 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:33:27.517971 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:33:27.521973 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:33:27.527404 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:33:27.531162 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:33:27.941008 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3eeb590>]}
[0m02:33:27.941776 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3f0fb10>]}
[0m02:33:27.943004 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.88s]
[0m02:33:27.944087 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.88s]
[0m02:33:27.945408 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:33:27.946353 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:33:28.138688 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:33:28.148522 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:33:28.435158 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:12e1789b-cc43-4647-924b-bc42aef657bd&page=queryresults
[0m02:33:28.441141 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3d4a950>]}
[0m02:33:28.442287 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 3.38s]
[0m02:33:28.443742 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:33:29.934680 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19fd3d24-093d-4274-a03e-4a209f1a03c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec02b0e10>]}
[0m02:33:29.935975 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.42s]
[0m02:33:29.938471 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:33:29.940838 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:33:29.943218 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:33:29.943944 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:33:29.944596 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:33:29.945375 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:33:29.946299 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:33:29.947609 [info ] [MainThread]: 
[0m02:33:29.950035 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.16 seconds (6.16s).
[0m02:33:29.952356 [debug] [MainThread]: Command end result
[0m02:33:29.986587 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:33:29.991711 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:33:30.001430 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:33:30.002329 [info ] [MainThread]: 
[0m02:33:30.003603 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:33:30.004676 [info ] [MainThread]: 
[0m02:33:30.005757 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:33:30.007350 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.143779, "process_in_blocks": "0", "process_kernel_time": 0.173195, "process_mem_max_rss": "228532", "process_out_blocks": "0", "process_user_time": 4.258565}
[0m02:33:30.008334 [debug] [MainThread]: Command `dbt run` succeeded at 02:33:30.008192 after 8.14 seconds
[0m02:33:30.009165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef26728d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef5a6cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ef5bf0a10>]}
[0m02:33:30.010117 [debug] [MainThread]: Flushing usage events
[0m02:33:31.296171 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:36:41.821347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6df2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6df3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6df2c10>]}


============================== 02:36:41.823803 | 470704e4-5630-418b-b44e-67fe2a9a74c0 ==============================
[0m02:36:41.823803 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:36:41.825035 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:36:42.386019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbd142650>]}
[0m02:36:42.431335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe90a1a50>]}
[0m02:36:42.432511 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:36:42.502714 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:36:42.570118 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m02:36:42.572317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe74eaa50>]}
[0m02:36:43.553068 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_project.staging
- models.dbt_project.facts
[0m02:36:43.566309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbcc88c50>]}
[0m02:36:43.636008 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:36:43.641330 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:36:43.657661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbc9dcd90>]}
[0m02:36:43.658847 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:36:43.659942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbcdbc2d0>]}
[0m02:36:43.662320 [info ] [MainThread]: 
[0m02:36:43.663376 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:36:43.664337 [info ] [MainThread]: 
[0m02:36:43.665491 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:36:43.670051 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:36:43.671021 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:36:45.377120 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_source)
[0m02:36:45.378158 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:36:45.590818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6eeb290>]}
[0m02:36:45.593051 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:36:45.598551 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:36:45.598955 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:36:45.599361 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:36:45.599712 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:36:45.600606 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_source.dim_customer ....... [RUN]
[0m02:36:45.602472 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [RUN]
[0m02:36:45.603774 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [RUN]
[0m02:36:45.605000 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [RUN]
[0m02:36:45.606240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_source, now model.hailing_project.dim_customer)
[0m02:36:45.607221 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_customer'
[0m02:36:45.608193 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:36:45.609339 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:36:45.610237 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:36:45.611071 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:36:45.611865 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:36:45.612672 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:36:45.621418 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:36:45.625265 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:36:45.629529 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:36:45.633483 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:36:45.640035 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:36:45.640563 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:36:45.640967 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:36:45.647436 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:36:45.682342 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:36:45.686525 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:36:45.689784 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:36:45.693159 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:36:45.974977 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:36:45.976100 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:36:45.981832 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:36:45.986548 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:36:45.987052 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:36:45.996144 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:36:45.998026 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:36:46.005142 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:36:46.261816 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:cb7bcdd0-d941-4556-bc15-ba1fb439fad2&page=queryresults
[0m02:36:46.267797 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:0170bc09-a95a-4042-a80e-cee82cbe31c2&page=queryresults
[0m02:36:46.269893 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:01d277b0-f6ed-4823-8795-c80fac2ab05a&page=queryresults
[0m02:36:46.520434 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:35ad6a63-3f78-4fab-9770-a940e02c8548&page=queryresults
[0m02:36:47.839279 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbca6e2d0>]}
[0m02:36:47.839623 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6e22f50>]}
[0m02:36:47.840534 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.23s]
[0m02:36:47.841923 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.23s]
[0m02:36:47.843332 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:36:47.844440 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:36:47.845385 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:36:47.847069 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [RUN]
[0m02:36:47.848043 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:36:47.849199 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:36:47.853907 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:36:47.862012 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:36:47.866195 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:36:48.027740 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbcab1d10>]}
[0m02:36:48.029426 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.42s]
[0m02:36:48.031038 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:36:48.078414 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbbc0ac150>]}
[0m02:36:48.079492 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_source.dim_customer .. [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.47s]
[0m02:36:48.080800 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:36:48.097232 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:36:48.105245 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:36:48.366640 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ff2c8b8d-dda4-475c-95bf-e484b75576a9&page=queryresults
[0m02:36:49.889472 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '470704e4-5630-418b-b44e-67fe2a9a74c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbb4d9cfd0>]}
[0m02:36:49.890814 [info ] [Thread-4 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_source.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.04s]
[0m02:36:49.892603 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:36:49.895455 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:36:49.899091 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:36:49.899971 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:36:49.900874 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:36:49.901919 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:36:49.903091 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:36:49.904028 [info ] [MainThread]: 
[0m02:36:49.905018 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.24 seconds (6.24s).
[0m02:36:49.907401 [debug] [MainThread]: Command end result
[0m02:36:49.940060 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:36:49.945423 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:36:49.954249 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:36:49.955067 [info ] [MainThread]: 
[0m02:36:49.956135 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:36:49.957323 [info ] [MainThread]: 
[0m02:36:49.958273 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:36:49.959745 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.185252, "process_in_blocks": "0", "process_kernel_time": 0.255493, "process_mem_max_rss": "226948", "process_out_blocks": "0", "process_user_time": 4.057232}
[0m02:36:49.960724 [debug] [MainThread]: Command `dbt run` succeeded at 02:36:49.960599 after 8.19 seconds
[0m02:36:49.961573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6e47d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbe6e4bd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbea7a5010>]}
[0m02:36:49.962387 [debug] [MainThread]: Flushing usage events
[0m02:36:51.527674 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:40:03.813667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3923890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a39667d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3d1e150>]}


============================== 02:40:03.816561 | 6323024f-9293-4b07-a0da-60267872d72b ==============================
[0m02:40:03.816561 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:40:03.818786 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:40:03.830515 [info ] [MainThread]: dbt version: 1.9.0
[0m02:40:03.831396 [info ] [MainThread]: python version: 3.11.2
[0m02:40:03.833761 [info ] [MainThread]: python path: /usr/local/bin/python
[0m02:40:03.835840 [info ] [MainThread]: os info: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
[0m02:40:04.314337 [info ] [MainThread]: Using profiles dir at /usr/app/dbt_project
[0m02:40:04.315818 [info ] [MainThread]: Using profiles.yml file at /usr/app/dbt_project/profiles.yml
[0m02:40:04.317569 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project/dbt_project.yml
[0m02:40:04.318850 [info ] [MainThread]: adapter type: bigquery
[0m02:40:04.320833 [info ] [MainThread]: adapter version: 1.9.0
[0m02:40:04.398822 [info ] [MainThread]: Configuration:
[0m02:40:04.399947 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m02:40:04.400879 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m02:40:04.401873 [info ] [MainThread]: Required dependencies:
[0m02:40:04.402823 [debug] [MainThread]: Executing "git --help"
[0m02:40:04.404899 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone             Clone a repository into a new directory\n   init              Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add               Add file contents to the index\n   mv                Move or rename a file, a directory, or a symlink\n   restore           Restore working tree files\n   rm                Remove files from the working tree and from the index\n   sparse-checkout   Initialize and modify the sparse-checkout\n\nexamine the history and state (see also: git help revisions)\n   bisect            Use binary search to find the commit that introduced a bug\n   diff              Show changes between commits, commit and working tree, etc\n   grep              Print lines matching a pattern\n   log               Show commit logs\n   show              Show various types of objects\n   status            Show the working tree status\n\ngrow, mark and tweak your common history\n   branch            List, create, or delete branches\n   commit            Record changes to the repository\n   merge             Join two or more development histories together\n   rebase            Reapply commits on top of another base tip\n   reset             Reset current HEAD to the specified state\n   switch            Switch branches\n   tag               Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch             Download objects and refs from another repository\n   pull              Fetch from and integrate with another repository or a local branch\n   push              Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m02:40:04.405594 [debug] [MainThread]: STDERR: "b''"
[0m02:40:04.406270 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m02:40:04.407231 [info ] [MainThread]: Connection:
[0m02:40:04.408463 [info ] [MainThread]:   method: service-account
[0m02:40:04.410058 [info ] [MainThread]:   database: purwadika
[0m02:40:04.411303 [info ] [MainThread]:   execution_project: purwadika
[0m02:40:04.412210 [info ] [MainThread]:   schema: rizky_dwh_hailing_source
[0m02:40:04.413274 [info ] [MainThread]:   location: None
[0m02:40:04.414121 [info ] [MainThread]:   priority: None
[0m02:40:04.414954 [info ] [MainThread]:   maximum_bytes_billed: None
[0m02:40:04.416128 [info ] [MainThread]:   impersonate_service_account: None
[0m02:40:04.417230 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m02:40:04.418222 [info ] [MainThread]:   job_retries: 1
[0m02:40:04.419223 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m02:40:04.420322 [info ] [MainThread]:   job_execution_timeout_seconds: None
[0m02:40:04.421251 [info ] [MainThread]:   timeout_seconds: None
[0m02:40:04.422149 [info ] [MainThread]:   client_id: None
[0m02:40:04.423157 [info ] [MainThread]:   token_uri: None
[0m02:40:04.424332 [info ] [MainThread]:   dataproc_region: None
[0m02:40:04.425252 [info ] [MainThread]:   dataproc_cluster_name: None
[0m02:40:04.426317 [info ] [MainThread]:   gcs_bucket: None
[0m02:40:04.427865 [info ] [MainThread]:   dataproc_batch: None
[0m02:40:04.429191 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:40:04.482867 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m02:40:04.483910 [debug] [MainThread]: On debug: select 1 as id
[0m02:40:04.484933 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:40:05.206577 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:e30beb94-084b-41e7-a5c3-8fadc0e892fb&page=queryresults
[0m02:40:05.933864 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m02:40:05.937402 [info ] [MainThread]: [32mAll checks passed![0m
[0m02:40:05.939213 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 2.169973, "process_in_blocks": "0", "process_kernel_time": 0.183383, "process_mem_max_rss": "212540", "process_out_blocks": "0", "process_user_time": 2.608118}
[0m02:40:05.940290 [debug] [MainThread]: Command `dbt debug` succeeded at 02:40:05.940175 after 2.17 seconds
[0m02:40:05.941081 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m02:40:05.941902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3955290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3928610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79a3a1a9d0>]}
[0m02:40:05.942673 [debug] [MainThread]: Flushing usage events
[0m02:40:07.040937 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:40:14.013600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9a6b2d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9a7071d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9a6b39d0>]}


============================== 02:40:14.016013 | 84ef3dfc-0ed5-4ab0-8521-d0df65337454 ==============================
[0m02:40:14.016013 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:40:14.018438 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt clean', 'send_anonymous_usage_stats': 'True'}
[0m02:40:14.098597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '84ef3dfc-0ed5-4ab0-8521-d0df65337454', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9a5b7f90>]}
[0m02:40:14.163057 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.19643295, "process_in_blocks": "16", "process_kernel_time": 0.07158, "process_mem_max_rss": "90112", "process_out_blocks": "0", "process_user_time": 0.910097}
[0m02:40:14.164050 [debug] [MainThread]: Command `dbt clean` succeeded at 02:40:14.163941 after 0.20 seconds
[0m02:40:14.164726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9ded4c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9e031350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d9e0310d0>]}
[0m02:40:14.165460 [debug] [MainThread]: Flushing usage events
[0m02:40:15.152785 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:40:16.273776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1cdbbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce21e89d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1d2f1d0>]}


============================== 02:40:16.276964 | 1df149ad-c3f0-413f-b4a6-38aedc60b0ae ==============================
[0m02:40:16.276964 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:40:16.278464 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m02:40:16.362501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1df149ad-c3f0-413f-b4a6-38aedc60b0ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1b9ced0>]}
[0m02:40:16.380425 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:40:16.383902 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:40:16.385453 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16651388, "process_in_blocks": "248", "process_kernel_time": 0.102933, "process_mem_max_rss": "90104", "process_out_blocks": "0", "process_user_time": 0.967572}
[0m02:40:16.386506 [debug] [MainThread]: Command `dbt deps` succeeded at 02:40:16.386386 after 0.17 seconds
[0m02:40:16.387348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1d0d850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce1c0c810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce56290d0>]}
[0m02:40:16.388190 [debug] [MainThread]: Flushing usage events
[0m02:40:17.414525 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:40:24.986706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9604f50490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96044e3390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f960415f610>]}


============================== 02:40:24.990308 | 8951e679-14fb-4492-927e-165b8d5f369e ==============================
[0m02:40:24.990308 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:40:24.991667 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:40:25.598271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d7d0edd0>]}
[0m02:40:25.642464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f960637e1d0>]}
[0m02:40:25.643462 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:40:25.714671 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:40:25.716835 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m02:40:25.717955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d627bd90>]}
[0m02:40:26.740359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5ed5b50>]}
[0m02:40:26.808388 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:40:26.814471 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:40:26.830413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5cd5090>]}
[0m02:40:26.831859 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:40:26.832999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5e03f10>]}
[0m02:40:26.835588 [info ] [MainThread]: 
[0m02:40:26.836836 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:40:26.838044 [info ] [MainThread]: 
[0m02:40:26.839527 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:40:26.843766 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:40:26.844452 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:40:26.845233 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:40:26.846081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:40:27.846493 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:40:27.847130 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:40:27.847938 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:40:27.848930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:40:28.096808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d60566d0>]}
[0m02:40:28.097782 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:40:28.103408 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:40:28.103839 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:40:28.104224 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:40:28.104679 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:40:28.105376 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:40:28.106653 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:40:28.108077 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:40:28.109202 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:40:28.110249 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m02:40:28.111388 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.production_hailing_staging_customer)
[0m02:40:28.112563 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:40:28.113499 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:40:28.114321 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:40:28.115263 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:40:28.116174 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:40:28.117010 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:40:28.125863 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:40:28.131164 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:40:28.135456 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:40:28.139412 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:40:28.152182 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:40:28.152918 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:40:28.164308 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:40:28.196639 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:40:28.199174 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:40:28.217612 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:40:28.220249 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:40:28.224275 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:40:28.306832 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:40:28.308012 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:40:28.533599 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:40:28.534842 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:40:28.535984 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:40:28.541706 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:40:28.544261 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:40:28.546777 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:40:28.707486 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5f264828-b286-4675-aabc-3a34f8bb533d&page=queryresults
[0m02:40:28.788486 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:50a516ff-955d-4355-98c2-f6bd11f2e723&page=queryresults
[0m02:40:29.087247 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2db72773-b20b-4f48-98f7-630a233d754a&page=queryresults
[0m02:40:29.089825 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1ec5eab9-6e68-4f01-9cd1-a6e8ce856abb&page=queryresults
[0m02:40:30.662022 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d43752d0>]}
[0m02:40:30.663798 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.55s]
[0m02:40:30.665271 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:40:30.666348 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:40:30.667325 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:40:30.668394 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:40:30.669345 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:40:30.674328 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:40:30.680939 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:40:30.685337 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:40:30.929964 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:40:30.936852 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:40:31.023408 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5d74810>]}
[0m02:40:31.025149 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.91s]
[0m02:40:31.026435 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:40:31.199711 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:bdc9a943-3f69-4cba-90f2-148689175577&page=queryresults
[0m02:40:31.446520 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d4373f90>]}
[0m02:40:31.447917 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 3.33s]
[0m02:40:31.449167 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:40:32.799178 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d5e01150>]}
[0m02:40:32.801853 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 4.69s]
[0m02:40:32.803153 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:40:32.998282 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8951e679-14fb-4492-927e-165b8d5f369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95d43ddc10>]}
[0m02:40:32.999817 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.33s]
[0m02:40:33.001293 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:40:33.003850 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:40:33.006838 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:40:33.007621 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:40:33.008491 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:40:33.009834 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:40:33.010749 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:40:33.011568 [info ] [MainThread]: 
[0m02:40:33.012515 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.17 seconds (6.17s).
[0m02:40:33.014488 [debug] [MainThread]: Command end result
[0m02:40:33.049963 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:40:33.054551 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:40:33.064703 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:40:33.065497 [info ] [MainThread]: 
[0m02:40:33.066567 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:40:33.067772 [info ] [MainThread]: 
[0m02:40:33.068976 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:40:33.070993 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.133492, "process_in_blocks": "0", "process_kernel_time": 0.25069, "process_mem_max_rss": "226520", "process_out_blocks": "0", "process_user_time": 4.231647}
[0m02:40:33.072248 [debug] [MainThread]: Command `dbt run` succeeded at 02:40:33.072062 after 8.13 seconds
[0m02:40:33.073335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9604183610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f960415f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96078fcc90>]}
[0m02:40:33.074301 [debug] [MainThread]: Flushing usage events
[0m02:40:34.356001 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:42:19.390060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da202bdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da202be90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da23d2290>]}


============================== 02:42:19.392662 | c6a5d014-8302-41d6-b1f3-5d38dac10cc0 ==============================
[0m02:42:19.392662 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:42:19.393856 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:42:19.945795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d7827f4d0>]}
[0m02:42:19.994337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da425e150>]}
[0m02:42:19.995639 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:42:20.063565 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:42:20.219830 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:42:20.221222 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:42:20.250536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d73f98350>]}
[0m02:42:20.359655 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:42:20.366829 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:42:20.382239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d78350f10>]}
[0m02:42:20.383350 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:42:20.384427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d78340f90>]}
[0m02:42:20.387059 [info ] [MainThread]: 
[0m02:42:20.388166 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:42:20.389339 [info ] [MainThread]: 
[0m02:42:20.390703 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:42:20.395815 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:42:20.396574 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:42:20.397535 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:42:20.398406 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:42:21.248870 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_facts)
[0m02:42:21.249408 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now create_purwadika_rizky_dwh_hailing_staging)
[0m02:42:21.250258 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_facts"
"
[0m02:42:21.252177 [debug] [ThreadPool]: Creating schema "database: "purwadika"
schema: "rizky_dwh_hailing_staging"
"
[0m02:42:21.262902 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_facts: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_facts"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_facts`
  
[0m02:42:21.265037 [debug] [ThreadPool]: On create_purwadika_rizky_dwh_hailing_staging: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "connection_name": "create_purwadika_rizky_dwh_hailing_staging"} */
create schema if not exists `purwadika`.`rizky_dwh_hailing_staging`
  
[0m02:42:21.266065 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:42:21.266941 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:42:22.125183 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:77109f8f-29c2-4aed-b18a-fc8c5f1bf5d0&page=queryresults
[0m02:42:22.718227 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:a10252c5-d2bb-4d8e-a092-1ed785647aa5&page=queryresults
[0m02:42:23.599187 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_facts, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:42:23.599775 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_purwadika_rizky_dwh_hailing_staging, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:42:23.601416 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:42:23.602405 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:42:24.120206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d7878d290>]}
[0m02:42:24.121165 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:42:24.126019 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:42:24.126382 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:42:24.126754 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:42:24.127207 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:42:24.127787 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:42:24.129547 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:42:24.131101 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:42:24.132327 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:42:24.133580 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:42:24.134572 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m02:42:24.135857 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:42:24.136888 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:42:24.137877 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:42:24.138960 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:42:24.140203 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:42:24.141208 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:42:24.152498 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:42:24.156391 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:42:24.160042 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:42:24.164726 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:42:24.171916 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:42:24.172414 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:42:24.172858 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:42:24.178969 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:42:24.251893 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:42:24.259683 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:42:24.261594 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:42:24.265329 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:42:24.270511 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m02:42:24.272515 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:42:24.273081 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:42:24.273802 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:42:24.275249 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:42:24.276807 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:42:24.278977 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:42:24.301576 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:42:24.572758 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8f87c786-27fc-4c39-bfbf-bb226287b2d9&page=queryresults
[0m02:42:24.573748 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:8f87c786-27fc-4c39-bfbf-bb226287b2d9&page=queryresults
[0m02:42:24.579718 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m02:42:24.582501 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d72ac7cd0>]}
[0m02:42:24.584164 [error] [Thread-4 (]: 4 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[31mERROR[0m in 0.44s]
[0m02:42:24.585345 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:42:24.586485 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:42:24.587003 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_ride' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql.
[0m02:42:24.588071 [info ] [Thread-4 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:42:24.590590 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_ride, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:42:24.591742 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:42:24.596695 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:42:24.604078 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:42:24.610682 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:42:24.611785 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e9c20031-7fee-4318-a1ae-89ae57b260a0&page=queryresults
[0m02:42:24.613278 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:e9c20031-7fee-4318-a1ae-89ae57b260a0&page=queryresults
[0m02:42:24.617319 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m02:42:24.618369 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2521dbca-7b1a-4ebf-a69d-75585f71d661&page=queryresults
[0m02:42:24.619347 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d78367210>]}
[0m02:42:24.621660 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m02:42:24.621132 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2521dbca-7b1a-4ebf-a69d-75585f71d661&page=queryresults
[0m02:42:24.623373 [error] [Thread-3 (]: 3 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[31mERROR[0m in 0.48s]
[0m02:42:24.624804 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:42:24.633736 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:42:24.636428 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:42:24.638805 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d73f6f910>]}
[0m02:42:24.642669 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_driver' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql.
[0m02:42:24.670883 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.50s]
[0m02:42:24.672878 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:42:24.673779 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m02:42:24.958003 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:16a68a8b-8f27-4193-a58e-2fac44c79ef7&page=queryresults
[0m02:42:24.961531 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:16a68a8b-8f27-4193-a58e-2fac44c79ef7&page=queryresults
[0m02:42:24.966591 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:42:24.967768 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d73fc3490>]}
[0m02:42:24.969289 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.83s]
[0m02:42:24.971894 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:42:24.973531 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m02:42:24.976170 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9032a92f-2cc4-4a7d-9221-636367d9bcea&page=queryresults
[0m02:42:24.977561 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9032a92f-2cc4-4a7d-9221-636367d9bcea&page=queryresults
[0m02:42:24.980759 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m02:42:24.981801 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6a5d014-8302-41d6-b1f3-5d38dac10cc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d72a71d50>]}
[0m02:42:24.983056 [error] [Thread-4 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[31mERROR[0m in 0.39s]
[0m02:42:24.984640 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:42:24.985760 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql.
[0m02:42:24.988009 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:42:24.991143 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:42:24.991821 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:42:24.992524 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:42:24.993179 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:42:24.994022 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:42:24.995012 [info ] [MainThread]: 
[0m02:42:24.996152 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 4.60 seconds (4.60s).
[0m02:42:24.998313 [debug] [MainThread]: Command end result
[0m02:42:25.032230 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:42:25.036584 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:42:25.044153 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:42:25.045027 [info ] [MainThread]: 
[0m02:42:25.046160 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m02:42:25.047191 [info ] [MainThread]: 
[0m02:42:25.048379 [error] [MainThread]:   Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m02:42:25.049468 [info ] [MainThread]: 
[0m02:42:25.050584 [error] [MainThread]:   Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m02:42:25.051805 [info ] [MainThread]: 
[0m02:42:25.052860 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:42:25.054195 [info ] [MainThread]: 
[0m02:42:25.055497 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:42:25.056366 [info ] [MainThread]: 
[0m02:42:25.057727 [error] [MainThread]:   Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m02:42:25.059255 [info ] [MainThread]: 
[0m02:42:25.060213 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m02:42:25.061673 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.718776, "process_in_blocks": "0", "process_kernel_time": 0.316244, "process_mem_max_rss": "221940", "process_out_blocks": "0", "process_user_time": 3.315464}
[0m02:42:25.062507 [debug] [MainThread]: Command `dbt run` failed at 02:42:25.062403 after 5.72 seconds
[0m02:42:25.063275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da1e4f690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da1e4f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2da59510d0>]}
[0m02:42:25.064278 [debug] [MainThread]: Flushing usage events
[0m02:42:26.384703 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:44:38.818697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a0b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817ec0490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a0bdd0>]}


============================== 02:44:38.821606 | ac1e74d4-d2b2-40ad-82a1-243837fa6df1 ==============================
[0m02:44:38.821606 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:44:38.823227 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:44:39.370338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9baab90>]}
[0m02:44:39.413971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4819c7cfd0>]}
[0m02:44:39.415407 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:44:39.480838 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:44:39.631579 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:44:39.632536 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:44:39.658904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9a500d0>]}
[0m02:44:39.777831 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:44:39.782715 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:44:39.798921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9b9ccd0>]}
[0m02:44:39.800087 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:44:39.801211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9d3de10>]}
[0m02:44:39.803623 [info ] [MainThread]: 
[0m02:44:39.804713 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:44:39.805628 [info ] [MainThread]: 
[0m02:44:39.806843 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:44:39.811753 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:44:39.812513 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:44:39.813200 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:44:39.814038 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:44:41.243929 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:44:41.244524 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:44:41.245260 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:44:41.246979 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:44:41.766181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47ea38b6d0>]}
[0m02:44:41.768611 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:44:41.775243 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:44:41.775622 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:44:41.776031 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:44:41.776373 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:44:41.777283 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:44:41.779119 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:44:41.782101 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:44:41.783441 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:44:41.785481 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:44:41.786654 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m02:44:41.787835 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:44:41.789368 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:44:41.790789 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:44:41.791771 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:44:41.792824 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:44:41.793810 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:44:41.806524 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:44:41.810117 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:44:41.814282 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:44:41.818580 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:44:41.823897 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:44:41.830157 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:44:41.835939 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:44:41.836268 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:44:41.940252 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:44:41.941853 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:44:41.945716 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:44:41.948722 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:44:41.954469 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:44:41.955160 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:44:41.955761 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m02:44:41.956217 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:44:41.956737 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:44:41.957512 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:44:41.958320 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:44:41.959067 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:44:42.213332 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:230e3561-f3cf-4e97-ae34-33fcec1eb9fe&page=queryresults
[0m02:44:42.214552 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:230e3561-f3cf-4e97-ae34-33fcec1eb9fe&page=queryresults
[0m02:44:42.218968 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:44:42.220905 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a21050>]}
[0m02:44:42.221933 [error] [Thread-2 (]: 2 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[31mERROR[0m in 0.43s]
[0m02:44:42.223048 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:44:42.224522 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:44:42.225056 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_customer' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql.
[0m02:44:42.225940 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:44:42.229278 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:44:42.230476 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:44:42.235128 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:44:42.241114 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7b784960-7f88-4f4f-8fcb-0617e7e3e354&page=queryresults
[0m02:44:42.242518 [error] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:7b784960-7f88-4f4f-8fcb-0617e7e3e354&page=queryresults
[0m02:44:42.244298 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:44:42.246709 [debug] [Thread-3 (]: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m02:44:42.250813 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:44:42.251775 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9859a10>]}
[0m02:44:42.253416 [error] [Thread-3 (]: 3 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[31mERROR[0m in 0.46s]
[0m02:44:42.254830 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:44:42.256204 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_driver' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql.
[0m02:44:42.260281 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m02:44:42.260937 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:82f3946d-264f-4b19-b3a4-94cfd442425a&page=queryresults
[0m02:44:42.261667 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:44:42.262883 [error] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:82f3946d-264f-4b19-b3a4-94cfd442425a&page=queryresults
[0m02:44:42.267760 [debug] [Thread-4 (]: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m02:44:42.292535 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9bd2d10>]}
[0m02:44:42.294465 [error] [Thread-4 (]: 4 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[31mERROR[0m in 0.50s]
[0m02:44:42.295952 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:44:42.298089 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_ride' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql.
[0m02:44:42.509701 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2e6ef395-f65e-40ec-95a0-4bee5eae6403&page=queryresults
[0m02:44:42.510755 [error] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:2e6ef395-f65e-40ec-95a0-4bee5eae6403&page=queryresults
[0m02:44:42.513957 [debug] [Thread-2 (]: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m02:44:42.514993 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e9a7ae10>]}
[0m02:44:42.516013 [error] [Thread-2 (]: 5 of 5 ERROR creating sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[31mERROR[0m in 0.29s]
[0m02:44:42.517237 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:44:42.518236 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.production_hailing_staging_vehicle' to be skipped because of status 'error'.  Reason: Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql.
[0m02:44:42.593792 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc163388-d04a-4a68-80ae-1bbd1f336b18&page=queryresults
[0m02:44:42.595795 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:US:cc163388-d04a-4a68-80ae-1bbd1f336b18&page=queryresults
[0m02:44:42.599609 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:44:42.600949 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac1e74d4-d2b2-40ad-82a1-243837fa6df1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47e866b010>]}
[0m02:44:42.602061 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.82s]
[0m02:44:42.603142 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:44:42.604110 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m02:44:42.605952 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:44:42.608581 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:44:42.609546 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:44:42.610318 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:44:42.611207 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:44:42.611951 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:44:42.613102 [info ] [MainThread]: 
[0m02:44:42.614237 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 2.81 seconds (2.81s).
[0m02:44:42.615776 [debug] [MainThread]: Command end result
[0m02:44:42.649976 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:44:42.655272 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:44:42.662876 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:44:42.663650 [info ] [MainThread]: 
[0m02:44:42.664706 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m02:44:42.665849 [info ] [MainThread]: 
[0m02:44:42.666860 [error] [MainThread]:   Database Error in model production_hailing_staging_customer (models/staging/production_hailing_staging_customer.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_customer.sql
[0m02:44:42.667823 [info ] [MainThread]: 
[0m02:44:42.668851 [error] [MainThread]:   Database Error in model production_hailing_staging_driver (models/staging/production_hailing_staging_driver.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_driver.sql
[0m02:44:42.669712 [info ] [MainThread]: 
[0m02:44:42.670641 [error] [MainThread]:   Database Error in model production_hailing_staging_ride (models/staging/production_hailing_staging_ride.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_ride.sql
[0m02:44:42.672671 [info ] [MainThread]: 
[0m02:44:42.673955 [error] [MainThread]:   Database Error in model production_hailing_staging_vehicle (models/staging/production_hailing_staging_vehicle.sql)
  Not found: Dataset purwadika:rizky_dwh_hailing_staging was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/staging/production_hailing_staging_vehicle.sql
[0m02:44:42.675180 [info ] [MainThread]: 
[0m02:44:42.676200 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location US
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:44:42.677243 [info ] [MainThread]: 
[0m02:44:42.678204 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m02:44:42.679751 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.9110105, "process_in_blocks": "0", "process_kernel_time": 0.250394, "process_mem_max_rss": "218580", "process_out_blocks": "0", "process_user_time": 3.305208}
[0m02:44:42.680911 [debug] [MainThread]: Command `dbt run` failed at 02:44:42.680759 after 3.91 seconds
[0m02:44:42.681712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a87a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a87790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4817a87b10>]}
[0m02:44:42.682714 [debug] [MainThread]: Flushing usage events
[0m02:44:43.970455 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:45:59.695588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15ca6f590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15cab2c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15ca6f090>]}


============================== 02:45:59.698073 | b9b24c18-3b4f-4399-83fa-4b94694dabb7 ==============================
[0m02:45:59.698073 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:45:59.700607 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:46:00.265271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ec45710>]}
[0m02:46:00.310865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15ecc2690>]}
[0m02:46:00.311930 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:46:00.379438 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:46:00.532428 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:46:00.533399 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:46:00.560106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12eab9990>]}
[0m02:46:00.676502 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:46:00.681807 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:46:00.696733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ec01c50>]}
[0m02:46:00.698844 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:46:00.700700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ebf4590>]}
[0m02:46:00.703304 [info ] [MainThread]: 
[0m02:46:00.704345 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:46:00.705334 [info ] [MainThread]: 
[0m02:46:00.706484 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:46:00.711368 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:46:00.712287 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:46:00.713141 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:46:00.714063 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:46:02.679198 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:46:02.679760 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:46:02.680469 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:46:02.683015 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:46:02.983644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15d87f690>]}
[0m02:46:02.987329 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:46:02.993035 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:46:02.993428 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:46:02.993797 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:46:02.994116 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:46:02.994769 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:46:02.995970 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:46:02.997359 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:46:02.998492 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:46:03.000558 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:46:03.001639 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m02:46:03.002641 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:46:03.003499 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:46:03.004416 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:46:03.005346 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:46:03.006342 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:46:03.007225 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:46:03.020576 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:46:03.024818 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:46:03.030485 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:46:03.034845 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:46:03.040240 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:46:03.040786 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:46:03.041245 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:46:03.047296 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:46:03.130626 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:46:03.132859 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:46:03.127671 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:46:03.136705 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:46:03.143802 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:46:03.144393 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    );
  
[0m02:46:03.147053 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:46:03.145856 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:46:03.144808 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:46:03.147785 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:46:03.149791 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:46:03.173957 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:46:03.629817 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b9afd9b-bd2b-4b5f-85aa-9f3fd6921778&page=queryresults
[0m02:46:03.630939 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:6b9afd9b-bd2b-4b5f-85aa-9f3fd6921778&page=queryresults
[0m02:46:03.635208 [debug] [Thread-1 (]: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:46:03.637287 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12e97b450>]}
[0m02:46:03.638543 [error] [Thread-1 (]: 1 of 5 ERROR creating sql incremental model rizky_dwh_hailing_facts.dim_customer  [[31mERROR[0m in 0.64s]
[0m02:46:03.640269 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:46:03.641984 [debug] [Thread-1 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:46:03.642484 [debug] [Thread-7 (]: Marking all children of 'model.hailing_project.dim_customer' to be skipped because of status 'error'.  Reason: Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql.
[0m02:46:03.643545 [info ] [Thread-1 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:46:03.646166 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.hailing_project.dim_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:46:03.647102 [debug] [Thread-1 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:46:03.651657 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:46:03.659144 [debug] [Thread-1 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:46:03.662635 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:46:03.669483 [debug] [Thread-1 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    );
  
[0m02:46:03.670835 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:46:03.844409 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9b169be5-a9ca-42b9-bc9c-467cba949065&page=queryresults
[0m02:46:04.114569 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:df35397d-e85f-4c44-888b-983c561e35e2&page=queryresults
[0m02:46:04.273102 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:ea597ff5-9804-45d0-8e27-779aec8b0cca&page=queryresults
[0m02:46:04.947982 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:9a559f7b-c151-4718-96c0-ee3847a8d8fc&page=queryresults
[0m02:46:05.898872 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12c5caa90>]}
[0m02:46:05.899977 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mCREATE TABLE (85.0 rows, 7.6 KiB processed)[0m in 2.90s]
[0m02:46:05.902330 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:46:06.291664 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12ec2eb90>]}
[0m02:46:06.293693 [info ] [Thread-1 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mCREATE TABLE (85.0 rows, 4.7 KiB processed)[0m in 2.65s]
[0m02:46:06.295811 [debug] [Thread-1 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:46:06.397760 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12e947050>]}
[0m02:46:06.399117 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 3.40s]
[0m02:46:06.400642 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:46:06.898035 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b24c18-3b4f-4399-83fa-4b94694dabb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff12c5b5350>]}
[0m02:46:06.899707 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mCREATE TABLE (85.0 rows, 5.8 KiB processed)[0m in 3.90s]
[0m02:46:06.901410 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:46:06.903755 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:46:06.907521 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:46:06.908244 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:46:06.909204 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_customer' was properly closed.
[0m02:46:06.909880 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:46:06.910539 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:46:06.911218 [info ] [MainThread]: 
[0m02:46:06.912139 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.20 seconds (6.20s).
[0m02:46:06.913825 [debug] [MainThread]: Command end result
[0m02:46:06.950467 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:46:06.954648 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:46:06.963251 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:46:06.963992 [info ] [MainThread]: 
[0m02:46:06.965029 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m02:46:06.966728 [info ] [MainThread]: 
[0m02:46:06.967715 [error] [MainThread]:   Database Error in model dim_customer (models/facts/dim_customer.sql)
  Not found: Table purwadika:rizky_dwh_hailing_staging.production_hailing_staging_customer was not found in location asia-southeast2
  compiled code at target/run/hailing_project/models/facts/dim_customer.sql
[0m02:46:06.968612 [info ] [MainThread]: 
[0m02:46:06.969697 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m02:46:06.971473 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.320235, "process_in_blocks": "0", "process_kernel_time": 0.174671, "process_mem_max_rss": "225608", "process_out_blocks": "0", "process_user_time": 3.39069}
[0m02:46:06.972571 [debug] [MainThread]: Command `dbt run` failed at 02:46:06.972439 after 7.32 seconds
[0m02:46:06.973477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff15caca3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1603bd610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff1603bd250>]}
[0m02:46:06.974458 [debug] [MainThread]: Flushing usage events
[0m02:46:08.282549 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:47:36.910123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90bb27010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90bb7b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90bb7b550>]}


============================== 02:47:36.913020 | 4e23a428-a996-42d2-93f7-789c2aa93d58 ==============================
[0m02:47:36.913020 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:47:36.915283 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'profiles_dir': '/usr/app/dbt_project', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_customer', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:47:37.516889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8ddcec6d0>]}
[0m02:47:37.559618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90dd9ca90>]}
[0m02:47:37.560845 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:47:37.627315 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:47:37.778761 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:47:37.779454 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:47:37.805183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8df30cdd0>]}
[0m02:47:37.913706 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:47:37.919057 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:47:37.934014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8ddeada50>]}
[0m02:47:37.934902 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:47:37.936297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8dde9dd10>]}
[0m02:47:37.938387 [info ] [MainThread]: 
[0m02:47:37.939721 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:47:37.940955 [info ] [MainThread]: 
[0m02:47:37.942649 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:47:37.944747 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:47:37.945876 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:38.660348 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:47:38.660962 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika_rizky_dwh_hailing_staging'
[0m02:47:38.662946 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:47:38.664459 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:38.901437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90d9e7810>]}
[0m02:47:38.902808 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:47:38.907169 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:47:38.907955 [info ] [Thread-1 (]: 1 of 1 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:47:38.909049 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.dim_customer)
[0m02:47:38.909947 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:47:38.923298 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:47:38.929352 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:47:38.994316 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:47:39.001328 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */

  
    

    create or replace table `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
      
    partition by timestamp_trunc(created_at, day)
    

    OPTIONS()
    as (
      

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    );
  
[0m02:47:39.002385 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:47:39.370377 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:99619465-0287-4353-819e-059fe9c79f4c&page=queryresults
[0m02:47:41.239719 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e23a428-a996-42d2-93f7-789c2aa93d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90c275f50>]}
[0m02:47:41.240753 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mCREATE TABLE (85.0 rows, 5.7 KiB processed)[0m in 2.33s]
[0m02:47:41.243909 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:47:41.246365 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:47:41.249179 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:47:41.250190 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:47:41.251171 [debug] [MainThread]: Connection 'list_purwadika_rizky_dwh_hailing_staging' was properly closed.
[0m02:47:41.252189 [info ] [MainThread]: 
[0m02:47:41.253426 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.31 seconds (3.31s).
[0m02:47:41.255531 [debug] [MainThread]: Command end result
[0m02:47:41.290240 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:47:41.295011 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:47:41.302242 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:47:41.303441 [info ] [MainThread]: 
[0m02:47:41.304536 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:47:41.305489 [info ] [MainThread]: 
[0m02:47:41.306700 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:47:41.308217 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.4489694, "process_in_blocks": "0", "process_kernel_time": 0.214428, "process_mem_max_rss": "220036", "process_out_blocks": "0", "process_user_time": 3.175581}
[0m02:47:41.309330 [debug] [MainThread]: Command `dbt run` succeeded at 02:47:41.309222 after 4.45 seconds
[0m02:47:41.310252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90bf228d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f31cc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8ddb5e950>]}
[0m02:47:41.311131 [debug] [MainThread]: Flushing usage events
[0m02:47:42.600073 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:47:53.018259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdbfa3710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdc39e750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdbfa3310>]}


============================== 02:47:53.020973 | 5674e5ae-01ea-4c69-8796-fa6290ecdb56 ==============================
[0m02:47:53.020973 [info ] [MainThread]: Running with dbt=1.9.0
[0m02:47:53.022830 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app/dbt_project', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/dbt_project/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m02:47:53.573306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdc01fdd0>]}
[0m02:47:53.617936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae28b5d0>]}
[0m02:47:53.619013 [info ] [MainThread]: Registered adapter: bigquery=1.9.0
[0m02:47:53.688111 [debug] [MainThread]: checksum: c99e828bba267739642b5a3ce85f17518764ea526e0e6c4fdc649171c1a66bff, vars: {}, profile: , target: , version: 1.9.0
[0m02:47:53.838010 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:47:53.839341 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:47:53.867949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3badfc6490>]}
[0m02:47:53.994582 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:47:53.999642 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:47:54.012936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae30f1d0>]}
[0m02:47:54.014786 [info ] [MainThread]: Found 5 models, 8 sources, 489 macros
[0m02:47:54.018037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae2fcd50>]}
[0m02:47:54.021498 [info ] [MainThread]: 
[0m02:47:54.022821 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:47:54.024070 [info ] [MainThread]: 
[0m02:47:54.025593 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m02:47:54.030244 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:47:54.030981 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_purwadika'
[0m02:47:54.031726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:54.032709 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:56.121240 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_staging)
[0m02:47:56.121892 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_purwadika, now list_purwadika_rizky_dwh_hailing_facts)
[0m02:47:56.122752 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:47:56.124379 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:47:56.364896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bbad89d50>]}
[0m02:47:56.365856 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:47:56.370851 [debug] [Thread-1 (]: Began running node model.hailing_project.dim_customer
[0m02:47:56.371178 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_customer
[0m02:47:56.371560 [debug] [Thread-3 (]: Began running node model.hailing_project.production_hailing_staging_driver
[0m02:47:56.372752 [debug] [Thread-4 (]: Began running node model.hailing_project.production_hailing_staging_ride
[0m02:47:56.373482 [info ] [Thread-1 (]: 1 of 5 START sql incremental model rizky_dwh_hailing_facts.dim_customer ........ [RUN]
[0m02:47:56.374920 [info ] [Thread-2 (]: 2 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [RUN]
[0m02:47:56.376203 [info ] [Thread-3 (]: 3 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [RUN]
[0m02:47:56.377311 [info ] [Thread-4 (]: 4 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [RUN]
[0m02:47:56.378486 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_staging, now model.hailing_project.dim_customer)
[0m02:47:56.379441 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_purwadika_rizky_dwh_hailing_facts, now model.hailing_project.production_hailing_staging_customer)
[0m02:47:56.380349 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_driver'
[0m02:47:56.381367 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.hailing_project.production_hailing_staging_ride'
[0m02:47:56.382257 [debug] [Thread-1 (]: Began compiling node model.hailing_project.dim_customer
[0m02:47:56.383115 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_customer
[0m02:47:56.383924 [debug] [Thread-3 (]: Began compiling node model.hailing_project.production_hailing_staging_driver
[0m02:47:56.384770 [debug] [Thread-4 (]: Began compiling node model.hailing_project.production_hailing_staging_ride
[0m02:47:56.399496 [debug] [Thread-1 (]: Writing injected SQL for node "model.hailing_project.dim_customer"
[0m02:47:56.403361 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_customer"
[0m02:47:56.407341 [debug] [Thread-3 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_driver"
[0m02:47:56.411647 [debug] [Thread-4 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_ride"
[0m02:47:56.418865 [debug] [Thread-3 (]: Began executing node model.hailing_project.production_hailing_staging_driver
[0m02:47:56.419356 [debug] [Thread-1 (]: Began executing node model.hailing_project.dim_customer
[0m02:47:56.419742 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_customer
[0m02:47:56.426095 [debug] [Thread-4 (]: Began executing node model.hailing_project.production_hailing_staging_ride
[0m02:47:56.469393 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:47:56.467888 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:47:56.472565 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:47:56.476383 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:47:56.753698 [debug] [Thread-3 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_driver"
[0m02:47:56.755028 [debug] [Thread-1 (]: Writing runtime sql for node "model.hailing_project.dim_customer"
[0m02:47:56.756817 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_customer"
[0m02:47:56.766104 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:47:56.766677 [debug] [Thread-1 (]: On model.hailing_project.dim_customer: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.dim_customer"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_customer`
),

cleaned AS (
    SELECT
        cust_id,
        name,
        -- Standardizing phone numbers (removing parentheses, dashes, spaces)
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        email,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_facts`.`dim_customer`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.cust_id = DBT_INTERNAL_DEST.cust_id
            )

    
    when matched then update set
        `cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`email` = DBT_INTERNAL_SOURCE.`email`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)
    values
        (`cust_id`, `name`, `phone_number`, `email`, `created_at`)


    
[0m02:47:56.769139 [debug] [Thread-3 (]: On model.hailing_project.production_hailing_staging_driver: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_driver"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_driver`
),

cleaned AS (
    SELECT
        driver_id,
        name,
        email,
        -- Standardizing phone numbers
        REGEXP_REPLACE(phone_number, r'[\s\-\(\)]', '') AS phone_number,
        created_at
    FROM source
)

SELECT * FROM cleaned

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_driver`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.driver_id = DBT_INTERNAL_DEST.driver_id
            )

    
    when matched then update set
        `driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`email` = DBT_INTERNAL_SOURCE.`email`,`phone_number` = DBT_INTERNAL_SOURCE.`phone_number`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)
    values
        (`driver_id`, `name`, `email`, `phone_number`, `created_at`)


    
[0m02:47:56.773439 [debug] [Thread-4 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_ride"
[0m02:47:56.780516 [debug] [Thread-4 (]: On model.hailing_project.production_hailing_staging_ride: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_ride"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_ride`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_ride`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.ride_id = DBT_INTERNAL_DEST.ride_id
            )

    
    when matched then update set
        `ride_id` = DBT_INTERNAL_SOURCE.`ride_id`,`cust_id` = DBT_INTERNAL_SOURCE.`cust_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`start_time` = DBT_INTERNAL_SOURCE.`start_time`,`end_time` = DBT_INTERNAL_SOURCE.`end_time`,`distance_km` = DBT_INTERNAL_SOURCE.`distance_km`,`fare` = DBT_INTERNAL_SOURCE.`fare`,`ride_status` = DBT_INTERNAL_SOURCE.`ride_status`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)
    values
        (`ride_id`, `cust_id`, `driver_id`, `start_time`, `end_time`, `distance_km`, `fare`, `ride_status`, `created_at`)


    
[0m02:47:57.012152 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:5e2071c3-e70e-49b4-96cb-9f44f58b8c47&page=queryresults
[0m02:47:57.013452 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:d7a68dcd-e736-47ad-a8b5-814e388c18ce&page=queryresults
[0m02:47:57.016364 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:1b6d14c0-8b6c-4bc9-aba3-9ce2bdaad3d9&page=queryresults
[0m02:47:58.127694 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:f3e54ada-0fd2-4487-ab07-552f379597cd&page=queryresults
[0m02:47:58.532268 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3badffdc10>]}
[0m02:47:58.533413 [info ] [Thread-2 (]: 2 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_customer  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 2.15s]
[0m02:47:58.535156 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_customer
[0m02:47:58.536636 [debug] [Thread-2 (]: Began running node model.hailing_project.production_hailing_staging_vehicle
[0m02:47:58.537756 [info ] [Thread-2 (]: 5 of 5 START sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [RUN]
[0m02:47:58.538982 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.hailing_project.production_hailing_staging_customer, now model.hailing_project.production_hailing_staging_vehicle)
[0m02:47:58.539917 [debug] [Thread-2 (]: Began compiling node model.hailing_project.production_hailing_staging_vehicle
[0m02:47:58.544734 [debug] [Thread-2 (]: Writing injected SQL for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:47:58.551195 [debug] [Thread-2 (]: Began executing node model.hailing_project.production_hailing_staging_vehicle
[0m02:47:58.555782 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:47:58.583999 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae1adc90>]}
[0m02:47:58.585299 [info ] [Thread-1 (]: 1 of 5 OK created sql incremental model rizky_dwh_hailing_facts.dim_customer ... [[32mMERGE (0.0 rows, 11.3 KiB processed)[0m in 2.21s]
[0m02:47:58.586501 [debug] [Thread-1 (]: Finished running node model.hailing_project.dim_customer
[0m02:47:58.775203 [debug] [Thread-2 (]: Writing runtime sql for node "model.hailing_project.production_hailing_staging_vehicle"
[0m02:47:58.782184 [debug] [Thread-2 (]: On model.hailing_project.production_hailing_staging_vehicle: /* {"app": "dbt", "dbt_version": "1.9.0", "profile_name": "hailing_project", "target_name": "dev", "node_id": "model.hailing_project.production_hailing_staging_vehicle"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle` as DBT_INTERNAL_DEST
        using (

WITH source AS (
    SELECT *
    FROM `purwadika`.`rizky_dwh_hailing_source`.`production_hailing_source_vehicle`
)

SELECT *
FROM source

    WHERE created_at > (
        SELECT MAX(created_at)
        FROM `purwadika`.`rizky_dwh_hailing_staging`.`production_hailing_staging_vehicle`
    )

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.vehicle_id = DBT_INTERNAL_DEST.vehicle_id
            )

    
    when matched then update set
        `vehicle_id` = DBT_INTERNAL_SOURCE.`vehicle_id`,`driver_id` = DBT_INTERNAL_SOURCE.`driver_id`,`vehicle_type` = DBT_INTERNAL_SOURCE.`vehicle_type`,`license_plate` = DBT_INTERNAL_SOURCE.`license_plate`,`year` = DBT_INTERNAL_SOURCE.`year`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`created_at` = DBT_INTERNAL_SOURCE.`created_at`
    

    when not matched then insert
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)
    values
        (`vehicle_id`, `driver_id`, `vehicle_type`, `license_plate`, `year`, `brand`, `created_at`)


    
[0m02:47:58.796726 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3badf53b10>]}
[0m02:47:58.797882 [info ] [Thread-4 (]: 4 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_ride  [[32mMERGE (0.0 rows, 15.1 KiB processed)[0m in 2.42s]
[0m02:47:58.799135 [debug] [Thread-4 (]: Finished running node model.hailing_project.production_hailing_staging_ride
[0m02:47:58.992795 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=purwadika&j=bq:asia-southeast2:878235f9-b32c-40dc-ba8a-6646cb82795c&page=queryresults
[0m02:47:59.639698 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae199350>]}
[0m02:47:59.641161 [info ] [Thread-3 (]: 3 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_driver  [[32mMERGE (0.0 rows, 11.5 KiB processed)[0m in 3.26s]
[0m02:47:59.642843 [debug] [Thread-3 (]: Finished running node model.hailing_project.production_hailing_staging_driver
[0m02:48:00.809855 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5674e5ae-01ea-4c69-8796-fa6290ecdb56', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bae3275d0>]}
[0m02:48:00.811403 [info ] [Thread-2 (]: 5 of 5 OK created sql incremental model rizky_dwh_hailing_staging.production_hailing_staging_vehicle  [[32mMERGE (0.0 rows, 9.3 KiB processed)[0m in 2.27s]
[0m02:48:00.812819 [debug] [Thread-2 (]: Finished running node model.hailing_project.production_hailing_staging_vehicle
[0m02:48:00.815315 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:48:00.818603 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:48:00.819433 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_vehicle' was properly closed.
[0m02:48:00.820400 [debug] [MainThread]: Connection 'model.hailing_project.dim_customer' was properly closed.
[0m02:48:00.821429 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_driver' was properly closed.
[0m02:48:00.822332 [debug] [MainThread]: Connection 'model.hailing_project.production_hailing_staging_ride' was properly closed.
[0m02:48:00.823478 [info ] [MainThread]: 
[0m02:48:00.824368 [info ] [MainThread]: Finished running 5 incremental models in 0 hours 0 minutes and 6.80 seconds (6.80s).
[0m02:48:00.826467 [debug] [MainThread]: Command end result
[0m02:48:00.861271 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/dbt_project/target/manifest.json
[0m02:48:00.866037 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/dbt_project/target/semantic_manifest.json
[0m02:48:00.874226 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/dbt_project/target/run_results.json
[0m02:48:00.874999 [info ] [MainThread]: 
[0m02:48:00.876031 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:48:00.877052 [info ] [MainThread]: 
[0m02:48:00.878054 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m02:48:00.879544 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.9075284, "process_in_blocks": "0", "process_kernel_time": 0.181158, "process_mem_max_rss": "221960", "process_out_blocks": "0", "process_user_time": 3.371561}
[0m02:48:00.880629 [debug] [MainThread]: Command `dbt run` succeeded at 02:48:00.880495 after 7.91 seconds
[0m02:48:00.881534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdc01f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdfacd7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3bdf7fcb90>]}
[0m02:48:00.882441 [debug] [MainThread]: Flushing usage events
[0m02:48:02.386003 [debug] [MainThread]: An error was encountered while trying to flush usage events
